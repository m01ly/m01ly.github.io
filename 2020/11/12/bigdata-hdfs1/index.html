<!DOCTYPE html><html lang="zh-Hans"><head><!--[if IE]><style>body{display:none;}</style><script>alert('IE浏览器下无法展示效果，请更换浏览器！');var headNode=document.getElementsByTagName('head')[0];var refresh=document.createElement('meta');refresh.setAttribute('http-equiv','Refresh');refresh.setAttribute('Content','0; url=http://outdatedbrowser.com/');headNode.appendChild(refresh);</script><![endif]--><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="m01ly"><meta name="description" content="1 前言本文来搭建hadoop集群，准备三台服务器，分别为hadoop102,hadoop103,hadoop104.其中hadoop 采用3.1.3版本，jdk      采用1.8.0_212  。 2 准备工作2.1 映射为了方便直接通过主机名去访问，下面进行映射 1）修改克隆机主机名，以下以hadoop102举例说明 （1）修改主机名称，：修改&#x2F;etc&#x2F;hostname文件 [root@h"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用"><meta property="og:url" content="https://m01ly.github.io/2020/11/12/bigdata-hdfs1/index.html"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="1 前言本文来搭建hadoop集群，准备三台服务器，分别为hadoop102,hadoop103,hadoop104.其中hadoop 采用3.1.3版本，jdk      采用1.8.0_212  。 2 准备工作2.1 映射为了方便直接通过主机名去访问，下面进行映射 1）修改克隆机主机名，以下以hadoop102举例说明 （1）修改主机名称，：修改&#x2F;etc&#x2F;hostname文件 [root@h"><meta property="og:locale"><meta property="og:image" content="https://m01ly.github.io/2020/11/12/bigdata-hdfs1/1636709256729.png"><meta property="article:published_time" content="2020-11-12T08:50:28.000Z"><meta property="article:modified_time" content="2021-12-01T06:44:50.144Z"><meta property="article:author" content="m01ly"><meta property="article:tag" content="Hadoop"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://m01ly.github.io/2020/11/12/bigdata-hdfs1/1636709256729.png"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="shortcut icon" href="/favicon.ico"><link href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css" rel="stylesheet"><link rel="stylesheet" href="/css/style.css"><title>Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用 | Hexo</title><script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"><script src="//cdn.bootcss.com/aos/2.2.0/aos.js"></script><script>var yiliaConfig={fancybox:!0,isHome:!1,isPost:!0,isArchive:!1,isTag:!1,isCategory:!1,fancybox_js:"//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js",search:!0}</script><script>yiliaConfig.jquery_ui=[!1]</script><script>yiliaConfig.rootUrl="/"</script><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/rss+xml">
<link rel="stylesheet" href="/css/prism-a11y-dark.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="container"><div class="left-col"><div class="intrude-less"><header id="header" class="inner"><a href="/" class="profilepic"><img src="/img/avatar.jpg"></a><hgroup><h1 class="header-author"><a href="/">m01ly</a></h1></hgroup><p class="header-subtitle">人生在世，全靠命</p><form id="search-form"><input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false"> <i class="fa fa-times" onclick="resetSearch()"></i></form><div id="local-search-result"></div><p class="no-result">No results found <i class="fa fa-spinner fa-pulse"></i></p><div id="switch-btn" class="switch-btn"><div class="icon"><div class="icon-ctn"><div class="icon-wrap icon-house" data-idx="0"><div class="birdhouse"></div><div class="birdhouse_holes"></div></div><div class="icon-wrap icon-ribbon hide" data-idx="1"><div class="ribbon"></div></div><div class="icon-wrap icon-link hide" data-idx="2"><div class="loopback_l"></div><div class="loopback_r"></div></div><div class="icon-wrap icon-me hide" data-idx="3"><div class="user"></div><div class="shoulder"></div></div></div></div><div class="tips-box hide"><div class="tips-arrow"></div><ul class="tips-inner"><li>菜单</li><li>标签</li><li>友情链接</li><li>目标</li></ul></div></div><div id="switch-area" class="switch-area"><div class="switch-wrap"><section class="switch-part switch-part1"><nav class="header-menu"><ul><li><a href="/">主页</a></li><li><a href="/archives/">所有文章</a></li><li><a href="/tags/">标签云</a></li><li><a href="/about/">简历</a></li></ul></nav><nav class="header-nav"><ul class="social"><a class="fa GitHub" target="_blank" rel="noopener" href="https://github.com/m01ly" title="GitHub"></a> <a class="fa RSS" href="/atom.xml" title="RSS"></a> <a class="fa 网易云音乐" target="_blank" rel="noopener" href="https://music.163.com/" title="网易云音乐"></a></ul><ul class="social"><div class="donateIcon-position"><p style="display:block"><a class="donateIcon" href="javascript:void(0)" onmouseout='var qr=document.getElementById("donate");qr.style.display="none"' onmouseenter='var qr=document.getElementById("donate");qr.style.display="block"'>赏</a></p><div id="donate"><img id="multipay" src="/img/multipay.png" width="250px" alt="m01ly Multipay"><div class="triangle"></div></div></div></ul></nav></section><section class="switch-part switch-part2"><div class="widget tagcloud" id="js-tagcloud"><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/HBase/" rel="tag">HBase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TLS/" rel="tag">TLS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Zookeeper/" rel="tag">Zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/" rel="tag">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/" rel="tag">kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqoop/" rel="tag">sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%81%E4%B8%9A%E5%AE%89%E5%85%A8%E5%BB%BA%E8%AE%BE/" rel="tag">企业安全建设</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E5%85%A8%E6%89%AB%E6%8F%8F/" rel="tag">安全扫描</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/" rel="tag">安装教程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%B9%E5%99%A8%E6%95%99%E7%A8%8B/" rel="tag">容器教程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" rel="tag">密码学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/" rel="tag">插件开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E4%BB%93%E9%87%87%E9%9B%86%E9%A1%B9%E7%9B%AE/" rel="tag">数仓采集项目</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/" rel="tag">日志管理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/" rel="tag">流量分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/" rel="tag">渗透测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/" rel="tag">漏洞扫描</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%BB%E5%8A%A8%E5%AE%89%E5%85%A8/" rel="tag">移动安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%B6%E5%9C%BAwriteup/" rel="tag">靶场writeup</a></li></ul></div></section><section class="switch-part switch-part3"><div id="js-friends"><a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/TechCatsLab">TechCatsLab</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://yangchenglong11.github.io">YangChengLong</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://jsharkc.github.io">LiuJiaChang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="http://blog.yusank.space">YusanKurban</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://blog.lizebang.top">Lizebang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/sunanxiang">SunAnXiang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/DoubleWoodH">LinHao</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://blog.littlechao.top">ShiChao</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/Txiaozhe">TangXiaoJi</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/LLLeon">JiaChenHui</a></div></section><section class="switch-part switch-part4"><div id="js-aboutme">不悲不喜，不卑不亢，努力成为一个更好的程序猿！</div></section></div></div></header></div></div><div class="hide-left-col" title="隐藏侧栏"><i class="fa fa-angle-double-left"></i></div><div class="mid-col"><nav id="mobile-nav"><div class="overlay"><div class="slider-trigger"></div><h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">m01ly</a></h1></div><div class="intrude-less"><header id="header" class="inner"><a href="/" class="profilepic"><img src="/img/avatar.jpg"></a><hgroup><h1 class="header-author"><a href="/" title="回到主页">m01ly</a></h1></hgroup><p class="header-subtitle">人生在世，全靠命</p><nav class="header-menu"><ul><li><a href="/">主页</a></li><li><a href="/archives/">所有文章</a></li><li><a href="/tags/">标签云</a></li><li><a href="/about/">简历</a></li><div class="clearfix"></div></ul></nav><nav class="header-nav"><ul class="social"><a class="fa GitHub" target="_blank" href="https://github.com/m01ly" title="GitHub"></a> <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a> <a class="fa 网易云音乐" target="_blank" href="https://music.163.com/" title="网易云音乐"></a></ul></nav></header></div><link class="menu-list" tags="标签" friends="友情链接" about="目标"></nav><div class="body-wrap"><article id="post-bigdata-hdfs1" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-meta"><a href="/2020/11/12/bigdata-hdfs1/" class="article-date"><time class="published" datetime="2020-11-12T08:50:28.000Z" itemprop="datePublished">2020-11-12 发布</time> <time class="updated" datetime="2021-12-01T06:44:50.144Z" itemprop="dateUpdated">2021-12-01 更新</time></a></div><div class="article-inner"><input type="hidden" class="isFancy"><header class="article-header"><h1 class="article-title" itemprop="name">Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用</h1></header><div class="article-info article-info-post"><div class="article-count"><div class="article-category tagcloud"><a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</a></div><div class="article-tag tagcloud"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li></ul></div><span class="post-count">总字数5.4k</span> <span class="post-count">预计阅读26分钟</span></div><div class="clearfix"></div></div><div class="article-entry" itemprop="articleBody"><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h2><p>本文来搭建hadoop集群，准备三台服务器，分别为hadoop102,hadoop103,hadoop104.其中hadoop 采用3.1.3版本，jdk 采用1.8.0_212 。</p><h2 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2 准备工作"></a>2 准备工作</h2><h3 id="2-1-映射"><a href="#2-1-映射" class="headerlink" title="2.1 映射"></a>2.1 映射</h3><p>为了方便直接通过主机名去访问，下面进行映射</p><p>1）修改克隆机主机名，以下以hadoop102举例说明</p><p>（1）修改主机名称，：修改/etc/hostname文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim /etc/hostname</span>
hadoop102<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）配置linux克隆机主机名称映射hosts文件，打开/etc/hosts</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim /etc/hosts</span>
192.168.1.102 hadoop102
192.168.1.103 hadoop103
192.168.1.104 hadoop104<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）重启hadoop102</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）修改windows的主机映射文件（hosts文件）</p><p>操作系统是window10，先拷贝出来，修改保存以后，再覆盖即可</p><p>（a）进入C:\Windows\System32\drivers\etc路径</p><p>（b）拷贝hosts文件到桌面</p><p>（c）打开桌面hosts文件并添加如下内容</p><pre><code>192.168.1.102 hadoop102
192.168.1.103 hadoop103
192.168.1.104 hadoop104</code></pre><p>（d）将桌面hosts文件覆盖C:\Windows\System32\drivers\etc路径hosts文件</p><h3 id="2-2-安装JDK"><a href="#2-2-安装JDK" class="headerlink" title="2.2 安装JDK"></a>2.2 安装JDK</h3><p>1）在Linux系统下的opt目录中下载软件包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">ls</span> /opt/software/
jdk-8u212-linux-x64.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）解压JDK到/opt/module目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）配置JDK环境变量</p><p>​ （1）新建/etc/profile.d/my_env.sh文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><p>#JAVA_HOME</p><p>export JAVA_HOME=/opt/module/jdk1.8.0_212</p><p>export PATH=$PATH:$JAVA_HOME/bin</p><p>​ （2）保存后退出:wq</p><p>​ （3）source一下/etc/profile文件，让新的环境变量PATH生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）测试JDK是否安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ java -version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果能看到以下结果，则代表Java安装成功。</p><p>java version “1.8.0_212”</p><p>注意：重启（如果java -version可以用就不用重启）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-3-SSH免密码登录"><a href="#2-3-SSH免密码登录" class="headerlink" title="2.3 SSH免密码登录"></a>2.3 SSH免密码登录</h3><p>免密登录原理如下图所示：</p><p><img src="/2020/11/12/bigdata-hdfs1/1636709256729.png" alt="1636709256729"></p><p>具体操作如下：</p><p>1）生成公钥和私钥：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 .ssh<span class="token punctuation">]</span>$ ssh-keygen -t rsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p><p>2）将公钥拷贝到要免密登录的目标机器上</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop102</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop103</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop104</p><p>这样hadoop102登录到hadoop103和hadoop104就不需要输入密码了。可以相互登录 还需要在hadoop103和hadoop104上做同样的操作。</p><h3 id="2-4-编写集群分发脚本"><a href="#2-4-编写集群分发脚本" class="headerlink" title="2.4 编写集群分发脚本"></a>2.4 编写集群分发脚本</h3><p>为了在集群中各个主机中文件拷贝方便，我们可以写个脚本用于三台主机中分发文件。</p><p>（1）需求：循环复制文件到所有节点的相同目录下</p><p>（2）需求分析：</p><p>（a）rsync命令原始拷贝：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">rsync</span> -av   /opt/module     root@hadoop103:/opt/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（b）期望脚本：</p><p>xsync要同步的文件名称</p><p>（c）说明：在/home/root/bin这个目录下存放的脚本，root用户可以在系统任何地方直接执行。</p><p>（3）脚本实现</p><p>（a）在/home/root/bin目录下创建xsync文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root
<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> bin
<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> bin
<span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ vim xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在该文件中编写如下代码</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bash
\#1. 判断参数个数
if [ $# -lt 1 ]
then
 echo Not Enough Arguement!
 exit;
fi
\#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
 echo ==================== $host ====================
 \#3. 遍历所有目录，挨个发送
 for file in $@
 do
  \#4. 判断文件是否存在
  if [ -e $file ]
  then
   \#5. 获取父目录
   pdir=$(cd -P $(dirname $file); pwd)
   \#6. 获取当前文件的名称
   fname=$(basename $file)
   ssh $host "mkdir -p $pdir"
   rsync -av $pdir/$fname $host:$pdir
  else
   echo $file does not exists!
  fi
 done
done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）修改脚本 xsync 具有执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> +x xsync<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（c）将脚本复制到/bin中，以便全局调用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">cp</span> xsync /bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（d）测试脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ xsync /home/root/bin
<span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">sudo</span> xsync /bin/xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="3-安装hadoop"><a href="#3-安装hadoop" class="headerlink" title="3 安装hadoop"></a>3 安装hadoop</h2><p>Hadoop下载地址：<a target="_blank" rel="noopener" href="https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/">https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/</a></p><p>1）下载hadoop并进入到Hadoop安装包路径下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /opt/software/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）解压安装文件到/opt/module下面</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf hadoop-3.1.3.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）查看是否解压成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">ls</span> /opt/module/
hadoop-3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4）将Hadoop添加到环境变量</p><p>​ （1）获取Hadoop安装路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">pwd</span>
/opt/module/hadoop-3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​ （2）打开/etc/profile.d/my_env.sh文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在my_env.sh文件末尾添加如下内容：（shift+g）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#HADOOP_HOME</span>
<span class="token function">export</span> HADOOP_HOME<span class="token operator">=</span>/opt/module/hadoop-3.1.3
<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HADOOP_HOME</span>/bin
<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HADOOP_HOME</span>/sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）保存后退出:wq</p><p>（4）让修改后的文件生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）测试是否安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop version
Hadoop 3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）重启(如果Hadoop命令不能用再重启)</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">sync</span>
<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="4-Hadoop运行模式启动"><a href="#4-Hadoop运行模式启动" class="headerlink" title="4  Hadoop运行模式启动"></a>4 Hadoop运行模式启动</h2><p>Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。本地允许模式很简单，公司用的大部分是完全分布式模式。</p><p>Hadoop官方网站：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p><h3 id="4-1-本地运行模式"><a href="#4-1-本地运行模式" class="headerlink" title="4.1 本地运行模式"></a>4.1 本地运行模式</h3><p>下面展示hadoop本地运行模式，并成功计算一个wordcout功能</p><p>1）创建在hadoop-3.1.3文件下面创建一个wcinput文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> wcinpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）在wcinput文件下创建一个word.txt文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">cd</span> wcinput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）编辑word.txt文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 wcinput<span class="token punctuation">]</span>$ vim word.txt
hadoop yarn
hadoop mapreduce
root
root<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存退出：：wq</p><p>4）回到Hadoop目录/opt/module/hadoop-3.1.3</p><p>5）执行程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）查看结果</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">cat</span> wcoutput/part-r-00000
root 2
hadoop 2
mapreduce    1
yarn  1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-完全分布式模式"><a href="#4-2-完全分布式模式" class="headerlink" title="4.2 完全分布式模式"></a>4.2 完全分布式模式</h3><h4 id="4-2-1-集群规划"><a href="#4-2-1-集群规划" class="headerlink" title="4.2.1 集群规划"></a>4.2.1 集群规划</h4><p>准备三台机器，分别安装HDFS和yarn。</p><table><thead><tr><th></th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode DataNode</td><td>DataNode</td><td>SecondaryNameNode DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager NodeManager</td><td>NodeManager</td></tr></tbody></table><p>注意：NameNode和SecondaryNameNode不要安装在同一台服务器</p><p>注意：ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</p><h4 id="4-2-2-配置文件说明"><a href="#4-2-2-配置文件说明" class="headerlink" title="4.2.2 配置文件说明"></a>4.2.2 配置文件说明</h4><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p><p>（1）默认配置文件：</p><table><thead><tr><th>要获取的默认文件</th><th>文件存放在Hadoop的jar包中的位置</th></tr></thead><tbody><tr><td>[core-default.xml]</td><td>hadoop-common-3.1.3.jar/ core-default.xml</td></tr><tr><td>[hdfs-default.xml]</td><td>hadoop-hdfs-3.1.3.jar/ hdfs-default.xml</td></tr><tr><td>[yarn-default.xml]</td><td>hadoop-yarn-common-3.1.3.jar/ yarn-default.xml</td></tr><tr><td>[mapred-default.xml]</td><td>hadoop-mapreduce-client-core-3.1.3.jar/ mapred-default.xml</td></tr></tbody></table><p>2）自定义配置文件：</p><p>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p><p>（3）常用端口号说明</p><table><thead><tr><th>Daemon</th><th>App</th><th>Hadoop2</th><th>Hadoop3</th></tr></thead><tbody><tr><td>NameNode Port</td><td>Hadoop HDFS NameNode</td><td>8020 / 9000</td><td>9820</td></tr><tr><td></td><td>Hadoop HDFS NameNode HTTP UI</td><td>50070</td><td>9870</td></tr><tr><td>Secondary NameNode Port</td><td>Secondary NameNode</td><td>50091</td><td>9869</td></tr><tr><td></td><td>Secondary NameNode HTTP UI</td><td>50090</td><td>9868</td></tr><tr><td>DataNode Port</td><td>Hadoop HDFS DataNode IPC</td><td>50020</td><td>9867</td></tr><tr><td></td><td>Hadoop HDFS DataNode</td><td>50010</td><td>9866</td></tr><tr><td></td><td>Hadoop HDFS DataNode HTTP UI</td><td>50075</td><td>9864</td></tr></tbody></table><h4 id="4-2-3-配置集群"><a href="#4-2-3-配置集群" class="headerlink" title="4.2.3 配置集群"></a>4.2.3 配置集群</h4><p>（1）核心配置文件：配置core-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> <span class="token variable">$HADOOP_HOME</span>/etc/hadoop
<span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
  <span class="token comment" spellcheck="true">&lt;!-- 指定NameNode的地址 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://hadoop102:9820<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- 指定hadoop数据的存储目录 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-3.1.3/data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- 配HDFS网页登录使用的静态用户为root --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理访问的主机节点 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理用户所属组 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理的用户--></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）HDFS配置文件:配置hdfs-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim hdfs-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
  <span class="token comment" spellcheck="true">&lt;!-- nn web端访问地址--></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop102:9870<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token comment" spellcheck="true">&lt;!-- 2nn web端访问地址--></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop104:9868<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）YARN配置文件:配置yarn-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim yarn-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
  <span class="token comment" spellcheck="true">&lt;!-- 指定MR走shuffle --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- 指定ResourceManager的地址--></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop103<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- 环境变量的继承 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.env-whitelist<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- yarn容器允许分配的最大最小内存 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.minimum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>512<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.maximum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>4096<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- yarn容器允许管理的物理内存大小 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.resource.memory-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>4096<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token comment" spellcheck="true">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）MapReduce配置文件:配置mapred-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim mapred-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
  <span class="token comment" spellcheck="true">&lt;!-- 指定MapReduce程序运行在Yarn上 --></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）在集群上分发配置好的Hadoop配置文件，将配置文件同步到hadoop103和hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）去103和104上查看文件分发情况</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop103 ~<span class="token punctuation">]</span>$ <span class="token function">cat</span> /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml
<span class="token punctuation">[</span>root@hadoop104 ~<span class="token punctuation">]</span>$ <span class="token function">cat</span> /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="4-2-4-启动集群"><a href="#4-2-4-启动集群" class="headerlink" title="4.2.4  启动集群"></a>4.2.4 启动集群</h4><p><strong>1）配置workers</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在该文件中增加如下内容：</p><pre><code>hadoop102
hadoop103
hadoop104</code></pre><p>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p><p>同步所有节点配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ xsync /opt/module/hadoop-3.1.3/etc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>2）启动集群</strong></p><p>​ （1）如果集群是第一次启动，需要在hadoop102节点格式化NameNode（注意格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。）</p><pre><code>[root@hadoop102 ~]$ hdfs namenode -format</code></pre><p>（2）启动HDFS</p><pre><code>[root@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</code></pre><p>（3）在配置了ResourceManager的节点（hadoop103）启动YARN</p><pre><code>[root@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</code></pre><p>（4）Web端查看HDFS的NameNode</p><p>​ （a）浏览器中输入：<a target="_blank" rel="noopener" href="http://hadoop102:9870/">http://hadoop102:9870</a></p><p>​ （b）查看HDFS上存储的数据信息</p><p>（5）Web端查看YARN的ResourceManager</p><p>​ （a）浏览器中输入：<a target="_blank" rel="noopener" href="http://hadoop103:8088/">http://hadoop103:8088</a></p><p>​ （b）查看YARN上运行的Job信息</p><h4 id="4-2-5-集群基本测试"><a href="#4-2-5-集群基本测试" class="headerlink" title="4.2.5 集群基本测试"></a>4.2.5 集群基本测试</h4><p>HDFS相当于一个文件存储框架，搭好集群后，可以在集群去对文件进行操作，上传，下载，删除，查看等。</p><p><strong>（1）上传文件到集群</strong></p><p>​ 上传小文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -mkdir /input
<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -put <span class="token variable">$HADOOP_HOME</span>/wcinput/word.txt /input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​ 上传大文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -put  /opt/software/jdk-8u212-linux-x64.tar.gz  /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>（2）上传文件后查看文件存放在什么位置</strong></p><p>（a）查看HDFS文件存储路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 subdir0<span class="token punctuation">]</span>$ <span class="token function">pwd</span>
/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-938951106-192.168.10.107-1495462844069/current/finalized/subdir0/subdir0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（b）查看HDFS在磁盘存储文件内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 subdir0<span class="token punctuation">]</span>$ <span class="token function">cat</span> blk_1073741825
hadoop yarn
hadoop mapreduce 
root
root<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>（3）下载</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop104 software<span class="token punctuation">]</span>$ hadoop fs -get /jdk-8u212-linux-x64.tar.gz ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>（4）执行wordcount程序</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-6-集群启动-停止方式总结"><a href="#4-2-6-集群启动-停止方式总结" class="headerlink" title="4.2.6 集群启动/停止方式总结"></a>4.2.6 集群启动/停止方式总结</h4><p><strong>1）各个服务组件逐一启动/停止</strong></p><p>​ （1）分别启动/停止HDFS组件</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs --daemon start/stop namenode/datanode/secondarynamenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​ （2）启动/停止YARN</p><pre class="line-numbers language-bash"><code class="language-bash">yarn --daemon start/stop resourcemanager/nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）各个模块分开启动/停止（配置ssh是前提）常用</p><p>​ （1）整体启动/停止HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">start-dfs.sh/stop-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​ （2）整体启动/停止YARN</p><pre class="line-numbers language-bash"><code class="language-bash">start-yarn.sh/stop-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-7-编写hadoop集群常用脚本"><a href="#4-2-7-编写hadoop集群常用脚本" class="headerlink" title="4.2.7 编写hadoop集群常用脚本"></a>4.2.7 编写hadoop集群常用脚本</h4><p><strong>(1）查看三台服务器java进程脚本：jpsall</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root/bin
<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ vim jpsall<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后输入</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>
<span class="token keyword">for</span> host <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
<span class="token keyword">do</span>
​    <span class="token keyword">echo</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> <span class="token variable">$host</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
​    <span class="token function">ssh</span> <span class="token variable">$host</span> jps <span class="token variable">$@</span> <span class="token operator">|</span> <span class="token function">grep</span> -v Jps
<span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存后退出，然后赋予脚本执行权限</p><p>[root@hadoop102 bin]$ chmod +x jpsall</p><p><strong>（2）hadoop集群启停脚本（包含hdfs，yarn，historyserver）：</strong>myhadoop.sh</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root/bin
<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ vim myhadoop.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后输入</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>

<span class="token keyword">if</span> <span class="token punctuation">[</span> $<span class="token comment" spellcheck="true"># -lt 1 ]</span>
<span class="token keyword">then</span>
  <span class="token keyword">echo</span> <span class="token string">"No Args Input..."</span>
  <span class="token keyword">exit</span> <span class="token punctuation">;</span>
<span class="token keyword">fi</span>
<span class="token keyword">case</span> <span class="token variable">$1</span> <span class="token keyword">in</span>
<span class="token string">"start"</span><span class="token punctuation">)</span>
​    <span class="token keyword">echo</span> <span class="token string">" =================== 启动 hadoop集群 ==================
​    echo "</span> --------------- 启动 hdfs ---------------<span class="token string">"
​    ssh hadoop102 "</span>/opt/module/hadoop-3.1.3/sbin/start-dfs.sh<span class="token string">"
​    echo "</span> --------------- 启动 yarn ---------------<span class="token string">"
​    ssh hadoop103 "</span>/opt/module/hadoop-3.1.3/sbin/start-yarn.sh<span class="token string">"
​    echo "</span> --------------- 启动 historyserver ---------------<span class="token string">"
​    ssh hadoop102 "</span>/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver<span class="token string">"
;;

"</span>stop<span class="token string">")
​    echo "</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> 关闭 hadoop集群 <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 historyserver ---------------"</span>
​    <span class="token function">ssh</span> hadoop102 <span class="token string">"/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"</span>
​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 yarn ---------------"</span>
​    <span class="token function">ssh</span> hadoop103 <span class="token string">"/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"</span>
​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 hdfs ---------------"</span>
​    <span class="token function">ssh</span> hadoop102 <span class="token string">"/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"</span>

<span class="token punctuation">;</span><span class="token punctuation">;</span>

*<span class="token punctuation">)</span>
  <span class="token keyword">echo</span> <span class="token string">"Input Args Error..."</span>

<span class="token punctuation">;</span><span class="token punctuation">;</span>
esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存后退出，然后赋予脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> +x myhadoop.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）分发/home/root/bin目录，保证自定义脚本在三台机器上都可以使用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ xsync /home/root/bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-hdfs常用shell操作"><a href="#5-hdfs常用shell操作" class="headerlink" title="5 hdfs常用shell操作"></a>5 hdfs常用shell操作</h2><h3 id="5-1-基本语法"><a href="#5-1-基本语法" class="headerlink" title="5.1 基本语法"></a>5.1 基本语法</h3><p>hadoop fs 具体命令 OR hdfs dfs 具体命令</p><p>两个是完全相同的。</p><h3 id="5-2-命令大全"><a href="#5-2-命令大全" class="headerlink" title="5.2 命令大全"></a>5.2 命令大全</h3><p>查看所有命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ bin/hadoop fs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="5-3-常用命令实操"><a href="#5-3-常用命令实操" class="headerlink" title="5.3 常用命令实操"></a>5.3 常用命令实操</h3><h4 id="5-3-1-准备工作"><a href="#5-3-1-准备工作" class="headerlink" title="5.3.1 准备工作"></a>5.3.1 准备工作</h4><p>1）启动Hadoop集群（方便后续的测试）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-dfs.sh
<span class="token punctuation">[</span>root@hadoop103 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）-help：输出这个命令参数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -help <span class="token function">rm</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="5-3-2-上传"><a href="#5-3-2-上传" class="headerlink" title="5.3.2 上传"></a>5.3.2 上传</h4><p>1）-moveFromLocal：从本地剪切粘贴到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">touch</span> kongming.txt
<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -moveFromLocal ./kongming.txt /sanguo/shuguo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -copyFromLocal README.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-appendToFile：追加一个文件到已经存在的文件末尾</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">touch</span> liubei.txt
<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">vi</span> liubei.txt
san gu mao lu
<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -appendToFile liubei.txt /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>4）-put：等同于copyFromLocal</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -put ./liubei.txt /user/root/test/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="5-3-3-下载"><a href="#5-3-3-下载" class="headerlink" title="5.3.3 下载"></a>5.3.3 下载</h4><p>1）-copyToLocal：从HDFS拷贝到本地</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -copyToLocal /sanguo/shuguo/kongming.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）-get：等同于copyToLocal，就是从HDFS下载文件到本地</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -get /sanguo/shuguo/kongming.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-getmerge：合并下载多个文件，比如HDFS的目录 /user/root/test下有多个文件:log.1, log.2,log.3,…</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -getmerge /user/root/test/* ./zaiyiqi.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="5-3-4-HDFS直接操作"><a href="#5-3-4-HDFS直接操作" class="headerlink" title="5.3.4 HDFS直接操作"></a>5.3.4 HDFS直接操作</h4><p>1）-ls: 显示目录信息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -ls /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）-mkdir：在HDFS上创建目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mkdir -p /sanguo/shuguo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-cat：显示文件内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -cat /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -chmod 666 /sanguo/shuguo/kongming.txt
<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -chown root:root  /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>5）-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -cp /sanguo/shuguo/kongming.txt /zhuge.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）-mv：在HDFS目录中移动文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mv /zhuge.txt /sanguo/shuguo/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）-tail：显示一个文件的末尾1kb的数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -tail /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）-rm：删除文件或文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -rm /user/root/test/jinlian2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>9）-rmdir：删除空目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mkdir /test
<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -rmdir /test<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>10）-du统计文件夹的大小信息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -du -s -h /user/root/test<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>11）-setrep：设置HDFS中文件的副本数量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -setrep 10 /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。</p><h1 id="6-hdfs的API操作"><a href="#6-hdfs的API操作" class="headerlink" title="6 hdfs的API操作"></a>6 hdfs的API操作</h1><h2 id="6-1-准备Windows关于Hadoop的开发环境"><a href="#6-1-准备Windows关于Hadoop的开发环境" class="headerlink" title="6.1 准备Windows关于Hadoop的开发环境"></a>6.1 准备Windows关于Hadoop的开发环境</h2><p>1）找到资料目录下的Windows依赖目录，打开：</p><p>选择Hadoop-3.1.0，拷贝到其他地方(比如d:)。<br>2）配置HADOOP_HOME环境变量。</p><p>3）配置Path环境变量。然后重启电脑</p><p>4）创建一个Maven工程HdfsClientDemo，并导入相应的依赖坐标+日志添加</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>4.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>log4j-slf4j-impl<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span>
在项目的src/main/resources目录下，新建一个文件，命名为“log4j2.xml”，在文件中填入
<span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Configuration</span> <span class="token attr-name">status</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>error<span class="token punctuation">"</span></span> <span class="token attr-name">strict</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>XMLConfig<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appenders</span><span class="token punctuation">></span></span>
        <span class="token comment" spellcheck="true">&lt;!-- 类型名为Console，名称为必须属性 --></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appender</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>Console<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
            <span class="token comment" spellcheck="true">&lt;!-- 布局为PatternLayout的方式，
            输出样式为[INFO] [2018-01-22 17:34:01][org.test.Console]I'm here --></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Layout</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>PatternLayout<span class="token punctuation">"</span></span>
                    <span class="token attr-name">pattern</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>[%p] [%d&amp;#123;yyyy-MM-dd HH:mm:ss&amp;#125;][%c&amp;#123;10&amp;#125;]%m%n<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appender</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appenders</span><span class="token punctuation">></span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Loggers</span><span class="token punctuation">></span></span>
        <span class="token comment" spellcheck="true">&lt;!-- 可加性为false --></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Logger</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>test<span class="token punctuation">"</span></span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span> <span class="token attr-name">additivity</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Logger</span><span class="token punctuation">></span></span>

        <span class="token comment" spellcheck="true">&lt;!-- root loggerConfig设置 --></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Root</span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Root</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Loggers</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）创建包名：com.atguigu.hdfs<br>6）创建HdfsClient类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClient</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    
<span class="token annotation punctuation">@Test</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testMkdirs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 1 获取文件系统</span>
        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">// 配置在集群上运行</span>
        <span class="token comment" spellcheck="true">// configuration.set("fs.defaultFS", "hdfs://hadoop102:9820");</span>
        <span class="token comment" spellcheck="true">// FileSystem fs = FileSystem.get(configuration);</span>

        FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 2 创建目录</span>
        fs<span class="token punctuation">.</span><span class="token function">mkdirs</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/1108/daxian/banzhang"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 3 关闭资源</span>
        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>
<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7）执行程序<br>运行时需要配置用户名称</p><p>客户端去操作HDFS时，是有一个用户身份的。默认情况下，HDFS客户端API会从JVM中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=atguigu，atguigu为用户名称。</p><h2 id="6-2-HDFS的API操作"><a href="#6-2-HDFS的API操作" class="headerlink" title="6.2 HDFS的API操作"></a>6.2 HDFS的API操作</h2><h3 id="6-2-1-HDFS文件上传（测试参数优先级）"><a href="#6-2-1-HDFS文件上传（测试参数优先级）" class="headerlink" title="6.2.1 HDFS文件上传（测试参数优先级）"></a>6.2.1 HDFS文件上传（测试参数优先级）</h3><p>1）编写源代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyFromLocalFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 1 获取文件系统</span>
        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"dfs.replication"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:8020"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 2 上传文件</span>
        fs<span class="token punctuation">.</span><span class="token function">copyFromLocalFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"e:/banzhang.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/banzhang.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 3 关闭资源</span>
        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"over"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
｝<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）将hdfs-site.xml拷贝到项目的根目录下</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）参数优先级<br>参数优先级排序：（1）客户端代码中设置的值 &gt;（2）ClassPath下的用户自定义配置文件 &gt;（3）然后是服务器的自定义配置(xxx-site.xml) &gt;（4）服务器的默认配置(xxx-default.xml)</p><h3 id="6-2-2-HDFS文件下载"><a href="#6-2-2-HDFS文件下载" class="headerlink" title="6.2.2 HDFS文件下载"></a>6.2.2 HDFS文件下载</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyToLocalFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 1 获取文件系统</span>
        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 2 执行下载操作</span>
        <span class="token comment" spellcheck="true">// boolean delSrc 指是否将原文件删除</span>
        <span class="token comment" spellcheck="true">// Path src 指要下载的文件路径</span>
        <span class="token comment" spellcheck="true">// Path dst 指将文件下载到的路径</span>
        <span class="token comment" spellcheck="true">// boolean useRawLocalFileSystem 是否开启文件校验</span>
        fs<span class="token punctuation">.</span><span class="token function">copyToLocalFile</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/banzhang.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"e:/banhua.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 3 关闭资源</span>
        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-3-HDFS删除文件和目录"><a href="#6-2-3-HDFS删除文件和目录" class="headerlink" title="6.2.3 HDFS删除文件和目录"></a>6.2.3 HDFS删除文件和目录</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDelete</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>
    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment" spellcheck="true">// 2 执行删除</span>
    fs<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/0508/"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment" spellcheck="true">// 3 关闭资源</span>
    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-4-HDFS文件更名和移动"><a href="#6-2-4-HDFS文件更名和移动" class="headerlink" title="6.2.4 HDFS文件更名和移动"></a>6.2.4 HDFS文件更名和移动</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testRename</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>
    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 

    <span class="token comment" spellcheck="true">// 2 修改文件名称</span>
    fs<span class="token punctuation">.</span><span class="token function">rename</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/banzhang.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/banhua.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment" spellcheck="true">// 3 关闭资源</span>
    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-5-HDFS文件详情查看"><a href="#6-2-5-HDFS文件详情查看" class="headerlink" title="6.2.5 HDFS文件详情查看"></a>6.2.5 HDFS文件详情查看</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//查看文件名称、权限、长度、块信息</span>
<span class="token annotation punctuation">@Test</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

    <span class="token comment" spellcheck="true">// 1获取文件系统</span>
    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 

    <span class="token comment" spellcheck="true">// 2 获取文件详情</span>
    RemoteIterator<span class="token operator">&lt;</span>LocatedFileStatus<span class="token operator">></span> listFiles <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listFiles</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">while</span><span class="token punctuation">(</span>listFiles<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
        LocatedFileStatus status <span class="token operator">=</span> listFiles<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 输出详情</span>
        <span class="token comment" spellcheck="true">// 文件名称</span>
        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">// 长度</span>
        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getLen</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">// 权限</span>
        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment" spellcheck="true">// 分组</span>
        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getGroup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 获取存储的块信息</span>
        BlockLocation<span class="token punctuation">[</span><span class="token punctuation">]</span> blockLocations <span class="token operator">=</span> status<span class="token punctuation">.</span><span class="token function">getBlockLocations</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token keyword">for</span> <span class="token punctuation">(</span>BlockLocation blockLocation <span class="token operator">:</span> blockLocations<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

            <span class="token comment" spellcheck="true">// 获取块存储的主机节点</span>
            String<span class="token punctuation">[</span><span class="token punctuation">]</span> hosts <span class="token operator">=</span> blockLocation<span class="token punctuation">.</span><span class="token function">getHosts</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

            <span class="token keyword">for</span> <span class="token punctuation">(</span>String host <span class="token operator">:</span> hosts<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>host<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>
        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>

        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"-----------班长的分割线----------"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>

<span class="token comment" spellcheck="true">// 3 关闭资源</span>
fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-6-HDFS文件和文件夹判断"><a href="#6-2-6-HDFS文件和文件夹判断" class="headerlink" title="6.2.6 HDFS文件和文件夹判断"></a>6.2.6 HDFS文件和文件夹判断</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>


    <span class="token comment" spellcheck="true">// 1 获取文件配置信息</span>
    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment" spellcheck="true">// 2 判断是文件还是文件夹</span>
    FileStatus<span class="token punctuation">[</span><span class="token punctuation">]</span> listStatus <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listStatus</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token keyword">for</span> <span class="token punctuation">(</span>FileStatus fileStatus <span class="token operator">:</span> listStatus<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

        <span class="token comment" spellcheck="true">// 如果是文件</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>fileStatus<span class="token punctuation">.</span><span class="token function">isFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"f:"</span><span class="token operator">+</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"d:"</span><span class="token operator">+</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>
        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>

    <span class="token comment" spellcheck="true">// 3 关闭资源</span>
    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><link href="//src.wangriyu.wang/lib/Aplayer/APlayer.min.css" rel="stylesheet"><script src="//src.wangriyu.wang/lib/Aplayer/APlayer.min.js"></script><div id="aplayer"></div><script src="/js/player.js"></script></div></div><div class="copyright"><p><span>本文标题:</span><a href="/2020/11/12/bigdata-hdfs1/">Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用</a></p><p><span>文章作者:</span><a href="/" title="回到主页">m01ly</a></p><p><span>发布时间:</span>2020-11-12, 16:50:28</p><p><span>最后更新:</span>2021-12-01, 14:44:50</p><p><span>原始链接:</span><a class="post-url" href="/2020/11/12/bigdata-hdfs1/" title="Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用">https://m01ly.github.io/2020/11/12/bigdata-hdfs1/</a></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target="_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。</p></div><nav id="article-nav"><div id="article-nav-newer" class="article-nav-title"><a href="/2020/11/14/bigdata-hive1/">Hive学习笔记（一） Hive安装</a></div><div id="article-nav-older" class="article-nav-title"><a href="/2020/11/12/bigdata-hdfs/">Hadoop 教程（一）hadoop介绍</a></div></nav></article><div id="toc" class="toc-article"><strong class="toc-title">文章目录</strong><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%89%8D%E8%A8%80"><span class="toc-text">1 前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-text">2 准备工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%98%A0%E5%B0%84"><span class="toc-text">2.1 映射</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%AE%89%E8%A3%85JDK"><span class="toc-text">2.2 安装JDK</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-SSH%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95"><span class="toc-text">2.3 SSH免密码登录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E7%BC%96%E5%86%99%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="toc-text">2.4 编写集群分发脚本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%AE%89%E8%A3%85hadoop"><span class="toc-text">3 安装hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F%E5%90%AF%E5%8A%A8"><span class="toc-text">4 Hadoop运行模式启动</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-text">4.1 本地运行模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%A8%A1%E5%BC%8F"><span class="toc-text">4.2 完全分布式模式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92"><span class="toc-text">4.2.1 集群规划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E"><span class="toc-text">4.2.2 配置文件说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-3-%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="toc-text">4.2.3 配置集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-4-%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-text">4.2.4 启动集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-5-%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E6%B5%8B%E8%AF%95"><span class="toc-text">4.2.5 集群基本测试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-6-%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93"><span class="toc-text">4.2.6 集群启动&#x2F;停止方式总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-7-%E7%BC%96%E5%86%99hadoop%E9%9B%86%E7%BE%A4%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC"><span class="toc-text">4.2.7 编写hadoop集群常用脚本</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-hdfs%E5%B8%B8%E7%94%A8shell%E6%93%8D%E4%BD%9C"><span class="toc-text">5 hdfs常用shell操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95"><span class="toc-text">5.1 基本语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8"><span class="toc-text">5.2 命令大全</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%AE%9E%E6%93%8D"><span class="toc-text">5.3 常用命令实操</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-1-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-text">5.3.1 准备工作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-2-%E4%B8%8A%E4%BC%A0"><span class="toc-text">5.3.2 上传</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-3-%E4%B8%8B%E8%BD%BD"><span class="toc-text">5.3.3 下载</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-4-HDFS%E7%9B%B4%E6%8E%A5%E6%93%8D%E4%BD%9C"><span class="toc-text">5.3.4 HDFS直接操作</span></a></li></ol></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#6-hdfs%E7%9A%84API%E6%93%8D%E4%BD%9C"><span class="toc-text">6 hdfs的API操作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-%E5%87%86%E5%A4%87Windows%E5%85%B3%E4%BA%8EHadoop%E7%9A%84%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83"><span class="toc-text">6.1 准备Windows关于Hadoop的开发环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-HDFS%E7%9A%84API%E6%93%8D%E4%BD%9C"><span class="toc-text">6.2 HDFS的API操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-1-HDFS%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%EF%BC%88%E6%B5%8B%E8%AF%95%E5%8F%82%E6%95%B0%E4%BC%98%E5%85%88%E7%BA%A7%EF%BC%89"><span class="toc-text">6.2.1 HDFS文件上传（测试参数优先级）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-2-HDFS%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD"><span class="toc-text">6.2.2 HDFS文件下载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-3-HDFS%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95"><span class="toc-text">6.2.3 HDFS删除文件和目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-4-HDFS%E6%96%87%E4%BB%B6%E6%9B%B4%E5%90%8D%E5%92%8C%E7%A7%BB%E5%8A%A8"><span class="toc-text">6.2.4 HDFS文件更名和移动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-5-HDFS%E6%96%87%E4%BB%B6%E8%AF%A6%E6%83%85%E6%9F%A5%E7%9C%8B"><span class="toc-text">6.2.5 HDFS文件详情查看</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-6-HDFS%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%A4%E6%96%AD"><span class="toc-text">6.2.6 HDFS文件和文件夹判断</span></a></li></ol></li></ol></li></div><style>.left-col .switch-area,.left-col .switch-btn{display:none}.toc-level-6 i,.toc-level-6 ol{display:none!important}</style><input type="button" id="tocButton" value="隐藏目录" title="点击按钮隐藏或者显示文章目录"><script>yiliaConfig.toc=["隐藏目录","显示目录",!0],$(".left-col").is(":hidden")&&$("#tocButton").attr("value",yiliaConfig.toc[1])</script><div class="share"><link rel="stylesheet" type="text/css" href="/share/iconfont.css"><link rel="stylesheet" href="/share/spongebob.min.css" type="text/css" media="all"><div class="social_share"><ul id="social_list" class="social_icon_list"></ul></div><script>var shareConfig={title:"Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用",url:window.location.href,author:"m01ly",img:"https:/img/avatar.jpg"}</script><script src="/share/qrcode.min.js"></script><script src="/share/spongebob.min.js"></script></div><section id="comments" style="margin:2em;padding:2em;background:rgba(255,255,255,.5)"><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script><div id="gitalk-container"></div><script type="text/javascript">var gitalk=new Gitalk({clientID:"41a199ade404435645c4",clientSecret:"1de34fbb95212de986a29fea6d6f22bb57b2d473",repo:"m01ly.github.io",owner:"m01ly",admin:["m01ly"],id:window.location.pathname});gitalk.render("gitalk-container")</script></section><div class="scroll" id="post-nav-button"><a href="/2020/11/14/bigdata-hive1/" title="上一篇: Hive学习笔记（一） Hive安装"><i class="fa fa-angle-left"></i> </a><a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a> <a href="/2020/11/12/bigdata-hdfs/" title="下一篇: Hadoop 教程（一）hadoop介绍"><i class="fa fa-angle-right"></i></a></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/12/01/bigdata-mapreduce2-framework/">Hadoop 教程（五）mapreduce架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/29/leetcode-binarytree/">leetcode-binarytree</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/28/scan-nessus-compliance/">nessus扫描合规性</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/22/cert-letsencrypt/">cert-letsencrypt</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/16/leetcode-stackandqueue/">栈和队列相关题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/06/htps-recommend/">安全的TLS协议</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/07/leetcode-slidewindow/">滑动窗口相关题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/07/leetcode-list/">链表相关题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/26/leetcode-binary/">二分查找相关的题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/24/burpsuite-develop-detect-nginx/">开发burpsuite插件-识别nginx版本并列出已知CVE</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/21/burpsuite-develop/">从0开发burpsuite插件（Java）</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/26/machine-learning-classify-knn/">机器学习算法之KNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/07/openvas-develop/">openvas插件开发</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/06/leetcode-daily/">leetcode每日一题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/30/pt-antSword/">渗透测试工具之蚁剑</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/29/leetcode-sort/">排序算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/linux-disk/">centos7把/mnt空间合并到/(根目录)</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/02/19/install-guide-elk-filebeats/">elk笔记三--利用elk+filebeat搭建SIEM系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/02/18/linux-jdk8/">linux安装jdk1.8</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/01/21/esc-DefectDojo/">DefectDojo安装与使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/01/bigdata-zookeeper3-API/">Zookeeper学习笔记（三） API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/01/bigdata-zookeeper2-framework/">Zookeeper学习笔记（二） 架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/01/bigdata-zookeeper1-setup/">Zookeeper学习笔记（一） 搭建教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/29/bigdata-Spark2-framework/">Spark学习笔记（二） 架构解析和RDD编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/29/bigdata-Spark1-setup/">Spark学习笔记（一） 搭建Spark</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/bigdata-HBase2-framework/">HBase学习笔记（二） HBase架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/bigdata-HBase4-phoenix/">HBase学习笔记（四） HBase整合phoenix和Hive</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/bigdata-HBase3-API/">HBase学习笔记（三） HBase的API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/bigdata-HBase1-setup/">HBase学习笔记（一） 安装教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/23/bigdata-datacollect1-userbehavior/">大数据实践（一）数仓采集项目</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/22/bigdata-sqoop/">sqoop安装教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/18/bigdata-kafka4-test/">kafka学习笔记（四） kafka面试集锦</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/17/bigdata-kafka3-API/">kafka学习笔记（三） kafka的API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/bigdata-flume3-monitor/">flume学习笔记（三） flum数据流监控及面试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/bigdata-kafka2-framework/">kafka学习笔记（二） kafka框架深入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-flume2-framework/">flume学习笔记（二） flum事务和部署架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-flume1-setup/">flume学习笔记（一） flume搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive3/">Hive学习笔记（三） Hive的分区表和分桶表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive5-example/">Hive学习笔记（五） Hive实战</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive4-optimize/">Hive学习笔记（四） Hive的企业级调优</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive2/">Hive学习笔记（二） Hive对数据基本操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-kafka1-setup/">kafka学习笔记（一） kafka搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/14/bigdata-hive1/">Hive学习笔记（一） Hive安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-hdfs1/">Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-hdfs/">Hadoop 教程（一）hadoop介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-yarn-framework/">Hadoop 教程（六）yarn-架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-mapreduce1-setup/">Hadoop 教程（四）mapreduce介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-hdfs3-framework/">Hadoop 教程（三）hdfs-架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/10/cipher-certificate-format/">证书的各种格式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/docker-guide/">docker使用大全</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/linux-cmd/">linux命令大全</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-metosploitInAliyun/">在阿里云主机反弹metosploit</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-info-collection/">信息收集</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-tools/">最佳网络安全和黑客软件</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/18/mobilesecurity-experience/">小白如何在三天一步步逆向app，找到私钥</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/elk-login/">elk笔记二--通过X-Pack权限控制设置elk登录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-centosInvm/">vm 安装centos 7教程详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/writeup-sqli-labs/">writeup-sqli-labs</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-elk-suricata/">elk笔记一---suricata+elk搭建入侵检测系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-suricata/">centos7中安装suricata</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/10/pt-sqlbypass/">sql关键词绕过</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/04/pt-portinfo/">常见端口说明和攻击汇总</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/03/m01ly-wiki/">m01ly-wiki</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/03/htps-attack-heartbleed/">TLS攻击之心脏滴血</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/01/htps-attack-paddingoracle/">TLS 攻击之POODLE</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/31/blockcipher-padding/">分组密码--填充模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/31/blockcipher-operation-mode/">分组密码--工作模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/hexo-guide/">Hexo踩坑</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/scan-awvs-nessus/">AWVS和Nessus镜像安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/scan-zap/">ZAP的安装和使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/pt-tiquan/">提权</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/htps-tools/">TLS安全检测小工具</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/htps-build/">搭建https网站</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/apple/">竟然有人能把https/TLS1.2协议讲的这么详细</a></li></ul><script></script></div><footer id="footer"><div class="outer"><div id="footer-info"><div class="footer-left"><i class="fa fa-copyright"></i> 2017-2021 冀-18010769-1</div><div class="visit"><span id="busuanzi_container_site_pv" style="display:none"><span id="site-visit" title="本站到访人数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span> </span></span><span>| </span><span id="busuanzi_container_page_pv" style="display:none"><span id="page-visit" title="本页访问次数"><i class="fa fa-eye" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span></span></span></div><div class="footer-right"><i class="fa fa-heart"></i><a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架"> Hexo</a> Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a></div></div></div></footer></div><script type="application/javascript">var leftWidth,hide=!1;$(".hide-left-col").click(function(){hide=hide?($(".left-col").css("width",leftWidth),$(".left-col .intrude-less").fadeIn(200),$("#tocButton").fadeIn(200),"block"===$("#switch-btn").css("display")&&"block"===$("#switch-area").css("display")||$("#toc").fadeIn(200),$(".hide-left-col").css("left",leftWidth).html('<i class="fa fa-angle-double-left"></i>'),$(".mid-col").css("left",leftWidth),$("#post-nav-button").css("left",leftWidth),$("#post-nav-button > a:nth-child(2)").css("display","block"),!1):(leftWidth=$(".left-col")[0].style.width,$(".left-col").css("width",0),$(".left-col .intrude-less").fadeOut(200),$("#toc").fadeOut(100),$("#tocButton").fadeOut(100),$(".hide-left-col").css("left",0).html('<i class="fa fa-angle-double-right"></i>'),$(".mid-col").css("left",0),$("#post-nav-button").css("left",0),$("#post-nav-button > a:nth-child(2)").css("display","none"),$(".post-list").is(":visible")&&($("#post-nav-button .fa-bars,#post-nav-button .fa-times").toggle(),$(".post-list").toggle()),!0)})</script><script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.3.5/require.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[["$$","$$"],["$","$"],["\\(","\\)"]],processEscapes:!0,skipTags:["script","noscript","style","textarea","pre","code"]}}),MathJax.Hub.Queue(function(){var a,e=MathJax.Hub.getAllJax();for(a=0;a<e.length;a+=1)e[a].SourceElement().parentNode.className+=" has-jax"})</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script><div class="scroll" id="scroll"><a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a> <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a> <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a></div><script>var oOpenInNew={post:".copyright a[href]",friends:"#js-friends a",socail:".social a"};for(var x in oOpenInNew)$(oOpenInNew[x]).attr("target","_blank")</script><script>var titleTime,originTitle=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="(つェ⊂)"+originTitle,clearTimeout(titleTime)):(document.title="(*´∇｀*)~ "+originTitle,titleTime=setTimeout(function(){document.title=originTitle},2e3))})</script><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><link href="//cdn.bootcss.com/aos/2.2.0/aos.css" rel="stylesheet"><script type="text/javascript">AOS.init({easing:"ease-out-back",once:!0})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"live2d_models/live2d-widget-model-izumi"},"display":{"position":"right","width":100,"height":200,"hOffset":-50,"vOffset":-85},"mobile":{"show":false},"react":{"opacityDefault":0.9,"opacityOnHover":0.3},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false});</script></body></html>