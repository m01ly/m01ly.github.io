<!DOCTYPE html><html lang="zh-Hans"><head><!--[if IE]><style>body{display:none;}</style><script>alert('IE浏览器下无法展示效果，请更换浏览器！');var headNode=document.getElementsByTagName('head')[0];var refresh=document.createElement('meta');refresh.setAttribute('http-equiv','Refresh');refresh.setAttribute('Content','0; url=http://outdatedbrowser.com/');headNode.appendChild(refresh);</script><![endif]--><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="m01ly"><meta name="description" content="前面我们学习到hadoop主要用于大数据的存储和计算；Hive提供更方便的数据分析能力；那有没有想过研究大数据，我们想想大数据是从哪里来的呢？这篇我们学习flume框架，用于数据采集的，并且采集的类型是日志（业务服务的行为数据）；所以flume就是将服务生产的日志自动实时的搬运（传输）到hdfs上。 1.1 Flume定义Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采"><meta property="og:type" content="article"><meta property="og:title" content="flume学习笔记（一） flume搭建"><meta property="og:url" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/index.html"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="前面我们学习到hadoop主要用于大数据的存储和计算；Hive提供更方便的数据分析能力；那有没有想过研究大数据，我们想想大数据是从哪里来的呢？这篇我们学习flume框架，用于数据采集的，并且采集的类型是日志（业务服务的行为数据）；所以flume就是将服务生产的日志自动实时的搬运（传输）到hdfs上。 1.1 Flume定义Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采"><meta property="og:locale"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637056045712.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637056457927.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637056654444.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637055202443.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637057440088.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637055240301.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637059514026.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637059968136.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637062965508.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637063102633.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637063607668.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637063370689.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637063420040.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637063679839.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637064020425.png"><meta property="article:published_time" content="2020-11-15T07:46:51.000Z"><meta property="article:modified_time" content="2021-11-16T12:13:07.481Z"><meta property="article:author" content="m01ly"><meta property="article:tag" content="flume"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/1637056045712.png"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="shortcut icon" href="/favicon.ico"><link href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css" rel="stylesheet"><link rel="stylesheet" href="/css/style.css"><title>flume学习笔记（一） flume搭建 | Hexo</title><script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"><script src="//cdn.bootcss.com/aos/2.2.0/aos.js"></script><script>var yiliaConfig={fancybox:!0,isHome:!1,isPost:!0,isArchive:!1,isTag:!1,isCategory:!1,fancybox_js:"//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js",search:!0}</script><script>yiliaConfig.jquery_ui=[!1]</script><script>yiliaConfig.rootUrl="/"</script><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/rss+xml">
<link rel="stylesheet" href="/css/prism-a11y-dark.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="container"><div class="left-col"><div class="intrude-less"><header id="header" class="inner"><a href="/" class="profilepic"><img src="/img/avatar.jpg"></a><hgroup><h1 class="header-author"><a href="/">m01ly</a></h1></hgroup><p class="header-subtitle">人生在世，全靠命</p><form id="search-form"><input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false"> <i class="fa fa-times" onclick="resetSearch()"></i></form><div id="local-search-result"></div><p class="no-result">No results found <i class="fa fa-spinner fa-pulse"></i></p><div id="switch-btn" class="switch-btn"><div class="icon"><div class="icon-ctn"><div class="icon-wrap icon-house" data-idx="0"><div class="birdhouse"></div><div class="birdhouse_holes"></div></div><div class="icon-wrap icon-ribbon hide" data-idx="1"><div class="ribbon"></div></div><div class="icon-wrap icon-link hide" data-idx="2"><div class="loopback_l"></div><div class="loopback_r"></div></div><div class="icon-wrap icon-me hide" data-idx="3"><div class="user"></div><div class="shoulder"></div></div></div></div><div class="tips-box hide"><div class="tips-arrow"></div><ul class="tips-inner"><li>菜单</li><li>标签</li><li>友情链接</li><li>目标</li></ul></div></div><div id="switch-area" class="switch-area"><div class="switch-wrap"><section class="switch-part switch-part1"><nav class="header-menu"><ul><li><a href="/">主页</a></li><li><a href="/archives/">所有文章</a></li><li><a href="/tags/">标签云</a></li><li><a href="/about/">简历</a></li></ul></nav><nav class="header-nav"><ul class="social"><a class="fa GitHub" target="_blank" rel="noopener" href="https://github.com/m01ly" title="GitHub"></a> <a class="fa RSS" href="/atom.xml" title="RSS"></a> <a class="fa 网易云音乐" target="_blank" rel="noopener" href="https://music.163.com/" title="网易云音乐"></a></ul><ul class="social"><div class="donateIcon-position"><p style="display:block"><a class="donateIcon" href="javascript:void(0)" onmouseout='var qr=document.getElementById("donate");qr.style.display="none"' onmouseenter='var qr=document.getElementById("donate");qr.style.display="block"'>赏</a></p><div id="donate"><img id="multipay" src="/img/multipay.png" width="250px" alt="m01ly Multipay"><div class="triangle"></div></div></div></ul></nav></section><section class="switch-part switch-part2"><div class="widget tagcloud" id="js-tagcloud"><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TLS/" rel="tag">TLS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/" rel="tag">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/" rel="tag">kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqoop/" rel="tag">sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%81%E4%B8%9A%E5%AE%89%E5%85%A8%E5%BB%BA%E8%AE%BE/" rel="tag">企业安全建设</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E5%85%A8%E6%89%AB%E6%8F%8F/" rel="tag">安全扫描</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/" rel="tag">安装教程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%B9%E5%99%A8%E6%95%99%E7%A8%8B/" rel="tag">容器教程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" rel="tag">密码学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/" rel="tag">插件开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E4%BB%93%E9%87%87%E9%9B%86%E9%A1%B9%E7%9B%AE/" rel="tag">数仓采集项目</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/" rel="tag">日志管理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/" rel="tag">流量分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/" rel="tag">渗透测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/" rel="tag">漏洞扫描</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%BB%E5%8A%A8%E5%AE%89%E5%85%A8/" rel="tag">移动安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%B6%E5%9C%BAwriteup/" rel="tag">靶场writeup</a></li></ul></div></section><section class="switch-part switch-part3"><div id="js-friends"><a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/TechCatsLab">TechCatsLab</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://yangchenglong11.github.io">YangChengLong</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://jsharkc.github.io">LiuJiaChang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="http://blog.yusank.space">YusanKurban</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://blog.lizebang.top">Lizebang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/sunanxiang">SunAnXiang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/DoubleWoodH">LinHao</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://blog.littlechao.top">ShiChao</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/Txiaozhe">TangXiaoJi</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/LLLeon">JiaChenHui</a></div></section><section class="switch-part switch-part4"><div id="js-aboutme">不悲不喜，不卑不亢，努力成为一个更好的程序猿！</div></section></div></div></header></div></div><div class="hide-left-col" title="隐藏侧栏"><i class="fa fa-angle-double-left"></i></div><div class="mid-col"><nav id="mobile-nav"><div class="overlay"><div class="slider-trigger"></div><h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">m01ly</a></h1></div><div class="intrude-less"><header id="header" class="inner"><a href="/" class="profilepic"><img src="/img/avatar.jpg"></a><hgroup><h1 class="header-author"><a href="/" title="回到主页">m01ly</a></h1></hgroup><p class="header-subtitle">人生在世，全靠命</p><nav class="header-menu"><ul><li><a href="/">主页</a></li><li><a href="/archives/">所有文章</a></li><li><a href="/tags/">标签云</a></li><li><a href="/about/">简历</a></li><div class="clearfix"></div></ul></nav><nav class="header-nav"><ul class="social"><a class="fa GitHub" target="_blank" href="https://github.com/m01ly" title="GitHub"></a> <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a> <a class="fa 网易云音乐" target="_blank" href="https://music.163.com/" title="网易云音乐"></a></ul></nav></header></div><link class="menu-list" tags="标签" friends="友情链接" about="目标"></nav><div class="body-wrap"><article id="post-bigdata-flume1-setup" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-meta"><a href="/2020/11/15/bigdata-flume1-setup/" class="article-date"><time class="published" datetime="2020-11-15T07:46:51.000Z" itemprop="datePublished">2020-11-15 发布</time> <time class="updated" datetime="2021-11-16T12:13:07.481Z" itemprop="dateUpdated">2021-11-16 更新</time></a></div><div class="article-inner"><input type="hidden" class="isFancy"><header class="article-header"><h1 class="article-title" itemprop="name">flume学习笔记（一） flume搭建</h1></header><div class="article-info article-info-post"><div class="article-count"><div class="article-category tagcloud"><a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</a></div><div class="article-tag tagcloud"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/flume/" rel="tag">flume</a></li></ul></div><span class="post-count">总字数3.3k</span> <span class="post-count">预计阅读14分钟</span></div><div class="clearfix"></div></div><div class="article-entry" itemprop="articleBody"><p>前面我们学习到hadoop主要用于大数据的存储和计算；Hive提供更方便的数据分析能力；那有没有想过研究大数据，我们想想大数据是从哪里来的呢？这篇我们学习flume框架，用于数据采集的，并且采集的类型是日志（业务服务的行为数据）；所以<strong>flume就是将服务生产的日志自动实时的搬运（传输）到hdfs上。</strong></p><h2 id="1-1-Flume定义"><a href="#1-1-Flume定义" class="headerlink" title="1.1 Flume定义"></a>1.1 Flume定义</h2><p><a target="_blank" rel="noopener" href="https://flume.apache.org/">Flume</a>是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume基于流式架构，灵活简单。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056045712.png" alt="1637056045712"></p><p><strong>Flume最主要的作用就是：实时读取服务器本地磁盘文件夹（或者日志服务器的日志）的日志/数据，然后将数据上传到hdfs中。</strong></p><h2 id="1-2-Flume基础架构"><a href="#1-2-Flume基础架构" class="headerlink" title="1.2 Flume基础架构"></a>1.2 Flume基础架构</h2><p>Flume组成架构如下图所示。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056457927.png" alt="1637056457927"></p><p>数据来源：从日志服务器</p><p>数据到哪里：hdfs</p><h3 id="1-2-1-Agent"><a href="#1-2-1-Agent" class="headerlink" title="1.2.1 Agent"></a>1.2.1 Agent</h3><p>Agent是一个JVM进程，它以事件的形式将数据从源头送至目的。</p><p>Agent主要有3个部分组成，Source、Channel、Sink。</p><h3 id="1-2-2-Source"><a href="#1-2-2-Source" class="headerlink" title="1.2.2 Source"></a>1.2.2 Source</h3><p>Source是负责<strong>接收数据</strong>到Flume Agent的组件。Source组件可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、 taildir 、sequence generator、syslog、http、legacy。</p><h3 id="1-2-3-Sink"><a href="#1-2-3-Sink" class="headerlink" title="1.2.3 Sink"></a>1.2.3 Sink</h3><p>Sink不断地轮询Channel中的事件且<strong>批量地移除</strong>它们，并将这些事件<strong>批量写入到存储或索引系统</strong>、或者被发送到另一个Flume Agent。</p><p>Sink组件目的地包括hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。</p><h3 id="1-2-4-Channel"><a href="#1-2-4-Channel" class="headerlink" title="1.2.4 Channel"></a>1.2.4 Channel</h3><p>Channel是位于Source和Sink之间的<strong>缓冲区</strong>。因此，Channel允许Source和Sink运作在不同的速率上。<strong>Channel是线程安全的，可以同时处理几个Source的写入操作和几个Sink的读取操作</strong>(有可能一个chanel对应多个source和多个sink)。</p><p><strong>Flume自带两种Channel：Memory Channel和File Channel。</strong></p><p>Memory Channel是内存中的队列。Memory Channel在不需要关心数据丢失的情景下适用。如果需要关心数据丢失，那么Memory Channel就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。</p><p>File Channel将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。</p><h3 id="1-2-5-Event"><a href="#1-2-5-Event" class="headerlink" title="1.2.5 Event"></a>1.2.5 Event</h3><p><strong>传输单元，Flume数据传输的基本单元</strong>，以Event的形式将数据从源头送至目的地。Event由Header和Body两部分组成，Header用来存放该event的一些属性，为K-V结构（通常是没有数据的），Body用来存放该条数据，形式为字节数组。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056654444.png" alt="1637056654444"></p><h1 id="2-Flume入门"><a href="#2-Flume入门" class="headerlink" title="2 Flume入门"></a>2 Flume入门</h1><h2 id="2-1-Flume安装部署"><a href="#2-1-Flume安装部署" class="headerlink" title="2.1 Flume安装部署"></a>2.1 Flume安装部署</h2><h3 id="2-1-1-安装地址"><a href="#2-1-1-安装地址" class="headerlink" title="2.1.1 安装地址"></a>2.1.1 安装地址</h3><p>（1）Flume官网地址：<a target="_blank" rel="noopener" href="http://flume.apache.org/">http://flume.apache.org/</a></p><p>（2）文档查看地址：<a target="_blank" rel="noopener" href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p><p>（3）下载地址：<a target="_blank" rel="noopener" href="http://archive.apache.org/dist/flume/">http://archive.apache.org/dist/flume/</a></p><h3 id="2-1-2-安装部署"><a href="#2-1-2-安装部署" class="headerlink" title="2.1.2 安装部署"></a>2.1.2 安装部署</h3><p>（1）将apache-flume-1.9.0-bin.tar.gz上传到linux的/opt/software目录下</p><p>（2）解压apache-flume-1.9.0-bin.tar.gz到/opt/module/目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）修改apache-flume-1.9.0-bin的名称为flume-1.9.0</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> /opt/module/apache-flume-1.9.0-bin /opt/module/flume<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）将lib文件夹下的guava-11.0.2.jar删除以兼容Hadoop 3.1.3</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 lib<span class="token punctuation">]</span>$ <span class="token function">rm</span> /opt/module/flume/lib/guava-11.0.2.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-Flume入门案例"><a href="#2-2-Flume入门案例" class="headerlink" title="2.2 Flume入门案例"></a>2.2 Flume入门案例</h2><h3 id="2-2-1-监控端口数据官方案例"><a href="#2-2-1-监控端口数据官方案例" class="headerlink" title="2.2.1 监控端口数据官方案例"></a>2.2.1 监控端口数据官方案例</h3><p>1）案例需求：</p><p>使用Flume监听一个端口4444，收集该端口数据，并打印到控制台。</p><p>2）需求分析：</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637055202443.png" alt="1637055202443"></p><p><img src="/2020/11/15/bigdata-flume1-setup/1637057440088.png" alt="1637057440088"></p><p>source端：选用netcat TCP</p><p>Channel：memory channel</p><p>sink：选用logger sink</p><p>3）实现步骤：</p><p>（1）安装netcat工具(man nc 查看手册)</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum <span class="token function">install</span> -y nc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）判断44444端口是否被占用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume-telnet<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">netstat</span> -nlp <span class="token operator">|</span> <span class="token function">grep</span> 44444<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）创建Flume Agent配置文件flume-netcat-logger.conf</p><p>（4）在flume目录下创建job文件夹并进入job文件夹。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> job
<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">cd</span> job/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（5）在job文件夹下创建Flume Agent配置文件flume-netcat-logger.conf。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-netcat-logger.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）在flume-netcat-logger.conf文件中添加如下内容。</p><p>添加内容如下：</p><pre class="line-numbers language-sh"><code class="language-sh"># Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1
# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444
# Describe the sink
a1.sinks.k1.type = logger
# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：配置文件来源于官方手册<a target="_blank" rel="noopener" href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p><p><img src="/2020/11/15/bigdata-flume1-setup/1637055240301.png" alt="1637055240301"></p><p>（7）先开启flume监听端口</p><p>第一种写法：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/flume-netcat-logger.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>第二种写法：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数说明：</p><p>​ –conf/-c：表示配置文件存储在conf/目录</p><p>​ –name/-n：表示给agent起名为a1</p><p>​ –conf-file/-f：flume本次启动读取的配置文件是在job文件夹下的flume-telnet.conf文件。</p><p>​ -Dflume.root.logger=INFO,console ：-D表示flume运行时动态修改flume.root.logger参数属性值，并将控制台日志打印级别设置为INFO级别。日志级别包括:log、info、warn、error。</p><p>（8）使用netcat工具向本机的44444端口发送内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ nc localhost 44444
hello 
molly<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（9）在Flume监听页面观察接收数据情况</p><p>思考：nc hadoop102 44444，flume能否接收到？</p><h3 id="2-2-2-实时监控单个追加文件"><a href="#2-2-2-实时监控单个追加文件" class="headerlink" title="2.2.2 实时监控单个追加文件"></a>2.2.2 实时监控单个追加文件</h3><p>1）案例需求：实时监控Hive日志，并上传到HDFS中</p><p>2）需求分析： source类型：exec source</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637059514026.png" alt="1637059514026"></p><p>3）实现步骤：</p><p>（1）Flume要想将数据输出到HDFS，依赖Hadoop相关jar包</p><p>检查/etc/profile.d/my_env.sh文件，确认Hadoop和Java环境变量配置正确</p><pre class="line-numbers language-sh"><code class="language-sh">JAVA_HOME=/opt/module/jdk1.8.0_212
HADOOP_HOME=/opt/module/ha/hadoop-3.1.3
PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export PATH JAVA_HOME HADOOP_HOME<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）创建flume-file-hdfs.conf文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-file-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注：要想读取Linux系统中的文件，就得按照Linux命令的规则执行命令。由于Hive日志在Linux系统中所以读取文件的类型选择：exec即execute执行的意思。表示执行Linux命令来读取文件。</p><p>添加如下内容</p><pre class="line-numbers language-sh"><code class="language-sh"># Name the components on this agent
a2.sources = r2
a2.sinks = k2
a2.channels = c2
# Describe/configure the source
a2.sources.r2.type = exec
a2.sources.r2.command = tail -F /opt/module/hive/logs/hive.log
# Describe the sink
a2.sinks.k2.type = hdfs# hdfs类型的sink
a2.sinks.k2.hdfs.path = hdfs://hadoop102:8020/flume/%Y%m%d/%H#上传到hdfs
#上传文件的前缀
a2.sinks.k2.hdfs.filePrefix = logs-
#是否按照时间滚动文件夹  #按照时间写入不同给的文件中
a2.sinks.k2.hdfs.round = true
#多少时间单位创建一个新的文件夹
a2.sinks.k2.hdfs.roundValue = 1
#重新定义时间单位
a2.sinks.k2.hdfs.roundUnit = hour
#是否使用本地时间戳
a2.sinks.k2.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
a2.sinks.k2.hdfs.batchSize = 100
#设置文件类型，可支持压缩
a2.sinks.k2.hdfs.fileType = DataStream
#多久生成一个新的文件
a2.sinks.k2.hdfs.rollInterval = 60
#设置每个文件的滚动大小
a2.sinks.k2.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
a2.sinks.k2.hdfs.rollCount = 0
# Use a channel which buffers events in memory
a2.channels.c2.type = memory
a2.channels.c2.capacity = 1000
a2.channels.c2.transactionCapacity = 100
# Bind the source and sink to the channel
a2.sources.r2.channels = c2
a2.sinks.k2.channel = c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：</p><p>对于所有与时间相关的转义序列，Event Header中必须存在以 “timestamp”的key（除非hdfs.useLocalTimeStamp设置为true，此方法会使用TimestampInterceptor自动添加timestamp）。</p><p>a3.sinks.k3.hdfs.useLocalTimeStamp = true</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637059968136.png" alt="1637059968136"></p><p>（3）运行Flume</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/flume-file-hdfs.conf  -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）开启Hadoop和Hive并操作Hive产生日志</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-dfs.sh
<span class="token punctuation">[</span>molly@hadoop103 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-yarn.sh
<span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive
hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（5）在HDFS上查看文件。</p><p>正在使用的文件的后缀是.tmp</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637062965508.png" alt="1637062965508"></p><h3 id="2-2-3-实时监控目录下多个新文件"><a href="#2-2-3-实时监控目录下多个新文件" class="headerlink" title="2.2.3 实时监控目录下多个新文件"></a>2.2.3 实时监控目录下多个新文件</h3><p>1）案例需求：使用Flume监听整个目录的新文件,<strong>有新文件</strong>出现，将新文件数据上传至HDFS</p><p>2）需求分析：</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063102633.png" alt="1637063102633"></p><p>3）实现步骤：</p><p>（1）创建配置文件flume-dir-hdfs.conf</p><p>创建一个文件</p><p>[molly@hadoop102 job]$ vim flume-dir-hdfs.conf</p><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash">a3.sources <span class="token operator">=</span> r3
a3.sinks <span class="token operator">=</span> k3
a3.channels <span class="token operator">=</span> c3
<span class="token comment" spellcheck="true"># Describe/configure the source</span>
a3.sources.r3.type <span class="token operator">=</span> spooldir
a3.sources.r3.spoolDir <span class="token operator">=</span> /opt/module/flume/upload  <span class="token comment" spellcheck="true">#监控的目录</span>
a3.sources.r3.fileSuffix <span class="token operator">=</span> .COMPLETED <span class="token comment" spellcheck="true">#采集过的文件表示这个后缀；后面将不会对旧文件进行采集</span>
a3.sources.r3.fileHeader <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment" spellcheck="true">#忽略所有以.tmp结尾的文件，不上传</span>
a3.sources.r3.ignorePattern <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>^ <span class="token punctuation">]</span>*\.tmp<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># Describe the sink</span>
a3.sinks.k3.type <span class="token operator">=</span> hdfs
a3.sinks.k3.hdfs.path <span class="token operator">=</span> hdfs://hadoop102:8020/flume/upload/%Y%m%d/%H
<span class="token comment" spellcheck="true">#上传文件的前缀</span>
a3.sinks.k3.hdfs.filePrefix <span class="token operator">=</span> upload-
<span class="token comment" spellcheck="true">#是否按照时间滚动文件夹</span>
a3.sinks.k3.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment" spellcheck="true">#多少时间单位创建一个新的文件夹</span>
a3.sinks.k3.hdfs.roundValue <span class="token operator">=</span> 1
<span class="token comment" spellcheck="true">#重新定义时间单位</span>
a3.sinks.k3.hdfs.roundUnit <span class="token operator">=</span> hour
<span class="token comment" spellcheck="true">#是否使用本地时间戳</span>
a3.sinks.k3.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment" spellcheck="true">#积攒多少个Event才flush到HDFS一次</span>
a3.sinks.k3.hdfs.batchSize <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true">#设置文件类型，可支持压缩</span>
a3.sinks.k3.hdfs.fileType <span class="token operator">=</span> DataStream
<span class="token comment" spellcheck="true">#多久生成一个新的文件</span>
a3.sinks.k3.hdfs.rollInterval <span class="token operator">=</span> 60
<span class="token comment" spellcheck="true">#设置每个文件的滚动大小大概是128M</span>
a3.sinks.k3.hdfs.rollSize <span class="token operator">=</span> 134217700
<span class="token comment" spellcheck="true">#文件的滚动与Event数量无关</span>
a3.sinks.k3.hdfs.rollCount <span class="token operator">=</span> 0
<span class="token comment" spellcheck="true"># Use a channel which buffers events in memory</span>
a3.channels.c3.type <span class="token operator">=</span> memory
a3.channels.c3.capacity <span class="token operator">=</span> 1000
a3.channels.c3.transactionCapacity <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>
a3.sources.r3.channels <span class="token operator">=</span> c3
a3.sinks.k3.channel <span class="token operator">=</span> c3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/11/15/bigdata-flume1-setup/1637063607668.png" alt="1637063607668"></p><p>（2）启动监控文件夹命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-dir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>说明：在使用Spooling Directory Source时，不要在监控目录中创建并持续修改文件；上传完成的文件会以.COMPLETED结尾；被监控文件夹每500毫秒扫描一次文件变动。</p><p>（3）向upload文件夹中添加文件</p><p>在/opt/module/flume目录下创建upload文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> upload<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>向upload文件夹中添加文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.txt
<span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.tmp
<span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）查看HDFS上的数据</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063370689.png" alt="1637063370689"></p><p>（5）查看采集后的文件，发现文件已经加了后缀COMPLETED</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063420040.png" alt="1637063420040"></p><h3 id="2-2-4-实时监控目录下的多个追加文件"><a href="#2-2-4-实时监控目录下的多个追加文件" class="headerlink" title="2.2.4 实时监控目录下的多个追加文件"></a>2.2.4 实时监控目录下的多个追加文件</h3><p>Exec source适用于监控<strong>一个实时追加**</strong>的文件，不能实现断点续传；Spooldir Source适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步；而<strong>Taildir Source适合用于监听多个实时追加的文件</strong>，并且能够实现断点续传。</p><p>1）案例需求:使用Flume监听整个目录的实时追加文件，并上传至HDFS</p><p>2）需求分析:</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063679839.png" alt="1637063679839"></p><p>3）实现步骤：</p><p>（1）创建配置文件flume-taildir-hdfs.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-taildir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">a3.sources = r3
a3.sinks = k3
a3.channels = c3
# Describe/configure the source
a3.sources.r3.type = TAILDIR
a3.sources.r3.positionFile = /opt/module/flume/tail_dir.json  #记录采集的位置 从而实现断点续传
a3.sources.r3.filegroups = f1 f2  #监控的多个文件组
a3.sources.r3.filegroups.f1 = /opt/module/flume/files/.*file.* #监控f1组的文件
a3.sources.r3.filegroups.f2 = /opt/module/flume/files2/.*log.*
# Describe the sink
a3.sinks.k3.type = hdfs
a3.sinks.k3.hdfs.path = hdfs://hadoop102:8020/flume/upload2/%Y%m%d/%H
#上传文件的前缀
a3.sinks.k3.hdfs.filePrefix = upload-
#是否按照时间滚动文件夹
a3.sinks.k3.hdfs.round = true
#多少时间单位创建一个新的文件夹
a3.sinks.k3.hdfs.roundValue = 1
#重新定义时间单位
a3.sinks.k3.hdfs.roundUnit = hour
#是否使用本地时间戳
a3.sinks.k3.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
a3.sinks.k3.hdfs.batchSize = 100
#设置文件类型，可支持压缩
a3.sinks.k3.hdfs.fileType = DataStream
#多久生成一个新的文件
a3.sinks.k3.hdfs.rollInterval = 60
#设置每个文件的滚动大小大概是128M
a3.sinks.k3.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
a3.sinks.k3.hdfs.rollCount = 0
# Use a channel which buffers events in memory
a3.channels.c3.type = memory
a3.channels.c3.capacity = 1000
a3.channels.c3.transactionCapacity = 100
# Bind the source and sink to the channel
a3.sources.r3.channels = c3
a3.sinks.k3.channel = c3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/11/15/bigdata-flume1-setup/1637064020425.png" alt="1637064020425"></p><p>（2）启动监控文件夹命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-taildir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）向files文件夹中追加内容</p><p>在/opt/module/flume目录下创建files文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> files<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>向upload文件夹中添加文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 files<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> hello <span class="token operator">>></span> file1.txt
<span class="token punctuation">[</span>molly@hadoop102 files<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> molly <span class="token operator">>></span> file2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）查看HDFS上的数据</p><p><strong>（5）为啥Taildir可以断点续传？？</strong></p><p>Taildir Source维护了一个json格式的position File，其会定期的往position File中更新每个文件读取到的最新的位置，因此能够实现断点续传。Position File的格式如下：</p><p>{“inode”:2496272,”pos”:12,”file”:”/opt/module/flume/files/file1.txt”}<br>{“inode”:2496275,”pos”:12,”file”:”/opt/module/flume/files/file2.txt”}</p><p>注：Linux中储存文件元数据的区域就叫做inode，每个inode都有一个号码，操作系统用inode号码来识别不同的文件，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。</p><link href="//src.wangriyu.wang/lib/Aplayer/APlayer.min.css" rel="stylesheet"><script src="//src.wangriyu.wang/lib/Aplayer/APlayer.min.js"></script><div id="aplayer"></div><script src="/js/player.js"></script></div></div><div class="copyright"><p><span>本文标题:</span><a href="/2020/11/15/bigdata-flume1-setup/">flume学习笔记（一） flume搭建</a></p><p><span>文章作者:</span><a href="/" title="回到主页">m01ly</a></p><p><span>发布时间:</span>2020-11-15, 15:46:51</p><p><span>最后更新:</span>2021-11-16, 20:13:07</p><p><span>原始链接:</span><a class="post-url" href="/2020/11/15/bigdata-flume1-setup/" title="flume学习笔记（一） flume搭建">https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/</a></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target="_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。</p></div><nav id="article-nav"><div id="article-nav-newer" class="article-nav-title"><a href="/2020/11/15/bigdata-flume2-framework/">flume学习笔记（二） flum事务和部署架构解析</a></div><div id="article-nav-older" class="article-nav-title"><a href="/2020/11/15/bigdata-hive2/">Hive学习笔记（二） Hive对数据基本操作</a></div></nav></article><div id="toc" class="toc-article"><strong class="toc-title">文章目录</strong><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-Flume%E5%AE%9A%E4%B9%89"><span class="toc-text">1.1 Flume定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-Flume%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84"><span class="toc-text">1.2 Flume基础架构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-1-Agent"><span class="toc-text">1.2.1 Agent</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-2-Source"><span class="toc-text">1.2.2 Source</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-3-Sink"><span class="toc-text">1.2.3 Sink</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-4-Channel"><span class="toc-text">1.2.4 Channel</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-5-Event"><span class="toc-text">1.2.5 Event</span></a></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Flume%E5%85%A5%E9%97%A8"><span class="toc-text">2 Flume入门</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Flume%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="toc-text">2.1 Flume安装部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-1-%E5%AE%89%E8%A3%85%E5%9C%B0%E5%9D%80"><span class="toc-text">2.1.1 安装地址</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-2-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="toc-text">2.1.2 安装部署</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-Flume%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B"><span class="toc-text">2.2 Flume入门案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-%E7%9B%91%E6%8E%A7%E7%AB%AF%E5%8F%A3%E6%95%B0%E6%8D%AE%E5%AE%98%E6%96%B9%E6%A1%88%E4%BE%8B"><span class="toc-text">2.2.1 监控端口数据官方案例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E5%8D%95%E4%B8%AA%E8%BF%BD%E5%8A%A0%E6%96%87%E4%BB%B6"><span class="toc-text">2.2.2 实时监控单个追加文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-3-%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%A4%9A%E4%B8%AA%E6%96%B0%E6%96%87%E4%BB%B6"><span class="toc-text">2.2.3 实时监控目录下多个新文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-4-%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E5%A4%9A%E4%B8%AA%E8%BF%BD%E5%8A%A0%E6%96%87%E4%BB%B6"><span class="toc-text">2.2.4 实时监控目录下的多个追加文件</span></a></li></ol></li></ol></li></div><style>.left-col .switch-area,.left-col .switch-btn{display:none}.toc-level-6 i,.toc-level-6 ol{display:none!important}</style><input type="button" id="tocButton" value="隐藏目录" title="点击按钮隐藏或者显示文章目录"><script>yiliaConfig.toc=["隐藏目录","显示目录",!0],$(".left-col").is(":hidden")&&$("#tocButton").attr("value",yiliaConfig.toc[1])</script><div class="share"><link rel="stylesheet" type="text/css" href="/share/iconfont.css"><link rel="stylesheet" href="/share/spongebob.min.css" type="text/css" media="all"><div class="social_share"><ul id="social_list" class="social_icon_list"></ul></div><script>var shareConfig={title:"flume学习笔记（一） flume搭建",url:window.location.href,author:"m01ly",img:"https:/img/avatar.jpg"}</script><script src="/share/qrcode.min.js"></script><script src="/share/spongebob.min.js"></script></div><section id="comments" style="margin:2em;padding:2em;background:rgba(255,255,255,.5)"><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script><div id="gitalk-container"></div><script type="text/javascript">var gitalk=new Gitalk({clientID:"41a199ade404435645c4",clientSecret:"1de34fbb95212de986a29fea6d6f22bb57b2d473",repo:"m01ly.github.io",owner:"m01ly",admin:["m01ly"],id:window.location.pathname});gitalk.render("gitalk-container")</script></section><div class="scroll" id="post-nav-button"><a href="/2020/11/15/bigdata-flume2-framework/" title="上一篇: flume学习笔记（二） flum事务和部署架构解析"><i class="fa fa-angle-left"></i> </a><a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a> <a href="/2020/11/15/bigdata-hive2/" title="下一篇: Hive学习笔记（二） Hive对数据基本操作"><i class="fa fa-angle-right"></i></a></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/11/12/bigdata-hadoop-yarn/">bigdata-hadoop-yarn</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/11/12/bigdata-mapreduce/">bigdata-mapreduce</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/29/leetcode-binarytree/">leetcode-binarytree</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/28/scan-nessus-compliance/">nessus扫描合规性</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/22/cert-letsencrypt/">cert-letsencrypt</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/16/leetcode-stackandqueue/">栈和队列相关题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/06/htps-recommend/">安全的TLS协议</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/28/leetcode-list/">链表相关</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/26/leetcode-binary/">二分查找相关的题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/24/burpsuite-develop-detect-nginx/">开发burpsuite插件-识别nginx版本并列出已知CVE</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/21/burpsuite-develop/">从0开发burpsuite插件（Java）</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/26/machine-learning-classify-knn/">机器学习算法之KNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/07/openvas-develop/">openvas插件开发</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/06/leetcode-daily/">leetcode每日一题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/30/pt-antSword/">渗透测试工具之蚁剑</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/29/leetcode-sort/">排序算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/linux-disk/">centos7把/mnt空间合并到/(根目录)</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/02/19/install-guide-elk-filebeats/">elk笔记三--利用elk+filebeat搭建SIEM系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/02/18/linux-jdk8/">linux安装jdk1.8</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/01/21/esc-DefectDojo/">DefectDojo安装与使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/23/bigdata-datacollect1-userbehavior/">大数据实践（一）数仓采集项目</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/22/bigdata-sqoop/">sqoop安装教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/18/bigdata-kafka4-test/">kafka学习笔记（四） kafka面试集锦</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/17/bigdata-kafka3-API/">kafka学习笔记（三） kafka的API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/bigdata-flume3-monitor/">flume学习笔记（三） flum数据流监控及面试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/bigdata-kafka2-framework/">kafka学习笔记（二） kafka框架深入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-flume2-framework/">flume学习笔记（二） flum事务和部署架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-flume1-setup/">flume学习笔记（一） flume搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive2/">Hive学习笔记（二） Hive对数据基本操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive3/">Hive学习笔记（三） Hive的分区表和分桶表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive5-example/">Hive学习笔记（五） Hive实战</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive4-optimize/">Hive学习笔记（四） Hive的企业级调优</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-kafka1-setup/">kafka学习笔记（一） kafka搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/14/bigdata-hive1/">Hive学习笔记（一） Hive安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-hdfs1/">Hadoop 教程（二）安装hadoop集群-完全分布式部署</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-hdfs/">Hadoop 教程（一）hadoop介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/10/cipher-certificate-format/">证书的各种格式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/docker-guide/">docker使用大全</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/linux-cmd/">linux命令大全</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-metosploitInAliyun/">在阿里云主机反弹metosploit</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-info-collection/">信息收集</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-tools/">最佳网络安全和黑客软件</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/18/mobilesecurity-experience/">小白如何在三天一步步逆向app，找到私钥</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/elk-login/">elk笔记二--通过X-Pack权限控制设置elk登录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-centosInvm/">vm 安装centos 7教程详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/writeup-sqli-labs/">writeup-sqli-labs</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-elk-suricata/">elk笔记一---suricata+elk搭建入侵检测系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-suricata/">centos7中安装suricata</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/10/pt-sqlbypass/">sql关键词绕过</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/04/pt-portinfo/">常见端口说明和攻击汇总</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/03/m01ly-wiki/">m01ly-wiki</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/03/htps-attack-heartbleed/">TLS攻击之心脏滴血</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/01/htps-attack-paddingoracle/">TLS 攻击之POODLE</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/31/blockcipher-padding/">分组密码--填充模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/31/blockcipher-operation-mode/">分组密码--工作模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/hexo-guide/">Hexo踩坑</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/scan-awvs-nessus/">AWVS和Nessus镜像安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/scan-zap/">ZAP的安装和使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/pt-tiquan/">提权</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/htps-tools/">TLS安全检测小工具</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/htps-build/">搭建https网站</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/apple/">竟然有人能把https/TLS1.2协议讲的这么详细</a></li></ul><script></script></div><footer id="footer"><div class="outer"><div id="footer-info"><div class="footer-left"><i class="fa fa-copyright"></i> 2017-2021 冀-18010769-1</div><div class="visit"><span id="busuanzi_container_site_pv" style="display:none"><span id="site-visit" title="本站到访人数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span> </span></span><span>| </span><span id="busuanzi_container_page_pv" style="display:none"><span id="page-visit" title="本页访问次数"><i class="fa fa-eye" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span></span></span></div><div class="footer-right"><i class="fa fa-heart"></i><a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架"> Hexo</a> Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a></div></div></div></footer></div><script type="application/javascript">var leftWidth,hide=!1;$(".hide-left-col").click(function(){hide=hide?($(".left-col").css("width",leftWidth),$(".left-col .intrude-less").fadeIn(200),$("#tocButton").fadeIn(200),"block"===$("#switch-btn").css("display")&&"block"===$("#switch-area").css("display")||$("#toc").fadeIn(200),$(".hide-left-col").css("left",leftWidth).html('<i class="fa fa-angle-double-left"></i>'),$(".mid-col").css("left",leftWidth),$("#post-nav-button").css("left",leftWidth),$("#post-nav-button > a:nth-child(2)").css("display","block"),!1):(leftWidth=$(".left-col")[0].style.width,$(".left-col").css("width",0),$(".left-col .intrude-less").fadeOut(200),$("#toc").fadeOut(100),$("#tocButton").fadeOut(100),$(".hide-left-col").css("left",0).html('<i class="fa fa-angle-double-right"></i>'),$(".mid-col").css("left",0),$("#post-nav-button").css("left",0),$("#post-nav-button > a:nth-child(2)").css("display","none"),$(".post-list").is(":visible")&&($("#post-nav-button .fa-bars,#post-nav-button .fa-times").toggle(),$(".post-list").toggle()),!0)})</script><script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.3.5/require.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[["$$","$$"],["$","$"],["\\(","\\)"]],processEscapes:!0,skipTags:["script","noscript","style","textarea","pre","code"]}}),MathJax.Hub.Queue(function(){var a,e=MathJax.Hub.getAllJax();for(a=0;a<e.length;a+=1)e[a].SourceElement().parentNode.className+=" has-jax"})</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script><div class="scroll" id="scroll"><a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a> <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a> <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a></div><script>var oOpenInNew={post:".copyright a[href]",friends:"#js-friends a",socail:".social a"};for(var x in oOpenInNew)$(oOpenInNew[x]).attr("target","_blank")</script><script>var titleTime,originTitle=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="(つェ⊂)"+originTitle,clearTimeout(titleTime)):(document.title="(*´∇｀*)~ "+originTitle,titleTime=setTimeout(function(){document.title=originTitle},2e3))})</script><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><link href="//cdn.bootcss.com/aos/2.2.0/aos.css" rel="stylesheet"><script type="text/javascript">AOS.init({easing:"ease-out-back",once:!0})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"live2d_models/live2d-widget-model-izumi"},"display":{"position":"right","width":100,"height":200,"hOffset":-50,"vOffset":-85},"mobile":{"show":false},"react":{"opacityDefault":0.9,"opacityOnHover":0.3},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false});</script></body></html>