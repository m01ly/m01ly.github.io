<!DOCTYPE html><html lang="zh-Hans"><head><!--[if IE]><style>body{display:none;}</style><script>alert('IE浏览器下无法展示效果，请更换浏览器！');var headNode=document.getElementsByTagName('head')[0];var refresh=document.createElement('meta');refresh.setAttribute('http-equiv','Refresh');refresh.setAttribute('Content','0; url=http://outdatedbrowser.com/');headNode.appendChild(refresh);</script><![endif]--><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="m01ly"><meta name="description" content="1 Flume事务一提到事务，首先就想到的是关系型数据库中的事务，事务一个典型的特征就是将一批操作做成原子性的，要么都成功，要么都失败。 flume事务就是保证fllume能安全正常的运行，保证服务的可靠性，安全性。 在Flume中一共有两个事务:  Put事务：在Source到Channel之间 Take事务：Channel到Sink之间  从Source到Channel过程中，数据在Flume"><meta property="og:type" content="article"><meta property="og:title" content="flume学习笔记（二） flum事务和部署架构解析"><meta property="og:url" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/index.html"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="1 Flume事务一提到事务，首先就想到的是关系型数据库中的事务，事务一个典型的特征就是将一批操作做成原子性的，要么都成功，要么都失败。 flume事务就是保证fllume能安全正常的运行，保证服务的可靠性，安全性。 在Flume中一共有两个事务:  Put事务：在Source到Channel之间 Take事务：Channel到Sink之间  从Source到Channel过程中，数据在Flume"><meta property="og:locale"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637064771603.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637065765693.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/clip_image002.jpg"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/clip_image004.jpg"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/clip_image006.jpg"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/clip_image008.jpg"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/clip_image002.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637066888396.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/clip_image004-1637066740449.jpg"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637118002481.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637068504415.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637067365266.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637067455399.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637116934865.png"><meta property="og:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/clip_image008.png"><meta property="og:image" content="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image010.png"><meta property="article:published_time" content="2020-11-15T08:46:51.000Z"><meta property="article:modified_time" content="2021-11-17T06:30:23.141Z"><meta property="article:author" content="m01ly"><meta property="article:tag" content="flume"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/1637064771603.png"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="shortcut icon" href="/favicon.ico"><link href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css" rel="stylesheet"><link rel="stylesheet" href="/css/style.css"><title>flume学习笔记（二） flum事务和部署架构解析 | Hexo</title><script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"><script src="//cdn.bootcss.com/aos/2.2.0/aos.js"></script><script>var yiliaConfig={fancybox:!0,isHome:!1,isPost:!0,isArchive:!1,isTag:!1,isCategory:!1,fancybox_js:"//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js",search:!0}</script><script>yiliaConfig.jquery_ui=[!1]</script><script>yiliaConfig.rootUrl="/"</script><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="Hexo" type="application/rss+xml">
<link rel="stylesheet" href="/css/prism-a11y-dark.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="container"><div class="left-col"><div class="intrude-less"><header id="header" class="inner"><a href="/" class="profilepic"><img src="/img/avatar.jpg"></a><hgroup><h1 class="header-author"><a href="/">m01ly</a></h1></hgroup><p class="header-subtitle">人生在世，全靠命</p><form id="search-form"><input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false"> <i class="fa fa-times" onclick="resetSearch()"></i></form><div id="local-search-result"></div><p class="no-result">No results found <i class="fa fa-spinner fa-pulse"></i></p><div id="switch-btn" class="switch-btn"><div class="icon"><div class="icon-ctn"><div class="icon-wrap icon-house" data-idx="0"><div class="birdhouse"></div><div class="birdhouse_holes"></div></div><div class="icon-wrap icon-ribbon hide" data-idx="1"><div class="ribbon"></div></div><div class="icon-wrap icon-link hide" data-idx="2"><div class="loopback_l"></div><div class="loopback_r"></div></div><div class="icon-wrap icon-me hide" data-idx="3"><div class="user"></div><div class="shoulder"></div></div></div></div><div class="tips-box hide"><div class="tips-arrow"></div><ul class="tips-inner"><li>菜单</li><li>标签</li><li>友情链接</li><li>目标</li></ul></div></div><div id="switch-area" class="switch-area"><div class="switch-wrap"><section class="switch-part switch-part1"><nav class="header-menu"><ul><li><a href="/">主页</a></li><li><a href="/archives/">所有文章</a></li><li><a href="/tags/">标签云</a></li><li><a href="/about/">简历</a></li></ul></nav><nav class="header-nav"><ul class="social"><a class="fa GitHub" target="_blank" rel="noopener" href="https://github.com/m01ly" title="GitHub"></a> <a class="fa RSS" href="/atom.xml" title="RSS"></a> <a class="fa 网易云音乐" target="_blank" rel="noopener" href="https://music.163.com/" title="网易云音乐"></a></ul><ul class="social"><div class="donateIcon-position"><p style="display:block"><a class="donateIcon" href="javascript:void(0)" onmouseout='var qr=document.getElementById("donate");qr.style.display="none"' onmouseenter='var qr=document.getElementById("donate");qr.style.display="block"'>赏</a></p><div id="donate"><img id="multipay" src="/img/multipay.png" width="250px" alt="m01ly Multipay"><div class="triangle"></div></div></div></ul></nav></section><section class="switch-part switch-part2"><div class="widget tagcloud" id="js-tagcloud"><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/HBase/" rel="tag">HBase</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TLS/" rel="tag">TLS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Zookeeper/" rel="tag">Zookeeper</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flume/" rel="tag">flume</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kafka/" rel="tag">kafka</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sqoop/" rel="tag">sqoop</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BC%81%E4%B8%9A%E5%AE%89%E5%85%A8%E5%BB%BA%E8%AE%BE/" rel="tag">企业安全建设</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7/" rel="tag">安全工具</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/" rel="tag">安装教程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%B9%E5%99%A8%E6%95%99%E7%A8%8B/" rel="tag">容器教程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" rel="tag">密码学</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/" rel="tag">插件开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E4%BB%93%E9%87%87%E9%9B%86%E9%A1%B9%E7%9B%AE/" rel="tag">数仓采集项目</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/" rel="tag">日志管理</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/" rel="tag">流量分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/" rel="tag">渗透测试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/" rel="tag">漏洞复现</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/" rel="tag">漏洞扫描</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A7%BB%E5%8A%A8%E5%AE%89%E5%85%A8/" rel="tag">移动安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%B6%E5%9C%BAwriteup/" rel="tag">靶场writeup</a></li></ul></div></section><section class="switch-part switch-part3"><div id="js-friends"><a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/TechCatsLab">TechCatsLab</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://yangchenglong11.github.io">YangChengLong</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://jsharkc.github.io">LiuJiaChang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="http://blog.yusank.space">YusanKurban</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://blog.lizebang.top">Lizebang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/sunanxiang">SunAnXiang</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/DoubleWoodH">LinHao</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://blog.littlechao.top">ShiChao</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/Txiaozhe">TangXiaoJi</a> <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://github.com/LLLeon">JiaChenHui</a></div></section><section class="switch-part switch-part4"><div id="js-aboutme">不悲不喜，不卑不亢，努力成为一个更好的程序猿！</div></section></div></div></header></div></div><div class="hide-left-col" title="隐藏侧栏"><i class="fa fa-angle-double-left"></i></div><div class="mid-col"><nav id="mobile-nav"><div class="overlay"><div class="slider-trigger"></div><h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">m01ly</a></h1></div><div class="intrude-less"><header id="header" class="inner"><a href="/" class="profilepic"><img src="/img/avatar.jpg"></a><hgroup><h1 class="header-author"><a href="/" title="回到主页">m01ly</a></h1></hgroup><p class="header-subtitle">人生在世，全靠命</p><nav class="header-menu"><ul><li><a href="/">主页</a></li><li><a href="/archives/">所有文章</a></li><li><a href="/tags/">标签云</a></li><li><a href="/about/">简历</a></li><div class="clearfix"></div></ul></nav><nav class="header-nav"><ul class="social"><a class="fa GitHub" target="_blank" href="https://github.com/m01ly" title="GitHub"></a> <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a> <a class="fa 网易云音乐" target="_blank" href="https://music.163.com/" title="网易云音乐"></a></ul></nav></header></div><link class="menu-list" tags="标签" friends="友情链接" about="目标"></nav><div class="body-wrap"><article id="post-bigdata-flume2-framework" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-meta"><a href="/2020/11/15/bigdata-flume2-framework/" class="article-date"><time class="published" datetime="2020-11-15T08:46:51.000Z" itemprop="datePublished">2020-11-15 发布</time> <time class="updated" datetime="2021-11-17T06:30:23.141Z" itemprop="dateUpdated">2021-11-17 更新</time></a></div><div class="article-inner"><input type="hidden" class="isFancy"><header class="article-header"><h1 class="article-title" itemprop="name">flume学习笔记（二） flum事务和部署架构解析</h1></header><div class="article-info article-info-post"><div class="article-count"><div class="article-category tagcloud"><a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</a></div><div class="article-tag tagcloud"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/flume/" rel="tag">flume</a></li></ul></div><span class="post-count">总字数5.6k</span> <span class="post-count">预计阅读25分钟</span></div><div class="clearfix"></div></div><div class="article-entry" itemprop="articleBody"><h2 id="1-Flume事务"><a href="#1-Flume事务" class="headerlink" title="1 Flume事务"></a><strong>1 Flume事务</strong></h2><p>一提到事务，首先就想到的是关系型数据库中的事务，事务一个典型的特征就是将一批操作做成原子性的，要么都成功，要么都失败。</p><p>flume事务就是保证fllume能安全正常的运行，保证服务的可靠性，安全性。</p><p>在Flume中一共有两个事务:</p><ul><li>Put事务：在Source到Channel之间</li><li>Take事务：Channel到Sink之间</li></ul><p>从Source到Channel过程中，数据在Flume中会被封装成Event对象，也就是一批Event，把这批Event放到一个事务中，把这个事务也就是这批event一次性的放入Channel中。同理，Take事务的时候，也是把这一批event组成的事务统一拿出来到sink放到HDFS上。</p><p>事务具体流程如下图所示：</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/1637064771603.png" alt="1637064771603"></strong></p><h4 id="1-1-Put事务流程"><a href="#1-1-Put事务流程" class="headerlink" title="1.1 Put事务流程"></a>1.1 Put事务流程</h4><ul><li><p>事务开始的时候会调用一个doPut 方法，doPut方法将一批数据放在putList中;</p></li><li><ul><li>putList在向Channel发送数据之前先检查Channel的容量能否放得下，如果放不下一个都不放，只能doRollback;</li><li>数据批的大小取决于配置参数batch size的值;</li><li>putList的大小取决于配置Channel的参数transaction capacity的大小，该参数大小就体现在putList上;(Channel的另一个参数capacity指的是Channel的容量);</li></ul></li><li><p>数据顺利的放到putList之后，Flume中的 Take 事务</p><p>Take事务同样也有takeList，HDFS sink配置有一个batch size，这个参数决定Sink从Channel 取数据的时候一次取多少个，所以该batch size得小于takeList的大小，而takeList的大小取决于 transaction capacity 的大小，同样是channel中的参数。其中putlist，takelist容量可以通过下面配置：a3.channels.c3.transactionCapacity = 100</p></li></ul><h4 id="1-2-Take事务流程"><a href="#1-2-Take事务流程" class="headerlink" title="1.2 Take事务流程:"></a>1.2 Take事务流程:</h4><p>事务开始后</p><ul><li><p>doTake方法会将channel中的event剪切到takeList中。如果后面接的是HDFS Sink的话，在把Channel中的event剪切到takeList中的同时也往写入HDFS的IO缓冲流中放一份event(数据写入HDFS是先写入IO缓冲流然后flush到HDFS);</p></li><li><p>当takeList中存放了batch size 数量的event之后，就会调用doCommit方法，doCommit方法会做两个操作:</p></li><li><ul><li>针对HDFS Sink，手动调用IO流的flush方法，将IO流缓冲区的数据写入到HDFS磁盘中;</li><li>清空takeList中的数据</li></ul><p>flush到HDFS的时候组容易出问题。flush到HDFS的时候，可能由于网络原因超时导致数据传输失败，这个时候调用doRollback方法来进行回滚，回滚的时候由于takeList中还有备份数据，所以将takeList中的数据原封不动地还给channel，这时候就完成了事务的回滚。</p><p>但是，如果flush到HDFS的时候，数据flush了一半之后出问题了，这意味着已经有一半的数据已经发送到HDFS上面了，现在出了问题，同样需要调用doRollback方法来进行回滚，回滚并没有“一半”之说，它只会把整个takeList中的数据返回给 channel，然后继续进行数据的读写。这样开启下一个事务的时候容易造成数据重复的问题。接下来可以调用doCommit方法，把putList中所有的Event放到 Channel 中，成功放完之后就清空putList;</p></li></ul><p>在doCommit提交之后，事务在向Channel存放数据的过程中，事务容易出问题。如Sink取数据慢，而Source放数据速度快，容易造成Channel中数据的积压，如果putList中的数据放不进去，会如何呢?</p><p>此时会调用 doRollback 方法，doRollback方法会进行两项操作：将putList清空; 抛出 ChannelException异常。source会捕捉到doRollback抛出的异常，然后source就将刚才的一批数据重新采集，然后重新开始一个新的事务，这就是事务的回滚。</p><h2 id="2-Flume-Agent内部原理"><a href="#2-Flume-Agent内部原理" class="headerlink" title="2 Flume Agent内部原理"></a>2 Flume Agent内部原理</h2><p><img src="/2020/11/15/bigdata-flume2-framework/1637065765693.png" alt="1637065765693"></p><p>重要组件：</p><p>1）ChannelSelector</p><p>ChannelSelector的作用就是选出Event将要被发往哪个Channel。其共有两种类型，分别是Replicating（复制）和Multiplexing（多路复用）。</p><p>ReplicatingSelector会将同一个Event发往所有的Channel，Multiplexing会根据相应的原则，将不同的Event发往不同的Channel。</p><p>2）SinkProcessor</p><p>SinkProcessor共有三种类型，分别是DefaultSinkProcessor、LoadBalancingSinkProcessor和FailoverSinkProcessor</p><p>DefaultSinkProcessor对应的是单个的Sink，LoadBalancingSinkProcessor和FailoverSinkProcessor对应的是Sink Group，</p><p>LoadBalancingSinkProcessor可以实现负载均衡的功能：利用一定算法将channel均衡的分配到sink上；</p><p>FailoverSinkProcessor可以错误恢复的功能：三个中只有一个是Active的sink,如果当前acticve的sink故障了，另外两台通过选举的方式上位，成为新的sink（选举的指标是配置文件中a1.sinkgroups.g1.processor.priority.k1）。</p><h2 id="3-Flume拓扑结构"><a href="#3-Flume拓扑结构" class="headerlink" title="3 Flume拓扑结构"></a>3 Flume拓扑结构</h2><p>在实际应用中，根据不同的场景，可能部署多个flume实现功能，很多个flume使用的搭配结果如下：</p><h3 id="3-1-简单串联"><a href="#3-1-简单串联" class="headerlink" title="3.1 简单串联"></a>3.1 简单串联</h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image002.jpg" alt="img"></strong></p><p>这种模式是将多个flume顺序连接起来了，从最初的source开始到最终sink传送的目的存储系统。此模式不建议桥接过多的flume数量， flume数量过多不仅会影响传输速率，而且一旦传输过程中某个节点flume宕机，会影响整个传输系统。</p><h3 id="3-2-复制和多路复用"><a href="#3-2-复制和多路复用" class="headerlink" title="3.2 复制和多路复用"></a><strong>3.2 复制和多路复用</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image004.jpg" alt="img"></strong></p><p>Flume支持将事件流向一个或者多个目的地。这种模式可以将相同数据复制到多个channel中，或者将不同数据分发到不同的channel中，sink可以选择传送到不同的目的地。</p><h3 id="3-3-负载均衡和故障转移"><a href="#3-3-负载均衡和故障转移" class="headerlink" title="3.3 负载均衡和故障转移"></a><strong>3.3 负载均衡和故障转移</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image006.jpg" alt="img"></strong></p><hr><p>Flume支持使用将多个sink逻辑上分到一个sink组，sink组配合不同的SinkProcessor可以实现负载均衡和错误恢复的功能。</p><h3 id="3-4-聚合"><a href="#3-4-聚合" class="headerlink" title="3.4 聚合"></a><strong>3.4 聚合</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image008.jpg" alt="img"></strong></p><p>这种模式是我们最常见的，也非常实用，日常web应用通常分布在上百个服务器，大者甚至上千个、上万个服务器。产生的日志，处理起来也非常麻烦。用flume的这种组合方式能很好的解决这一问题，每台服务器部署一个flume采集日志，传送到一个集中收集日志的flume，再由此flume上传到hdfs、hive、hbase等，进行日志分析。</p><h2 id="4-Flume开发案例"><a href="#4-Flume开发案例" class="headerlink" title="4 Flume开发案例"></a><strong>4 Flume开发案例</strong></h2><h3 id="4-1-复制"><a href="#4-1-复制" class="headerlink" title="4.1 复制"></a>4.1 复制</h3><p><strong>1）案例需求</strong></p><p>使用Flume-1监控文件变动，Flume-1将变动内容传递给Flume-2，Flume-2负责存储到HDFS。同时Flume-1将变动内容传递给Flume-3，Flume-3负责输出到Local FileSystem。</p><p><strong>2）需求分析：</strong></p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image002.png" alt="img"></strong></p><p>具体类型选择如下图所示：</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/1637066888396.png" alt="1637066888396"></strong></p><p>3）实现步骤：</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group1文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group1/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在/opt/module/datas/目录下创建flume3文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> flume3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-file-flume.conf</p><p>配置1个接收日志文件的source和两个channel、两个sink，分别输送给flume-flume-hdfs和flume-flume-dir。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-file-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>
a1.sources <span class="token operator">=</span> r1
a1.sinks <span class="token operator">=</span> k1 k2
a1.channels <span class="token operator">=</span> c1 c2
<span class="token comment" spellcheck="true"># 将数据流复制给所有channel</span>
a1.sources.r1.selector.type <span class="token operator">=</span> replicating
<span class="token comment" spellcheck="true"># Describe/configure the source</span>
a1.sources.r1.type <span class="token operator">=</span> <span class="token function">exec</span>
a1.sources.r1.command <span class="token operator">=</span> <span class="token function">tail</span> -F /opt/module/hive/logs/hive.log
a1.sources.r1.shell <span class="token operator">=</span> /bin/bash -c
<span class="token comment" spellcheck="true"># Describe the sink</span>
<span class="token comment" spellcheck="true"># sink端的avro是一个数据发送者</span>
a1.sinks.k1.type <span class="token operator">=</span> avro
a1.sinks.k1.hostname <span class="token operator">=</span> hadoop102 
a1.sinks.k1.port <span class="token operator">=</span> 4141
a1.sinks.k2.type <span class="token operator">=</span> avro
a1.sinks.k2.hostname <span class="token operator">=</span> hadoop102
a1.sinks.k2.port <span class="token operator">=</span> 4142
<span class="token comment" spellcheck="true"># Describe the channel</span>
a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> 1000
a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100
a1.channels.c2.type <span class="token operator">=</span> memory
a1.channels.c2.capacity <span class="token operator">=</span> 1000
a1.channels.c2.transactionCapacity <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>
a1.sources.r1.channels <span class="token operator">=</span> c1 c2
a1.sinks.k1.channel <span class="token operator">=</span> c1
a1.sinks.k2.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）创建flume-flume-hdfs.conf</p><p>配置上级Flume输出的Source，输出是到HDFS的Sink。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-flume-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>
a2.sources <span class="token operator">=</span> r1
a2.sinks <span class="token operator">=</span> k1
a2.channels <span class="token operator">=</span> c1
<span class="token comment" spellcheck="true"># Describe/configure the source</span>
<span class="token comment" spellcheck="true"># source端的avro是一个数据接收服务</span>
a2.sources.r1.type <span class="token operator">=</span> avro
a2.sources.r1.bind <span class="token operator">=</span> hadoop102
a2.sources.r1.port <span class="token operator">=</span> 4141
<span class="token comment" spellcheck="true"># Describe the sink</span>
a2.sinks.k1.type <span class="token operator">=</span> hdfs
a2.sinks.k1.hdfs.path <span class="token operator">=</span> hdfs://hadoop102:8020/flume2/%Y%m%d/%H
<span class="token comment" spellcheck="true">#上传文件的前缀</span>
a2.sinks.k1.hdfs.filePrefix <span class="token operator">=</span> flume2-
<span class="token comment" spellcheck="true">#是否按照时间滚动文件夹</span>
a2.sinks.k1.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment" spellcheck="true">#多少时间单位创建一个新的文件夹</span>
a2.sinks.k1.hdfs.roundValue <span class="token operator">=</span> 1
<span class="token comment" spellcheck="true">#重新定义时间单位</span>
a2.sinks.k1.hdfs.roundUnit <span class="token operator">=</span> hour
<span class="token comment" spellcheck="true">#是否使用本地时间戳</span>
a2.sinks.k1.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment" spellcheck="true">#积攒多少个Event才flush到HDFS一次</span>
a2.sinks.k1.hdfs.batchSize <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true">#设置文件类型，可支持压缩</span>
a2.sinks.k1.hdfs.fileType <span class="token operator">=</span> DataStream
<span class="token comment" spellcheck="true">#多久生成一个新的文件</span>
a2.sinks.k1.hdfs.rollInterval <span class="token operator">=</span> 600
<span class="token comment" spellcheck="true">#设置每个文件的滚动大小大概是128M</span>
a2.sinks.k1.hdfs.rollSize <span class="token operator">=</span> 134217700
<span class="token comment" spellcheck="true">#文件的滚动与Event数量无关</span>
a2.sinks.k1.hdfs.rollCount <span class="token operator">=</span> 0
<span class="token comment" spellcheck="true"># Describe the channel</span>
a2.channels.c1.type <span class="token operator">=</span> memory
a2.channels.c1.capacity <span class="token operator">=</span> 1000
a2.channels.c1.transactionCapacity <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>
a2.sources.r1.channels <span class="token operator">=</span> c1
a2.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）创建flume-flume-dir.conf</p><p>配置上级Flume输出的Source，输出是到本地目录的Sink。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-flume-dir.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>
a3.sources <span class="token operator">=</span> r1
a3.sinks <span class="token operator">=</span> k1
a3.channels <span class="token operator">=</span> c2
<span class="token comment" spellcheck="true"># Describe/configure the source</span>
a3.sources.r1.type <span class="token operator">=</span> avro
a3.sources.r1.bind <span class="token operator">=</span> hadoop102
a3.sources.r1.port <span class="token operator">=</span> 4142
<span class="token comment" spellcheck="true"># Describe the sink</span>
a3.sinks.k1.type <span class="token operator">=</span> file_roll
a3.sinks.k1.sink.directory <span class="token operator">=</span> /opt/module/data/flume3
<span class="token comment" spellcheck="true"># Describe the channel</span>
a3.channels.c2.type <span class="token operator">=</span> memory
a3.channels.c2.capacity <span class="token operator">=</span> 1000
a3.channels.c2.transactionCapacity <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>
a3.sources.r1.channels <span class="token operator">=</span> c2
a3.sinks.k1.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提示：输出的本地目录必须是已经存在的目录，如果该目录不存在，并不会创建新的目录。</p><p>（5）执行配置文件</p><p>分别启动对应的flume进程：flume-flume-dir，flume-flume-hdfs，flume-file-flume。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group1/flume-flume-dir.conf

<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group1/flume-flume-hdfs.conf

<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group1/flume-file-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（6）启动Hadoop和Hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-dfs.sh
<span class="token punctuation">[</span>molly@hadoop103 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-yarn.sh
<span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive
hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（7）检查HDFS上数据</p><p><img src="/2020/11/15/bigdata-flume2-framework/clip_image004-1637066740449.jpg" alt="img"></p><p>（8）检查/opt/module/datas/flume3目录中数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume3<span class="token punctuation">]</span>$ ll
-rw-rw-r--. 1 molly molly 5942 5月 22 00:09 1526918887550-3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-2-多路复用-自定义Interceptor"><a href="#4-2-多路复用-自定义Interceptor" class="headerlink" title="4.2 多路复用+自定义Interceptor"></a>4.2 多路复用+自定义Interceptor</h3><p>1)案例需求</p><p>使用Flume采集服务器本地日志，需要按照日志类型的不同，将不同种类的日志发往不同的分析系统。</p><ol start="2"><li>需求分析</li></ol><p>在实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要发送到不同的分析系统。此时会用到Flume拓扑结构中的Multiplexing结构，Multiplexing的原理是，根据event中Header的某个key的值，将不同的event发送到不同的Channel中，所以我们需要自定义一个Interceptor，为不同类型的event的Header中的key赋予不同的值。</p><p>需求1 架构：在该案例中，我们以端口数据模拟日志，以数字（单个）和字母（单个）模拟不同类型的日志，我们需要自定义interceptor区分数字和字母，将其分别发往不同的分析系统（Channel）。</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637118002481.png" alt="1637118002481"></p><p>需求2架构：</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637068504415.png" alt="1637068504415"></p><ol start="3"><li>需求1实现步骤</li></ol><p>主要分为两大步：</p><p><strong>第一 使用拦截器对数据进行处理：对不同数据添加不同的head</strong></p><p><strong>第二：使用选择器将不同head的数据分发到不同的channel</strong></p><p>（1）创建一个maven项目，并引入以下依赖。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flume<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flume-ng-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）定义CustomInterceptor类并实现Interceptor接口。将写好的代码打包jar，并放到flume的lib目录（/opt/module/flume）下。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span>
<span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

        <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token string">'z'</span> <span class="token operator">&amp;&amp;</span> body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
            event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">,</span> <span class="token string">"letter"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token string">'0'</span> <span class="token operator">&amp;&amp;</span> body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token string">'9'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
            event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">,</span> <span class="token string">"number"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> event<span class="token punctuation">;</span>

    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span>Event event <span class="token operator">:</span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
            <span class="token function">intercept</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> events<span class="token punctuation">;</span>
    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>

    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Builder</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor<span class="token punctuation">.</span>Builder</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">CustomInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>

        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>
        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>
    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>
<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编辑flume配置文件</p><p>为hadoop102上的Flume1配置1个netcat source，1个sink group（2个avro sink），并配置相应的ChannelSelector和interceptor。根据下面的配置，head里是letter就放c1,header是number就放c2。</p><p>a1.sources.r1.selector.mapping.letter = c1</p><p>a1.sources.r1.selector.mapping.number = c2</p><p>完整配置如下：</p><pre><code># Name the components on this agent
a1.sources = r1
a1.sinks = k1 k2
a1.channels = c1 c2

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = com.atguigu.flume.interceptor.CustomInterceptor$Builder
a1.sources.r1.selector.type = multiplexing
a1.sources.r1.selector.header = type
a1.sources.r1.selector.mapping.letter = c1
a1.sources.r1.selector.mapping.number = c2
# Describe the sink
a1.sinks.k1.type = avro
a1.sinks.k1.hostname = hadoop103
a1.sinks.k1.port = 4141

a1.sinks.k2.type=avro
a1.sinks.k2.hostname = hadoop104
a1.sinks.k2.port = 4242

# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Use a channel which buffers events in memory
a1.channels.c2.type = memory
a1.channels.c2.capacity = 1000
a1.channels.c2.transactionCapacity = 100


# Bind the source and sink to the channel
a1.sources.r1.channels = c1 c2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2</code></pre><p>为hadoop103上的Flume4配置一个avro source和一个logger sink。</p><pre class="line-numbers language-bash"><code class="language-bash">a1.sources <span class="token operator">=</span> r1
a1.sinks <span class="token operator">=</span> k1
a1.channels <span class="token operator">=</span> c1

a1.sources.r1.type <span class="token operator">=</span> avro
a1.sources.r1.bind <span class="token operator">=</span> hadoop103
a1.sources.r1.port <span class="token operator">=</span> 4141

a1.sinks.k1.type <span class="token operator">=</span> logger

a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> 1000
a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100

a1.sinks.k1.channel <span class="token operator">=</span> c1
a1.sources.r1.channels <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为hadoop104上的Flume3配置一个avro source和一个logger sink。</p><pre class="line-numbers language-bash"><code class="language-bash">a1.sources <span class="token operator">=</span> r1
a1.sinks <span class="token operator">=</span> k1
a1.channels <span class="token operator">=</span> c1

a1.sources.r1.type <span class="token operator">=</span> avro
a1.sources.r1.bind <span class="token operator">=</span> hadoop104
a1.sources.r1.port <span class="token operator">=</span> 4242

a1.sinks.k1.type <span class="token operator">=</span> logger

a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> 1000
a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100

a1.sinks.k1.channel <span class="token operator">=</span> c1
a1.sources.r1.channels <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）分别在hadoop102，hadoop103，hadoop104上启动flume进程，注意先后顺序。</p><p>（5）在hadoop102使用netcat向localhost:44444发送字母和数字。</p><p>（6）观察hadoop103和hadoop104打印的日志。</p><h3 id="4-3-负载均衡"><a href="#4-3-负载均衡" class="headerlink" title="4.3 负载均衡"></a>4.3 负载均衡</h3><p>负载均衡片处理器提供在多个Sink之间负载平衡的能力。实现支持通过<strong>round_robin（轮询）或者random（随机）</strong>参数来实现负载分发</p><p><strong>默认情况下使用round_robin</strong>，但可以通过配置覆盖这个默认值。还可以通过集成AbstractSinkSelector类来实现用户自己的选择机制。</p><p>当被调用的时候，这选择器通过配置的选择规则选择下一个sink来调用。</p><p>1）案例需求</p><p>使用Flume1监控一个端口，将监控到的内容通过轮询或者随机的方式给到flume2和flume3。Flume2和Flume3将内容打印到控制台。这个时候需要使用LoadBalancingSinkProcessor。</p><p>2）架构分析：</p><p>具体架构选择见下图。</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637067365266.png" alt="1637067365266"></p><p>3）实现步骤</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group3文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group3/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-netcat-flume.conf：flume1的配置</p><p>配置1个netcat source和1个channel、1个sink group（2个sink），分别输送给flume-flume-console2和flume-flume-console3。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#负载均衡</span>
<span class="token comment" spellcheck="true">#配置Agent a1的组件</span>
a1.sources<span class="token operator">=</span>r1
a1.channels<span class="token operator">=</span>c1
a1.sinks<span class="token operator">=</span>s1 s2

<span class="token comment" spellcheck="true">#配置a1的source</span>
a1.sources.r1.type<span class="token operator">=</span>netcat
a1.sources.r1.bind<span class="token operator">=</span>0.0.0.0
a1.sources.r1.port<span class="token operator">=</span>3333

<span class="token comment" spellcheck="true">##配置a1的channel</span>
a1.channels.c1.type<span class="token operator">=</span>memory
a1.channels.c1.capacity<span class="token operator">=</span>1000
a1.channels.c1.trancactionCapacity<span class="token operator">=</span>100

<span class="token comment" spellcheck="true">#配置a1的sink</span>
a1.sinks.s1.type<span class="token operator">=</span>avro
a1.sinks.s1.hostname<span class="token operator">=</span>node2
a1.sinks.s1.port<span class="token operator">=</span>8888

a1.sinks.s2.type<span class="token operator">=</span>avro
a1.sinks.s2.hostname<span class="token operator">=</span>node3
a1.sinks.s2.port<span class="token operator">=</span>8888

<span class="token comment" spellcheck="true">#配置sink组以及sink处理器运行</span>
a1.sinkgroups <span class="token operator">=</span> g1
a1.sinkgroups.g1.sinks <span class="token operator">=</span> s1 s2
a1.sinkgroups.g1.processor.type <span class="token operator">=</span> load_balance
a1.sinkgroups.g1.processor.backoff <span class="token operator">=</span> <span class="token boolean">true</span>
<span class="token comment" spellcheck="true">#参数可选round_robin（轮询）或者random（随机）</span>
a1.sinkgroups.g1.processor.selector <span class="token operator">=</span> round_robin

<span class="token comment" spellcheck="true">#绑定</span>
a1.sources.r1.channels<span class="token operator">=</span>c1
a1.sinks.s1.channel<span class="token operator">=</span>c1
a1.sinks.s2.channel<span class="token operator">=</span>c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）flume2和flume3的配置：两个配置是一样的.flume-flume-console2，flume-flume-console1</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 配置Agent a1的组件</span>
a1.sources<span class="token operator">=</span>r1
a1.channels<span class="token operator">=</span>c1
a1.sinks<span class="token operator">=</span>s1
<span class="token comment" spellcheck="true"># 配置a1的source</span>
a1.sources.r1.type<span class="token operator">=</span>avro
a1.sources.r1.bind<span class="token operator">=</span>0.0.0.0
a1.sources.r1.port<span class="token operator">=</span>8888
<span class="token comment" spellcheck="true"># 配置a1的channel</span>
a1.channels.c1.type<span class="token operator">=</span>memory
<span class="token comment" spellcheck="true"># 配置a1的sink</span>
a1.sinks.s1.type<span class="token operator">=</span>logger
<span class="token comment" spellcheck="true"># 绑定</span>
a1.sources.r1.channels<span class="token operator">=</span>c1
a1.sinks.s1.channel<span class="token operator">=</span>c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）执行配置文件</p><p>分别开启对应配置文件：flume-flume-console2，flume-flume-console1，flume-netcat-flume。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group2/flume-flume-console2.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console
<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group2/flume-flume-console1.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console
<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group2/flume-netcat-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）使用netcat工具向本机的44444端口发送内容</p><pre class="line-numbers language-bash"><code class="language-bash">$ nc localhost 44444<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（7）查看Flume2及Flume3的控制台打印日志</p><h3 id="4-4-故障转移"><a href="#4-4-故障转移" class="headerlink" title="4.4 故障转移"></a>4.4 故障转移</h3><p>1）案例需求</p><p>使用Flume1监控一个端口，其sink组中的sink分别对接Flume2和Flume3，采用FailoverSinkProcessor，实现故障转移的功能。</p><p><strong>2）需求分析</strong></p><p><img src="/2020/11/15/bigdata-flume2-framework/1637067455399.png" alt="1637067455399"></p><p><img src="/2020/11/15/bigdata-flume2-framework/1637116934865.png" alt="1637116934865">3）实现步骤</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group2文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group2/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-netcat-flume.conf</p><p>配置1个netcat source和1个channel、1个sink group（2个sink），分别输送给flume-flume-console1和flume-flume-console2。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-netcat-flume.conf
<span class="token comment" spellcheck="true">#添加如下内容</span>
<span class="token comment" spellcheck="true"># Name the components on this agent</span>
a1.sources <span class="token operator">=</span> r1
a1.channels <span class="token operator">=</span> c1
a1.sinkgroups <span class="token operator">=</span> g1
a1.sinks <span class="token operator">=</span> k1 k2
<span class="token comment" spellcheck="true"># Describe/configure the source</span>
a1.sources.r1.type <span class="token operator">=</span> netcat
a1.sources.r1.bind <span class="token operator">=</span> localhost
a1.sources.r1.port <span class="token operator">=</span> 44444
<span class="token comment" spellcheck="true">#设置sinkgroups processor为failover</span>
a1.sinkgroups.g1.processor.type <span class="token operator">=</span> failover
<span class="token comment" spellcheck="true">#两个sink，k1与k2,其中2个优先级是5和10</span>
a1.sinkgroups.g1.processor.priority.k1 <span class="token operator">=</span> 5
a1.sinkgroups.g1.processor.priority.k2 <span class="token operator">=</span> 10
<span class="token comment" spellcheck="true">#failover time的上限可以通过maxpenalty 属性来进行设置默认10s。</span>
a1.sinkgroups.g1.processor.maxpenalty <span class="token operator">=</span> 10000
<span class="token comment" spellcheck="true"># Describe the sink</span>
a1.sinks.k1.type <span class="token operator">=</span> avro
a1.sinks.k1.hostname <span class="token operator">=</span> hadoop102
a1.sinks.k1.port <span class="token operator">=</span> 4141
a1.sinks.k2.type <span class="token operator">=</span> avro
a1.sinks.k2.hostname <span class="token operator">=</span> hadoop102
a1.sinks.k2.port <span class="token operator">=</span> 4142
<span class="token comment" spellcheck="true"># Describe the channel</span>
a1.channels.c1.type <span class="token operator">=</span> memory
a1.channels.c1.capacity <span class="token operator">=</span> 1000
a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>
a1.sources.r1.channels <span class="token operator">=</span> c1
a1.sinkgroups.g1.sinks <span class="token operator">=</span> k1 k2
a1.sinks.k1.channel <span class="token operator">=</span> c1
a1.sinks.k2.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）创建flume-flume-console1.conf</p><p>配置上级Flume输出的Source，输出是到本地控制台。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-flume-console1.conf

<span class="token comment" spellcheck="true">#添加如下内容</span>
<span class="token comment" spellcheck="true"># Name the components on this agent</span>
a2.sources <span class="token operator">=</span> r1
a2.sinks <span class="token operator">=</span> k1
a2.channels <span class="token operator">=</span> c1
<span class="token comment" spellcheck="true"># Describe/configure the source</span>
a2.sources.r1.type <span class="token operator">=</span> avro
a2.sources.r1.bind <span class="token operator">=</span> hadoop102
a2.sources.r1.port <span class="token operator">=</span> 4141
<span class="token comment" spellcheck="true"># Describe the sink</span>
a2.sinks.k1.type <span class="token operator">=</span> logger
<span class="token comment" spellcheck="true"># Describe the channel</span>
a2.channels.c1.type <span class="token operator">=</span> memory
a2.channels.c1.capacity <span class="token operator">=</span> 1000
a2.channels.c1.transactionCapacity <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>
a2.sources.r1.channels <span class="token operator">=</span> c1
a2.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）创建flume-flume-console2.conf</p><p>配置上级Flume输出的Source，输出是到本地控制台。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-flume-console2.conf
添加如下内容
<span class="token comment" spellcheck="true"># Name the components on this agent</span>
a3.sources <span class="token operator">=</span> r1
a3.sinks <span class="token operator">=</span> k1
a3.channels <span class="token operator">=</span> c2
<span class="token comment" spellcheck="true"># Describe/configure the source</span>
a3.sources.r1.type <span class="token operator">=</span> avro
a3.sources.r1.bind <span class="token operator">=</span> hadoop102
a3.sources.r1.port <span class="token operator">=</span> 4142
<span class="token comment" spellcheck="true"># Describe the sink</span>
a3.sinks.k1.type <span class="token operator">=</span> logger
<span class="token comment" spellcheck="true"># Describe the channel</span>
a3.channels.c2.type <span class="token operator">=</span> memory
a3.channels.c2.capacity <span class="token operator">=</span> 1000
a3.channels.c2.transactionCapacity <span class="token operator">=</span> 100
<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>
a3.sources.r1.channels <span class="token operator">=</span> c2
a3.sinks.k1.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）执行配置文件</p><p>分别开启对应配置文件：flume-flume-console2，flume-flume-console1，flume-netcat-flume。</p><pre><code>[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group2/flume-flume-console2.conf -Dflume.root.logger=INFO,console
[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group2/flume-flume-console1.conf -Dflume.root.logger=INFO,console
[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group2/flume-netcat-flume.conf</code></pre><p>（6）使用netcat工具向本机的44444端口发送内容</p><pre><code>$ nc localhost 44444</code></pre><p>（7）查看Flume2及Flume3的控制台打印日志</p><p><strong>因为k1的优先级是5，K2是10因此当K2正常运行的时候，是发送到K2的</strong>。</p><p>（8）将Flume2 kill，观察Flume3的控制台打印情况。</p><p>我们发现源代理发生事件到K2失败，然后他将K2放入到failover list（故障列表）</p><p>因为K1还是正常运行的，因此这个时候他会接收到数据。</p><p>注：使用jps -ml查看Flume进程。</p><h3 id="4-5聚合"><a href="#4-5聚合" class="headerlink" title="4.5聚合"></a>4.5聚合</h3><p>1）案例需求：</p><p>hadoop102上的Flume-1监控文件/opt/module/group.log，</p><p>hadoop103上的Flume-2监控某一个端口的数据流，</p><p>Flume-1与Flume-2将数据发送给hadoop104上的Flume-3，Flume-3将最终数据打印到控制台。</p><p>2）需求分析</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image008.png" alt="img"></strong></p><p>3）实现步骤：</p><p>（1）准备工作</p><p>分发Flume</p><p>[molly@hadoop102 module]$ xsync flume</p><p>在hadoop102、hadoop103以及hadoop104的/opt/module/flume/job目录下创建一个group3文件夹。</p><p>[molly@hadoop102 job]$ mkdir group3</p><p>[molly@hadoop103 job]$ mkdir group3</p><p>[molly@hadoop104 job]$ mkdir group3</p><p>（2）创建flume1-logger-flume.conf</p><p>配置Source用于监控hive.log文件，配置Sink输出数据到下一级Flume。</p><p>在hadoop102上编辑配置文件</p><p>[molly@hadoop102 group3]$ vim flume1-logger-flume.conf</p><p>添加如下内容</p><p># Name the components on this agent</p><p>a1.sources = r1</p><p>a1.sinks = k1</p><p>a1.channels = c1</p><p># Describe/configure the source</p><p>a1.sources.r1.type = exec</p><p>a1.sources.r1.command = tail -F /opt/module/group.log</p><p>a1.sources.r1.shell = /bin/bash -c</p><p># Describe the sink</p><p>a1.sinks.k1.type = avro</p><p>a1.sinks.k1.hostname = hadoop104</p><p>a1.sinks.k1.port = 4141</p><p># Describe the channel</p><p>a1.channels.c1.type = memory</p><p>a1.channels.c1.capacity = 1000</p><p>a1.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a1.sources.r1.channels = c1</p><p>a1.sinks.k1.channel = c1</p><p>（3）创建flume2-netcat-flume.conf</p><p>配置Source监控端口44444数据流，配置Sink数据到下一级Flume：</p><p>在hadoop103上编辑配置文件</p><p>[molly@hadoop102 group3]$ vim flume2-netcat-flume.conf</p><p>添加如下内容</p><p># Name the components on this agent</p><p>a2.sources = r1</p><p>a2.sinks = k1</p><p>a2.channels = c1</p><p># Describe/configure the source</p><p>a2.sources.r1.type = netcat</p><p>a2.sources.r1.bind = hadoop103</p><p>a2.sources.r1.port = 44444</p><p># Describe the sink</p><p>a2.sinks.k1.type = avro</p><p>a2.sinks.k1.hostname = hadoop104</p><p>a2.sinks.k1.port = 4141</p><p># Use a channel which buffers events in memory</p><p>a2.channels.c1.type = memory</p><p>a2.channels.c1.capacity = 1000</p><p>a2.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a2.sources.r1.channels = c1</p><p>a2.sinks.k1.channel = c1</p><p>（4）创建flume3-flume-logger.conf</p><p>配置source用于接收flume1与flume2发送过来的数据流，最终合并后sink到控制台。</p><p>在hadoop104上编辑配置文件</p><p>[molly@hadoop104 group3]$ touch flume3-flume-logger.conf</p><p>[molly@hadoop104 group3]$ vim flume3-flume-logger.conf</p><p>添加如下内容</p><p># Name the components on this agent</p><p>a3.sources = r1</p><p>a3.sinks = k1</p><p>a3.channels = c1</p><p># Describe/configure the source</p><p>a3.sources.r1.type = avro</p><p>a3.sources.r1.bind = hadoop104</p><p>a3.sources.r1.port = 4141</p><p># Describe the sink</p><p># Describe the sink</p><p>a3.sinks.k1.type = logger</p><p># Describe the channel</p><p>a3.channels.c1.type = memory</p><p>a3.channels.c1.capacity = 1000</p><p>a3.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a3.sources.r1.channels = c1</p><p>a3.sinks.k1.channel = c1</p><p>（5）执行配置文件</p><p>分别开启对应配置文件：flume3-flume-logger.conf，flume2-netcat-flume.conf，flume1-logger-flume.conf。</p><p>[molly@hadoop104 flume]$ bin/flume-ng agent –conf conf/ –name a3 –conf-file job/group3/flume3-flume-logger.conf -Dflume.root.logger=INFO,console</p><p>[molly@hadoop102 flume]$ bin/flume-ng agent –conf conf/ –name a2 –conf-file job/group3/flume1-logger-flume.conf</p><p>[molly@hadoop103 flume]$ bin/flume-ng agent –conf conf/ –name a1 –conf-file job/group3/flume2-netcat-flume.conf</p><p>（6）在hadoop103上向/opt/module目录下的group.log追加内容</p><p>[molly@hadoop103 module]$ echo ‘hello’ &gt; group.log</p><p>（7）在hadoop102上向44444端口发送数据</p><p>[molly@hadoop102 flume]$ telnet hadoop102 44444</p><p>（8）检查hadoop104上数据</p><p><strong><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image010.png" alt="1528770881(bigdata-flume2-framework/clip_image010.png)"></strong></p><link href="//src.wangriyu.wang/lib/Aplayer/APlayer.min.css" rel="stylesheet"><script src="//src.wangriyu.wang/lib/Aplayer/APlayer.min.js"></script><div id="aplayer"></div><script src="/js/player.js"></script></div></div><div class="copyright"><p><span>本文标题:</span><a href="/2020/11/15/bigdata-flume2-framework/">flume学习笔记（二） flum事务和部署架构解析</a></p><p><span>文章作者:</span><a href="/" title="回到主页">m01ly</a></p><p><span>发布时间:</span>2020-11-15, 16:46:51</p><p><span>最后更新:</span>2021-11-17, 14:30:23</p><p><span>原始链接:</span><a class="post-url" href="/2020/11/15/bigdata-flume2-framework/" title="flume学习笔记（二） flum事务和部署架构解析">https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/</a></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target="_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。</p></div><nav id="article-nav"><div id="article-nav-newer" class="article-nav-title"><a href="/2020/11/16/bigdata-kafka2-framework/">kafka学习笔记（二） kafka框架深入</a></div><div id="article-nav-older" class="article-nav-title"><a href="/2020/11/15/bigdata-flume1-setup/">flume学习笔记（一） flume搭建</a></div></nav></article><div id="toc" class="toc-article"><strong class="toc-title">文章目录</strong><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Flume%E4%BA%8B%E5%8A%A1"><span class="toc-text">1 Flume事务</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-Put%E4%BA%8B%E5%8A%A1%E6%B5%81%E7%A8%8B"><span class="toc-text">1.1 Put事务流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-Take%E4%BA%8B%E5%8A%A1%E6%B5%81%E7%A8%8B"><span class="toc-text">1.2 Take事务流程:</span></a></li></ol></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Flume-Agent%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86"><span class="toc-text">2 Flume Agent内部原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Flume%E6%8B%93%E6%89%91%E7%BB%93%E6%9E%84"><span class="toc-text">3 Flume拓扑结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E7%AE%80%E5%8D%95%E4%B8%B2%E8%81%94"><span class="toc-text">3.1 简单串联</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%A4%8D%E5%88%B6%E5%92%8C%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8"><span class="toc-text">3.2 复制和多路复用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%92%8C%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="toc-text">3.3 负载均衡和故障转移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E8%81%9A%E5%90%88"><span class="toc-text">3.4 聚合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Flume%E5%BC%80%E5%8F%91%E6%A1%88%E4%BE%8B"><span class="toc-text">4 Flume开发案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%A4%8D%E5%88%B6"><span class="toc-text">4.1 复制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-%E8%87%AA%E5%AE%9A%E4%B9%89Interceptor"><span class="toc-text">4.2 多路复用+自定义Interceptor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1"><span class="toc-text">4.3 负载均衡</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="toc-text">4.4 故障转移</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5%E8%81%9A%E5%90%88"><span class="toc-text">4.5聚合</span></a></li></ol></li></div><style>.left-col .switch-area,.left-col .switch-btn{display:none}.toc-level-6 i,.toc-level-6 ol{display:none!important}</style><input type="button" id="tocButton" value="隐藏目录" title="点击按钮隐藏或者显示文章目录"><script>yiliaConfig.toc=["隐藏目录","显示目录",!0],$(".left-col").is(":hidden")&&$("#tocButton").attr("value",yiliaConfig.toc[1])</script><div class="share"><link rel="stylesheet" type="text/css" href="/share/iconfont.css"><link rel="stylesheet" href="/share/spongebob.min.css" type="text/css" media="all"><div class="social_share"><ul id="social_list" class="social_icon_list"></ul></div><script>var shareConfig={title:"flume学习笔记（二） flum事务和部署架构解析",url:window.location.href,author:"m01ly",img:"https:/img/avatar.jpg"}</script><script src="/share/qrcode.min.js"></script><script src="/share/spongebob.min.js"></script></div><section id="comments" style="margin:2em;padding:2em;background:rgba(255,255,255,.5)"><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script><div id="gitalk-container"></div><script type="text/javascript">var gitalk=new Gitalk({clientID:"41a199ade404435645c4",clientSecret:"1de34fbb95212de986a29fea6d6f22bb57b2d473",repo:"m01ly.github.io",owner:"m01ly",admin:["m01ly"],id:window.location.pathname});gitalk.render("gitalk-container")</script></section><div class="scroll" id="post-nav-button"><a href="/2020/11/16/bigdata-kafka2-framework/" title="上一篇: kafka学习笔记（二） kafka框架深入"><i class="fa fa-angle-left"></i> </a><a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a> <a href="/2020/11/15/bigdata-flume1-setup/" title="下一篇: flume学习笔记（一） flume搭建"><i class="fa fa-angle-right"></i></a></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/01/04/pt-docker-escape/">docker逃逸常用方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/23/security-tools-kubebench/">kube-bench工具使用--</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/21/security-cve-recurrent-CVE-2019-5736/">Docker逃逸漏洞复现（CVE-2019-5736）</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/20/security-tools-kubehunter/">kube-hunter工具使用--</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/17/security-tools-kubesploit/">kubesploit工具使用--一个针对容器化环境的跨平台后渗透利用工具</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/12/07/security-tools/">security-tools</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/28/scan-nessus-compliance/">nessus扫描合规性</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/22/cert-letsencrypt/">证书管理工具之letsencrypt</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/07/06/htps-recommend/">安全的TLS协议</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/07/leetcode-slidewindow/">滑动窗口相关题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/24/burpsuite-develop-detect-nginx/">开发burpsuite插件-识别nginx版本并列出已知CVE</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/21/burpsuite-develop/">从0开发burpsuite插件（Java）</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/26/machine-learning-classify-knn/">机器学习算法之KNN</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/07/openvas-develop/">openvas插件开发</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/30/pt-antSword/">渗透测试工具之蚁剑</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/03/11/linux-disk/">centos7把/mnt空间合并到/(根目录)</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/02/19/install-guide-elk-filebeats/">elk笔记三--利用elk+filebeat搭建SIEM系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/02/18/linux-jdk8/">linux安装jdk1.8</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/01/21/esc-DefectDojo/">DefectDojo安装与使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/01/bigdata-zookeeper3-API/">Zookeeper学习笔记（三） API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/01/bigdata-zookeeper2-framework/">Zookeeper学习笔记（二） 架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/01/bigdata-zookeeper1-setup/">Zookeeper学习笔记（一） 搭建教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/29/bigdata-Spark2-framework/">Spark学习笔记（二） 架构解析和RDD编程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/29/bigdata-Spark1-setup/">Spark学习笔记（一） 搭建Spark</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/bigdata-HBase2-framework/">HBase学习笔记（二） HBase架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/bigdata-HBase4-phoenix/">HBase学习笔记（四） HBase整合phoenix和Hive</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/bigdata-HBase3-API/">HBase学习笔记（三） HBase的API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/25/bigdata-HBase1-setup/">HBase学习笔记（一） 安装教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/23/bigdata-datacollect1-userbehavior/">大数据实践（一）数仓采集项目</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/22/bigdata-sqoop/">sqoop安装教程</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/18/bigdata-kafka4-test/">kafka学习笔记（四） kafka面试集锦</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/17/bigdata-kafka3-API/">kafka学习笔记（三） kafka的API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/bigdata-flume3-monitor/">flume学习笔记（三） flum数据流监控及面试题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/16/bigdata-kafka2-framework/">kafka学习笔记（二） kafka框架深入</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-flume2-framework/">flume学习笔记（二） flum事务和部署架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-flume1-setup/">flume学习笔记（一） flume搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive3/">Hive学习笔记（三） Hive的分区表和分桶表</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive5-example/">Hive学习笔记（五） Hive实战</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive4-optimize/">Hive学习笔记（四） Hive的企业级调优</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-hive2/">Hive学习笔记（二） Hive对数据基本操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/15/bigdata-kafka1-setup/">kafka学习笔记（一） kafka搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/14/bigdata-hive1/">Hive学习笔记（一） Hive安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-mapreduce2-framework/">Hadoop 教程（五）mapreduce架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-hdfs1/">Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-hdfs/">Hadoop 教程（一）hadoop介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-yarn-framework/">Hadoop 教程（六）yarn-架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-mapreduce1-setup/">Hadoop 教程（四）mapreduce介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/11/12/bigdata-hdfs3-framework/">Hadoop 教程（三）hdfs-架构解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/10/cipher-certificate-format/">证书的各种格式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/docker-guide/">docker使用大全</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/linux-cmd/">linux命令大全</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-metosploitInAliyun/">在阿里云主机反弹metosploit</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-info-collection/">信息收集</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/28/pt-tools/">最佳网络安全和黑客软件</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/18/mobilesecurity-experience/">小白如何在三天一步步逆向app，找到私钥</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/elk-login/">elk笔记二--通过X-Pack权限控制设置elk登录</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-centosInvm/">vm 安装centos 7教程详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/writeup-sqli-labs/">writeup-sqli-labs</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-elk-suricata/">elk笔记一---suricata+elk搭建入侵检测系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/11/install-guide-suricata/">centos7中安装suricata</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/10/pt-sqlbypass/">sql关键词绕过</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/04/pt-portinfo/">常见端口说明和攻击汇总</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/03/m01ly-wiki/">m01ly-wiki</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/03/htps-attack-heartbleed/">TLS攻击之心脏滴血</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/09/01/htps-attack-paddingoracle/">TLS 攻击之POODLE</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/31/blockcipher-padding/">分组密码--填充模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/31/blockcipher-operation-mode/">分组密码--工作模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/hexo-guide/">Hexo踩坑</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/scan-awvs-nessus/">AWVS和Nessus镜像安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/scan-zap/">ZAP的安装和使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/pt-tiquan/">提权</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/htps-tools/">TLS安全检测小工具</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/htps-build/">搭建https网站</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/08/26/apple/">竟然有人能把https/TLS1.2协议讲的这么详细</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/26/leetcode-binary/">二分查找相关的题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/16/leetcode-stackandqueue/">栈和队列相关题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/07/leetcode-list/">链表相关题目</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/06/leetcode-daily/">leetcode每日一题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/29/leetcode-sort/">排序算法</a></li></ul><script></script></div><footer id="footer"><div class="outer"><div id="footer-info"><div class="footer-left"><i class="fa fa-copyright"></i> 2017-2022 冀-18010769-1</div><div class="visit"><span id="busuanzi_container_site_pv" style="display:none"><span id="site-visit" title="本站到访人数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span> </span></span><span>| </span><span id="busuanzi_container_page_pv" style="display:none"><span id="page-visit" title="本页访问次数"><i class="fa fa-eye" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span></span></span></div><div class="footer-right"><i class="fa fa-heart"></i><a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架"> Hexo</a> Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a></div></div></div></footer></div><script type="application/javascript">var leftWidth,hide=!1;$(".hide-left-col").click(function(){hide=hide?($(".left-col").css("width",leftWidth),$(".left-col .intrude-less").fadeIn(200),$("#tocButton").fadeIn(200),"block"===$("#switch-btn").css("display")&&"block"===$("#switch-area").css("display")||$("#toc").fadeIn(200),$(".hide-left-col").css("left",leftWidth).html('<i class="fa fa-angle-double-left"></i>'),$(".mid-col").css("left",leftWidth),$("#post-nav-button").css("left",leftWidth),$("#post-nav-button > a:nth-child(2)").css("display","block"),!1):(leftWidth=$(".left-col")[0].style.width,$(".left-col").css("width",0),$(".left-col .intrude-less").fadeOut(200),$("#toc").fadeOut(100),$("#tocButton").fadeOut(100),$(".hide-left-col").css("left",0).html('<i class="fa fa-angle-double-right"></i>'),$(".mid-col").css("left",0),$("#post-nav-button").css("left",0),$("#post-nav-button > a:nth-child(2)").css("display","none"),$(".post-list").is(":visible")&&($("#post-nav-button .fa-bars,#post-nav-button .fa-times").toggle(),$(".post-list").toggle()),!0)})</script><script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.3.5/require.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax:{inlineMath:[["$$","$$"],["$","$"],["\\(","\\)"]],processEscapes:!0,skipTags:["script","noscript","style","textarea","pre","code"]}}),MathJax.Hub.Queue(function(){var a,e=MathJax.Hub.getAllJax();for(a=0;a<e.length;a+=1)e[a].SourceElement().parentNode.className+=" has-jax"})</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script><div class="scroll" id="scroll"><a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a> <a href="#comments" title="查看评论"><i class="fa fa-comments-o"></i></a> <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a></div><script>var oOpenInNew={post:".copyright a[href]",friends:"#js-friends a",socail:".social a"};for(var x in oOpenInNew)$(oOpenInNew[x]).attr("target","_blank")</script><script>var titleTime,originTitle=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="(つェ⊂)"+originTitle,clearTimeout(titleTime)):(document.title="(*´∇｀*)~ "+originTitle,titleTime=setTimeout(function(){document.title=originTitle},2e3))})</script><script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><link href="//cdn.bootcss.com/aos/2.2.0/aos.css" rel="stylesheet"><script type="text/javascript">AOS.init({easing:"ease-out-back",once:!0})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"live2d_models/live2d-widget-model-izumi"},"display":{"position":"right","width":100,"height":200,"hOffset":-50,"vOffset":-85},"mobile":{"show":false},"react":{"opacityDefault":0.9,"opacityOnHover":0.3},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false});</script></body></html>